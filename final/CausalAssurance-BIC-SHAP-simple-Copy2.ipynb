{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes \n",
    "### Required installing Oracle JAVA 8 to get javabridge installed\n",
    "### Then, I was able to install py-causal from https://bd2kccd.github.io/docs/py-causal/\n",
    "### GFCI is slower than RFCI, but more accurate (SPIRTES), GFCI and RFCI account for unobserved variables, FGES assumes no unobserved variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure Learning Performance Guarantees If the assumptions in the previous section hold, then in the large sample limit, the CBN structure output by GFCId will contain an edge of one of four kinds between Xand Y   if and only if Xand Yare not independent conditional on any subset of the other measured variables of less than or equal to a specified size. In addition, there is (1) an arc X->Y   if and only if Xdirectly or indirectly causes Y, and Y   does not directly or indirectly cause X; (2) an edge X <-->Y   if and only if X   is not a direct or indirect cause of Yand Y   is not a direct or indirect cause of X(which can only occur if there are latent confounders of Xand some other variable or Yand some other variable; (3) an edge Xo->Y   only if Yis not a direct or indirect cause of X, but Xmay or may not be an indirect cause of Y; (4) an edge X o–o Y   indicates that Xand Y   are dependent no matter what subset of observed variables is conditioned on, but contains no orientation information (X   may be a direct or indirect cause of Y, and Ymay be an indirect cause of X, or there may be a latent common cause of Xand Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying some various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, \\\n",
    "                        Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "import keras.optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "# select your GPU Here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #Comment this line out if you want all GPUS (2 hehe)\n",
    "\n",
    "# python full-display web browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def get_model(dense, dropouts, inputs):\n",
    "    # dense is an ordered list of the number of dense neurons like [1024, 2048, 1024]\n",
    "    # dropouts is an ordered list of the dropout masks like [0.2, 0.3, 0.4]\n",
    "    inputs = keras.Input(shape = (inputs,))\n",
    "\n",
    "    x = keras.layers.Dense(dense[0], activation = 'relu')(inputs)\n",
    "    x = keras.layers.Dropout(dropouts[0])(x, training=True)\n",
    "    for den, drop in zip(dense[1:], dropouts[1:]):\n",
    "        x = keras.layers.Dense(den, activation = 'relu')(x)\n",
    "        x = keras.layers.Dropout(drop)(x, training=True)\n",
    "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256]] ['temp/f0', 'temp/f1', 'temp/f2', 'temp/f3', 'temp/f4', 'temp/f5', 'temp/f6', 'temp/f7', 'temp/f8', 'temp/f9', 'temp/f10', 'temp/f11', 'temp/f12', 'temp/f13', 'temp/f14', 'temp/f15', 'temp/f16', 'temp/f17', 'temp/f18', 'temp/f19', 'temp/f20', 'temp/f21', 'temp/f22', 'temp/f23', 'temp/f24', 'temp/f25', 'temp/f26', 'temp/f27', 'temp/f28', 'temp/f29', 'temp/f30', 'temp/f31', 'temp/f32', 'temp/f33', 'temp/f34', 'temp/f35', 'temp/f36', 'temp/f37', 'temp/f38', 'temp/f39', 'temp/f40', 'temp/f41', 'temp/f42', 'temp/f43', 'temp/f44', 'temp/f45', 'temp/f46', 'temp/f47', 'temp/f48', 'temp/f49', 'temp/f50', 'temp/f51', 'temp/f52', 'temp/f53', 'temp/f54', 'temp/f55', 'temp/f56', 'temp/f57', 'temp/f58', 'temp/f59', 'temp/f60', 'temp/f61', 'temp/f62', 'temp/f63', 'temp/f64', 'temp/f65', 'temp/f66', 'temp/f67', 'temp/f68', 'temp/f69', 'temp/f70', 'temp/f71', 'temp/f72', 'temp/f73', 'temp/f74', 'temp/f75', 'temp/f76', 'temp/f77', 'temp/f78', 'temp/f79', 'temp/f80', 'temp/f81', 'temp/f82', 'temp/f83', 'temp/f84', 'temp/f85', 'temp/f86', 'temp/f87', 'temp/f88', 'temp/f89', 'temp/f90', 'temp/f91', 'temp/f92', 'temp/f93', 'temp/f94', 'temp/f95', 'temp/f96', 'temp/f97', 'temp/f98', 'temp/f99', 'temp/f100', 'temp/f101', 'temp/f102', 'temp/f103', 'temp/f104', 'temp/f105', 'temp/f106', 'temp/f107', 'temp/f108', 'temp/f109', 'temp/f110', 'temp/f111', 'temp/f112', 'temp/f113', 'temp/f114', 'temp/f115', 'temp/f116', 'temp/f117', 'temp/f118', 'temp/f119', 'temp/f120', 'temp/f121', 'temp/f122', 'temp/f123', 'temp/f124', 'temp/f125', 'temp/f126', 'temp/f127', 'temp/f128', 'temp/f129', 'temp/f130', 'temp/f131', 'temp/f132', 'temp/f133', 'temp/f134', 'temp/f135', 'temp/f136', 'temp/f137', 'temp/f138', 'temp/f139', 'temp/f140', 'temp/f141', 'temp/f142', 'temp/f143', 'temp/f144', 'temp/f145', 'temp/f146', 'temp/f147', 'temp/f148', 'temp/f149', 'temp/f150', 'temp/f151', 'temp/f152', 'temp/f153', 'temp/f154', 'temp/f155', 'temp/f156', 'temp/f157', 'temp/f158', 'temp/f159', 'temp/f160', 'temp/f161', 'temp/f162', 'temp/f163', 'temp/f164', 'temp/f165', 'temp/f166', 'temp/f167', 'temp/f168', 'temp/f169', 'temp/f170', 'temp/f171', 'temp/f172', 'temp/f173', 'temp/f174', 'temp/f175', 'temp/f176', 'temp/f177', 'temp/f178', 'temp/f179', 'temp/f180', 'temp/f181', 'temp/f182', 'temp/f183', 'temp/f184', 'temp/f185', 'temp/f186', 'temp/f187', 'temp/f188', 'temp/f189', 'temp/f190', 'temp/f191', 'temp/f192', 'temp/f193', 'temp/f194', 'temp/f195', 'temp/f196', 'temp/f197', 'temp/f198', 'temp/f199']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from pycausal import search as s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def discrete_gauss(low, high, samples, std = 20):\n",
    "    x = np.arange(low, high)\n",
    "    xU, xL = x + 0.5, x - 0.5 \n",
    "    prob = ss.norm.cdf(xU, scale = std) - ss.norm.cdf(xL, scale = std)\n",
    "    prob = prob / prob.sum() #normalize the probabilities so their sum is 1\n",
    "    nums = np.random.choice(x, size = samples, p = prob)\n",
    "    return nums\n",
    "\n",
    "\n",
    "\n",
    "def bar_plot(x_ax, val1, val1std, val2, val2std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ## the data\n",
    "    N = len(x_ax)\n",
    "\n",
    "    ## necessary variables\n",
    "    ind = np.arange(N)                # the x locations for the groups\n",
    "    width = 0.35                      # the width of the bars\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ## the bars\n",
    "    rects1 = ax.bar(ind, val1, width,\n",
    "                    color='gray',\n",
    "                    yerr=val1std,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "\n",
    "    rects2 = ax.bar(ind+width, val2, width,\n",
    "                        color='blue',\n",
    "                        #yerr=val2std,\n",
    "                        error_kw=dict(elinewidth=2,ecolor='gray'))\n",
    "\n",
    "    # axes and labels\n",
    "    ax.set_xlim(-width,len(ind)+width)\n",
    "    #ax.set_ylim(0,45)\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_title('')\n",
    "    plt.xticks(ind + width / 2, x_ax, rotation=75, size = 14)\n",
    "    ## add a legend\n",
    "    ax.legend( (rects1[0], rects2[0]), ('Accuracy', '% Violations') )\n",
    "    fig.savefig(\"violations.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def gen_data(mean = 0, var = 1, SIZE = 20000):\n",
    "    a = np.random.normal(mean, var, SIZE)\n",
    "    b = 1.1* a + np.random.normal(mean, var, SIZE)\n",
    "    c =  0.5* b + np.random.normal(mean, var, SIZE)\n",
    "    \n",
    "    e = np.random.normal(mean, var, SIZE)\n",
    "    \n",
    "    d = e + b + np.random.normal(mean, var, SIZE)\n",
    "    \n",
    "    f= b +  d + np.random.normal(mean, var, SIZE)\n",
    "    g = f + np.random.normal(mean,var, SIZE)\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "\n",
    "\n",
    "def gen_data(mean = 0, var = 1, SIZE = 20000):\n",
    "    a = np.random.normal(mean, var, SIZE)\n",
    "    b = a + np.random.normal(mean, var, SIZE)\n",
    "    c =  a + b + np.random.normal(mean, var, SIZE)\n",
    "  \n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c})\n",
    "\n",
    "\n",
    "def get_CG(df, tetrad):\n",
    "    tetrad.run(algoId = 'gfci', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "           structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "           completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "    #tetrad.run(algoId = 'fges-mb', targetName = 'g', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "    #       structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "    #       completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def get_MB(graph, var, pc):\n",
    "    parents = set()\n",
    "    children = set()\n",
    "    for i in pc.extractTetradGraphEdges(graph):\n",
    "        if i[-1] == var and i[3:5] == '->':\n",
    "            parents.add(i[0])\n",
    "        if i[0] == var and i[3:5] == '->':\n",
    "            children.add(i[-1])\n",
    "    return parents, children\n",
    "\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from collections import defaultdict\n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '5000M')\n",
    "tetrad = s.tetradrunner()\n",
    "\n",
    "\n",
    "verbosity = 1\n",
    "\n",
    "\n",
    "\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "num_models = 200\n",
    "model_layers = [512, 256]\n",
    "for i in range(num_models):\n",
    "    models.append(model_layers)\n",
    "    model_names.append('temp/f' + str(i))\n",
    "\n",
    "print(models, model_names)\n",
    "\n",
    "inputs = ['a', 'b']\n",
    "target = ['c']\n",
    "df = gen_data()\n",
    "X = df[inputs].values\n",
    "y = df[target].values\n",
    "\n",
    "val_df = gen_data(SIZE = 2000)\n",
    "x_val = df[inputs].values\n",
    "y_val = df[target].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/f0\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 1.1679 - mean_squared_error: 1.1679 - val_loss: 1.0386 - val_mean_squared_error: 1.0386\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03856, saving model to temp/f0\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03856 to 1.02233, saving model to temp/f0\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0242 - mean_squared_error: 1.0242 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02233 to 1.01612, saving model to temp/f0\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0257 - val_mean_squared_error: 1.0257\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01612\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0104 - mean_squared_error: 1.0104 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01612 to 1.01084, saving model to temp/f0\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01084\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0128 - mean_squared_error: 1.0128 - val_loss: 1.0082 - val_mean_squared_error: 1.0082\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01084 to 1.00818, saving model to temp/f0\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0069 - val_mean_squared_error: 1.0069\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00818 to 1.00694, saving model to temp/f0\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00694\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00694\n",
      "Epoch 00010: early stopping\n",
      "temp/f1\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.1557 - mean_squared_error: 1.1557 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02320, saving model to temp/f1\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0258 - mean_squared_error: 1.0258 - val_loss: 1.0293 - val_mean_squared_error: 1.0293\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02320\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0266 - mean_squared_error: 1.0266 - val_loss: 1.0203 - val_mean_squared_error: 1.0203\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02320 to 1.02031, saving model to temp/f1\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02031 to 1.01233, saving model to temp/f1\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0194 - val_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01233\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0126 - mean_squared_error: 1.0126 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01233 to 1.01113, saving model to temp/f1\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0045 - val_mean_squared_error: 1.0045\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01113 to 1.00449, saving model to temp/f1\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0155 - val_mean_squared_error: 1.0155\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00449\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0073 - val_mean_squared_error: 1.0073\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00449\n",
      "Epoch 00009: early stopping\n",
      "temp/f2\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1576 - mean_squared_error: 1.1576 - val_loss: 1.0311 - val_mean_squared_error: 1.0311\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03109, saving model to temp/f2\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03109 to 1.02081, saving model to temp/f2\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0179 - val_mean_squared_error: 1.0179\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02081 to 1.01794, saving model to temp/f2\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01794 to 1.01372, saving model to temp/f2\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0116 - val_mean_squared_error: 1.0116\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01372 to 1.01160, saving model to temp/f2\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 101us/step - loss: 1.0107 - mean_squared_error: 1.0107 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01160\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01160 to 1.00850, saving model to temp/f2\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00850\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0110 - val_mean_squared_error: 1.0110\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00850\n",
      "Epoch 00009: early stopping\n",
      "temp/f3\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1612 - mean_squared_error: 1.1612 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01864, saving model to temp/f3\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01864 to 1.01858, saving model to temp/f3\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01858 to 1.01002, saving model to temp/f3\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01002\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01002\n",
      "Epoch 00005: early stopping\n",
      "temp/f4\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.1594 - mean_squared_error: 1.1594 - val_loss: 1.0220 - val_mean_squared_error: 1.0220\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02197, saving model to temp/f4\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0258 - mean_squared_error: 1.0258 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02197 to 1.02083, saving model to temp/f4\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0179 - val_mean_squared_error: 1.0179\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02083 to 1.01795, saving model to temp/f4\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01795 to 1.00968, saving model to temp/f4\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00968\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00968\n",
      "Epoch 00006: early stopping\n",
      "temp/f5\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.1619 - mean_squared_error: 1.1619 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02661, saving model to temp/f5\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 1.0306 - val_mean_squared_error: 1.0306\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02661\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02661 to 1.01569, saving model to temp/f5\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01569 to 1.01328, saving model to temp/f5\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0134 - val_mean_squared_error: 1.0134\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01328\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01328 to 1.01207, saving model to temp/f5\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01207\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0126 - mean_squared_error: 1.0126 - val_loss: 1.0217 - val_mean_squared_error: 1.0217\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01207\n",
      "Epoch 00008: early stopping\n",
      "temp/f6\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.1553 - mean_squared_error: 1.1553 - val_loss: 1.0396 - val_mean_squared_error: 1.0396\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03959, saving model to temp/f6\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0206 - val_mean_squared_error: 1.0206\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03959 to 1.02055, saving model to temp/f6\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0290 - val_mean_squared_error: 1.0290\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02055\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0278 - val_mean_squared_error: 1.0278\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02055\n",
      "Epoch 00004: early stopping\n",
      "temp/f7\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 1.1592 - mean_squared_error: 1.1592 - val_loss: 1.0262 - val_mean_squared_error: 1.0262\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02618, saving model to temp/f7\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0268 - val_mean_squared_error: 1.0268\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02618\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0262 - mean_squared_error: 1.0262 - val_loss: 1.0287 - val_mean_squared_error: 1.0287\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02618\n",
      "Epoch 00003: early stopping\n",
      "temp/f8\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.1621 - mean_squared_error: 1.1621 - val_loss: 1.0178 - val_mean_squared_error: 1.0178\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01778, saving model to temp/f8\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0206 - mean_squared_error: 1.0206 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01778\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0194 - val_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01778\n",
      "Epoch 00003: early stopping\n",
      "temp/f9\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1610 - mean_squared_error: 1.1610 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02723, saving model to temp/f9\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0270 - mean_squared_error: 1.0270 - val_loss: 1.0224 - val_mean_squared_error: 1.0224\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02723 to 1.02240, saving model to temp/f9\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02240 to 1.01767, saving model to temp/f9\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0213 - val_mean_squared_error: 1.0213\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01767\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01767 to 1.01573, saving model to temp/f9\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0067 - val_mean_squared_error: 1.0067\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01573 to 1.00672, saving model to temp/f9\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00672\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00672\n",
      "Epoch 00008: early stopping\n",
      "temp/f10\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1670 - mean_squared_error: 1.1670 - val_loss: 1.0194 - val_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01942, saving model to temp/f10\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01942 to 1.01728, saving model to temp/f10\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0204 - mean_squared_error: 1.0204 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01728 to 1.00959, saving model to temp/f10\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00959\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0116 - val_mean_squared_error: 1.0116\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00959\n",
      "Epoch 00005: early stopping\n",
      "temp/f11\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1679 - mean_squared_error: 1.1679 - val_loss: 1.0246 - val_mean_squared_error: 1.0246\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02463, saving model to temp/f11\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0256 - mean_squared_error: 1.0256 - val_loss: 1.0143 - val_mean_squared_error: 1.0143\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02463 to 1.01428, saving model to temp/f11\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0233 - val_mean_squared_error: 1.0233\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01428\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01428\n",
      "Epoch 00004: early stopping\n",
      "temp/f12\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.1457 - mean_squared_error: 1.1457 - val_loss: 1.0247 - val_mean_squared_error: 1.0247\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02472, saving model to temp/f12\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0524 - val_mean_squared_error: 1.0524\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02472\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0259 - mean_squared_error: 1.0259 - val_loss: 1.0187 - val_mean_squared_error: 1.0187\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02472 to 1.01866, saving model to temp/f12\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01866 to 1.01538, saving model to temp/f12\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0086 - val_mean_squared_error: 1.0086\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01538 to 1.00863, saving model to temp/f12\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0101 - mean_squared_error: 1.0101 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00863\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0192 - val_mean_squared_error: 1.0192\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00863\n",
      "Epoch 00007: early stopping\n",
      "temp/f13\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1560 - mean_squared_error: 1.1560 - val_loss: 1.0264 - val_mean_squared_error: 1.0264\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02638, saving model to temp/f13\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0206 - mean_squared_error: 1.0206 - val_loss: 1.0179 - val_mean_squared_error: 1.0179\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02638 to 1.01793, saving model to temp/f13\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01793 to 1.01767, saving model to temp/f13\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0079 - val_mean_squared_error: 1.0079\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01767 to 1.00792, saving model to temp/f13\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00792\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00792\n",
      "Epoch 00006: early stopping\n",
      "temp/f14\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.1457 - mean_squared_error: 1.1457 - val_loss: 1.0308 - val_mean_squared_error: 1.0308\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03075, saving model to temp/f14\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03075 to 1.01409, saving model to temp/f14\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0244 - mean_squared_error: 1.0244 - val_loss: 1.0107 - val_mean_squared_error: 1.0107\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01409 to 1.01072, saving model to temp/f14\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01072\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0182 - val_mean_squared_error: 1.0182\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01072\n",
      "Epoch 00005: early stopping\n",
      "temp/f15\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1562 - mean_squared_error: 1.1562 - val_loss: 1.0270 - val_mean_squared_error: 1.0270\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02698, saving model to temp/f15\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02698 to 1.01978, saving model to temp/f15\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0219 - val_mean_squared_error: 1.0219\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01978\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01978 to 1.01746, saving model to temp/f15\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0225 - mean_squared_error: 1.0225 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01746 to 1.01205, saving model to temp/f15\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01205 to 1.01153, saving model to temp/f15\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01153\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0120 - mean_squared_error: 1.0120 - val_loss: 1.0073 - val_mean_squared_error: 1.0073\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01153 to 1.00733, saving model to temp/f15\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0108 - mean_squared_error: 1.0108 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00733\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0098 - mean_squared_error: 1.0098 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00733\n",
      "Epoch 00010: early stopping\n",
      "temp/f16\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 1.1730 - mean_squared_error: 1.1730 - val_loss: 1.0222 - val_mean_squared_error: 1.0222\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02223, saving model to temp/f16\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0249 - mean_squared_error: 1.0249 - val_loss: 1.0258 - val_mean_squared_error: 1.0258\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02223\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0163 - val_mean_squared_error: 1.0163\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02223 to 1.01630, saving model to temp/f16\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0188 - mean_squared_error: 1.0188 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01630 to 1.01587, saving model to temp/f16\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0086 - val_mean_squared_error: 1.0086\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01587 to 1.00862, saving model to temp/f16\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0126 - mean_squared_error: 1.0126 - val_loss: 1.0063 - val_mean_squared_error: 1.0063\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00862 to 1.00634, saving model to temp/f16\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0054 - val_mean_squared_error: 1.0054\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00634 to 1.00544, saving model to temp/f16\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0108 - mean_squared_error: 1.0108 - val_loss: 1.0071 - val_mean_squared_error: 1.0071\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00544\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0130 - mean_squared_error: 1.0130 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00544\n",
      "Epoch 00009: early stopping\n",
      "temp/f17\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1625 - mean_squared_error: 1.1625 - val_loss: 1.0340 - val_mean_squared_error: 1.0340\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03403, saving model to temp/f17\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0239 - mean_squared_error: 1.0239 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03403 to 1.01332, saving model to temp/f17\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0259 - mean_squared_error: 1.0259 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01332 to 1.00972, saving model to temp/f17\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0285 - val_mean_squared_error: 1.0285\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00972\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00972\n",
      "Epoch 00005: early stopping\n",
      "temp/f18\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.1777 - mean_squared_error: 1.1777 - val_loss: 1.0276 - val_mean_squared_error: 1.0276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02764, saving model to temp/f18\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0273 - mean_squared_error: 1.0273 - val_loss: 1.0190 - val_mean_squared_error: 1.0190\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02764 to 1.01900, saving model to temp/f18\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0162 - val_mean_squared_error: 1.0162\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01900 to 1.01620, saving model to temp/f18\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01620\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0134 - mean_squared_error: 1.0134 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01620 to 1.01527, saving model to temp/f18\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0144 - mean_squared_error: 1.0144 - val_loss: 1.0145 - val_mean_squared_error: 1.0145\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01527 to 1.01446, saving model to temp/f18\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0090 - val_mean_squared_error: 1.0090\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01446 to 1.00901, saving model to temp/f18\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00901\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00901\n",
      "Epoch 00009: early stopping\n",
      "temp/f19\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1710 - mean_squared_error: 1.1710 - val_loss: 1.0370 - val_mean_squared_error: 1.0370\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03696, saving model to temp/f19\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03696 to 1.02087, saving model to temp/f19\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0244 - mean_squared_error: 1.0244 - val_loss: 1.0107 - val_mean_squared_error: 1.0107\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02087 to 1.01074, saving model to temp/f19\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01074\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01074\n",
      "Epoch 00005: early stopping\n",
      "temp/f20\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1589 - mean_squared_error: 1.1589 - val_loss: 1.0254 - val_mean_squared_error: 1.0254\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02538, saving model to temp/f20\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02538 to 1.01542, saving model to temp/f20\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01542\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0122 - val_mean_squared_error: 1.0122\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01542 to 1.01219, saving model to temp/f20\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01219 to 1.00796, saving model to temp/f20\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0379 - val_mean_squared_error: 1.0379\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00796\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00796\n",
      "Epoch 00007: early stopping\n",
      "temp/f21\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1770 - mean_squared_error: 1.1770 - val_loss: 1.0372 - val_mean_squared_error: 1.0372\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03723, saving model to temp/f21\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0296 - mean_squared_error: 1.0296 - val_loss: 1.0468 - val_mean_squared_error: 1.0468\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03723\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03723 to 1.01410, saving model to temp/f21\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0156 - mean_squared_error: 1.0156 - val_loss: 1.0402 - val_mean_squared_error: 1.0402\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01410\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0211 - val_mean_squared_error: 1.0211\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01410\n",
      "Epoch 00005: early stopping\n",
      "temp/f22\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1649 - mean_squared_error: 1.1649 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02279, saving model to temp/f22\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0184 - val_mean_squared_error: 1.0184\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02279 to 1.01842, saving model to temp/f22\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01842 to 1.01234, saving model to temp/f22\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01234\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0140 - val_mean_squared_error: 1.0140\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01234\n",
      "Epoch 00005: early stopping\n",
      "temp/f23\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1635 - mean_squared_error: 1.1635 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02279, saving model to temp/f23\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0223 - mean_squared_error: 1.0223 - val_loss: 1.0189 - val_mean_squared_error: 1.0189\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02279 to 1.01894, saving model to temp/f23\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0251 - val_mean_squared_error: 1.0251\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01894\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0110 - mean_squared_error: 1.0110 - val_loss: 1.0143 - val_mean_squared_error: 1.0143\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01894 to 1.01426, saving model to temp/f23\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01426\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01426 to 1.01292, saving model to temp/f23\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0062 - val_mean_squared_error: 1.0062\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01292 to 1.00620, saving model to temp/f23\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0072 - val_mean_squared_error: 1.0072\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00620\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0095 - mean_squared_error: 1.0095 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00620\n",
      "Epoch 00009: early stopping\n",
      "temp/f24\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1529 - mean_squared_error: 1.1529 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02389, saving model to temp/f24\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0214 - mean_squared_error: 1.0214 - val_loss: 1.0227 - val_mean_squared_error: 1.0227\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02389 to 1.02266, saving model to temp/f24\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0099 - val_mean_squared_error: 1.0099\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02266 to 1.00991, saving model to temp/f24\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00991\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.00991 to 1.00955, saving model to temp/f24\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0068 - val_mean_squared_error: 1.0068\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00955 to 1.00677, saving model to temp/f24\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0066 - val_mean_squared_error: 1.0066\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00677 to 1.00662, saving model to temp/f24\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00662\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00662\n",
      "Epoch 00009: early stopping\n",
      "temp/f25\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 1.1733 - mean_squared_error: 1.1733 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02095, saving model to temp/f25\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0299 - mean_squared_error: 1.0299 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02095\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02095 to 1.01743, saving model to temp/f25\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0278 - val_mean_squared_error: 1.0278\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01743\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0169 - val_mean_squared_error: 1.0169\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01743 to 1.01688, saving model to temp/f25\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01688 to 1.01467, saving model to temp/f25\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0083 - val_mean_squared_error: 1.0083\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01467 to 1.00825, saving model to temp/f25\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0041 - val_mean_squared_error: 1.0041\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00825 to 1.00411, saving model to temp/f25\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00411\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0116 - mean_squared_error: 1.0116 - val_loss: 1.0091 - val_mean_squared_error: 1.0091\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00411\n",
      "Epoch 00010: early stopping\n",
      "temp/f26\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 1.1391 - mean_squared_error: 1.1391 - val_loss: 1.0348 - val_mean_squared_error: 1.0348\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03477, saving model to temp/f26\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0265 - mean_squared_error: 1.0265 - val_loss: 1.0205 - val_mean_squared_error: 1.0205\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03477 to 1.02053, saving model to temp/f26\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0118 - mean_squared_error: 1.0118 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02053\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0214 - val_mean_squared_error: 1.0214\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02053\n",
      "Epoch 00004: early stopping\n",
      "temp/f27\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1582 - mean_squared_error: 1.1582 - val_loss: 1.0320 - val_mean_squared_error: 1.0320\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03198, saving model to temp/f27\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0262 - mean_squared_error: 1.0262 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03198 to 1.02371, saving model to temp/f27\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0358 - val_mean_squared_error: 1.0358\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02371\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0220 - mean_squared_error: 1.0220 - val_loss: 1.0250 - val_mean_squared_error: 1.0250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02371\n",
      "Epoch 00004: early stopping\n",
      "temp/f28\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.1461 - mean_squared_error: 1.1461 - val_loss: 1.0468 - val_mean_squared_error: 1.0468\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04683, saving model to temp/f28\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04683 to 1.01640, saving model to temp/f28\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0218 - val_mean_squared_error: 1.0218\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01640\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0190 - val_mean_squared_error: 1.0190\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01640\n",
      "Epoch 00004: early stopping\n",
      "temp/f29\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1626 - mean_squared_error: 1.1626 - val_loss: 1.0297 - val_mean_squared_error: 1.0297\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02965, saving model to temp/f29\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0242 - mean_squared_error: 1.0242 - val_loss: 1.0243 - val_mean_squared_error: 1.0243\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02965 to 1.02428, saving model to temp/f29\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02428 to 1.01329, saving model to temp/f29\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01329\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0156 - mean_squared_error: 1.0156 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01329\n",
      "Epoch 00005: early stopping\n",
      "temp/f30\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.1636 - mean_squared_error: 1.1636 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02227, saving model to temp/f30\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0280 - mean_squared_error: 1.0280 - val_loss: 1.0222 - val_mean_squared_error: 1.0222\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02227 to 1.02220, saving model to temp/f30\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0166 - val_mean_squared_error: 1.0166\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02220 to 1.01659, saving model to temp/f30\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01659 to 1.01145, saving model to temp/f30\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0171 - val_mean_squared_error: 1.0171\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01145\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01145 to 1.00809, saving model to temp/f30\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00809\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 1.0274 - val_mean_squared_error: 1.0274\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00809\n",
      "Epoch 00008: early stopping\n",
      "temp/f31\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1495 - mean_squared_error: 1.1495 - val_loss: 1.0311 - val_mean_squared_error: 1.0311\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03111, saving model to temp/f31\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03111 to 1.01908, saving model to temp/f31\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0144 - val_mean_squared_error: 1.0144\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01908 to 1.01442, saving model to temp/f31\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0208 - mean_squared_error: 1.0208 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01442 to 1.01111, saving model to temp/f31\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01111 to 1.00848, saving model to temp/f31\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0094 - mean_squared_error: 1.0094 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00848\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00848\n",
      "Epoch 00007: early stopping\n",
      "temp/f32\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.1614 - mean_squared_error: 1.1614 - val_loss: 1.0267 - val_mean_squared_error: 1.0267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02674, saving model to temp/f32\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0195 - val_mean_squared_error: 1.0195\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02674 to 1.01951, saving model to temp/f32\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01951 to 1.01772, saving model to temp/f32\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01772 to 1.01270, saving model to temp/f32\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0242 - val_mean_squared_error: 1.0242\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01270\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0107 - val_mean_squared_error: 1.0107\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01270 to 1.01073, saving model to temp/f32\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01073 to 1.00945, saving model to temp/f32\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0113 - mean_squared_error: 1.0113 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00945\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0204 - mean_squared_error: 1.0204 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00945\n",
      "Epoch 00009: early stopping\n",
      "temp/f33\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.1501 - mean_squared_error: 1.1501 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02388, saving model to temp/f33\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 1.0234 - val_mean_squared_error: 1.0234\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02388 to 1.02340, saving model to temp/f33\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02340 to 1.01771, saving model to temp/f33\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01771 to 1.01423, saving model to temp/f33\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0132 - val_mean_squared_error: 1.0132\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01423 to 1.01316, saving model to temp/f33\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0109 - val_mean_squared_error: 1.0109\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01316 to 1.01087, saving model to temp/f33\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0116 - mean_squared_error: 1.0116 - val_loss: 1.0023 - val_mean_squared_error: 1.0023\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01087 to 1.00232, saving model to temp/f33\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0101 - mean_squared_error: 1.0101 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00232\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0098 - val_mean_squared_error: 1.0098\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00232\n",
      "Epoch 00009: early stopping\n",
      "temp/f34\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.1437 - mean_squared_error: 1.1437 - val_loss: 1.0242 - val_mean_squared_error: 1.0242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02421, saving model to temp/f34\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0246 - mean_squared_error: 1.0246 - val_loss: 1.0167 - val_mean_squared_error: 1.0167\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02421 to 1.01671, saving model to temp/f34\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01671\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01671\n",
      "Epoch 00004: early stopping\n",
      "temp/f35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1519 - mean_squared_error: 1.1519 - val_loss: 1.0206 - val_mean_squared_error: 1.0206\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02062, saving model to temp/f35\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0248 - val_mean_squared_error: 1.0248\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02062\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0143 - val_mean_squared_error: 1.0143\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02062 to 1.01433, saving model to temp/f35\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01433\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01433\n",
      "Epoch 00005: early stopping\n",
      "temp/f36\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.1592 - mean_squared_error: 1.1592 - val_loss: 1.0326 - val_mean_squared_error: 1.0326\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03259, saving model to temp/f36\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0382 - val_mean_squared_error: 1.0382\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03259\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0212 - mean_squared_error: 1.0212 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03259 to 1.01345, saving model to temp/f36\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0144 - val_mean_squared_error: 1.0144\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01345\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0052 - val_mean_squared_error: 1.0052\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01345 to 1.00518, saving model to temp/f36\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0067 - mean_squared_error: 1.0067 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00518\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00518\n",
      "Epoch 00007: early stopping\n",
      "temp/f37\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1594 - mean_squared_error: 1.1594 - val_loss: 1.0248 - val_mean_squared_error: 1.0248\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02475, saving model to temp/f37\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0222 - val_mean_squared_error: 1.0222\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02475 to 1.02218, saving model to temp/f37\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02218 to 1.01808, saving model to temp/f37\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0208 - mean_squared_error: 1.0208 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01808 to 1.01405, saving model to temp/f37\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0086 - val_mean_squared_error: 1.0086\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01405 to 1.00856, saving model to temp/f37\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0177 - mean_squared_error: 1.0177 - val_loss: 1.0156 - val_mean_squared_error: 1.0156\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00856\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00856\n",
      "Epoch 00007: early stopping\n",
      "temp/f38\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.1519 - mean_squared_error: 1.1519 - val_loss: 1.0250 - val_mean_squared_error: 1.0250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02496, saving model to temp/f38\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0274 - mean_squared_error: 1.0274 - val_loss: 1.0369 - val_mean_squared_error: 1.0369\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02496\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0217 - mean_squared_error: 1.0217 - val_loss: 1.0336 - val_mean_squared_error: 1.0336\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02496\n",
      "Epoch 00003: early stopping\n",
      "temp/f39\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1602 - mean_squared_error: 1.1602 - val_loss: 1.0212 - val_mean_squared_error: 1.0212\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02122, saving model to temp/f39\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0257 - mean_squared_error: 1.0257 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02122 to 1.01768, saving model to temp/f39\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0215 - mean_squared_error: 1.0215 - val_loss: 1.0168 - val_mean_squared_error: 1.0168\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01768 to 1.01676, saving model to temp/f39\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0275 - val_mean_squared_error: 1.0275\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01676\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0192 - mean_squared_error: 1.0192 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01676 to 1.01262, saving model to temp/f39\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01262 to 1.00814, saving model to temp/f39\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00814\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0090 - mean_squared_error: 1.0090 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00814\n",
      "Epoch 00008: early stopping\n",
      "temp/f40\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1510 - mean_squared_error: 1.1510 - val_loss: 1.0211 - val_mean_squared_error: 1.0211\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02105, saving model to temp/f40\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0241 - mean_squared_error: 1.0241 - val_loss: 1.0233 - val_mean_squared_error: 1.0233\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02105\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0228 - mean_squared_error: 1.0228 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02105 to 1.01145, saving model to temp/f40\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0189 - mean_squared_error: 1.0189 - val_loss: 1.0192 - val_mean_squared_error: 1.0192\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01145\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01145 to 1.00958, saving model to temp/f40\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00958\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0086 - val_mean_squared_error: 1.0086\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00958 to 1.00859, saving model to temp/f40\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00859\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0114 - mean_squared_error: 1.0114 - val_loss: 1.0091 - val_mean_squared_error: 1.0091\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00859\n",
      "Epoch 00009: early stopping\n",
      "temp/f41\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.1379 - mean_squared_error: 1.1379 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02077, saving model to temp/f41\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0166 - val_mean_squared_error: 1.0166\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02077 to 1.01656, saving model to temp/f41\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0257 - val_mean_squared_error: 1.0257\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01656\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0185 - mean_squared_error: 1.0185 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01656 to 1.01203, saving model to temp/f41\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01203 to 1.00798, saving model to temp/f41\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00798\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00798\n",
      "Epoch 00007: early stopping\n",
      "temp/f42\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1676 - mean_squared_error: 1.1676 - val_loss: 1.0296 - val_mean_squared_error: 1.0296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02959, saving model to temp/f42\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0233 - mean_squared_error: 1.0233 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02959 to 1.01698, saving model to temp/f42\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01698 to 1.01419, saving model to temp/f42\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01419 to 1.01199, saving model to temp/f42\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0140 - val_mean_squared_error: 1.0140\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01199\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01199\n",
      "Epoch 00006: early stopping\n",
      "temp/f43\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1769 - mean_squared_error: 1.1769 - val_loss: 1.0276 - val_mean_squared_error: 1.0276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02764, saving model to temp/f43\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0328 - mean_squared_error: 1.0328 - val_loss: 1.0234 - val_mean_squared_error: 1.0234\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02764 to 1.02337, saving model to temp/f43\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0182 - val_mean_squared_error: 1.0182\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02337 to 1.01824, saving model to temp/f43\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0250 - val_mean_squared_error: 1.0250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01824\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01824 to 1.01305, saving model to temp/f43\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0049 - val_mean_squared_error: 1.0049\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01305 to 1.00493, saving model to temp/f43\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00493\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0104 - mean_squared_error: 1.0104 - val_loss: 1.0053 - val_mean_squared_error: 1.0053\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00493\n",
      "Epoch 00008: early stopping\n",
      "temp/f44\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.1600 - mean_squared_error: 1.1600 - val_loss: 1.0315 - val_mean_squared_error: 1.0315\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03150, saving model to temp/f44\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0288 - mean_squared_error: 1.0288 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03150 to 1.02035, saving model to temp/f44\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02035 to 1.02017, saving model to temp/f44\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02017\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.02017\n",
      "Epoch 00005: early stopping\n",
      "temp/f45\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1727 - mean_squared_error: 1.1727 - val_loss: 1.0253 - val_mean_squared_error: 1.0253\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02534, saving model to temp/f45\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0236 - mean_squared_error: 1.0236 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02534 to 1.02292, saving model to temp/f45\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02292 to 1.01200, saving model to temp/f45\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0334 - val_mean_squared_error: 1.0334\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01200\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0165 - mean_squared_error: 1.0165 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01200\n",
      "Epoch 00005: early stopping\n",
      "temp/f46\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.1572 - mean_squared_error: 1.1572 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02234, saving model to temp/f46\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0185 - mean_squared_error: 1.0185 - val_loss: 1.0218 - val_mean_squared_error: 1.0218\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02234 to 1.02176, saving model to temp/f46\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0124 - val_mean_squared_error: 1.0124\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02176 to 1.01240, saving model to temp/f46\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0122 - val_mean_squared_error: 1.0122\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01240 to 1.01223, saving model to temp/f46\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01223\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01223 to 1.00935, saving model to temp/f46\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00935 to 1.00783, saving model to temp/f46\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0101 - mean_squared_error: 1.0101 - val_loss: 1.0084 - val_mean_squared_error: 1.0084\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00783\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0113 - val_mean_squared_error: 1.0113\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00783\n",
      "Epoch 00009: early stopping\n",
      "temp/f47\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1524 - mean_squared_error: 1.1524 - val_loss: 1.0391 - val_mean_squared_error: 1.0391\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03912, saving model to temp/f47\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03912 to 1.01733, saving model to temp/f47\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01733 to 1.01111, saving model to temp/f47\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0144 - val_mean_squared_error: 1.0144\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01111\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0070 - val_mean_squared_error: 1.0070\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01111 to 1.00700, saving model to temp/f47\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0059 - val_mean_squared_error: 1.0059\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00700 to 1.00594, saving model to temp/f47\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0087 - mean_squared_error: 1.0087 - val_loss: 1.0225 - val_mean_squared_error: 1.0225\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00594\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0076 - mean_squared_error: 1.0076 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00594\n",
      "Epoch 00008: early stopping\n",
      "temp/f48\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.1468 - mean_squared_error: 1.1468 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01986, saving model to temp/f48\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0220 - mean_squared_error: 1.0220 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01986 to 1.01772, saving model to temp/f48\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 1.0144 - val_mean_squared_error: 1.0144\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01772 to 1.01443, saving model to temp/f48\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0177 - mean_squared_error: 1.0177 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01443\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01443 to 1.01295, saving model to temp/f48\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0210 - mean_squared_error: 1.0210 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01295 to 1.01005, saving model to temp/f48\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0114 - mean_squared_error: 1.0114 - val_loss: 1.0088 - val_mean_squared_error: 1.0088\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01005 to 1.00878, saving model to temp/f48\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00878\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0098 - mean_squared_error: 1.0098 - val_loss: 1.0122 - val_mean_squared_error: 1.0122\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00878\n",
      "Epoch 00009: early stopping\n",
      "temp/f49\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.1457 - mean_squared_error: 1.1457 - val_loss: 1.0299 - val_mean_squared_error: 1.0299\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02991, saving model to temp/f49\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02991 to 1.01990, saving model to temp/f49\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0217 - val_mean_squared_error: 1.0217\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01990\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0189 - mean_squared_error: 1.0189 - val_loss: 1.0155 - val_mean_squared_error: 1.0155\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01990 to 1.01548, saving model to temp/f49\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01548 to 1.01264, saving model to temp/f49\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0078 - mean_squared_error: 1.0078 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01264 to 1.01019, saving model to temp/f49\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0090 - mean_squared_error: 1.0090 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01019\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0092 - mean_squared_error: 1.0092 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01019\n",
      "Epoch 00008: early stopping\n",
      "temp/f50\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1766 - mean_squared_error: 1.1766 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01863, saving model to temp/f50\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0271 - mean_squared_error: 1.0271 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01863 to 1.01594, saving model to temp/f50\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0192 - mean_squared_error: 1.0192 - val_loss: 1.0125 - val_mean_squared_error: 1.0125\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01594 to 1.01250, saving model to temp/f50\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01250\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01250 to 1.00807, saving model to temp/f50\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0110 - mean_squared_error: 1.0110 - val_loss: 1.0189 - val_mean_squared_error: 1.0189\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00807\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00807\n",
      "Epoch 00007: early stopping\n",
      "temp/f51\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1467 - mean_squared_error: 1.1467 - val_loss: 1.0303 - val_mean_squared_error: 1.0303\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03026, saving model to temp/f51\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0231 - mean_squared_error: 1.0231 - val_loss: 1.0301 - val_mean_squared_error: 1.0301\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03026 to 1.03009, saving model to temp/f51\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03009 to 1.01523, saving model to temp/f51\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0230 - val_mean_squared_error: 1.0230\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01523\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0134 - val_mean_squared_error: 1.0134\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01523 to 1.01337, saving model to temp/f51\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0134 - mean_squared_error: 1.0134 - val_loss: 1.0169 - val_mean_squared_error: 1.0169\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01337\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01337\n",
      "Epoch 00007: early stopping\n",
      "temp/f52\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1622 - mean_squared_error: 1.1622 - val_loss: 1.0274 - val_mean_squared_error: 1.0274\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02737, saving model to temp/f52\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0195 - mean_squared_error: 1.0195 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02737 to 1.01513, saving model to temp/f52\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01513\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0143 - val_mean_squared_error: 1.0143\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01513 to 1.01428, saving model to temp/f52\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0062 - val_mean_squared_error: 1.0062\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01428 to 1.00621, saving model to temp/f52\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0053 - val_mean_squared_error: 1.0053\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00621 to 1.00533, saving model to temp/f52\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00533\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00533\n",
      "Epoch 00008: early stopping\n",
      "temp/f53\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.1549 - mean_squared_error: 1.1549 - val_loss: 1.0264 - val_mean_squared_error: 1.0264\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02642, saving model to temp/f53\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0242 - mean_squared_error: 1.0242 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02642 to 1.01716, saving model to temp/f53\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0050 - val_mean_squared_error: 1.0050\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01716 to 1.00505, saving model to temp/f53\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00505\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0146 - val_mean_squared_error: 1.0146\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00505\n",
      "Epoch 00005: early stopping\n",
      "temp/f54\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1399 - mean_squared_error: 1.1399 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01914, saving model to temp/f54\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0253 - mean_squared_error: 1.0253 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01914 to 1.01589, saving model to temp/f54\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0180 - val_mean_squared_error: 1.0180\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01589\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01589 to 1.01529, saving model to temp/f54\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0214 - mean_squared_error: 1.0214 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01529 to 1.01137, saving model to temp/f54\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0042 - val_mean_squared_error: 1.0042\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01137 to 1.00425, saving model to temp/f54\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0087 - mean_squared_error: 1.0087 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00425\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00425\n",
      "Epoch 00008: early stopping\n",
      "temp/f55\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1706 - mean_squared_error: 1.1706 - val_loss: 1.0269 - val_mean_squared_error: 1.0269\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02691, saving model to temp/f55\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0240 - mean_squared_error: 1.0240 - val_loss: 1.0233 - val_mean_squared_error: 1.0233\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02691 to 1.02332, saving model to temp/f55\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0342 - val_mean_squared_error: 1.0342\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02332\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0279 - val_mean_squared_error: 1.0279\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02332\n",
      "Epoch 00004: early stopping\n",
      "temp/f56\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.1600 - mean_squared_error: 1.1600 - val_loss: 1.0269 - val_mean_squared_error: 1.0269\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02692, saving model to temp/f56\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0277 - mean_squared_error: 1.0277 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02692 to 1.02087, saving model to temp/f56\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0241 - mean_squared_error: 1.0241 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02087\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0218 - mean_squared_error: 1.0218 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02087 to 1.01566, saving model to temp/f56\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01566\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0158 - val_mean_squared_error: 1.0158\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01566\n",
      "Epoch 00006: early stopping\n",
      "temp/f57\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1801 - mean_squared_error: 1.1801 - val_loss: 1.0351 - val_mean_squared_error: 1.0351\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03507, saving model to temp/f57\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0271 - mean_squared_error: 1.0271 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03507 to 1.02074, saving model to temp/f57\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0210 - mean_squared_error: 1.0210 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02074\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0204 - mean_squared_error: 1.0204 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02074 to 1.01543, saving model to temp/f57\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01543 to 1.01493, saving model to temp/f57\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01493 to 1.00948, saving model to temp/f57\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00948\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0084 - mean_squared_error: 1.0084 - val_loss: 1.0090 - val_mean_squared_error: 1.0090\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00948 to 1.00900, saving model to temp/f57\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0092 - val_mean_squared_error: 1.0092\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00900\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0094 - mean_squared_error: 1.0094 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00900\n",
      "Epoch 00010: early stopping\n",
      "temp/f58\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1558 - mean_squared_error: 1.1558 - val_loss: 1.0398 - val_mean_squared_error: 1.0398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03975, saving model to temp/f58\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 1.0225 - val_mean_squared_error: 1.0225\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03975 to 1.02254, saving model to temp/f58\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0220 - val_mean_squared_error: 1.0220\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02254 to 1.02204, saving model to temp/f58\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0145 - val_mean_squared_error: 1.0145\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02204 to 1.01447, saving model to temp/f58\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01447\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01447 to 1.01042, saving model to temp/f58\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0067 - val_mean_squared_error: 1.0067\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01042 to 1.00674, saving model to temp/f58\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0116 - mean_squared_error: 1.0116 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00674\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00674\n",
      "Epoch 00009: early stopping\n",
      "temp/f59\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.1567 - mean_squared_error: 1.1567 - val_loss: 1.0187 - val_mean_squared_error: 1.0187\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01870, saving model to temp/f59\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 1.0268 - val_mean_squared_error: 1.0268\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01870\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 101us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01870 to 1.01293, saving model to temp/f59\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0091 - val_mean_squared_error: 1.0091\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01293 to 1.00906, saving model to temp/f59\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00906\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00906\n",
      "Epoch 00006: early stopping\n",
      "temp/f60\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1511 - mean_squared_error: 1.1511 - val_loss: 1.0299 - val_mean_squared_error: 1.0299\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02988, saving model to temp/f60\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0277 - mean_squared_error: 1.0277 - val_loss: 1.0220 - val_mean_squared_error: 1.0220\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02988 to 1.02197, saving model to temp/f60\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 1.0528 - val_mean_squared_error: 1.0528\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02197\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0187 - val_mean_squared_error: 1.0187\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02197 to 1.01874, saving model to temp/f60\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01874 to 1.01029, saving model to temp/f60\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0116 - mean_squared_error: 1.0116 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01029\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01029\n",
      "Epoch 00007: early stopping\n",
      "temp/f61\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1680 - mean_squared_error: 1.1680 - val_loss: 1.0294 - val_mean_squared_error: 1.0294\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02939, saving model to temp/f61\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0247 - mean_squared_error: 1.0247 - val_loss: 1.0213 - val_mean_squared_error: 1.0213\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02939 to 1.02125, saving model to temp/f61\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02125 to 1.02089, saving model to temp/f61\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0208 - mean_squared_error: 1.0208 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02089 to 1.01204, saving model to temp/f61\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0086 - val_mean_squared_error: 1.0086\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01204 to 1.00860, saving model to temp/f61\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00860\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.0110 - val_mean_squared_error: 1.0110\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00860\n",
      "Epoch 00007: early stopping\n",
      "temp/f62\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1569 - mean_squared_error: 1.1569 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02085, saving model to temp/f62\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02085 to 1.01830, saving model to temp/f62\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0185 - mean_squared_error: 1.0185 - val_loss: 1.0180 - val_mean_squared_error: 1.0180\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01830 to 1.01797, saving model to temp/f62\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01797\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01797 to 1.00852, saving model to temp/f62\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00852\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00852\n",
      "Epoch 00007: early stopping\n",
      "temp/f63\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1633 - mean_squared_error: 1.1633 - val_loss: 1.0254 - val_mean_squared_error: 1.0254\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02543, saving model to temp/f63\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0281 - mean_squared_error: 1.0281 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02543 to 1.02036, saving model to temp/f63\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0306 - val_mean_squared_error: 1.0306\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02036\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02036 to 1.01725, saving model to temp/f63\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0273 - val_mean_squared_error: 1.0273\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01725\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0219 - val_mean_squared_error: 1.0219\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01725\n",
      "Epoch 00006: early stopping\n",
      "temp/f64\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1674 - mean_squared_error: 1.1674 - val_loss: 1.0280 - val_mean_squared_error: 1.0280\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02804, saving model to temp/f64\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0271 - mean_squared_error: 1.0271 - val_loss: 1.0351 - val_mean_squared_error: 1.0351\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02804\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0239 - mean_squared_error: 1.0239 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02804 to 1.01605, saving model to temp/f64\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0171 - val_mean_squared_error: 1.0171\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01605\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01605 to 1.01412, saving model to temp/f64\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01412 to 1.01023, saving model to temp/f64\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0241 - val_mean_squared_error: 1.0241\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01023\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01023\n",
      "Epoch 00008: early stopping\n",
      "temp/f65\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1510 - mean_squared_error: 1.1510 - val_loss: 1.0235 - val_mean_squared_error: 1.0235\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02346, saving model to temp/f65\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0256 - mean_squared_error: 1.0256 - val_loss: 1.0145 - val_mean_squared_error: 1.0145\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02346 to 1.01453, saving model to temp/f65\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01453\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0222 - val_mean_squared_error: 1.0222\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01453\n",
      "Epoch 00004: early stopping\n",
      "temp/f66\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1672 - mean_squared_error: 1.1672 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02008, saving model to temp/f66\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0274 - mean_squared_error: 1.0274 - val_loss: 1.0251 - val_mean_squared_error: 1.0251\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02008\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0218 - mean_squared_error: 1.0218 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02008 to 1.01137, saving model to temp/f66\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01137\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0082 - val_mean_squared_error: 1.0082\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01137 to 1.00825, saving model to temp/f66\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00825\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00825\n",
      "Epoch 00007: early stopping\n",
      "temp/f67\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1438 - mean_squared_error: 1.1438 - val_loss: 1.0180 - val_mean_squared_error: 1.0180\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01801, saving model to temp/f67\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0229 - mean_squared_error: 1.0229 - val_loss: 1.0203 - val_mean_squared_error: 1.0203\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01801\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0241 - val_mean_squared_error: 1.0241\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01801\n",
      "Epoch 00003: early stopping\n",
      "temp/f68\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.1935 - mean_squared_error: 1.1935 - val_loss: 1.0376 - val_mean_squared_error: 1.0376\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03761, saving model to temp/f68\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0308 - mean_squared_error: 1.0308 - val_loss: 1.0182 - val_mean_squared_error: 1.0182\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03761 to 1.01822, saving model to temp/f68\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0217 - mean_squared_error: 1.0217 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01822\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0187 - mean_squared_error: 1.0187 - val_loss: 1.0226 - val_mean_squared_error: 1.0226\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01822\n",
      "Epoch 00004: early stopping\n",
      "temp/f69\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1650 - mean_squared_error: 1.1650 - val_loss: 1.0326 - val_mean_squared_error: 1.0326\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03263, saving model to temp/f69\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0269 - mean_squared_error: 1.0269 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03263 to 1.01807, saving model to temp/f69\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0348 - val_mean_squared_error: 1.0348\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01807\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01807 to 1.01373, saving model to temp/f69\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01373 to 1.01167, saving model to temp/f69\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 100us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0084 - val_mean_squared_error: 1.0084\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01167 to 1.00839, saving model to temp/f69\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0169 - val_mean_squared_error: 1.0169\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00839\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0028 - val_mean_squared_error: 1.0028\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00839 to 1.00279, saving model to temp/f69\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00279\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0111 - mean_squared_error: 1.0111 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00279\n",
      "Epoch 00010: early stopping\n",
      "temp/f70\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1648 - mean_squared_error: 1.1648 - val_loss: 1.0319 - val_mean_squared_error: 1.0319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03188, saving model to temp/f70\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0279 - mean_squared_error: 1.0279 - val_loss: 1.0227 - val_mean_squared_error: 1.0227\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03188 to 1.02271, saving model to temp/f70\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0212 - mean_squared_error: 1.0212 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02271\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0211 - val_mean_squared_error: 1.0211\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02271 to 1.02107, saving model to temp/f70\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.02107\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0297 - val_mean_squared_error: 1.0297\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.02107\n",
      "Epoch 00006: early stopping\n",
      "temp/f71\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1518 - mean_squared_error: 1.1518 - val_loss: 1.0234 - val_mean_squared_error: 1.0234\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02345, saving model to temp/f71\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0255 - mean_squared_error: 1.0255 - val_loss: 1.0219 - val_mean_squared_error: 1.0219\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02345 to 1.02187, saving model to temp/f71\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02187 to 1.02025, saving model to temp/f71\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02025 to 1.02007, saving model to temp/f71\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0087 - val_mean_squared_error: 1.0087\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.02007 to 1.00868, saving model to temp/f71\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00868\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00868\n",
      "Epoch 00007: early stopping\n",
      "temp/f72\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1528 - mean_squared_error: 1.1528 - val_loss: 1.0248 - val_mean_squared_error: 1.0248\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02482, saving model to temp/f72\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0261 - mean_squared_error: 1.0261 - val_loss: 1.0341 - val_mean_squared_error: 1.0341\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02482\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02482 to 1.01718, saving model to temp/f72\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0071 - val_mean_squared_error: 1.0071\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01718 to 1.00708, saving model to temp/f72\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00708\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0069 - val_mean_squared_error: 1.0069\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00708 to 1.00686, saving model to temp/f72\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00686\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00686\n",
      "Epoch 00008: early stopping\n",
      "temp/f73\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1470 - mean_squared_error: 1.1470 - val_loss: 1.0312 - val_mean_squared_error: 1.0312\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03122, saving model to temp/f73\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0276 - mean_squared_error: 1.0276 - val_loss: 1.0330 - val_mean_squared_error: 1.0330\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03122\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0113 - val_mean_squared_error: 1.0113\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03122 to 1.01133, saving model to temp/f73\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0082 - val_mean_squared_error: 1.0082\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01133 to 1.00816, saving model to temp/f73\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00816\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00816\n",
      "Epoch 00006: early stopping\n",
      "temp/f74\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1689 - mean_squared_error: 1.1689 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01975, saving model to temp/f74\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0236 - mean_squared_error: 1.0236 - val_loss: 1.0248 - val_mean_squared_error: 1.0248\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01975\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01975 to 1.01931, saving model to temp/f74\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01931 to 1.01473, saving model to temp/f74\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01473\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01473 to 1.01262, saving model to temp/f74\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0118 - mean_squared_error: 1.0118 - val_loss: 1.0068 - val_mean_squared_error: 1.0068\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01262 to 1.00680, saving model to temp/f74\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0089 - val_mean_squared_error: 1.0089\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00680\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0114 - mean_squared_error: 1.0114 - val_loss: 1.0036 - val_mean_squared_error: 1.0036\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00680 to 1.00362, saving model to temp/f74\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0097 - mean_squared_error: 1.0097 - val_loss: 1.0189 - val_mean_squared_error: 1.0189\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00362\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0089 - mean_squared_error: 1.0089 - val_loss: 1.0099 - val_mean_squared_error: 1.0099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00362\n",
      "Epoch 00011: early stopping\n",
      "temp/f75\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1562 - mean_squared_error: 1.1562 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02149, saving model to temp/f75\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0244 - val_mean_squared_error: 1.0244\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02149\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0251 - mean_squared_error: 1.0251 - val_loss: 1.0189 - val_mean_squared_error: 1.0189\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02149 to 1.01891, saving model to temp/f75\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01891 to 1.01385, saving model to temp/f75\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01385 to 1.01108, saving model to temp/f75\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0126 - mean_squared_error: 1.0126 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01108\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01108\n",
      "Epoch 00007: early stopping\n",
      "temp/f76\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1706 - mean_squared_error: 1.1706 - val_loss: 1.0281 - val_mean_squared_error: 1.0281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02806, saving model to temp/f76\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0256 - mean_squared_error: 1.0256 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02806 to 1.01494, saving model to temp/f76\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0189 - mean_squared_error: 1.0189 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01494 to 1.01148, saving model to temp/f76\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01148\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0066 - val_mean_squared_error: 1.0066\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01148 to 1.00663, saving model to temp/f76\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0122 - mean_squared_error: 1.0122 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00663\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00663\n",
      "Epoch 00007: early stopping\n",
      "temp/f77\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1690 - mean_squared_error: 1.1690 - val_loss: 1.0348 - val_mean_squared_error: 1.0348\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03477, saving model to temp/f77\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0262 - mean_squared_error: 1.0262 - val_loss: 1.0197 - val_mean_squared_error: 1.0197\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03477 to 1.01966, saving model to temp/f77\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0205 - mean_squared_error: 1.0205 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01966\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0198 - mean_squared_error: 1.0198 - val_loss: 1.0288 - val_mean_squared_error: 1.0288\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01966\n",
      "Epoch 00004: early stopping\n",
      "temp/f78\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1491 - mean_squared_error: 1.1491 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02324, saving model to temp/f78\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0293 - mean_squared_error: 1.0293 - val_loss: 1.0213 - val_mean_squared_error: 1.0213\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02324 to 1.02127, saving model to temp/f78\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0238 - mean_squared_error: 1.0238 - val_loss: 1.0179 - val_mean_squared_error: 1.0179\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02127 to 1.01794, saving model to temp/f78\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0242 - val_mean_squared_error: 1.0242\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01794\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01794 to 1.01028, saving model to temp/f78\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01028\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0171 - val_mean_squared_error: 1.0171\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01028\n",
      "Epoch 00007: early stopping\n",
      "temp/f79\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1519 - mean_squared_error: 1.1519 - val_loss: 1.0267 - val_mean_squared_error: 1.0267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02675, saving model to temp/f79\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0239 - mean_squared_error: 1.0239 - val_loss: 1.0318 - val_mean_squared_error: 1.0318\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02675\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0257 - mean_squared_error: 1.0257 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02675 to 1.01601, saving model to temp/f79\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01601 to 1.01109, saving model to temp/f79\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01109\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0124 - mean_squared_error: 1.0124 - val_loss: 1.0132 - val_mean_squared_error: 1.0132\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01109\n",
      "Epoch 00006: early stopping\n",
      "temp/f80\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1689 - mean_squared_error: 1.1689 - val_loss: 1.0278 - val_mean_squared_error: 1.0278\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02778, saving model to temp/f80\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0259 - mean_squared_error: 1.0259 - val_loss: 1.0244 - val_mean_squared_error: 1.0244\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02778 to 1.02439, saving model to temp/f80\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0254 - val_mean_squared_error: 1.0254\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02439\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0147 - mean_squared_error: 1.0147 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02439 to 1.01118, saving model to temp/f80\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01118\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0200 - val_mean_squared_error: 1.0200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01118\n",
      "Epoch 00006: early stopping\n",
      "temp/f81\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.1666 - mean_squared_error: 1.1666 - val_loss: 1.0358 - val_mean_squared_error: 1.0358\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03583, saving model to temp/f81\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 1.0212 - val_mean_squared_error: 1.0212\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03583 to 1.02118, saving model to temp/f81\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0233 - mean_squared_error: 1.0233 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02118 to 1.01213, saving model to temp/f81\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0143 - val_mean_squared_error: 1.0143\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01213\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01213 to 1.01192, saving model to temp/f81\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01192\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01192\n",
      "Epoch 00007: early stopping\n",
      "temp/f82\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1724 - mean_squared_error: 1.1724 - val_loss: 1.0285 - val_mean_squared_error: 1.0285\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02847, saving model to temp/f82\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0263 - mean_squared_error: 1.0263 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02847 to 1.01599, saving model to temp/f82\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0217 - val_mean_squared_error: 1.0217\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01599\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0233 - mean_squared_error: 1.0233 - val_loss: 1.0245 - val_mean_squared_error: 1.0245\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01599\n",
      "Epoch 00004: early stopping\n",
      "temp/f83\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1712 - mean_squared_error: 1.1712 - val_loss: 1.0268 - val_mean_squared_error: 1.0268\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02680, saving model to temp/f83\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0291 - mean_squared_error: 1.0291 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02680 to 1.01472, saving model to temp/f83\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0225 - val_mean_squared_error: 1.0225\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01472\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01472\n",
      "Epoch 00004: early stopping\n",
      "temp/f84\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1457 - mean_squared_error: 1.1457 - val_loss: 1.0200 - val_mean_squared_error: 1.0200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02003, saving model to temp/f84\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0271 - mean_squared_error: 1.0271 - val_loss: 1.0260 - val_mean_squared_error: 1.0260\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02003\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0189 - mean_squared_error: 1.0189 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02003\n",
      "Epoch 00003: early stopping\n",
      "temp/f85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.1628 - mean_squared_error: 1.1628 - val_loss: 1.0249 - val_mean_squared_error: 1.0249\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02491, saving model to temp/f85\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0261 - mean_squared_error: 1.0261 - val_loss: 1.0289 - val_mean_squared_error: 1.0289\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02491\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02491 to 1.01081, saving model to temp/f85\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01081\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01081\n",
      "Epoch 00005: early stopping\n",
      "temp/f86\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1887 - mean_squared_error: 1.1887 - val_loss: 1.0306 - val_mean_squared_error: 1.0306\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03058, saving model to temp/f86\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 1.0224 - val_mean_squared_error: 1.0224\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03058 to 1.02243, saving model to temp/f86\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0226 - val_mean_squared_error: 1.0226\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02243\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02243 to 1.01832, saving model to temp/f86\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01832 to 1.00958, saving model to temp/f86\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00958\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00958\n",
      "Epoch 00007: early stopping\n",
      "temp/f87\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1611 - mean_squared_error: 1.1611 - val_loss: 1.0271 - val_mean_squared_error: 1.0271\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02707, saving model to temp/f87\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0507 - val_mean_squared_error: 1.0507\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02707\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0215 - mean_squared_error: 1.0215 - val_loss: 1.0246 - val_mean_squared_error: 1.0246\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02707 to 1.02457, saving model to temp/f87\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02457 to 1.01327, saving model to temp/f87\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0165 - mean_squared_error: 1.0165 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01327\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0079 - val_mean_squared_error: 1.0079\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01327 to 1.00789, saving model to temp/f87\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00789\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0128 - mean_squared_error: 1.0128 - val_loss: 1.0113 - val_mean_squared_error: 1.0113\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00789\n",
      "Epoch 00008: early stopping\n",
      "temp/f88\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1707 - mean_squared_error: 1.1707 - val_loss: 1.0238 - val_mean_squared_error: 1.0238\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02385, saving model to temp/f88\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02385 to 1.01754, saving model to temp/f88\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01754 to 1.01174, saving model to temp/f88\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01174\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0177 - mean_squared_error: 1.0177 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01174\n",
      "Epoch 00005: early stopping\n",
      "temp/f89\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1503 - mean_squared_error: 1.1503 - val_loss: 1.0276 - val_mean_squared_error: 1.0276\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02756, saving model to temp/f89\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0261 - mean_squared_error: 1.0261 - val_loss: 1.0233 - val_mean_squared_error: 1.0233\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02756 to 1.02335, saving model to temp/f89\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0234 - mean_squared_error: 1.0234 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02335 to 1.01573, saving model to temp/f89\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0166 - val_mean_squared_error: 1.0166\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01573\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01573\n",
      "Epoch 00005: early stopping\n",
      "temp/f90\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1611 - mean_squared_error: 1.1611 - val_loss: 1.0328 - val_mean_squared_error: 1.0328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03279, saving model to temp/f90\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0226 - val_mean_squared_error: 1.0226\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03279 to 1.02256, saving model to temp/f90\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 1.02256 to 1.01860, saving model to temp/f90\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0144 - mean_squared_error: 1.0144 - val_loss: 1.0216 - val_mean_squared_error: 1.0216\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01860\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01860 to 1.01061, saving model to temp/f90\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0074 - val_mean_squared_error: 1.0074\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01061 to 1.00743, saving model to temp/f90\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0098 - mean_squared_error: 1.0098 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00743 to 1.00606, saving model to temp/f90\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00606\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0102 - mean_squared_error: 1.0102 - val_loss: 0.9999 - val_mean_squared_error: 0.9999\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00606 to 0.99992, saving model to temp/f90\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0036 - mean_squared_error: 1.0036 - val_loss: 1.0109 - val_mean_squared_error: 1.0109\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.99992\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0097 - mean_squared_error: 1.0097 - val_loss: 1.0026 - val_mean_squared_error: 1.0026\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.99992\n",
      "Epoch 00011: early stopping\n",
      "temp/f91\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1754 - mean_squared_error: 1.1754 - val_loss: 1.0362 - val_mean_squared_error: 1.0362\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03617, saving model to temp/f91\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0282 - mean_squared_error: 1.0282 - val_loss: 1.0233 - val_mean_squared_error: 1.0233\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03617 to 1.02326, saving model to temp/f91\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0208 - mean_squared_error: 1.0208 - val_loss: 1.0184 - val_mean_squared_error: 1.0184\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02326 to 1.01841, saving model to temp/f91\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0205 - mean_squared_error: 1.0205 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01841\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01841 to 1.01229, saving model to temp/f91\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0042 - val_mean_squared_error: 1.0042\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01229 to 1.00418, saving model to temp/f91\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00418\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0155 - val_mean_squared_error: 1.0155\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00418\n",
      "Epoch 00008: early stopping\n",
      "temp/f92\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.1680 - mean_squared_error: 1.1680 - val_loss: 1.0281 - val_mean_squared_error: 1.0281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02814, saving model to temp/f92\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0217 - mean_squared_error: 1.0217 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02814 to 1.02662, saving model to temp/f92\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0179 - val_mean_squared_error: 1.0179\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02662 to 1.01787, saving model to temp/f92\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0187 - mean_squared_error: 1.0187 - val_loss: 1.0197 - val_mean_squared_error: 1.0197\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01787\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0179 - val_mean_squared_error: 1.0179\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01787\n",
      "Epoch 00005: early stopping\n",
      "temp/f93\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.1663 - mean_squared_error: 1.1663 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02023, saving model to temp/f93\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0253 - mean_squared_error: 1.0253 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02023\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0236 - val_mean_squared_error: 1.0236\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02023\n",
      "Epoch 00003: early stopping\n",
      "temp/f94\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.1620 - mean_squared_error: 1.1620 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01735, saving model to temp/f94\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0272 - mean_squared_error: 1.0272 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01735\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0187 - val_mean_squared_error: 1.0187\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01735\n",
      "Epoch 00003: early stopping\n",
      "temp/f95\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1670 - mean_squared_error: 1.1670 - val_loss: 1.0275 - val_mean_squared_error: 1.0275\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02748, saving model to temp/f95\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0247 - mean_squared_error: 1.0247 - val_loss: 1.0116 - val_mean_squared_error: 1.0116\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02748 to 1.01162, saving model to temp/f95\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 99us/step - loss: 1.0198 - mean_squared_error: 1.0198 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01162\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01162 to 1.01114, saving model to temp/f95\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0091 - val_mean_squared_error: 1.0091\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01114 to 1.00912, saving model to temp/f95\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0093 - val_mean_squared_error: 1.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00912\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0090 - val_mean_squared_error: 1.0090\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00912 to 1.00900, saving model to temp/f95\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0253 - val_mean_squared_error: 1.0253\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00900\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0081 - mean_squared_error: 1.0081 - val_loss: 1.0075 - val_mean_squared_error: 1.0075\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00900 to 1.00752, saving model to temp/f95\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0073 - val_mean_squared_error: 1.0073\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00752 to 1.00726, saving model to temp/f95\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0074 - mean_squared_error: 1.0074 - val_loss: 1.0099 - val_mean_squared_error: 1.0099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00726\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0108 - mean_squared_error: 1.0108 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.00726\n",
      "Epoch 00012: early stopping\n",
      "temp/f96\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1667 - mean_squared_error: 1.1667 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02088, saving model to temp/f96\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0230 - mean_squared_error: 1.0230 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02088 to 1.02065, saving model to temp/f96\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0220 - mean_squared_error: 1.0220 - val_loss: 1.0234 - val_mean_squared_error: 1.0234\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02065\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02065 to 1.01503, saving model to temp/f96\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0245 - val_mean_squared_error: 1.0245\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01503\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0113 - val_mean_squared_error: 1.0113\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01503 to 1.01127, saving model to temp/f96\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0120 - mean_squared_error: 1.0120 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01127\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0124 - mean_squared_error: 1.0124 - val_loss: 1.0062 - val_mean_squared_error: 1.0062\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01127 to 1.00622, saving model to temp/f96\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0098 - mean_squared_error: 1.0098 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00622\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0122 - mean_squared_error: 1.0122 - val_loss: 1.0074 - val_mean_squared_error: 1.0074\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00622\n",
      "Epoch 00010: early stopping\n",
      "temp/f97\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.1578 - mean_squared_error: 1.1578 - val_loss: 1.0308 - val_mean_squared_error: 1.0308\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03083, saving model to temp/f97\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0292 - mean_squared_error: 1.0292 - val_loss: 1.0277 - val_mean_squared_error: 1.0277\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03083 to 1.02773, saving model to temp/f97\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0233 - mean_squared_error: 1.0233 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02773 to 1.01515, saving model to temp/f97\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0206 - val_mean_squared_error: 1.0206\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01515\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0030 - val_mean_squared_error: 1.0030\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01515 to 1.00299, saving model to temp/f97\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0167 - val_mean_squared_error: 1.0167\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00299\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0088 - mean_squared_error: 1.0088 - val_loss: 1.0043 - val_mean_squared_error: 1.0043\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00299\n",
      "Epoch 00007: early stopping\n",
      "temp/f98\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1736 - mean_squared_error: 1.1736 - val_loss: 1.0343 - val_mean_squared_error: 1.0343\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03427, saving model to temp/f98\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0252 - mean_squared_error: 1.0252 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03427 to 1.01860, saving model to temp/f98\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01860 to 1.01719, saving model to temp/f98\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01719 to 1.01274, saving model to temp/f98\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0208 - mean_squared_error: 1.0208 - val_loss: 1.0189 - val_mean_squared_error: 1.0189\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01274\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0116 - val_mean_squared_error: 1.0116\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01274 to 1.01161, saving model to temp/f98\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01161\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0109 - mean_squared_error: 1.0109 - val_loss: 1.0259 - val_mean_squared_error: 1.0259\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01161\n",
      "Epoch 00008: early stopping\n",
      "temp/f99\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1829 - mean_squared_error: 1.1829 - val_loss: 1.0509 - val_mean_squared_error: 1.0509\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05092, saving model to temp/f99\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0251 - mean_squared_error: 1.0251 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05092 to 1.01829, saving model to temp/f99\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0301 - val_mean_squared_error: 1.0301\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01829\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01829 to 1.01517, saving model to temp/f99\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0082 - val_mean_squared_error: 1.0082\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01517 to 1.00815, saving model to temp/f99\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0087 - val_mean_squared_error: 1.0087\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00815\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0156 - mean_squared_error: 1.0156 - val_loss: 1.0051 - val_mean_squared_error: 1.0051\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00815 to 1.00506, saving model to temp/f99\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0240 - val_mean_squared_error: 1.0240\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00506\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0171 - val_mean_squared_error: 1.0171\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00506\n",
      "Epoch 00009: early stopping\n",
      "temp/f100\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.1575 - mean_squared_error: 1.1575 - val_loss: 1.0410 - val_mean_squared_error: 1.0410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04104, saving model to temp/f100\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0273 - mean_squared_error: 1.0273 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04104 to 1.01517, saving model to temp/f100\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0205 - mean_squared_error: 1.0205 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01517\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0120 - mean_squared_error: 1.0120 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01517\n",
      "Epoch 00004: early stopping\n",
      "temp/f101\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1413 - mean_squared_error: 1.1413 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02656, saving model to temp/f101\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0220 - mean_squared_error: 1.0220 - val_loss: 1.0301 - val_mean_squared_error: 1.0301\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02656\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0206 - mean_squared_error: 1.0206 - val_loss: 1.0156 - val_mean_squared_error: 1.0156\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02656 to 1.01564, saving model to temp/f101\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01564\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0122 - val_mean_squared_error: 1.0122\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01564 to 1.01220, saving model to temp/f101\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01220\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01220\n",
      "Epoch 00007: early stopping\n",
      "temp/f102\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1474 - mean_squared_error: 1.1474 - val_loss: 1.0270 - val_mean_squared_error: 1.0270\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02698, saving model to temp/f102\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0217 - mean_squared_error: 1.0217 - val_loss: 1.0185 - val_mean_squared_error: 1.0185\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02698 to 1.01852, saving model to temp/f102\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0188 - mean_squared_error: 1.0188 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01852 to 1.01416, saving model to temp/f102\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0236 - val_mean_squared_error: 1.0236\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01416\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0111 - mean_squared_error: 1.0111 - val_loss: 1.0247 - val_mean_squared_error: 1.0247\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01416\n",
      "Epoch 00005: early stopping\n",
      "temp/f103\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.1653 - mean_squared_error: 1.1653 - val_loss: 1.0291 - val_mean_squared_error: 1.0291\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02908, saving model to temp/f103\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02908 to 1.01750, saving model to temp/f103\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01750\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0227 - mean_squared_error: 1.0227 - val_loss: 1.0075 - val_mean_squared_error: 1.0075\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01750 to 1.00753, saving model to temp/f103\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0165 - mean_squared_error: 1.0165 - val_loss: 1.0221 - val_mean_squared_error: 1.0221\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00753\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00753\n",
      "Epoch 00006: early stopping\n",
      "temp/f104\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.1672 - mean_squared_error: 1.1672 - val_loss: 1.0293 - val_mean_squared_error: 1.0293\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02932, saving model to temp/f104\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0264 - mean_squared_error: 1.0264 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02932 to 1.01835, saving model to temp/f104\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01835 to 1.01810, saving model to temp/f104\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01810 to 1.01287, saving model to temp/f104\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0189 - mean_squared_error: 1.0189 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01287\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0194 - val_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01287\n",
      "Epoch 00006: early stopping\n",
      "temp/f105\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1514 - mean_squared_error: 1.1514 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02366, saving model to temp/f105\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0239 - mean_squared_error: 1.0239 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02366 to 1.01721, saving model to temp/f105\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01721\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01721\n",
      "Epoch 00004: early stopping\n",
      "temp/f106\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1673 - mean_squared_error: 1.1673 - val_loss: 1.0293 - val_mean_squared_error: 1.0293\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02925, saving model to temp/f106\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0268 - mean_squared_error: 1.0268 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02925 to 1.01965, saving model to temp/f106\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0188 - mean_squared_error: 1.0188 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01965 to 1.01705, saving model to temp/f106\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01705 to 1.01370, saving model to temp/f106\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0147 - mean_squared_error: 1.0147 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01370\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0185 - val_mean_squared_error: 1.0185\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01370\n",
      "Epoch 00006: early stopping\n",
      "temp/f107\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1425 - mean_squared_error: 1.1425 - val_loss: 1.0311 - val_mean_squared_error: 1.0311\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03107, saving model to temp/f107\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0241 - mean_squared_error: 1.0241 - val_loss: 1.0205 - val_mean_squared_error: 1.0205\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03107 to 1.02048, saving model to temp/f107\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0236 - mean_squared_error: 1.0236 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02048 to 1.01276, saving model to temp/f107\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0215 - mean_squared_error: 1.0215 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01276 to 1.01212, saving model to temp/f107\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01212 to 1.01201, saving model to temp/f107\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01201 to 1.01023, saving model to temp/f107\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01023\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0079 - val_mean_squared_error: 1.0079\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01023 to 1.00786, saving model to temp/f107\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0093 - mean_squared_error: 1.0093 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00786\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0113 - mean_squared_error: 1.0113 - val_loss: 1.0039 - val_mean_squared_error: 1.0039\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00786 to 1.00391, saving model to temp/f107\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0047 - mean_squared_error: 1.0047 - val_loss: 1.0216 - val_mean_squared_error: 1.0216\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00391\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.00391\n",
      "Epoch 00012: early stopping\n",
      "temp/f108\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1573 - mean_squared_error: 1.1573 - val_loss: 1.0263 - val_mean_squared_error: 1.0263\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02625, saving model to temp/f108\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02625 to 1.02278, saving model to temp/f108\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0230 - val_mean_squared_error: 1.0230\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02278\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02278 to 1.01234, saving model to temp/f108\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01234 to 1.01196, saving model to temp/f108\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 1.0063 - val_mean_squared_error: 1.0063\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01196 to 1.00632, saving model to temp/f108\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0093 - val_mean_squared_error: 1.0093\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00632\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00632\n",
      "Epoch 00008: early stopping\n",
      "temp/f109\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.1495 - mean_squared_error: 1.1495 - val_loss: 1.0400 - val_mean_squared_error: 1.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04001, saving model to temp/f109\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0247 - mean_squared_error: 1.0247 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04001 to 1.01535, saving model to temp/f109\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0194 - val_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01535\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0234 - mean_squared_error: 1.0234 - val_loss: 1.0134 - val_mean_squared_error: 1.0134\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01535 to 1.01338, saving model to temp/f109\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01338 to 1.01301, saving model to temp/f109\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0124 - val_mean_squared_error: 1.0124\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01301 to 1.01240, saving model to temp/f109\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0124 - val_mean_squared_error: 1.0124\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01240\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0084 - val_mean_squared_error: 1.0084\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.01240 to 1.00843, saving model to temp/f109\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0045 - val_mean_squared_error: 1.0045\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00843 to 1.00449, saving model to temp/f109\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0089 - mean_squared_error: 1.0089 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00449\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00449\n",
      "Epoch 00011: early stopping\n",
      "temp/f110\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1606 - mean_squared_error: 1.1606 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02072, saving model to temp/f110\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0214 - mean_squared_error: 1.0214 - val_loss: 1.0217 - val_mean_squared_error: 1.0217\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02072\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0220 - mean_squared_error: 1.0220 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02072 to 1.02015, saving model to temp/f110\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02015 to 1.01763, saving model to temp/f110\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01763 to 1.01004, saving model to temp/f110\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01004\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01004\n",
      "Epoch 00007: early stopping\n",
      "temp/f111\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1698 - mean_squared_error: 1.1698 - val_loss: 1.0206 - val_mean_squared_error: 1.0206\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02058, saving model to temp/f111\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0244 - val_mean_squared_error: 1.0244\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02058\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02058 to 1.01513, saving model to temp/f111\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0187 - mean_squared_error: 1.0187 - val_loss: 1.0180 - val_mean_squared_error: 1.0180\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01513\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0214 - val_mean_squared_error: 1.0214\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01513\n",
      "Epoch 00005: early stopping\n",
      "temp/f112\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1539 - mean_squared_error: 1.1539 - val_loss: 1.0279 - val_mean_squared_error: 1.0279\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02791, saving model to temp/f112\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0273 - mean_squared_error: 1.0273 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02791 to 1.02316, saving model to temp/f112\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0323 - val_mean_squared_error: 1.0323\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02316\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0165 - val_mean_squared_error: 1.0165\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02316 to 1.01654, saving model to temp/f112\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0150 - mean_squared_error: 1.0150 - val_loss: 1.0110 - val_mean_squared_error: 1.0110\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01654 to 1.01100, saving model to temp/f112\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01100\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01100\n",
      "Epoch 00007: early stopping\n",
      "temp/f113\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1834 - mean_squared_error: 1.1834 - val_loss: 1.0314 - val_mean_squared_error: 1.0314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03141, saving model to temp/f113\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0251 - mean_squared_error: 1.0251 - val_loss: 1.0227 - val_mean_squared_error: 1.0227\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03141 to 1.02272, saving model to temp/f113\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0236 - mean_squared_error: 1.0236 - val_loss: 1.0296 - val_mean_squared_error: 1.0296\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02272\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0163 - val_mean_squared_error: 1.0163\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02272 to 1.01628, saving model to temp/f113\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0156 - mean_squared_error: 1.0156 - val_loss: 1.0088 - val_mean_squared_error: 1.0088\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01628 to 1.00879, saving model to temp/f113\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0147 - mean_squared_error: 1.0147 - val_loss: 1.0398 - val_mean_squared_error: 1.0398\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00879\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00879\n",
      "Epoch 00007: early stopping\n",
      "temp/f114\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.1648 - mean_squared_error: 1.1648 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02549, saving model to temp/f114\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0312 - mean_squared_error: 1.0312 - val_loss: 1.0184 - val_mean_squared_error: 1.0184\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02549 to 1.01842, saving model to temp/f114\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01842\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01842 to 1.01574, saving model to temp/f114\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01574 to 1.01370, saving model to temp/f114\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 101us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0287 - val_mean_squared_error: 1.0287\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01370\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 99us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01370 to 1.00801, saving model to temp/f114\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00801\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0126 - mean_squared_error: 1.0126 - val_loss: 1.0074 - val_mean_squared_error: 1.0074\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00801 to 1.00738, saving model to temp/f114\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00738\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00738\n",
      "Epoch 00011: early stopping\n",
      "temp/f115\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.1702 - mean_squared_error: 1.1702 - val_loss: 1.0264 - val_mean_squared_error: 1.0264\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02640, saving model to temp/f115\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0234 - mean_squared_error: 1.0234 - val_loss: 1.0242 - val_mean_squared_error: 1.0242\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02640 to 1.02423, saving model to temp/f115\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0177 - mean_squared_error: 1.0177 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02423 to 1.01387, saving model to temp/f115\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0223 - mean_squared_error: 1.0223 - val_loss: 1.0310 - val_mean_squared_error: 1.0310\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01387\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01387 to 1.01144, saving model to temp/f115\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0088 - val_mean_squared_error: 1.0088\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01144 to 1.00877, saving model to temp/f115\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0104 - mean_squared_error: 1.0104 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00877\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0119 - mean_squared_error: 1.0119 - val_loss: 1.0315 - val_mean_squared_error: 1.0315\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00877\n",
      "Epoch 00008: early stopping\n",
      "temp/f116\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1562 - mean_squared_error: 1.1562 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02042, saving model to temp/f116\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0288 - mean_squared_error: 1.0288 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02042 to 1.01741, saving model to temp/f116\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0242 - mean_squared_error: 1.0242 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01741 to 1.01311, saving model to temp/f116\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01311\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01311 to 1.01176, saving model to temp/f116\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01176 to 1.00970, saving model to temp/f116\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0092 - val_mean_squared_error: 1.0092\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00970 to 1.00921, saving model to temp/f116\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0071 - val_mean_squared_error: 1.0071\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00921 to 1.00708, saving model to temp/f116\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0111 - mean_squared_error: 1.0111 - val_loss: 1.0072 - val_mean_squared_error: 1.0072\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00708\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00708\n",
      "Epoch 00010: early stopping\n",
      "temp/f117\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1694 - mean_squared_error: 1.1694 - val_loss: 1.0364 - val_mean_squared_error: 1.0364\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03643, saving model to temp/f117\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0256 - mean_squared_error: 1.0256 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03643 to 1.01995, saving model to temp/f117\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0163 - val_mean_squared_error: 1.0163\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01995 to 1.01635, saving model to temp/f117\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01635 to 1.01413, saving model to temp/f117\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01413\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01413 to 1.01351, saving model to temp/f117\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0139 - mean_squared_error: 1.0139 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01351 to 1.00798, saving model to temp/f117\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0144 - mean_squared_error: 1.0144 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00798 to 1.00614, saving model to temp/f117\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0020 - val_mean_squared_error: 1.0020\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00614 to 1.00205, saving model to temp/f117\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0092 - val_mean_squared_error: 1.0092\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00205\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0100 - mean_squared_error: 1.0100 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00205\n",
      "Epoch 00011: early stopping\n",
      "temp/f118\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.1559 - mean_squared_error: 1.1559 - val_loss: 1.0247 - val_mean_squared_error: 1.0247\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02468, saving model to temp/f118\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0242 - mean_squared_error: 1.0242 - val_loss: 1.0248 - val_mean_squared_error: 1.0248\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02468\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0205 - val_mean_squared_error: 1.0205\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02468 to 1.02046, saving model to temp/f118\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0247 - val_mean_squared_error: 1.0247\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02046\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.02046 to 1.00955, saving model to temp/f118\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0293 - val_mean_squared_error: 1.0293\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00955\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00955\n",
      "Epoch 00007: early stopping\n",
      "temp/f119\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.1642 - mean_squared_error: 1.1642 - val_loss: 1.0231 - val_mean_squared_error: 1.0231\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02310, saving model to temp/f119\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0270 - val_mean_squared_error: 1.0270\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02310\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0261 - mean_squared_error: 1.0261 - val_loss: 1.0169 - val_mean_squared_error: 1.0169\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02310 to 1.01690, saving model to temp/f119\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0223 - mean_squared_error: 1.0223 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01690\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01690\n",
      "Epoch 00005: early stopping\n",
      "temp/f120\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.1727 - mean_squared_error: 1.1727 - val_loss: 1.0381 - val_mean_squared_error: 1.0381\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03805, saving model to temp/f120\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0255 - mean_squared_error: 1.0255 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03805 to 1.01961, saving model to temp/f120\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0217 - val_mean_squared_error: 1.0217\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01961\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0261 - mean_squared_error: 1.0261 - val_loss: 1.0253 - val_mean_squared_error: 1.0253\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01961\n",
      "Epoch 00004: early stopping\n",
      "temp/f121\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1637 - mean_squared_error: 1.1637 - val_loss: 1.0522 - val_mean_squared_error: 1.0522\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05218, saving model to temp/f121\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0299 - mean_squared_error: 1.0299 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05218 to 1.01696, saving model to temp/f121\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01696 to 1.00848, saving model to temp/f121\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0217 - mean_squared_error: 1.0217 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00848\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0135 - mean_squared_error: 1.0135 - val_loss: 1.0072 - val_mean_squared_error: 1.0072\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.00848 to 1.00725, saving model to temp/f121\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0167 - val_mean_squared_error: 1.0167\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00725\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0079 - mean_squared_error: 1.0079 - val_loss: 1.0071 - val_mean_squared_error: 1.0071\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00725 to 1.00705, saving model to temp/f121\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00705\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0124 - mean_squared_error: 1.0124 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00705\n",
      "Epoch 00009: early stopping\n",
      "temp/f122\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1633 - mean_squared_error: 1.1633 - val_loss: 1.0333 - val_mean_squared_error: 1.0333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03330, saving model to temp/f122\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 99us/step - loss: 1.0258 - mean_squared_error: 1.0258 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03330 to 1.02724, saving model to temp/f122\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0253 - val_mean_squared_error: 1.0253\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02724 to 1.02530, saving model to temp/f122\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02530 to 1.01592, saving model to temp/f122\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01592 to 1.01265, saving model to temp/f122\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01265\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0126 - mean_squared_error: 1.0126 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01265\n",
      "Epoch 00007: early stopping\n",
      "temp/f123\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.1525 - mean_squared_error: 1.1525 - val_loss: 1.0301 - val_mean_squared_error: 1.0301\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03010, saving model to temp/f123\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0229 - mean_squared_error: 1.0229 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03010 to 1.01698, saving model to temp/f123\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01698 to 1.01353, saving model to temp/f123\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0271 - val_mean_squared_error: 1.0271\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01353\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01353\n",
      "Epoch 00005: early stopping\n",
      "temp/f124\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.1479 - mean_squared_error: 1.1479 - val_loss: 1.0307 - val_mean_squared_error: 1.0307\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03074, saving model to temp/f124\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03074 to 1.01978, saving model to temp/f124\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01978 to 1.01593, saving model to temp/f124\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0212 - mean_squared_error: 1.0212 - val_loss: 1.0098 - val_mean_squared_error: 1.0098\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01593 to 1.00981, saving model to temp/f124\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0071 - val_mean_squared_error: 1.0071\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.00981 to 1.00709, saving model to temp/f124\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00709\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0165 - mean_squared_error: 1.0165 - val_loss: 1.0064 - val_mean_squared_error: 1.0064\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00709 to 1.00641, saving model to temp/f124\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0051 - val_mean_squared_error: 1.0051\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00641 to 1.00507, saving model to temp/f124\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0024 - val_mean_squared_error: 1.0024\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00507 to 1.00238, saving model to temp/f124\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0084 - val_mean_squared_error: 1.0084\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00238\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 1.0085 - mean_squared_error: 1.0085 - val_loss: 1.0043 - val_mean_squared_error: 1.0043\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00238\n",
      "Epoch 00011: early stopping\n",
      "temp/f125\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.1817 - mean_squared_error: 1.1817 - val_loss: 1.0226 - val_mean_squared_error: 1.0226\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02264, saving model to temp/f125\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 1.0189 - val_mean_squared_error: 1.0189\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02264 to 1.01886, saving model to temp/f125\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0218 - mean_squared_error: 1.0218 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01886 to 1.01385, saving model to temp/f125\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 103us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01385 to 1.01175, saving model to temp/f125\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0150 - mean_squared_error: 1.0150 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01175\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0147 - mean_squared_error: 1.0147 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01175\n",
      "Epoch 00006: early stopping\n",
      "temp/f126\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.1707 - mean_squared_error: 1.1707 - val_loss: 1.0274 - val_mean_squared_error: 1.0274\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02736, saving model to temp/f126\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0303 - mean_squared_error: 1.0303 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02736 to 1.01695, saving model to temp/f126\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 89us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0178 - val_mean_squared_error: 1.0178\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01695\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 100us/step - loss: 1.0237 - mean_squared_error: 1.0237 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01695 to 1.01205, saving model to temp/f126\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0185 - mean_squared_error: 1.0185 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01205 to 1.01116, saving model to temp/f126\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01116 to 1.01008, saving model to temp/f126\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01008\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01008\n",
      "Epoch 00008: early stopping\n",
      "temp/f127\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1702 - mean_squared_error: 1.1702 - val_loss: 1.0291 - val_mean_squared_error: 1.0291\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02907, saving model to temp/f127\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0256 - mean_squared_error: 1.0256 - val_loss: 1.0246 - val_mean_squared_error: 1.0246\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02907 to 1.02456, saving model to temp/f127\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0267 - mean_squared_error: 1.0267 - val_loss: 1.0299 - val_mean_squared_error: 1.0299\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02456\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02456 to 1.01303, saving model to temp/f127\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01303 to 1.01153, saving model to temp/f127\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0081 - val_mean_squared_error: 1.0081\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01153 to 1.00806, saving model to temp/f127\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0113 - mean_squared_error: 1.0113 - val_loss: 1.0065 - val_mean_squared_error: 1.0065\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00806 to 1.00652, saving model to temp/f127\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00652\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0063 - val_mean_squared_error: 1.0063\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00652 to 1.00627, saving model to temp/f127\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0134 - mean_squared_error: 1.0134 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00627\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0077 - mean_squared_error: 1.0077 - val_loss: 1.0072 - val_mean_squared_error: 1.0072\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00627\n",
      "Epoch 00011: early stopping\n",
      "temp/f128\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1571 - mean_squared_error: 1.1571 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02317, saving model to temp/f128\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0285 - mean_squared_error: 1.0285 - val_loss: 1.0269 - val_mean_squared_error: 1.0269\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02317\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0299 - val_mean_squared_error: 1.0299\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02317\n",
      "Epoch 00003: early stopping\n",
      "temp/f129\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.1726 - mean_squared_error: 1.1726 - val_loss: 1.0303 - val_mean_squared_error: 1.0303\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03030, saving model to temp/f129\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0230 - mean_squared_error: 1.0230 - val_loss: 1.0185 - val_mean_squared_error: 1.0185\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03030 to 1.01851, saving model to temp/f129\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0205 - mean_squared_error: 1.0205 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01851\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01851 to 1.01615, saving model to temp/f129\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0182 - mean_squared_error: 1.0182 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01615 to 1.00970, saving model to temp/f129\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00970\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00970\n",
      "Epoch 00007: early stopping\n",
      "temp/f130\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1628 - mean_squared_error: 1.1628 - val_loss: 1.0436 - val_mean_squared_error: 1.0436\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.04356, saving model to temp/f130\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0239 - mean_squared_error: 1.0239 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.04356 to 1.01695, saving model to temp/f130\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0228 - mean_squared_error: 1.0228 - val_loss: 1.0226 - val_mean_squared_error: 1.0226\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01695\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0187 - mean_squared_error: 1.0187 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01695\n",
      "Epoch 00004: early stopping\n",
      "temp/f131\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1555 - mean_squared_error: 1.1555 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02372, saving model to temp/f131\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02372 to 1.01313, saving model to temp/f131\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.0165 - val_mean_squared_error: 1.0165\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01313\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01313 to 1.00612, saving model to temp/f131\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0184 - mean_squared_error: 1.0184 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00612\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00612\n",
      "Epoch 00006: early stopping\n",
      "temp/f132\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1671 - mean_squared_error: 1.1671 - val_loss: 1.0293 - val_mean_squared_error: 1.0293\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02930, saving model to temp/f132\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0258 - mean_squared_error: 1.0258 - val_loss: 1.0224 - val_mean_squared_error: 1.0224\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02930 to 1.02241, saving model to temp/f132\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0283 - val_mean_squared_error: 1.0283\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02241\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02241 to 1.01958, saving model to temp/f132\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0231 - val_mean_squared_error: 1.0231\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01958\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0088 - val_mean_squared_error: 1.0088\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01958 to 1.00880, saving model to temp/f132\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0213 - val_mean_squared_error: 1.0213\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00880\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0150 - mean_squared_error: 1.0150 - val_loss: 1.0059 - val_mean_squared_error: 1.0059\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00880 to 1.00592, saving model to temp/f132\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0101 - mean_squared_error: 1.0101 - val_loss: 1.0035 - val_mean_squared_error: 1.0035\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00592 to 1.00352, saving model to temp/f132\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0134 - val_mean_squared_error: 1.0134\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00352\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0114 - mean_squared_error: 1.0114 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00352\n",
      "Epoch 00011: early stopping\n",
      "temp/f133\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1468 - mean_squared_error: 1.1468 - val_loss: 1.0248 - val_mean_squared_error: 1.0248\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02481, saving model to temp/f133\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0251 - mean_squared_error: 1.0251 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02481 to 1.01864, saving model to temp/f133\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0228 - mean_squared_error: 1.0228 - val_loss: 1.0242 - val_mean_squared_error: 1.0242\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01864\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0207 - mean_squared_error: 1.0207 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01864 to 1.01468, saving model to temp/f133\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0089 - val_mean_squared_error: 1.0089\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01468 to 1.00895, saving model to temp/f133\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00895\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0083 - val_mean_squared_error: 1.0083\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00895 to 1.00831, saving model to temp/f133\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0089 - mean_squared_error: 1.0089 - val_loss: 1.0218 - val_mean_squared_error: 1.0218\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00831\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0105 - mean_squared_error: 1.0105 - val_loss: 1.0085 - val_mean_squared_error: 1.0085\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00831\n",
      "Epoch 00009: early stopping\n",
      "temp/f134\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 1.1795 - mean_squared_error: 1.1795 - val_loss: 1.0253 - val_mean_squared_error: 1.0253\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02528, saving model to temp/f134\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0250 - mean_squared_error: 1.0250 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02528 to 1.01610, saving model to temp/f134\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01610 to 1.01269, saving model to temp/f134\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01269\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0162 - val_mean_squared_error: 1.0162\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01269\n",
      "Epoch 00005: early stopping\n",
      "temp/f135\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1596 - mean_squared_error: 1.1596 - val_loss: 1.0205 - val_mean_squared_error: 1.0205\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02052, saving model to temp/f135\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0243 - mean_squared_error: 1.0243 - val_loss: 1.0283 - val_mean_squared_error: 1.0283\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02052\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02052 to 1.01813, saving model to temp/f135\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01813 to 1.01044, saving model to temp/f135\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01044 to 1.00951, saving model to temp/f135\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0139 - mean_squared_error: 1.0139 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00951\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0194 - val_mean_squared_error: 1.0194\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00951\n",
      "Epoch 00007: early stopping\n",
      "temp/f136\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 1.1516 - mean_squared_error: 1.1516 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01907, saving model to temp/f136\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0289 - mean_squared_error: 1.0289 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01907 to 1.01857, saving model to temp/f136\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0234 - mean_squared_error: 1.0234 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01857 to 1.01362, saving model to temp/f136\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0326 - val_mean_squared_error: 1.0326\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01362\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01362 to 1.00760, saving model to temp/f136\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00760\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00760\n",
      "Epoch 00007: early stopping\n",
      "temp/f137\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1814 - mean_squared_error: 1.1814 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01859, saving model to temp/f137\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0253 - mean_squared_error: 1.0253 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01859 to 1.01814, saving model to temp/f137\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0188 - mean_squared_error: 1.0188 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01814\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0147 - mean_squared_error: 1.0147 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01814 to 1.01521, saving model to temp/f137\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0090 - val_mean_squared_error: 1.0090\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01521 to 1.00898, saving model to temp/f137\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0249 - val_mean_squared_error: 1.0249\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00898\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0108 - mean_squared_error: 1.0108 - val_loss: 1.0070 - val_mean_squared_error: 1.0070\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00898 to 1.00701, saving model to temp/f137\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0168 - val_mean_squared_error: 1.0168\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00701\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0043 - val_mean_squared_error: 1.0043\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00701 to 1.00430, saving model to temp/f137\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0098 - mean_squared_error: 1.0098 - val_loss: 1.0049 - val_mean_squared_error: 1.0049\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00430\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0069 - mean_squared_error: 1.0069 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00430\n",
      "Epoch 00011: early stopping\n",
      "temp/f138\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1590 - mean_squared_error: 1.1590 - val_loss: 1.0270 - val_mean_squared_error: 1.0270\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02699, saving model to temp/f138\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0241 - mean_squared_error: 1.0241 - val_loss: 1.0171 - val_mean_squared_error: 1.0171\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02699 to 1.01707, saving model to temp/f138\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01707 to 1.01174, saving model to temp/f138\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0203 - val_mean_squared_error: 1.0203\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01174\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0191 - val_mean_squared_error: 1.0191\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01174\n",
      "Epoch 00005: early stopping\n",
      "temp/f139\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.1454 - mean_squared_error: 1.1454 - val_loss: 1.0323 - val_mean_squared_error: 1.0323\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03232, saving model to temp/f139\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0224 - val_mean_squared_error: 1.0224\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03232 to 1.02236, saving model to temp/f139\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0264 - mean_squared_error: 1.0264 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02236 to 1.01292, saving model to temp/f139\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0295 - val_mean_squared_error: 1.0295\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01292\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01292 to 1.01011, saving model to temp/f139\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01011\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0077 - val_mean_squared_error: 1.0077\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01011 to 1.00768, saving model to temp/f139\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0091 - mean_squared_error: 1.0091 - val_loss: 1.0090 - val_mean_squared_error: 1.0090\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00768\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0130 - mean_squared_error: 1.0130 - val_loss: 1.0083 - val_mean_squared_error: 1.0083\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00768\n",
      "Epoch 00009: early stopping\n",
      "temp/f140\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 1.1661 - mean_squared_error: 1.1661 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01864, saving model to temp/f140\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0282 - mean_squared_error: 1.0282 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.01864 to 1.01702, saving model to temp/f140\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0167 - val_mean_squared_error: 1.0167\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01702 to 1.01672, saving model to temp/f140\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0068 - val_mean_squared_error: 1.0068\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01672 to 1.00676, saving model to temp/f140\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0109 - val_mean_squared_error: 1.0109\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00676\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00676 to 1.00607, saving model to temp/f140\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0108 - mean_squared_error: 1.0108 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00607\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0023 - val_mean_squared_error: 1.0023\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00607 to 1.00233, saving model to temp/f140\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0056 - mean_squared_error: 1.0056 - val_loss: 1.0107 - val_mean_squared_error: 1.0107\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00233\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0077 - mean_squared_error: 1.0077 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00233\n",
      "Epoch 00010: early stopping\n",
      "temp/f141\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1576 - mean_squared_error: 1.1576 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02067, saving model to temp/f141\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0161 - val_mean_squared_error: 1.0161\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02067 to 1.01608, saving model to temp/f141\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0210 - mean_squared_error: 1.0210 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01608\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0121 - val_mean_squared_error: 1.0121\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01608 to 1.01210, saving model to temp/f141\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0192 - mean_squared_error: 1.0192 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01210 to 1.00778, saving model to temp/f141\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00778\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00778\n",
      "Epoch 00007: early stopping\n",
      "temp/f142\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1692 - mean_squared_error: 1.1692 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01991, saving model to temp/f142\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0231 - val_mean_squared_error: 1.0231\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01991\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0241 - mean_squared_error: 1.0241 - val_loss: 1.0258 - val_mean_squared_error: 1.0258\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01991\n",
      "Epoch 00003: early stopping\n",
      "temp/f143\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1605 - mean_squared_error: 1.1605 - val_loss: 1.0301 - val_mean_squared_error: 1.0301\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03013, saving model to temp/f143\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0289 - mean_squared_error: 1.0289 - val_loss: 1.0284 - val_mean_squared_error: 1.0284\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03013 to 1.02836, saving model to temp/f143\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0212 - mean_squared_error: 1.0212 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02836 to 1.01736, saving model to temp/f143\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0144 - val_mean_squared_error: 1.0144\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01736 to 1.01445, saving model to temp/f143\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01445 to 1.01371, saving model to temp/f143\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0083 - val_mean_squared_error: 1.0083\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01371 to 1.00831, saving model to temp/f143\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0115 - val_mean_squared_error: 1.0115\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00831\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0111 - mean_squared_error: 1.0111 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00831\n",
      "Epoch 00008: early stopping\n",
      "temp/f144\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.1593 - mean_squared_error: 1.1593 - val_loss: 1.0299 - val_mean_squared_error: 1.0299\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02987, saving model to temp/f144\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 1.02987 to 1.01978, saving model to temp/f144\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0218 - mean_squared_error: 1.0218 - val_loss: 1.0205 - val_mean_squared_error: 1.0205\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01978\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0211 - val_mean_squared_error: 1.0211\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01978\n",
      "Epoch 00004: early stopping\n",
      "temp/f145\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1446 - mean_squared_error: 1.1446 - val_loss: 1.0246 - val_mean_squared_error: 1.0246\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02459, saving model to temp/f145\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0227 - mean_squared_error: 1.0227 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02459 to 1.01390, saving model to temp/f145\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01390\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01390 to 1.00947, saving model to temp/f145\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00947\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0089 - val_mean_squared_error: 1.0089\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00947 to 1.00891, saving model to temp/f145\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0116 - mean_squared_error: 1.0116 - val_loss: 1.0067 - val_mean_squared_error: 1.0067\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00891 to 1.00666, saving model to temp/f145\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00666\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0127 - mean_squared_error: 1.0127 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00666\n",
      "Epoch 00009: early stopping\n",
      "temp/f146\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.1594 - mean_squared_error: 1.1594 - val_loss: 1.0240 - val_mean_squared_error: 1.0240\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02400, saving model to temp/f146\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02400 to 1.01762, saving model to temp/f146\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01762 to 1.01722, saving model to temp/f146\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01722 to 1.01196, saving model to temp/f146\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01196\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0124 - mean_squared_error: 1.0124 - val_loss: 1.0190 - val_mean_squared_error: 1.0190\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01196\n",
      "Epoch 00006: early stopping\n",
      "temp/f147\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 1.1459 - mean_squared_error: 1.1459 - val_loss: 1.0257 - val_mean_squared_error: 1.0257\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02568, saving model to temp/f147\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0246 - mean_squared_error: 1.0246 - val_loss: 1.0226 - val_mean_squared_error: 1.0226\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02568 to 1.02262, saving model to temp/f147\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 1.0206 - val_mean_squared_error: 1.0206\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02262 to 1.02060, saving model to temp/f147\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0304 - val_mean_squared_error: 1.0304\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02060\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0147 - mean_squared_error: 1.0147 - val_loss: 1.0295 - val_mean_squared_error: 1.0295\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.02060\n",
      "Epoch 00005: early stopping\n",
      "temp/f148\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1448 - mean_squared_error: 1.1448 - val_loss: 1.0398 - val_mean_squared_error: 1.0398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03981, saving model to temp/f148\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0284 - val_mean_squared_error: 1.0284\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03981 to 1.02841, saving model to temp/f148\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0249 - mean_squared_error: 1.0249 - val_loss: 1.0186 - val_mean_squared_error: 1.0186\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02841 to 1.01856, saving model to temp/f148\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0143 - val_mean_squared_error: 1.0143\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01856 to 1.01433, saving model to temp/f148\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0240 - val_mean_squared_error: 1.0240\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01433\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01433 to 1.01083, saving model to temp/f148\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0120 - mean_squared_error: 1.0120 - val_loss: 1.0113 - val_mean_squared_error: 1.0113\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01083\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01083\n",
      "Epoch 00008: early stopping\n",
      "temp/f149\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1818 - mean_squared_error: 1.1818 - val_loss: 1.0278 - val_mean_squared_error: 1.0278\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02782, saving model to temp/f149\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0252 - mean_squared_error: 1.0252 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02782 to 1.01642, saving model to temp/f149\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0225 - mean_squared_error: 1.0225 - val_loss: 1.0259 - val_mean_squared_error: 1.0259\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01642\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0220 - mean_squared_error: 1.0220 - val_loss: 1.0146 - val_mean_squared_error: 1.0146\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01642 to 1.01460, saving model to temp/f149\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0162 - val_mean_squared_error: 1.0162\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01460\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0158 - val_mean_squared_error: 1.0158\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01460\n",
      "Epoch 00006: early stopping\n",
      "temp/f150\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1714 - mean_squared_error: 1.1714 - val_loss: 1.0335 - val_mean_squared_error: 1.0335\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03354, saving model to temp/f150\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0275 - mean_squared_error: 1.0275 - val_loss: 1.0294 - val_mean_squared_error: 1.0294\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03354 to 1.02938, saving model to temp/f150\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0332 - val_mean_squared_error: 1.0332\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02938\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02938 to 1.01809, saving model to temp/f150\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0183 - mean_squared_error: 1.0183 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01809 to 1.01539, saving model to temp/f150\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01539 to 1.01355, saving model to temp/f150\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0107 - mean_squared_error: 1.0107 - val_loss: 1.0087 - val_mean_squared_error: 1.0087\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01355 to 1.00868, saving model to temp/f150\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00868\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0067 - val_mean_squared_error: 1.0067\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00868 to 1.00672, saving model to temp/f150\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0097 - mean_squared_error: 1.0097 - val_loss: 1.0069 - val_mean_squared_error: 1.0069\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00672\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0094 - mean_squared_error: 1.0094 - val_loss: 1.0249 - val_mean_squared_error: 1.0249\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00672\n",
      "Epoch 00011: early stopping\n",
      "temp/f151\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1603 - mean_squared_error: 1.1603 - val_loss: 1.0254 - val_mean_squared_error: 1.0254\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02535, saving model to temp/f151\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0239 - mean_squared_error: 1.0239 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02535 to 1.02387, saving model to temp/f151\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0236 - mean_squared_error: 1.0236 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02387 to 1.02084, saving model to temp/f151\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0111 - val_mean_squared_error: 1.0111\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02084 to 1.01115, saving model to temp/f151\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0082 - val_mean_squared_error: 1.0082\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01115 to 1.00816, saving model to temp/f151\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 1.0079 - val_mean_squared_error: 1.0079\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00816 to 1.00789, saving model to temp/f151\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00789\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0134 - mean_squared_error: 1.0134 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00789 to 1.00606, saving model to temp/f151\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0109 - mean_squared_error: 1.0109 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00606\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0073 - val_mean_squared_error: 1.0073\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00606\n",
      "Epoch 00010: early stopping\n",
      "temp/f152\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1497 - mean_squared_error: 1.1497 - val_loss: 1.0295 - val_mean_squared_error: 1.0295\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02948, saving model to temp/f152\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0246 - mean_squared_error: 1.0246 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02948 to 1.01032, saving model to temp/f152\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 125us/step - loss: 1.0268 - mean_squared_error: 1.0268 - val_loss: 1.0261 - val_mean_squared_error: 1.0261\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01032\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01032\n",
      "Epoch 00004: early stopping\n",
      "temp/f153\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 1.1660 - mean_squared_error: 1.1660 - val_loss: 1.0236 - val_mean_squared_error: 1.0236\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02360, saving model to temp/f153\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02360 to 1.01036, saving model to temp/f153\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0202 - mean_squared_error: 1.0202 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01036\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0112 - val_mean_squared_error: 1.0112\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01036\n",
      "Epoch 00004: early stopping\n",
      "temp/f154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 1.1516 - mean_squared_error: 1.1516 - val_loss: 1.0264 - val_mean_squared_error: 1.0264\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02639, saving model to temp/f154\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 1.0551 - val_mean_squared_error: 1.0551\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02639\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0198 - mean_squared_error: 1.0198 - val_loss: 1.0195 - val_mean_squared_error: 1.0195\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02639 to 1.01954, saving model to temp/f154\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01954 to 1.01016, saving model to temp/f154\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0159 - mean_squared_error: 1.0159 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01016\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0099 - mean_squared_error: 1.0099 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01016 to 1.00954, saving model to temp/f154\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0089 - mean_squared_error: 1.0089 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00954 to 1.00606, saving model to temp/f154\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0090 - mean_squared_error: 1.0090 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00606\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0111 - mean_squared_error: 1.0111 - val_loss: 1.0419 - val_mean_squared_error: 1.0419\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00606\n",
      "Epoch 00009: early stopping\n",
      "temp/f155\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1693 - mean_squared_error: 1.1693 - val_loss: 1.0204 - val_mean_squared_error: 1.0204\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02043, saving model to temp/f155\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0277 - mean_squared_error: 1.0277 - val_loss: 1.0184 - val_mean_squared_error: 1.0184\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02043 to 1.01843, saving model to temp/f155\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0148 - val_mean_squared_error: 1.0148\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01843 to 1.01479, saving model to temp/f155\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01479 to 1.01372, saving model to temp/f155\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0138 - val_mean_squared_error: 1.0138\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01372\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0128 - mean_squared_error: 1.0128 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01372\n",
      "Epoch 00006: early stopping\n",
      "temp/f156\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1467 - mean_squared_error: 1.1467 - val_loss: 1.0321 - val_mean_squared_error: 1.0321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03210, saving model to temp/f156\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0257 - mean_squared_error: 1.0257 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03210 to 1.01274, saving model to temp/f156\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0227 - mean_squared_error: 1.0227 - val_loss: 1.0145 - val_mean_squared_error: 1.0145\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01274\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0215 - mean_squared_error: 1.0215 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01274\n",
      "Epoch 00004: early stopping\n",
      "temp/f157\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1421 - mean_squared_error: 1.1421 - val_loss: 1.0313 - val_mean_squared_error: 1.0313\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03128, saving model to temp/f157\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0216 - mean_squared_error: 1.0216 - val_loss: 1.0323 - val_mean_squared_error: 1.0323\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03128\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0348 - val_mean_squared_error: 1.0348\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.03128\n",
      "Epoch 00003: early stopping\n",
      "temp/f158\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1643 - mean_squared_error: 1.1643 - val_loss: 1.0317 - val_mean_squared_error: 1.0317\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03168, saving model to temp/f158\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0288 - mean_squared_error: 1.0288 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03168 to 1.01357, saving model to temp/f158\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0210 - mean_squared_error: 1.0210 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01357\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0169 - mean_squared_error: 1.0169 - val_loss: 1.0124 - val_mean_squared_error: 1.0124\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01357 to 1.01243, saving model to temp/f158\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0079 - val_mean_squared_error: 1.0079\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01243 to 1.00789, saving model to temp/f158\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0180 - val_mean_squared_error: 1.0180\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00789\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00789\n",
      "Epoch 00007: early stopping\n",
      "temp/f159\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1666 - mean_squared_error: 1.1666 - val_loss: 1.0265 - val_mean_squared_error: 1.0265\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02651, saving model to temp/f159\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0216 - mean_squared_error: 1.0216 - val_loss: 1.0222 - val_mean_squared_error: 1.0222\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02651 to 1.02215, saving model to temp/f159\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02215 to 1.01695, saving model to temp/f159\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01695 to 1.00974, saving model to temp/f159\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.00974 to 1.00959, saving model to temp/f159\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0258 - val_mean_squared_error: 1.0258\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00959\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0120 - mean_squared_error: 1.0120 - val_loss: 1.0184 - val_mean_squared_error: 1.0184\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00959\n",
      "Epoch 00007: early stopping\n",
      "temp/f160\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1612 - mean_squared_error: 1.1612 - val_loss: 1.0246 - val_mean_squared_error: 1.0246\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02463, saving model to temp/f160\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0240 - mean_squared_error: 1.0240 - val_loss: 1.0116 - val_mean_squared_error: 1.0116\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02463 to 1.01163, saving model to temp/f160\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0125 - val_mean_squared_error: 1.0125\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01163\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01163\n",
      "Epoch 00004: early stopping\n",
      "temp/f161\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 1.1575 - mean_squared_error: 1.1575 - val_loss: 1.0311 - val_mean_squared_error: 1.0311\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03110, saving model to temp/f161\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0313 - mean_squared_error: 1.0313 - val_loss: 1.0200 - val_mean_squared_error: 1.0200\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03110 to 1.01995, saving model to temp/f161\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0191 - mean_squared_error: 1.0191 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01995 to 1.01723, saving model to temp/f161\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0182 - val_mean_squared_error: 1.0182\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01723\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0153 - mean_squared_error: 1.0153 - val_loss: 1.0181 - val_mean_squared_error: 1.0181\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01723\n",
      "Epoch 00005: early stopping\n",
      "temp/f162\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 1.1761 - mean_squared_error: 1.1761 - val_loss: 1.0219 - val_mean_squared_error: 1.0219\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02189, saving model to temp/f162\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0236 - mean_squared_error: 1.0236 - val_loss: 1.0297 - val_mean_squared_error: 1.0297\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02189\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0213 - val_mean_squared_error: 1.0213\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02189 to 1.02130, saving model to temp/f162\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0192 - mean_squared_error: 1.0192 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02130 to 1.01412, saving model to temp/f162\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0187 - val_mean_squared_error: 1.0187\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01412\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0166 - val_mean_squared_error: 1.0166\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01412\n",
      "Epoch 00006: early stopping\n",
      "temp/f163\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1653 - mean_squared_error: 1.1653 - val_loss: 1.0267 - val_mean_squared_error: 1.0267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02674, saving model to temp/f163\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0264 - mean_squared_error: 1.0264 - val_loss: 1.0264 - val_mean_squared_error: 1.0264\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02674 to 1.02635, saving model to temp/f163\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0223 - mean_squared_error: 1.0223 - val_loss: 1.0162 - val_mean_squared_error: 1.0162\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02635 to 1.01618, saving model to temp/f163\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0122 - val_mean_squared_error: 1.0122\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01618 to 1.01218, saving model to temp/f163\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0075 - val_mean_squared_error: 1.0075\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01218 to 1.00748, saving model to temp/f163\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0195 - val_mean_squared_error: 1.0195\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00748\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00748\n",
      "Epoch 00007: early stopping\n",
      "temp/f164\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1599 - mean_squared_error: 1.1599 - val_loss: 1.0369 - val_mean_squared_error: 1.0369\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03687, saving model to temp/f164\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0269 - mean_squared_error: 1.0269 - val_loss: 1.0162 - val_mean_squared_error: 1.0162\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03687 to 1.01625, saving model to temp/f164\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0188 - mean_squared_error: 1.0188 - val_loss: 1.0330 - val_mean_squared_error: 1.0330\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01625\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0208 - mean_squared_error: 1.0208 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01625\n",
      "Epoch 00004: early stopping\n",
      "temp/f165\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.1745 - mean_squared_error: 1.1745 - val_loss: 1.0240 - val_mean_squared_error: 1.0240\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02399, saving model to temp/f165\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0277 - mean_squared_error: 1.0277 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02399 to 1.02148, saving model to temp/f165\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0251 - mean_squared_error: 1.0251 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02148\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0195 - val_mean_squared_error: 1.0195\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02148 to 1.01953, saving model to temp/f165\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0152 - mean_squared_error: 1.0152 - val_loss: 1.0140 - val_mean_squared_error: 1.0140\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01953 to 1.01401, saving model to temp/f165\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01401 to 1.01011, saving model to temp/f165\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0153 - val_mean_squared_error: 1.0153\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01011\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0119 - mean_squared_error: 1.0119 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01011\n",
      "Epoch 00008: early stopping\n",
      "temp/f166\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 1.1525 - mean_squared_error: 1.1525 - val_loss: 1.0305 - val_mean_squared_error: 1.0305\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03045, saving model to temp/f166\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0284 - mean_squared_error: 1.0284 - val_loss: 1.0235 - val_mean_squared_error: 1.0235\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03045 to 1.02354, saving model to temp/f166\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02354 to 1.01081, saving model to temp/f166\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0214 - mean_squared_error: 1.0214 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01081 to 1.01000, saving model to temp/f166\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01000\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0118 - mean_squared_error: 1.0118 - val_loss: 1.0127 - val_mean_squared_error: 1.0127\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01000\n",
      "Epoch 00006: early stopping\n",
      "temp/f167\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1544 - mean_squared_error: 1.1544 - val_loss: 1.0290 - val_mean_squared_error: 1.0290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02895, saving model to temp/f167\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02895 to 1.01080, saving model to temp/f167\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01080\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0114 - val_mean_squared_error: 1.0114\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01080\n",
      "Epoch 00004: early stopping\n",
      "temp/f168\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1909 - mean_squared_error: 1.1909 - val_loss: 1.0366 - val_mean_squared_error: 1.0366\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03659, saving model to temp/f168\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0279 - mean_squared_error: 1.0279 - val_loss: 1.0280 - val_mean_squared_error: 1.0280\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03659 to 1.02795, saving model to temp/f168\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0255 - mean_squared_error: 1.0255 - val_loss: 1.0250 - val_mean_squared_error: 1.0250\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02795 to 1.02501, saving model to temp/f168\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02501 to 1.02287, saving model to temp/f168\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0190 - val_mean_squared_error: 1.0190\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.02287 to 1.01896, saving model to temp/f168\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0107 - val_mean_squared_error: 1.0107\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01896 to 1.01072, saving model to temp/f168\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0055 - val_mean_squared_error: 1.0055\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01072 to 1.00554, saving model to temp/f168\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0092 - mean_squared_error: 1.0092 - val_loss: 1.0050 - val_mean_squared_error: 1.0050\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00554 to 1.00501, saving model to temp/f168\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0115 - mean_squared_error: 1.0115 - val_loss: 1.0147 - val_mean_squared_error: 1.0147\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00501\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0110 - mean_squared_error: 1.0110 - val_loss: 1.0050 - val_mean_squared_error: 1.0050\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00501 to 1.00500, saving model to temp/f168\n",
      "Epoch 00010: early stopping\n",
      "temp/f169\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1439 - mean_squared_error: 1.1439 - val_loss: 1.0200 - val_mean_squared_error: 1.0200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02004, saving model to temp/f169\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0289 - mean_squared_error: 1.0289 - val_loss: 1.0291 - val_mean_squared_error: 1.0291\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02004\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0297 - mean_squared_error: 1.0297 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02004\n",
      "Epoch 00003: early stopping\n",
      "temp/f170\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1680 - mean_squared_error: 1.1680 - val_loss: 1.0240 - val_mean_squared_error: 1.0240\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02401, saving model to temp/f170\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0281 - mean_squared_error: 1.0281 - val_loss: 1.0177 - val_mean_squared_error: 1.0177\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02401 to 1.01766, saving model to temp/f170\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0225 - mean_squared_error: 1.0225 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01766\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0230 - mean_squared_error: 1.0230 - val_loss: 1.0198 - val_mean_squared_error: 1.0198\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01766\n",
      "Epoch 00004: early stopping\n",
      "temp/f171\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 1.1611 - mean_squared_error: 1.1611 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02715, saving model to temp/f171\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0205 - mean_squared_error: 1.0205 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02715 to 1.01716, saving model to temp/f171\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0202 - val_mean_squared_error: 1.0202\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01716\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0155 - mean_squared_error: 1.0155 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01716 to 1.01600, saving model to temp/f171\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01600 to 1.01358, saving model to temp/f171\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0176 - mean_squared_error: 1.0176 - val_loss: 1.0216 - val_mean_squared_error: 1.0216\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01358\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01358\n",
      "Epoch 00007: early stopping\n",
      "temp/f172\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.1540 - mean_squared_error: 1.1540 - val_loss: 1.0203 - val_mean_squared_error: 1.0203\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02032, saving model to temp/f172\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0280 - mean_squared_error: 1.0280 - val_loss: 1.0228 - val_mean_squared_error: 1.0228\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02032\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0226 - mean_squared_error: 1.0226 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02032 to 1.01833, saving model to temp/f172\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0153 - mean_squared_error: 1.0153 - val_loss: 1.0097 - val_mean_squared_error: 1.0097\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01833 to 1.00970, saving model to temp/f172\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0144 - mean_squared_error: 1.0144 - val_loss: 1.0200 - val_mean_squared_error: 1.0200\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00970\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0110 - val_mean_squared_error: 1.0110\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00970\n",
      "Epoch 00006: early stopping\n",
      "temp/f173\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.1449 - mean_squared_error: 1.1449 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02389, saving model to temp/f173\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02389 to 1.02370, saving model to temp/f173\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0269 - mean_squared_error: 1.0269 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02370 to 1.01001, saving model to temp/f173\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0089 - val_mean_squared_error: 1.0089\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01001 to 1.00889, saving model to temp/f173\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0175 - mean_squared_error: 1.0175 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00889\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0119 - mean_squared_error: 1.0119 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00889\n",
      "Epoch 00006: early stopping\n",
      "temp/f174\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1624 - mean_squared_error: 1.1624 - val_loss: 1.0265 - val_mean_squared_error: 1.0265\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02649, saving model to temp/f174\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0217 - mean_squared_error: 1.0217 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02649 to 1.02393, saving model to temp/f174\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0193 - val_mean_squared_error: 1.0193\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02393 to 1.01928, saving model to temp/f174\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01928 to 1.01487, saving model to temp/f174\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0214 - val_mean_squared_error: 1.0214\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01487\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0193 - mean_squared_error: 1.0193 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01487\n",
      "Epoch 00006: early stopping\n",
      "temp/f175\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1638 - mean_squared_error: 1.1638 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02388, saving model to temp/f175\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.0245 - val_mean_squared_error: 1.0245\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02388\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0235 - mean_squared_error: 1.0235 - val_loss: 1.0141 - val_mean_squared_error: 1.0141\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02388 to 1.01411, saving model to temp/f175\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0157 - val_mean_squared_error: 1.0157\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01411\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 1.0086 - val_mean_squared_error: 1.0086\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01411 to 1.00859, saving model to temp/f175\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0101 - mean_squared_error: 1.0101 - val_loss: 1.0100 - val_mean_squared_error: 1.0100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00859\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00859\n",
      "Epoch 00007: early stopping\n",
      "temp/f176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 1.1814 - mean_squared_error: 1.1814 - val_loss: 1.0331 - val_mean_squared_error: 1.0331\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03313, saving model to temp/f176\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0278 - mean_squared_error: 1.0278 - val_loss: 1.0300 - val_mean_squared_error: 1.0300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03313 to 1.03001, saving model to temp/f176\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0233 - mean_squared_error: 1.0233 - val_loss: 1.0167 - val_mean_squared_error: 1.0167\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03001 to 1.01666, saving model to temp/f176\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0195 - mean_squared_error: 1.0195 - val_loss: 1.0138 - val_mean_squared_error: 1.0138\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01666 to 1.01381, saving model to temp/f176\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0195 - mean_squared_error: 1.0195 - val_loss: 1.0125 - val_mean_squared_error: 1.0125\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01381 to 1.01255, saving model to temp/f176\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0150 - mean_squared_error: 1.0150 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01255 to 1.01200, saving model to temp/f176\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0106 - mean_squared_error: 1.0106 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01200\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01200\n",
      "Epoch 00008: early stopping\n",
      "temp/f177\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1656 - mean_squared_error: 1.1656 - val_loss: 1.0324 - val_mean_squared_error: 1.0324\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03239, saving model to temp/f177\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0341 - mean_squared_error: 1.0341 - val_loss: 1.0155 - val_mean_squared_error: 1.0155\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03239 to 1.01547, saving model to temp/f177\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0196 - mean_squared_error: 1.0196 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01547\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0276 - val_mean_squared_error: 1.0276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01547\n",
      "Epoch 00004: early stopping\n",
      "temp/f178\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1752 - mean_squared_error: 1.1752 - val_loss: 1.0320 - val_mean_squared_error: 1.0320\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03195, saving model to temp/f178\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0232 - mean_squared_error: 1.0232 - val_loss: 1.0246 - val_mean_squared_error: 1.0246\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03195 to 1.02459, saving model to temp/f178\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.0210 - val_mean_squared_error: 1.0210\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02459 to 1.02100, saving model to temp/f178\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02100 to 1.01255, saving model to temp/f178\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0138 - mean_squared_error: 1.0138 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01255\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0146 - val_mean_squared_error: 1.0146\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01255\n",
      "Epoch 00006: early stopping\n",
      "temp/f179\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1491 - mean_squared_error: 1.1491 - val_loss: 1.0216 - val_mean_squared_error: 1.0216\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02164, saving model to temp/f179\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0238 - mean_squared_error: 1.0238 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02164\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02164 to 1.00938, saving model to temp/f179\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.00938\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0129 - mean_squared_error: 1.0129 - val_loss: 1.0165 - val_mean_squared_error: 1.0165\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.00938\n",
      "Epoch 00005: early stopping\n",
      "temp/f180\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 1.1636 - mean_squared_error: 1.1636 - val_loss: 1.0291 - val_mean_squared_error: 1.0291\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02914, saving model to temp/f180\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.0233 - val_mean_squared_error: 1.0233\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02914 to 1.02334, saving model to temp/f180\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0238 - mean_squared_error: 1.0238 - val_loss: 1.0148 - val_mean_squared_error: 1.0148\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02334 to 1.01476, saving model to temp/f180\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01476\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01476\n",
      "Epoch 00005: early stopping\n",
      "temp/f181\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1631 - mean_squared_error: 1.1631 - val_loss: 1.0244 - val_mean_squared_error: 1.0244\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02441, saving model to temp/f181\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0197 - mean_squared_error: 1.0197 - val_loss: 1.0267 - val_mean_squared_error: 1.0267\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02441\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0173 - val_mean_squared_error: 1.0173\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02441 to 1.01735, saving model to temp/f181\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01735 to 1.01393, saving model to temp/f181\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0179 - mean_squared_error: 1.0179 - val_loss: 1.0180 - val_mean_squared_error: 1.0180\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01393\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01393\n",
      "Epoch 00006: early stopping\n",
      "temp/f182\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1601 - mean_squared_error: 1.1601 - val_loss: 1.0330 - val_mean_squared_error: 1.0330\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03302, saving model to temp/f182\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0247 - mean_squared_error: 1.0247 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03302 to 1.02009, saving model to temp/f182\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0195 - val_mean_squared_error: 1.0195\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02009 to 1.01949, saving model to temp/f182\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0262 - mean_squared_error: 1.0262 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01949 to 1.01259, saving model to temp/f182\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0185 - mean_squared_error: 1.0185 - val_loss: 1.0174 - val_mean_squared_error: 1.0174\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01259\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0149 - val_mean_squared_error: 1.0149\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01259\n",
      "Epoch 00006: early stopping\n",
      "temp/f183\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1618 - mean_squared_error: 1.1618 - val_loss: 1.0263 - val_mean_squared_error: 1.0263\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02629, saving model to temp/f183\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0237 - mean_squared_error: 1.0237 - val_loss: 1.0201 - val_mean_squared_error: 1.0201\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02629 to 1.02012, saving model to temp/f183\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0219 - mean_squared_error: 1.0219 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02012\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0181 - mean_squared_error: 1.0181 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02012 to 1.01181, saving model to temp/f183\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0245 - val_mean_squared_error: 1.0245\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01181\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0061 - val_mean_squared_error: 1.0061\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01181 to 1.00608, saving model to temp/f183\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0145 - mean_squared_error: 1.0145 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00608\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0140 - mean_squared_error: 1.0140 - val_loss: 1.0102 - val_mean_squared_error: 1.0102\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00608\n",
      "Epoch 00008: early stopping\n",
      "temp/f184\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1521 - mean_squared_error: 1.1521 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02231, saving model to temp/f184\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0215 - mean_squared_error: 1.0215 - val_loss: 1.0166 - val_mean_squared_error: 1.0166\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02231 to 1.01656, saving model to temp/f184\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0162 - val_mean_squared_error: 1.0162\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01656 to 1.01620, saving model to temp/f184\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01620 to 1.01030, saving model to temp/f184\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0166 - mean_squared_error: 1.0166 - val_loss: 1.0120 - val_mean_squared_error: 1.0120\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01030\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01030\n",
      "Epoch 00006: early stopping\n",
      "temp/f185\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1745 - mean_squared_error: 1.1745 - val_loss: 1.0207 - val_mean_squared_error: 1.0207\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02073, saving model to temp/f185\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0245 - mean_squared_error: 1.0245 - val_loss: 1.0261 - val_mean_squared_error: 1.0261\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02073\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0195 - mean_squared_error: 1.0195 - val_loss: 1.0239 - val_mean_squared_error: 1.0239\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.02073\n",
      "Epoch 00003: early stopping\n",
      "temp/f186\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1625 - mean_squared_error: 1.1625 - val_loss: 1.0251 - val_mean_squared_error: 1.0251\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02507, saving model to temp/f186\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02507 to 1.01601, saving model to temp/f186\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0225 - mean_squared_error: 1.0225 - val_loss: 1.0164 - val_mean_squared_error: 1.0164\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01601\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0154 - val_mean_squared_error: 1.0154\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01601 to 1.01539, saving model to temp/f186\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0158 - mean_squared_error: 1.0158 - val_loss: 1.0229 - val_mean_squared_error: 1.0229\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01539\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0064 - val_mean_squared_error: 1.0064\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01539 to 1.00644, saving model to temp/f186\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00644\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0093 - mean_squared_error: 1.0093 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00644\n",
      "Epoch 00008: early stopping\n",
      "temp/f187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1490 - mean_squared_error: 1.1490 - val_loss: 1.0222 - val_mean_squared_error: 1.0222\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02215, saving model to temp/f187\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0186 - mean_squared_error: 1.0186 - val_loss: 1.0324 - val_mean_squared_error: 1.0324\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02215\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0241 - mean_squared_error: 1.0241 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02215 to 1.01723, saving model to temp/f187\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0126 - val_mean_squared_error: 1.0126\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01723 to 1.01263, saving model to temp/f187\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01263\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0080 - val_mean_squared_error: 1.0080\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01263 to 1.00802, saving model to temp/f187\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0130 - mean_squared_error: 1.0130 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00802\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0059 - val_mean_squared_error: 1.0059\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00802 to 1.00588, saving model to temp/f187\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0089 - val_mean_squared_error: 1.0089\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00588\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0098 - mean_squared_error: 1.0098 - val_loss: 1.0066 - val_mean_squared_error: 1.0066\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00588\n",
      "Epoch 00010: early stopping\n",
      "temp/f188\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1469 - mean_squared_error: 1.1469 - val_loss: 1.0195 - val_mean_squared_error: 1.0195\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01948, saving model to temp/f188\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0211 - mean_squared_error: 1.0211 - val_loss: 1.0280 - val_mean_squared_error: 1.0280\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01948\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0243 - mean_squared_error: 1.0243 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01948 to 1.01422, saving model to temp/f188\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01422 to 1.01298, saving model to temp/f188\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0150 - mean_squared_error: 1.0150 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01298 to 1.01007, saving model to temp/f188\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0092 - mean_squared_error: 1.0092 - val_loss: 1.0219 - val_mean_squared_error: 1.0219\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01007\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01007 to 1.00936, saving model to temp/f188\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0119 - mean_squared_error: 1.0119 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.00936 to 1.00783, saving model to temp/f188\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0122 - mean_squared_error: 1.0122 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00783\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00783\n",
      "Epoch 00010: early stopping\n",
      "temp/f189\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 1.1603 - mean_squared_error: 1.1603 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02655, saving model to temp/f189\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02655 to 1.01831, saving model to temp/f189\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01831 to 1.01184, saving model to temp/f189\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0171 - mean_squared_error: 1.0171 - val_loss: 1.0322 - val_mean_squared_error: 1.0322\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01184\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0238 - val_mean_squared_error: 1.0238\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01184\n",
      "Epoch 00005: early stopping\n",
      "temp/f190\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1577 - mean_squared_error: 1.1577 - val_loss: 1.0214 - val_mean_squared_error: 1.0214\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02139, saving model to temp/f190\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0240 - mean_squared_error: 1.0240 - val_loss: 1.0232 - val_mean_squared_error: 1.0232\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.02139\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 89us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02139 to 1.01280, saving model to temp/f190\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 93us/step - loss: 1.0194 - mean_squared_error: 1.0194 - val_loss: 1.0110 - val_mean_squared_error: 1.0110\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01280 to 1.01098, saving model to temp/f190\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 1.0091 - val_mean_squared_error: 1.0091\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01098 to 1.00906, saving model to temp/f190\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0095 - val_mean_squared_error: 1.0095\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00906\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00906\n",
      "Epoch 00007: early stopping\n",
      "temp/f191\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 1.1744 - mean_squared_error: 1.1744 - val_loss: 1.0268 - val_mean_squared_error: 1.0268\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02677, saving model to temp/f191\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 89us/step - loss: 1.0269 - mean_squared_error: 1.0269 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02677 to 1.02375, saving model to temp/f191\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 92us/step - loss: 1.0180 - mean_squared_error: 1.0180 - val_loss: 1.0225 - val_mean_squared_error: 1.0225\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02375 to 1.02251, saving model to temp/f191\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02251 to 1.01605, saving model to temp/f191\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0151 - mean_squared_error: 1.0151 - val_loss: 1.0044 - val_mean_squared_error: 1.0044\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01605 to 1.00438, saving model to temp/f191\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0168 - mean_squared_error: 1.0168 - val_loss: 1.0118 - val_mean_squared_error: 1.0118\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00438\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00438\n",
      "Epoch 00007: early stopping\n",
      "temp/f192\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.1584 - mean_squared_error: 1.1584 - val_loss: 1.0333 - val_mean_squared_error: 1.0333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03328, saving model to temp/f192\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 91us/step - loss: 1.0280 - mean_squared_error: 1.0280 - val_loss: 1.0183 - val_mean_squared_error: 1.0183\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03328 to 1.01831, saving model to temp/f192\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 1.0198 - mean_squared_error: 1.0198 - val_loss: 1.0152 - val_mean_squared_error: 1.0152\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01831 to 1.01522, saving model to temp/f192\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01522 to 1.01507, saving model to temp/f192\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0164 - mean_squared_error: 1.0164 - val_loss: 1.0119 - val_mean_squared_error: 1.0119\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01507 to 1.01192, saving model to temp/f192\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0128 - val_mean_squared_error: 1.0128\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01192\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01192\n",
      "Epoch 00007: early stopping\n",
      "temp/f193\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 124us/step - loss: 1.1737 - mean_squared_error: 1.1737 - val_loss: 1.0272 - val_mean_squared_error: 1.0272\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02716, saving model to temp/f193\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0237 - mean_squared_error: 1.0237 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02716 to 1.02374, saving model to temp/f193\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0201 - mean_squared_error: 1.0201 - val_loss: 1.0137 - val_mean_squared_error: 1.0137\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02374 to 1.01365, saving model to temp/f193\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0321 - val_mean_squared_error: 1.0321\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01365\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0216 - mean_squared_error: 1.0216 - val_loss: 1.0139 - val_mean_squared_error: 1.0139\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01365\n",
      "Epoch 00005: early stopping\n",
      "temp/f194\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 1.1529 - mean_squared_error: 1.1529 - val_loss: 1.0307 - val_mean_squared_error: 1.0307\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03071, saving model to temp/f194\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0269 - val_mean_squared_error: 1.0269\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03071 to 1.02693, saving model to temp/f194\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 92us/step - loss: 1.0254 - mean_squared_error: 1.0254 - val_loss: 1.0176 - val_mean_squared_error: 1.0176\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02693 to 1.01756, saving model to temp/f194\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0223 - mean_squared_error: 1.0223 - val_loss: 1.0190 - val_mean_squared_error: 1.0190\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01756\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0170 - mean_squared_error: 1.0170 - val_loss: 1.0150 - val_mean_squared_error: 1.0150\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01756 to 1.01497, saving model to temp/f194\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 115us/step - loss: 1.0117 - mean_squared_error: 1.0117 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01497\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0121 - mean_squared_error: 1.0121 - val_loss: 1.0078 - val_mean_squared_error: 1.0078\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01497 to 1.00779, saving model to temp/f194\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0163 - mean_squared_error: 1.0163 - val_loss: 1.0105 - val_mean_squared_error: 1.0105\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00779\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0104 - mean_squared_error: 1.0104 - val_loss: 1.0048 - val_mean_squared_error: 1.0048\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00779 to 1.00482, saving model to temp/f194\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0105 - mean_squared_error: 1.0105 - val_loss: 1.0074 - val_mean_squared_error: 1.0074\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00482\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0123 - mean_squared_error: 1.0123 - val_loss: 1.0220 - val_mean_squared_error: 1.0220\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.00482\n",
      "Epoch 00011: early stopping\n",
      "temp/f195\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.1683 - mean_squared_error: 1.1683 - val_loss: 1.0281 - val_mean_squared_error: 1.0281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02806, saving model to temp/f195\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0269 - mean_squared_error: 1.0269 - val_loss: 1.0251 - val_mean_squared_error: 1.0251\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02806 to 1.02509, saving model to temp/f195\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0248 - mean_squared_error: 1.0248 - val_loss: 1.0155 - val_mean_squared_error: 1.0155\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02509 to 1.01546, saving model to temp/f195\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0161 - mean_squared_error: 1.0161 - val_loss: 1.0107 - val_mean_squared_error: 1.0107\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01546 to 1.01071, saving model to temp/f195\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 91us/step - loss: 1.0149 - mean_squared_error: 1.0149 - val_loss: 1.0133 - val_mean_squared_error: 1.0133\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01071\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0174 - mean_squared_error: 1.0174 - val_loss: 1.0151 - val_mean_squared_error: 1.0151\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01071\n",
      "Epoch 00006: early stopping\n",
      "temp/f196\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1591 - mean_squared_error: 1.1591 - val_loss: 1.0249 - val_mean_squared_error: 1.0249\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02493, saving model to temp/f196\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0222 - mean_squared_error: 1.0222 - val_loss: 1.0172 - val_mean_squared_error: 1.0172\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02493 to 1.01717, saving model to temp/f196\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0199 - mean_squared_error: 1.0199 - val_loss: 1.0170 - val_mean_squared_error: 1.0170\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01717 to 1.01705, saving model to temp/f196\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 1.0200 - mean_squared_error: 1.0200 - val_loss: 1.0145 - val_mean_squared_error: 1.0145\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01705 to 1.01449, saving model to temp/f196\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0213 - mean_squared_error: 1.0213 - val_loss: 1.0136 - val_mean_squared_error: 1.0136\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01449 to 1.01356, saving model to temp/f196\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0131 - mean_squared_error: 1.0131 - val_loss: 1.0108 - val_mean_squared_error: 1.0108\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01356 to 1.01084, saving model to temp/f196\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0141 - mean_squared_error: 1.0141 - val_loss: 1.0135 - val_mean_squared_error: 1.0135\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01084\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0157 - mean_squared_error: 1.0157 - val_loss: 1.0436 - val_mean_squared_error: 1.0436\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01084\n",
      "Epoch 00008: early stopping\n",
      "temp/f197\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1528 - mean_squared_error: 1.1528 - val_loss: 1.0285 - val_mean_squared_error: 1.0285\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02849, saving model to temp/f197\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 1.0262 - mean_squared_error: 1.0262 - val_loss: 1.0197 - val_mean_squared_error: 1.0197\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02849 to 1.01967, saving model to temp/f197\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.0221 - mean_squared_error: 1.0221 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01967\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0125 - mean_squared_error: 1.0125 - val_loss: 1.0101 - val_mean_squared_error: 1.0101\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01967 to 1.01011, saving model to temp/f197\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0146 - mean_squared_error: 1.0146 - val_loss: 1.0160 - val_mean_squared_error: 1.0160\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01011\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0154 - mean_squared_error: 1.0154 - val_loss: 1.0094 - val_mean_squared_error: 1.0094\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01011 to 1.00938, saving model to temp/f197\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0137 - mean_squared_error: 1.0137 - val_loss: 1.0117 - val_mean_squared_error: 1.0117\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.00938\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0093 - mean_squared_error: 1.0093 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00938\n",
      "Epoch 00008: early stopping\n",
      "temp/f198\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 2s 123us/step - loss: 1.1688 - mean_squared_error: 1.1688 - val_loss: 1.0255 - val_mean_squared_error: 1.0255\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02545, saving model to temp/f198\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 120us/step - loss: 1.0298 - mean_squared_error: 1.0298 - val_loss: 1.0163 - val_mean_squared_error: 1.0163\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02545 to 1.01631, saving model to temp/f198\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0209 - mean_squared_error: 1.0209 - val_loss: 1.0306 - val_mean_squared_error: 1.0306\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01631\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 116us/step - loss: 1.0229 - mean_squared_error: 1.0229 - val_loss: 1.0123 - val_mean_squared_error: 1.0123\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01631 to 1.01227, saving model to temp/f198\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 119us/step - loss: 1.0142 - mean_squared_error: 1.0142 - val_loss: 1.0109 - val_mean_squared_error: 1.0109\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01227 to 1.01089, saving model to temp/f198\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0148 - mean_squared_error: 1.0148 - val_loss: 1.0237 - val_mean_squared_error: 1.0237\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.01089\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 1.0104 - mean_squared_error: 1.0104 - val_loss: 1.0131 - val_mean_squared_error: 1.0131\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.01089\n",
      "Epoch 00007: early stopping\n",
      "temp/f199\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 1.1711 - mean_squared_error: 1.1711 - val_loss: 1.0212 - val_mean_squared_error: 1.0212\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02122, saving model to temp/f199\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0264 - mean_squared_error: 1.0264 - val_loss: 1.0192 - val_mean_squared_error: 1.0192\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02122 to 1.01918, saving model to temp/f199\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0240 - mean_squared_error: 1.0240 - val_loss: 1.0184 - val_mean_squared_error: 1.0184\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01918 to 1.01840, saving model to temp/f199\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 1.0178 - mean_squared_error: 1.0178 - val_loss: 1.0140 - val_mean_squared_error: 1.0140\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.01840 to 1.01398, saving model to temp/f199\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 1.0130 - mean_squared_error: 1.0130 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.01398\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 88us/step - loss: 1.0136 - mean_squared_error: 1.0136 - val_loss: 1.0130 - val_mean_squared_error: 1.0130\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.01398 to 1.01297, saving model to temp/f199\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0160 - mean_squared_error: 1.0160 - val_loss: 1.0084 - val_mean_squared_error: 1.0084\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01297 to 1.00839, saving model to temp/f199\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0173 - mean_squared_error: 1.0173 - val_loss: 1.0223 - val_mean_squared_error: 1.0223\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.00839\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 118us/step - loss: 1.0133 - mean_squared_error: 1.0133 - val_loss: 1.0082 - val_mean_squared_error: 1.0082\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00839 to 1.00823, saving model to temp/f199\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 1.0110 - mean_squared_error: 1.0110 - val_loss: 1.0134 - val_mean_squared_error: 1.0134\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00823\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 88us/step - loss: 1.0076 - mean_squared_error: 1.0076 - val_loss: 1.0032 - val_mean_squared_error: 1.0032\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.00823 to 1.00321, saving model to temp/f199\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 1.0112 - mean_squared_error: 1.0112 - val_loss: 1.0205 - val_mean_squared_error: 1.0205\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.00321\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 2s 117us/step - loss: 1.0132 - mean_squared_error: 1.0132 - val_loss: 1.0045 - val_mean_squared_error: 1.0045\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.00321\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "for idx, model_name in enumerate(model_names):\n",
    "    print(model_name)\n",
    "\n",
    "    if type(models[idx]) is list:\n",
    "        #clear session\n",
    "        keras.backend.clear_session() \n",
    "        #get model according to specification\n",
    "        model = get_model(models[idx], [0.2] * len(models), len(inputs))\n",
    "        callbacks = [ModelCheckpoint(model_name, verbose= verbosity, monitor='val_loss',save_best_only=True), \n",
    "                     EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose= verbosity, mode='auto')]\n",
    "        model.compile(optimizer = optimizers.SGD(lr = 0.001, momentum = 0.9, ), loss='mean_squared_error', metrics = ['mse'])\n",
    "        #print(len(X), len(y))\n",
    "        model.fit(X, y, epochs = 20, validation_data = (x_val, y_val), callbacks = callbacks, batch_size = 32, verbose = verbosity)\n",
    "    else:\n",
    "        models[idx].fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align='center'><img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAdxJREFUeNq0Vt1Rg0AQJjcpgBJiBWIFkgoMFYhPPAIVECogPuYpdJBYgXQQrMCUkA50V7+d2ZwXuXPGm9khHLu3f9+3l1nkWNvtNqfHLgpfQ1EUS3tz5nAQ0+NIsiAZSc6eDlI8M3J00B/mDuUKDk6kfOebAgW3pkdD0pFcODGW4gKKvOrAUm04MA4QDt1OEIXU9hDigfS5rC1eS5T90gltck1Xrizo257kgySZcNRzgCSxCvgiE9nckPJo2b/B2AcEkk2OwL8bD8gmOKR1GPbaCUqxEgTq0tLvgb6zfo7+DgYGkkWL2tqLDV4RSITfbHPPfJKIrWz4nJQTMPAWA7IbD6imcNaDeDfgk+4No+wZr40BL3g9eQJJCFqRQ54KiSt72lsLpE3o3MCBSxDuq4yOckU2hKXRuwBH3OyMR4g1UpyTYw6mlmBqNdUXRM1NfyF5EPI6JkcpIDBIX8jX6DR/6ckAZJ0wEAdLR8DEk6OfC1Pp8BKo6TQIwPJbvJ6toK5lmuvJoRtfK6Ym1iRYIarRo2UyYHvRN5qpakR3yoizWrouoyuXXQqI185LCw07op5ZyCRGL99h24InP0e9xdQukEKVmhzrqZuRIfwISB//cP3Wk3f8f/yR+BRgAHu00HjLcEQBAAAAAElFTkSuQmCC' /></div><script>!function(t){function e(r){if(n[r])return n[r].exports;var i=n[r]={i:r,l:!1,exports:{}};return t[r].call(i.exports,i,i.exports,e),i.l=!0,i.exports}var n={};e.m=t,e.c=n,e.i=function(t){return t},e.d=function(t,n,r){e.o(t,n)||Object.defineProperty(t,n,{configurable:!1,enumerable:!0,get:r})},e.n=function(t){var n=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(n,\"a\",n),n},e.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},e.p=\"\",e(e.s=189)}([function(t,e,n){\"use strict\";function r(t,e,n,r,o,a,u,c){if(i(e),!t){var s;if(void 0===e)s=new Error(\"Minified exception occurred; use the non-minified dev environment for the full error message and additional helpful warnings.\");else{var l=[n,r,o,a,u,c],f=0;s=new Error(e.replace(/%s/g,function(){return l[f++]})),s.name=\"Invariant Violation\"}throw s.framesToPop=1,s}}var i=function(t){};t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e=arguments.length-1,n=\"Minified React error #\"+t+\"; visit http://facebook.github.io/react/docs/error-decoder.html?invariant=\"+t,r=0;r<e;r++)n+=\"&args[]=\"+encodeURIComponent(arguments[r+1]);n+=\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\";var i=new Error(n);throw i.name=\"Invariant Violation\",i.framesToPop=1,i}t.exports=r},function(t,e,n){\"use strict\";var r=n(11),i=r;t.exports=i},function(t,e,n){\"use strict\";function r(t){if(null===t||void 0===t)throw new TypeError(\"Object.assign cannot be called with null or undefined\");return Object(t)}/*\n",
       "object-assign\n",
       "(c) Sindre Sorhus\n",
       "@license MIT\n",
       "*/\n",
       "var i=Object.getOwnPropertySymbols,o=Object.prototype.hasOwnProperty,a=Object.prototype.propertyIsEnumerable;t.exports=function(){try{if(!Object.assign)return!1;var t=new String(\"abc\");if(t[5]=\"de\",\"5\"===Object.getOwnPropertyNames(t)[0])return!1;for(var e={},n=0;n<10;n++)e[\"_\"+String.fromCharCode(n)]=n;if(\"0123456789\"!==Object.getOwnPropertyNames(e).map(function(t){return e[t]}).join(\"\"))return!1;var r={};return\"abcdefghijklmnopqrst\".split(\"\").forEach(function(t){r[t]=t}),\"abcdefghijklmnopqrst\"===Object.keys(Object.assign({},r)).join(\"\")}catch(t){return!1}}()?Object.assign:function(t,e){for(var n,u,c=r(t),s=1;s<arguments.length;s++){n=Object(arguments[s]);for(var l in n)o.call(n,l)&&(c[l]=n[l]);if(i){u=i(n);for(var f=0;f<u.length;f++)a.call(n,u[f])&&(c[u[f]]=n[u[f]])}}return c}},function(t,e,n){\"use strict\";function r(t,e){return 1===t.nodeType&&t.getAttribute(d)===String(e)||8===t.nodeType&&t.nodeValue===\" react-text: \"+e+\" \"||8===t.nodeType&&t.nodeValue===\" react-empty: \"+e+\" \"}function i(t){for(var e;e=t._renderedComponent;)t=e;return t}function o(t,e){var n=i(t);n._hostNode=e,e[g]=n}function a(t){var e=t._hostNode;e&&(delete e[g],t._hostNode=null)}function u(t,e){if(!(t._flags&v.hasCachedChildNodes)){var n=t._renderedChildren,a=e.firstChild;t:for(var u in n)if(n.hasOwnProperty(u)){var c=n[u],s=i(c)._domID;if(0!==s){for(;null!==a;a=a.nextSibling)if(r(a,s)){o(c,a);continue t}f(\"32\",s)}}t._flags|=v.hasCachedChildNodes}}function c(t){if(t[g])return t[g];for(var e=[];!t[g];){if(e.push(t),!t.parentNode)return null;t=t.parentNode}for(var n,r;t&&(r=t[g]);t=e.pop())n=r,e.length&&u(r,t);return n}function s(t){var e=c(t);return null!=e&&e._hostNode===t?e:null}function l(t){if(void 0===t._hostNode&&f(\"33\"),t._hostNode)return t._hostNode;for(var e=[];!t._hostNode;)e.push(t),t._hostParent||f(\"34\"),t=t._hostParent;for(;e.length;t=e.pop())u(t,t._hostNode);return t._hostNode}var f=n(1),p=n(21),h=n(161),d=(n(0),p.ID_ATTRIBUTE_NAME),v=h,g=\"__reactInternalInstance$\"+Math.random().toString(36).slice(2),m={getClosestInstanceFromNode:c,getInstanceFromNode:s,getNodeFromInstance:l,precacheChildNodes:u,precacheNode:o,uncacheNode:a};t.exports=m},function(t,e,n){\"use strict\";function r(t,e,n,a){function u(e){return t(e=new Date(+e)),e}return u.floor=u,u.ceil=function(n){return t(n=new Date(n-1)),e(n,1),t(n),n},u.round=function(t){var e=u(t),n=u.ceil(t);return t-e<n-t?e:n},u.offset=function(t,n){return e(t=new Date(+t),null==n?1:Math.floor(n)),t},u.range=function(n,r,i){var o,a=[];if(n=u.ceil(n),i=null==i?1:Math.floor(i),!(n<r&&i>0))return a;do{a.push(o=new Date(+n)),e(n,i),t(n)}while(o<n&&n<r);return a},u.filter=function(n){return r(function(e){if(e>=e)for(;t(e),!n(e);)e.setTime(e-1)},function(t,r){if(t>=t)if(r<0)for(;++r<=0;)for(;e(t,-1),!n(t););else for(;--r>=0;)for(;e(t,1),!n(t););})},n&&(u.count=function(e,r){return i.setTime(+e),o.setTime(+r),t(i),t(o),Math.floor(n(i,o))},u.every=function(t){return t=Math.floor(t),isFinite(t)&&t>0?t>1?u.filter(a?function(e){return a(e)%t==0}:function(e){return u.count(0,e)%t==0}):u:null}),u}e.a=r;var i=new Date,o=new Date},function(t,e,n){\"use strict\";var r=!(\"undefined\"==typeof window||!window.document||!window.document.createElement),i={canUseDOM:r,canUseWorkers:\"undefined\"!=typeof Worker,canUseEventListeners:r&&!(!window.addEventListener&&!window.attachEvent),canUseViewport:r&&!!window.screen,isInWorker:!r};t.exports=i},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(101);n.d(e,\"bisect\",function(){return r.a}),n.d(e,\"bisectRight\",function(){return r.b}),n.d(e,\"bisectLeft\",function(){return r.c});var i=n(19);n.d(e,\"ascending\",function(){return i.a});var o=n(102);n.d(e,\"bisector\",function(){return o.a});var a=n(193);n.d(e,\"cross\",function(){return a.a});var u=n(194);n.d(e,\"descending\",function(){return u.a});var c=n(103);n.d(e,\"deviation\",function(){return c.a});var s=n(104);n.d(e,\"extent\",function(){return s.a});var l=n(195);n.d(e,\"histogram\",function(){return l.a});var f=n(205);n.d(e,\"thresholdFreedmanDiaconis\",function(){return f.a});var p=n(206);n.d(e,\"thresholdScott\",function(){return p.a});var h=n(108);n.d(e,\"thresholdSturges\",function(){return h.a});var d=n(197);n.d(e,\"max\",function(){return d.a});var v=n(198);n.d(e,\"mean\",function(){return v.a});var g=n(199);n.d(e,\"median\",function(){return g.a});var m=n(200);n.d(e,\"merge\",function(){return m.a});var y=n(105);n.d(e,\"min\",function(){return y.a});var _=n(106);n.d(e,\"pairs\",function(){return _.a});var b=n(201);n.d(e,\"permute\",function(){return b.a});var x=n(59);n.d(e,\"quantile\",function(){return x.a});var w=n(107);n.d(e,\"range\",function(){return w.a});var C=n(202);n.d(e,\"scan\",function(){return C.a});var k=n(203);n.d(e,\"shuffle\",function(){return k.a});var E=n(204);n.d(e,\"sum\",function(){return E.a});var M=n(109);n.d(e,\"ticks\",function(){return M.a}),n.d(e,\"tickIncrement\",function(){return M.b}),n.d(e,\"tickStep\",function(){return M.c});var T=n(110);n.d(e,\"transpose\",function(){return T.a});var S=n(111);n.d(e,\"variance\",function(){return S.a});var N=n(207);n.d(e,\"zip\",function(){return N.a})},function(t,e,n){\"use strict\";function r(t,e){this._groups=t,this._parents=e}function i(){return new r([[document.documentElement]],R)}n.d(e,\"c\",function(){return R}),e.b=r;var o=n(283),a=n(284),u=n(272),c=n(266),s=n(132),l=n(271),f=n(276),p=n(279),h=n(286),d=n(263),v=n(278),g=n(277),m=n(285),y=n(270),_=n(269),b=n(262),x=n(134),w=n(280),C=n(264),k=n(287),E=n(273),M=n(281),T=n(275),S=n(261),N=n(274),A=n(282),P=n(265),O=n(267),I=n(70),D=n(268),R=[null];r.prototype=i.prototype={constructor:r,select:o.a,selectAll:a.a,filter:u.a,data:c.a,enter:s.a,exit:l.a,merge:f.a,order:p.a,sort:h.a,call:d.a,nodes:v.a,node:g.a,size:m.a,empty:y.a,each:_.a,attr:b.a,style:x.b,property:w.a,classed:C.a,text:k.a,html:E.a,raise:M.a,lower:T.a,append:S.a,insert:N.a,remove:A.a,clone:P.a,datum:O.a,on:I.c,dispatch:D.a},e.a=i},function(t,e,n){\"use strict\";var r=null;t.exports={debugTool:r}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(61);n.d(e,\"color\",function(){return r.a}),n.d(e,\"rgb\",function(){return r.b}),n.d(e,\"hsl\",function(){return r.c});var i=n(218);n.d(e,\"lab\",function(){return i.a}),n.d(e,\"hcl\",function(){return i.b});var o=n(217);n.d(e,\"cubehelix\",function(){return o.a})},function(t,e,n){\"use strict\";function r(t){return function(){return t}}var i=function(){};i.thatReturns=r,i.thatReturnsFalse=r(!1),i.thatReturnsTrue=r(!0),i.thatReturnsNull=r(null),i.thatReturnsThis=function(){return this},i.thatReturnsArgument=function(t){return t},t.exports=i},function(t,e,n){\"use strict\";function r(){S.ReactReconcileTransaction&&w||l(\"123\")}function i(){this.reinitializeTransaction(),this.dirtyComponentsLength=null,this.callbackQueue=p.getPooled(),this.reconcileTransaction=S.ReactReconcileTransaction.getPooled(!0)}function o(t,e,n,i,o,a){return r(),w.batchedUpdates(t,e,n,i,o,a)}function a(t,e){return t._mountOrder-e._mountOrder}function u(t){var e=t.dirtyComponentsLength;e!==y.length&&l(\"124\",e,y.length),y.sort(a),_++;for(var n=0;n<e;n++){var r=y[n],i=r._pendingCallbacks;r._pendingCallbacks=null;var o;if(d.logTopLevelRenders){var u=r;r._currentElement.type.isReactTopLevelWrapper&&(u=r._renderedComponent),o=\"React update: \"+u.getName(),console.time(o)}if(v.performUpdateIfNecessary(r,t.reconcileTransaction,_),o&&console.timeEnd(o),i)for(var c=0;c<i.length;c++)t.callbackQueue.enqueue(i[c],r.getPublicInstance())}}function c(t){if(r(),!w.isBatchingUpdates)return void w.batchedUpdates(c,t);y.push(t),null==t._updateBatchNumber&&(t._updateBatchNumber=_+1)}function s(t,e){m(w.isBatchingUpdates,\"ReactUpdates.asap: Can't enqueue an asap callback in a context whereupdates are not being batched.\"),b.enqueue(t,e),x=!0}var l=n(1),f=n(3),p=n(159),h=n(18),d=n(164),v=n(24),g=n(55),m=n(0),y=[],_=0,b=p.getPooled(),x=!1,w=null,C={initialize:function(){this.dirtyComponentsLength=y.length},close:function(){this.dirtyComponentsLength!==y.length?(y.splice(0,this.dirtyComponentsLength),M()):y.length=0}},k={initialize:function(){this.callbackQueue.reset()},close:function(){this.callbackQueue.notifyAll()}},E=[C,k];f(i.prototype,g,{getTransactionWrappers:function(){return E},destructor:function(){this.dirtyComponentsLength=null,p.release(this.callbackQueue),this.callbackQueue=null,S.ReactReconcileTransaction.release(this.reconcileTransaction),this.reconcileTransaction=null},perform:function(t,e,n){return g.perform.call(this,this.reconcileTransaction.perform,this.reconcileTransaction,t,e,n)}}),h.addPoolingTo(i);var M=function(){for(;y.length||x;){if(y.length){var t=i.getPooled();t.perform(u,null,t),i.release(t)}if(x){x=!1;var e=b;b=p.getPooled(),e.notifyAll(),p.release(e)}}},T={injectReconcileTransaction:function(t){t||l(\"126\"),S.ReactReconcileTransaction=t},injectBatchingStrategy:function(t){t||l(\"127\"),\"function\"!=typeof t.batchedUpdates&&l(\"128\"),\"boolean\"!=typeof t.isBatchingUpdates&&l(\"129\"),w=t}},S={ReactReconcileTransaction:null,batchedUpdates:o,enqueueUpdate:c,flushBatchedUpdates:M,injection:T,asap:s};t.exports=S},function(t,e,n){\"use strict\";n.d(e,\"e\",function(){return r}),n.d(e,\"d\",function(){return i}),n.d(e,\"c\",function(){return o}),n.d(e,\"b\",function(){return a}),n.d(e,\"a\",function(){return u});var r=1e3,i=6e4,o=36e5,a=864e5,u=6048e5},function(t,e,n){\"use strict\";function r(t,e,n,r){this.dispatchConfig=t,this._targetInst=e,this.nativeEvent=n;var i=this.constructor.Interface;for(var o in i)if(i.hasOwnProperty(o)){var u=i[o];u?this[o]=u(n):\"target\"===o?this.target=r:this[o]=n[o]}var c=null!=n.defaultPrevented?n.defaultPrevented:!1===n.returnValue;return this.isDefaultPrevented=c?a.thatReturnsTrue:a.thatReturnsFalse,this.isPropagationStopped=a.thatReturnsFalse,this}var i=n(3),o=n(18),a=n(11),u=(n(2),[\"dispatchConfig\",\"_targetInst\",\"nativeEvent\",\"isDefaultPrevented\",\"isPropagationStopped\",\"_dispatchListeners\",\"_dispatchInstances\"]),c={type:null,target:null,currentTarget:a.thatReturnsNull,eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(t){return t.timeStamp||Date.now()},defaultPrevented:null,isTrusted:null};i(r.prototype,{preventDefault:function(){this.defaultPrevented=!0;var t=this.nativeEvent;t&&(t.preventDefault?t.preventDefault():\"unknown\"!=typeof t.returnValue&&(t.returnValue=!1),this.isDefaultPrevented=a.thatReturnsTrue)},stopPropagation:function(){var t=this.nativeEvent;t&&(t.stopPropagation?t.stopPropagation():\"unknown\"!=typeof t.cancelBubble&&(t.cancelBubble=!0),this.isPropagationStopped=a.thatReturnsTrue)},persist:function(){this.isPersistent=a.thatReturnsTrue},isPersistent:a.thatReturnsFalse,destructor:function(){var t=this.constructor.Interface;for(var e in t)this[e]=null;for(var n=0;n<u.length;n++)this[u[n]]=null}}),r.Interface=c,r.augmentClass=function(t,e){var n=this,r=function(){};r.prototype=n.prototype;var a=new r;i(a,t.prototype),t.prototype=a,t.prototype.constructor=t,t.Interface=i({},n.Interface,e),t.augmentClass=n.augmentClass,o.addPoolingTo(t,o.fourArgumentPooler)},o.addPoolingTo(r,o.fourArgumentPooler),t.exports=r},function(t,e,n){\"use strict\";var r={current:null};t.exports=r},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return i}),n.d(e,\"b\",function(){return o});var r=Array.prototype,i=r.map,o=r.slice},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";var r=n(1),i=(n(0),function(t){var e=this;if(e.instancePool.length){var n=e.instancePool.pop();return e.call(n,t),n}return new e(t)}),o=function(t,e){var n=this;if(n.instancePool.length){var r=n.instancePool.pop();return n.call(r,t,e),r}return new n(t,e)},a=function(t,e,n){var r=this;if(r.instancePool.length){var i=r.instancePool.pop();return r.call(i,t,e,n),i}return new r(t,e,n)},u=function(t,e,n,r){var i=this;if(i.instancePool.length){var o=i.instancePool.pop();return i.call(o,t,e,n,r),o}return new i(t,e,n,r)},c=function(t){var e=this;t instanceof e||r(\"25\"),t.destructor(),e.instancePool.length<e.poolSize&&e.instancePool.push(t)},s=i,l=function(t,e){var n=t;return n.instancePool=[],n.getPooled=e||s,n.poolSize||(n.poolSize=10),n.release=c,n},f={addPoolingTo:l,oneArgumentPooler:i,twoArgumentPooler:o,threeArgumentPooler:a,fourArgumentPooler:u};t.exports=f},function(t,e,n){\"use strict\";e.a=function(t,e){return t<e?-1:t>e?1:t>=e?0:NaN}},function(t,e,n){\"use strict\";function r(t){if(d){var e=t.node,n=t.children;if(n.length)for(var r=0;r<n.length;r++)v(e,n[r],null);else null!=t.html?f(e,t.html):null!=t.text&&h(e,t.text)}}function i(t,e){t.parentNode.replaceChild(e.node,t),r(e)}function o(t,e){d?t.children.push(e):t.node.appendChild(e.node)}function a(t,e){d?t.html=e:f(t.node,e)}function u(t,e){d?t.text=e:h(t.node,e)}function c(){return this.node.nodeName}function s(t){return{node:t,children:[],html:null,text:null,toString:c}}var l=n(83),f=n(57),p=n(91),h=n(176),d=\"undefined\"!=typeof document&&\"number\"==typeof document.documentMode||\"undefined\"!=typeof navigator&&\"string\"==typeof navigator.userAgent&&/\\bEdge\\/\\d/.test(navigator.userAgent),v=p(function(t,e,n){11===e.node.nodeType||1===e.node.nodeType&&\"object\"===e.node.nodeName.toLowerCase()&&(null==e.node.namespaceURI||e.node.namespaceURI===l.html)?(r(e),t.insertBefore(e.node,n)):(t.insertBefore(e.node,n),r(e))});s.insertTreeBefore=v,s.replaceChildWithTree=i,s.queueChild=o,s.queueHTML=a,s.queueText=u,t.exports=s},function(t,e,n){\"use strict\";function r(t,e){return(t&e)===e}var i=n(1),o=(n(0),{MUST_USE_PROPERTY:1,HAS_BOOLEAN_VALUE:4,HAS_NUMERIC_VALUE:8,HAS_POSITIVE_NUMERIC_VALUE:24,HAS_OVERLOADED_BOOLEAN_VALUE:32,injectDOMPropertyConfig:function(t){var e=o,n=t.Properties||{},a=t.DOMAttributeNamespaces||{},c=t.DOMAttributeNames||{},s=t.DOMPropertyNames||{},l=t.DOMMutationMethods||{};t.isCustomAttribute&&u._isCustomAttributeFunctions.push(t.isCustomAttribute);for(var f in n){u.properties.hasOwnProperty(f)&&i(\"48\",f);var p=f.toLowerCase(),h=n[f],d={attributeName:p,attributeNamespace:null,propertyName:f,mutationMethod:null,mustUseProperty:r(h,e.MUST_USE_PROPERTY),hasBooleanValue:r(h,e.HAS_BOOLEAN_VALUE),hasNumericValue:r(h,e.HAS_NUMERIC_VALUE),hasPositiveNumericValue:r(h,e.HAS_POSITIVE_NUMERIC_VALUE),hasOverloadedBooleanValue:r(h,e.HAS_OVERLOADED_BOOLEAN_VALUE)};if(d.hasBooleanValue+d.hasNumericValue+d.hasOverloadedBooleanValue<=1||i(\"50\",f),c.hasOwnProperty(f)){var v=c[f];d.attributeName=v}a.hasOwnProperty(f)&&(d.attributeNamespace=a[f]),s.hasOwnProperty(f)&&(d.propertyName=s[f]),l.hasOwnProperty(f)&&(d.mutationMethod=l[f]),u.properties[f]=d}}}),a=\":A-Z_a-z\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u02FF\\\\u0370-\\\\u037D\\\\u037F-\\\\u1FFF\\\\u200C-\\\\u200D\\\\u2070-\\\\u218F\\\\u2C00-\\\\u2FEF\\\\u3001-\\\\uD7FF\\\\uF900-\\\\uFDCF\\\\uFDF0-\\\\uFFFD\",u={ID_ATTRIBUTE_NAME:\"data-reactid\",ROOT_ATTRIBUTE_NAME:\"data-reactroot\",ATTRIBUTE_NAME_START_CHAR:a,ATTRIBUTE_NAME_CHAR:a+\"\\\\-.0-9\\\\u00B7\\\\u0300-\\\\u036F\\\\u203F-\\\\u2040\",properties:{},getPossibleStandardName:null,_isCustomAttributeFunctions:[],isCustomAttribute:function(t){for(var e=0;e<u._isCustomAttributeFunctions.length;e++){if((0,u._isCustomAttributeFunctions[e])(t))return!0}return!1},injection:o};t.exports=u},function(t,e,n){\"use strict\";function r(t){return\"button\"===t||\"input\"===t||\"select\"===t||\"textarea\"===t}function i(t,e,n){switch(t){case\"onClick\":case\"onClickCapture\":case\"onDoubleClick\":case\"onDoubleClickCapture\":case\"onMouseDown\":case\"onMouseDownCapture\":case\"onMouseMove\":case\"onMouseMoveCapture\":case\"onMouseUp\":case\"onMouseUpCapture\":return!(!n.disabled||!r(e));default:return!1}}var o=n(1),a=n(84),u=n(52),c=n(88),s=n(169),l=n(170),f=(n(0),{}),p=null,h=function(t,e){t&&(u.executeDispatchesInOrder(t,e),t.isPersistent()||t.constructor.release(t))},d=function(t){return h(t,!0)},v=function(t){return h(t,!1)},g=function(t){return\".\"+t._rootNodeID},m={injection:{injectEventPluginOrder:a.injectEventPluginOrder,injectEventPluginsByName:a.injectEventPluginsByName},putListener:function(t,e,n){\"function\"!=typeof n&&o(\"94\",e,typeof n);var r=g(t);(f[e]||(f[e]={}))[r]=n;var i=a.registrationNameModules[e];i&&i.didPutListener&&i.didPutListener(t,e,n)},getListener:function(t,e){var n=f[e];if(i(e,t._currentElement.type,t._currentElement.props))return null;var r=g(t);return n&&n[r]},deleteListener:function(t,e){var n=a.registrationNameModules[e];n&&n.willDeleteListener&&n.willDeleteListener(t,e);var r=f[e];if(r){delete r[g(t)]}},deleteAllListeners:function(t){var e=g(t);for(var n in f)if(f.hasOwnProperty(n)&&f[n][e]){var r=a.registrationNameModules[n];r&&r.willDeleteListener&&r.willDeleteListener(t,n),delete f[n][e]}},extractEvents:function(t,e,n,r){for(var i,o=a.plugins,u=0;u<o.length;u++){var c=o[u];if(c){var l=c.extractEvents(t,e,n,r);l&&(i=s(i,l))}}return i},enqueueEvents:function(t){t&&(p=s(p,t))},processEventQueue:function(t){var e=p;p=null,t?l(e,d):l(e,v),p&&o(\"95\"),c.rethrowCaughtError()},__purge:function(){f={}},__getListenerBank:function(){return f}};t.exports=m},function(t,e,n){\"use strict\";function r(t,e,n){var r=e.dispatchConfig.phasedRegistrationNames[n];return m(t,r)}function i(t,e,n){var i=r(t,n,e);i&&(n._dispatchListeners=v(n._dispatchListeners,i),n._dispatchInstances=v(n._dispatchInstances,t))}function o(t){t&&t.dispatchConfig.phasedRegistrationNames&&d.traverseTwoPhase(t._targetInst,i,t)}function a(t){if(t&&t.dispatchConfig.phasedRegistrationNames){var e=t._targetInst,n=e?d.getParentInstance(e):null;d.traverseTwoPhase(n,i,t)}}function u(t,e,n){if(n&&n.dispatchConfig.registrationName){var r=n.dispatchConfig.registrationName,i=m(t,r);i&&(n._dispatchListeners=v(n._dispatchListeners,i),n._dispatchInstances=v(n._dispatchInstances,t))}}function c(t){t&&t.dispatchConfig.registrationName&&u(t._targetInst,null,t)}function s(t){g(t,o)}function l(t){g(t,a)}function f(t,e,n,r){d.traverseEnterLeave(n,r,u,t,e)}function p(t){g(t,c)}var h=n(22),d=n(52),v=n(169),g=n(170),m=(n(2),h.getListener),y={accumulateTwoPhaseDispatches:s,accumulateTwoPhaseDispatchesSkipTarget:l,accumulateDirectDispatches:p,accumulateEnterLeaveDispatches:f};t.exports=y},function(t,e,n){\"use strict\";function r(){i.attachRefs(this,this._currentElement)}var i=n(382),o=(n(9),n(2),{mountComponent:function(t,e,n,i,o,a){var u=t.mountComponent(e,n,i,o,a);return t._currentElement&&null!=t._currentElement.ref&&e.getReactMountReady().enqueue(r,t),u},getHostNode:function(t){return t.getHostNode()},unmountComponent:function(t,e){i.detachRefs(t,t._currentElement),t.unmountComponent(e)},receiveComponent:function(t,e,n,o){var a=t._currentElement;if(e!==a||o!==t._context){var u=i.shouldUpdateRefs(a,e);u&&i.detachRefs(t,a),t.receiveComponent(e,n,o),u&&t._currentElement&&null!=t._currentElement.ref&&n.getReactMountReady().enqueue(r,t)}},performUpdateIfNecessary:function(t,e,n){t._updateBatchNumber===n&&t.performUpdateIfNecessary(e)}});t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o=n(94),a={view:function(t){if(t.view)return t.view;var e=o(t);if(e.window===e)return e;var n=e.ownerDocument;return n?n.defaultView||n.parentWindow:window},detail:function(t){return t.detail||0}};i.augmentClass(r,a),t.exports=r},function(t,e,n){\"use strict\";var r=n(3),i=n(178),o=n(414),a=n(415),u=n(27),c=n(416),s=n(417),l=n(418),f=n(422),p=u.createElement,h=u.createFactory,d=u.cloneElement,v=r,g=function(t){return t},m={Children:{map:o.map,forEach:o.forEach,count:o.count,toArray:o.toArray,only:f},Component:i.Component,PureComponent:i.PureComponent,createElement:p,cloneElement:d,isValidElement:u.isValidElement,PropTypes:c,createClass:l,createFactory:h,createMixin:g,DOM:a,version:s,__spread:v};t.exports=m},function(t,e,n){\"use strict\";function r(t){return void 0!==t.ref}function i(t){return void 0!==t.key}var o=n(3),a=n(15),u=(n(2),n(182),Object.prototype.hasOwnProperty),c=n(180),s={key:!0,ref:!0,__self:!0,__source:!0},l=function(t,e,n,r,i,o,a){var u={$$typeof:c,type:t,key:e,ref:n,props:a,_owner:o};return u};l.createElement=function(t,e,n){var o,c={},f=null,p=null;if(null!=e){r(e)&&(p=e.ref),i(e)&&(f=\"\"+e.key),void 0===e.__self?null:e.__self,void 0===e.__source?null:e.__source;for(o in e)u.call(e,o)&&!s.hasOwnProperty(o)&&(c[o]=e[o])}var h=arguments.length-2;if(1===h)c.children=n;else if(h>1){for(var d=Array(h),v=0;v<h;v++)d[v]=arguments[v+2];c.children=d}if(t&&t.defaultProps){var g=t.defaultProps;for(o in g)void 0===c[o]&&(c[o]=g[o])}return l(t,f,p,0,0,a.current,c)},l.createFactory=function(t){var e=l.createElement.bind(null,t);return e.type=t,e},l.cloneAndReplaceKey=function(t,e){return l(t.type,e,t.ref,t._self,t._source,t._owner,t.props)},l.cloneElement=function(t,e,n){var c,f=o({},t.props),p=t.key,h=t.ref,d=(t._self,t._source,t._owner);if(null!=e){r(e)&&(h=e.ref,d=a.current),i(e)&&(p=\"\"+e.key);var v;t.type&&t.type.defaultProps&&(v=t.type.defaultProps);for(c in e)u.call(e,c)&&!s.hasOwnProperty(c)&&(void 0===e[c]&&void 0!==v?f[c]=v[c]:f[c]=e[c])}var g=arguments.length-2;if(1===g)f.children=n;else if(g>1){for(var m=Array(g),y=0;y<g;y++)m[y]=arguments[y+2];f.children=m}return l(t.type,p,h,0,0,d,f)},l.isValidElement=function(t){return\"object\"==typeof t&&null!==t&&t.$$typeof===c},t.exports=l},function(t,e,n){\"use strict\";e.a=function(t){return null===t?NaN:+t}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(219);n.d(e,\"formatDefaultLocale\",function(){return r.a}),n.d(e,\"format\",function(){return r.b}),n.d(e,\"formatPrefix\",function(){return r.c});var i=n(117);n.d(e,\"formatLocale\",function(){return i.a});var o=n(115);n.d(e,\"formatSpecifier\",function(){return o.a});var a=n(225);n.d(e,\"precisionFixed\",function(){return a.a});var u=n(226);n.d(e,\"precisionPrefix\",function(){return u.a});var c=n(227);n.d(e,\"precisionRound\",function(){return c.a})},function(t,e,n){\"use strict\";var r=n(65);n.d(e,\"b\",function(){return r.a});var i=(n(118),n(64),n(119),n(121),n(43));n.d(e,\"a\",function(){return i.a});var o=(n(122),n(233));n.d(e,\"c\",function(){return o.a});var a=(n(124),n(235),n(237),n(123),n(230),n(231),n(229),n(228));n.d(e,\"d\",function(){return a.a});n(232)},function(t,e,n){\"use strict\";function r(t,e){return function(n){return t+n*e}}function i(t,e,n){return t=Math.pow(t,n),e=Math.pow(e,n)-t,n=1/n,function(r){return Math.pow(t+r*e,n)}}function o(t,e){var i=e-t;return i?r(t,i>180||i<-180?i-360*Math.round(i/360):i):n.i(c.a)(isNaN(t)?e:t)}function a(t){return 1==(t=+t)?u:function(e,r){return r-e?i(e,r,t):n.i(c.a)(isNaN(e)?r:e)}}function u(t,e){var i=e-t;return i?r(t,i):n.i(c.a)(isNaN(t)?e:t)}e.b=o,e.c=a,e.a=u;var c=n(120)},function(t,e,n){\"use strict\";var r=n(238);n.d(e,\"a\",function(){return r.a})},function(t,e,n){\"use strict\";e.a=function(t){return t.match(/.{6}/g).map(function(t){return\"#\"+t})}},function(t,e,n){\"use strict\";function r(t){var e=t.domain;return t.ticks=function(t){var r=e();return n.i(o.ticks)(r[0],r[r.length-1],null==t?10:t)},t.tickFormat=function(t,r){return n.i(c.a)(e(),t,r)},t.nice=function(r){null==r&&(r=10);var i,a=e(),u=0,c=a.length-1,s=a[u],l=a[c];return l<s&&(i=s,s=l,l=i,i=u,u=c,c=i),i=n.i(o.tickIncrement)(s,l,r),i>0?(s=Math.floor(s/i)*i,l=Math.ceil(l/i)*i,i=n.i(o.tickIncrement)(s,l,r)):i<0&&(s=Math.ceil(s*i)/i,l=Math.floor(l*i)/i,i=n.i(o.tickIncrement)(s,l,r)),i>0?(a[u]=Math.floor(s/i)*i,a[c]=Math.ceil(l/i)*i,e(a)):i<0&&(a[u]=Math.ceil(s*i)/i,a[c]=Math.floor(l*i)/i,e(a)),t},t}function i(){var t=n.i(u.a)(u.b,a.a);return t.copy=function(){return n.i(u.c)(t,i())},r(t)}e.b=r,e.a=i;var o=n(7),a=n(30),u=n(44),c=n(253)},function(t,e,n){\"use strict\";function r(t){return t>1?0:t<-1?h:Math.acos(t)}function i(t){return t>=1?d:t<=-1?-d:Math.asin(t)}n.d(e,\"g\",function(){return o}),n.d(e,\"m\",function(){return a}),n.d(e,\"h\",function(){return u}),n.d(e,\"e\",function(){return c}),n.d(e,\"j\",function(){return s}),n.d(e,\"i\",function(){return l}),n.d(e,\"d\",function(){return f}),n.d(e,\"a\",function(){return p}),n.d(e,\"b\",function(){return h}),n.d(e,\"f\",function(){return d}),n.d(e,\"c\",function(){return v}),e.l=r,e.k=i;var o=Math.abs,a=Math.atan2,u=Math.cos,c=Math.max,s=Math.min,l=Math.sin,f=Math.sqrt,p=1e-12,h=Math.PI,d=h/2,v=2*h},function(t,e,n){\"use strict\";e.a=function(t,e){if((i=t.length)>1)for(var n,r,i,o=1,a=t[e[0]],u=a.length;o<i;++o)for(r=a,a=t[e[o]],n=0;n<u;++n)a[n][1]+=a[n][0]=isNaN(r[n][1])?r[n][0]:r[n][1]}},function(t,e,n){\"use strict\";e.a=function(t){for(var e=t.length,n=new Array(e);--e>=0;)n[e]=e;return n}},function(t,e,n){(function(t,r){var i;(function(){function o(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}function a(t,e,n,r){for(var i=-1,o=null==t?0:t.length;++i<o;){var a=t[i];e(r,a,n(a),t)}return r}function u(t,e){for(var n=-1,r=null==t?0:t.length;++n<r&&!1!==e(t[n],n,t););return t}function c(t,e){for(var n=null==t?0:t.length;n--&&!1!==e(t[n],n,t););return t}function s(t,e){for(var n=-1,r=null==t?0:t.length;++n<r;)if(!e(t[n],n,t))return!1;return!0}function l(t,e){for(var n=-1,r=null==t?0:t.length,i=0,o=[];++n<r;){var a=t[n];e(a,n,t)&&(o[i++]=a)}return o}function f(t,e){return!!(null==t?0:t.length)&&w(t,e,0)>-1}function p(t,e,n){for(var r=-1,i=null==t?0:t.length;++r<i;)if(n(e,t[r]))return!0;return!1}function h(t,e){for(var n=-1,r=null==t?0:t.length,i=Array(r);++n<r;)i[n]=e(t[n],n,t);return i}function d(t,e){for(var n=-1,r=e.length,i=t.length;++n<r;)t[i+n]=e[n];return t}function v(t,e,n,r){var i=-1,o=null==t?0:t.length;for(r&&o&&(n=t[++i]);++i<o;)n=e(n,t[i],i,t);return n}function g(t,e,n,r){var i=null==t?0:t.length;for(r&&i&&(n=t[--i]);i--;)n=e(n,t[i],i,t);return n}function m(t,e){for(var n=-1,r=null==t?0:t.length;++n<r;)if(e(t[n],n,t))return!0;return!1}function y(t){return t.split(\"\")}function _(t){return t.match(Ue)||[]}function b(t,e,n){var r;return n(t,function(t,n,i){if(e(t,n,i))return r=n,!1}),r}function x(t,e,n,r){for(var i=t.length,o=n+(r?1:-1);r?o--:++o<i;)if(e(t[o],o,t))return o;return-1}function w(t,e,n){return e===e?$(t,e,n):x(t,k,n)}function C(t,e,n,r){for(var i=n-1,o=t.length;++i<o;)if(r(t[i],e))return i;return-1}function k(t){return t!==t}function E(t,e){var n=null==t?0:t.length;return n?A(t,e)/n:It}function M(t){return function(e){return null==e?nt:e[t]}}function T(t){return function(e){return null==t?nt:t[e]}}function S(t,e,n,r,i){return i(t,function(t,i,o){n=r?(r=!1,t):e(n,t,i,o)}),n}function N(t,e){var n=t.length;for(t.sort(e);n--;)t[n]=t[n].value;return t}function A(t,e){for(var n,r=-1,i=t.length;++r<i;){var o=e(t[r]);o!==nt&&(n=n===nt?o:n+o)}return n}function P(t,e){for(var n=-1,r=Array(t);++n<t;)r[n]=e(n);return r}function O(t,e){return h(e,function(e){return[e,t[e]]})}function I(t){return function(e){return t(e)}}function D(t,e){return h(e,function(e){return t[e]})}function R(t,e){return t.has(e)}function L(t,e){for(var n=-1,r=t.length;++n<r&&w(e,t[n],0)>-1;);return n}function U(t,e){for(var n=t.length;n--&&w(e,t[n],0)>-1;);return n}function F(t,e){for(var n=t.length,r=0;n--;)t[n]===e&&++r;return r}function j(t){return\"\\\\\"+En[t]}function B(t,e){return null==t?nt:t[e]}function V(t){return gn.test(t)}function W(t){return mn.test(t)}function z(t){for(var e,n=[];!(e=t.next()).done;)n.push(e.value);return n}function H(t){var e=-1,n=Array(t.size);return t.forEach(function(t,r){n[++e]=[r,t]}),n}function q(t,e){return function(n){return t(e(n))}}function Y(t,e){for(var n=-1,r=t.length,i=0,o=[];++n<r;){var a=t[n];a!==e&&a!==ct||(t[n]=ct,o[i++]=n)}return o}function K(t){var e=-1,n=Array(t.size);return t.forEach(function(t){n[++e]=t}),n}function G(t){var e=-1,n=Array(t.size);return t.forEach(function(t){n[++e]=[t,t]}),n}function $(t,e,n){for(var r=n-1,i=t.length;++r<i;)if(t[r]===e)return r;return-1}function X(t,e,n){for(var r=n+1;r--;)if(t[r]===e)return r;return r}function Q(t){return V(t)?J(t):Wn(t)}function Z(t){return V(t)?tt(t):y(t)}function J(t){for(var e=dn.lastIndex=0;dn.test(t);)++e;return e}function tt(t){return t.match(dn)||[]}function et(t){return t.match(vn)||[]}var nt,rt=200,it=\"Unsupported core-js use. Try https://npms.io/search?q=ponyfill.\",ot=\"Expected a function\",at=\"__lodash_hash_undefined__\",ut=500,ct=\"__lodash_placeholder__\",st=1,lt=2,ft=4,pt=1,ht=2,dt=1,vt=2,gt=4,mt=8,yt=16,_t=32,bt=64,xt=128,wt=256,Ct=512,kt=30,Et=\"...\",Mt=800,Tt=16,St=1,Nt=2,At=1/0,Pt=9007199254740991,Ot=1.7976931348623157e308,It=NaN,Dt=4294967295,Rt=Dt-1,Lt=Dt>>>1,Ut=[[\"ary\",xt],[\"bind\",dt],[\"bindKey\",vt],[\"curry\",mt],[\"curryRight\",yt],[\"flip\",Ct],[\"partial\",_t],[\"partialRight\",bt],[\"rearg\",wt]],Ft=\"[object Arguments]\",jt=\"[object Array]\",Bt=\"[object AsyncFunction]\",Vt=\"[object Boolean]\",Wt=\"[object Date]\",zt=\"[object DOMException]\",Ht=\"[object Error]\",qt=\"[object Function]\",Yt=\"[object GeneratorFunction]\",Kt=\"[object Map]\",Gt=\"[object Number]\",$t=\"[object Null]\",Xt=\"[object Object]\",Qt=\"[object Proxy]\",Zt=\"[object RegExp]\",Jt=\"[object Set]\",te=\"[object String]\",ee=\"[object Symbol]\",ne=\"[object Undefined]\",re=\"[object WeakMap]\",ie=\"[object WeakSet]\",oe=\"[object ArrayBuffer]\",ae=\"[object DataView]\",ue=\"[object Float32Array]\",ce=\"[object Float64Array]\",se=\"[object Int8Array]\",le=\"[object Int16Array]\",fe=\"[object Int32Array]\",pe=\"[object Uint8Array]\",he=\"[object Uint8ClampedArray]\",de=\"[object Uint16Array]\",ve=\"[object Uint32Array]\",ge=/\\b__p \\+= '';/g,me=/\\b(__p \\+=) '' \\+/g,ye=/(__e\\(.*?\\)|\\b__t\\)) \\+\\n'';/g,_e=/&(?:amp|lt|gt|quot|#39);/g,be=/[&<>\"']/g,xe=RegExp(_e.source),we=RegExp(be.source),Ce=/<%-([\\s\\S]+?)%>/g,ke=/<%([\\s\\S]+?)%>/g,Ee=/<%=([\\s\\S]+?)%>/g,Me=/\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,Te=/^\\w*$/,Se=/[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g,Ne=/[\\\\^$.*+?()[\\]{}|]/g,Ae=RegExp(Ne.source),Pe=/^\\s+|\\s+$/g,Oe=/^\\s+/,Ie=/\\s+$/,De=/\\{(?:\\n\\/\\* \\[wrapped with .+\\] \\*\\/)?\\n?/,Re=/\\{\\n\\/\\* \\[wrapped with (.+)\\] \\*/,Le=/,? & /,Ue=/[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g,Fe=/\\\\(\\\\)?/g,je=/\\$\\{([^\\\\}]*(?:\\\\.[^\\\\}]*)*)\\}/g,Be=/\\w*$/,Ve=/^[-+]0x[0-9a-f]+$/i,We=/^0b[01]+$/i,ze=/^\\[object .+?Constructor\\]$/,He=/^0o[0-7]+$/i,qe=/^(?:0|[1-9]\\d*)$/,Ye=/[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g,Ke=/($^)/,Ge=/['\\n\\r\\u2028\\u2029\\\\]/g,$e=\"\\\\u0300-\\\\u036f\\\\ufe20-\\\\ufe2f\\\\u20d0-\\\\u20ff\",Xe=\"\\\\xac\\\\xb1\\\\xd7\\\\xf7\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf\\\\u2000-\\\\u206f \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000\",Qe=\"[\"+Xe+\"]\",Ze=\"[\"+$e+\"]\",Je=\"[a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff]\",tn=\"[^\\\\ud800-\\\\udfff\"+Xe+\"\\\\d+\\\\u2700-\\\\u27bfa-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xffA-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde]\",en=\"\\\\ud83c[\\\\udffb-\\\\udfff]\",nn=\"(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}\",rn=\"[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]\",on=\"[A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde]\",an=\"(?:\"+Je+\"|\"+tn+\")\",un=\"(?:[\\\\u0300-\\\\u036f\\\\ufe20-\\\\ufe2f\\\\u20d0-\\\\u20ff]|\\\\ud83c[\\\\udffb-\\\\udfff])?\",cn=\"(?:\\\\u200d(?:\"+[\"[^\\\\ud800-\\\\udfff]\",nn,rn].join(\"|\")+\")[\\\\ufe0e\\\\ufe0f]?\"+un+\")*\",sn=\"[\\\\ufe0e\\\\ufe0f]?\"+un+cn,ln=\"(?:\"+[\"[\\\\u2700-\\\\u27bf]\",nn,rn].join(\"|\")+\")\"+sn,fn=\"(?:\"+[\"[^\\\\ud800-\\\\udfff]\"+Ze+\"?\",Ze,nn,rn,\"[\\\\ud800-\\\\udfff]\"].join(\"|\")+\")\",pn=RegExp(\"['’]\",\"g\"),hn=RegExp(Ze,\"g\"),dn=RegExp(en+\"(?=\"+en+\")|\"+fn+sn,\"g\"),vn=RegExp([on+\"?\"+Je+\"+(?:['’](?:d|ll|m|re|s|t|ve))?(?=\"+[Qe,on,\"$\"].join(\"|\")+\")\",\"(?:[A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde]|[^\\\\ud800-\\\\udfff\\\\xac\\\\xb1\\\\xd7\\\\xf7\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf\\\\u2000-\\\\u206f \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000\\\\d+\\\\u2700-\\\\u27bfa-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xffA-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde])+(?:['’](?:D|LL|M|RE|S|T|VE))?(?=\"+[Qe,on+an,\"$\"].join(\"|\")+\")\",on+\"?\"+an+\"+(?:['’](?:d|ll|m|re|s|t|ve))?\",on+\"+(?:['’](?:D|LL|M|RE|S|T|VE))?\",\"\\\\d*(?:1ST|2ND|3RD|(?![123])\\\\dTH)(?=\\\\b|[a-z_])\",\"\\\\d*(?:1st|2nd|3rd|(?![123])\\\\dth)(?=\\\\b|[A-Z_])\",\"\\\\d+\",ln].join(\"|\"),\"g\"),gn=RegExp(\"[\\\\u200d\\\\ud800-\\\\udfff\"+$e+\"\\\\ufe0e\\\\ufe0f]\"),mn=/[a-z][A-Z]|[A-Z]{2}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/,yn=[\"Array\",\"Buffer\",\"DataView\",\"Date\",\"Error\",\"Float32Array\",\"Float64Array\",\"Function\",\"Int8Array\",\"Int16Array\",\"Int32Array\",\"Map\",\"Math\",\"Object\",\"Promise\",\"RegExp\",\"Set\",\"String\",\"Symbol\",\"TypeError\",\"Uint8Array\",\"Uint8ClampedArray\",\"Uint16Array\",\"Uint32Array\",\"WeakMap\",\"_\",\"clearTimeout\",\"isFinite\",\"parseInt\",\"setTimeout\"],_n=-1,bn={};bn[ue]=bn[ce]=bn[se]=bn[le]=bn[fe]=bn[pe]=bn[he]=bn[de]=bn[ve]=!0,bn[Ft]=bn[jt]=bn[oe]=bn[Vt]=bn[ae]=bn[Wt]=bn[Ht]=bn[qt]=bn[Kt]=bn[Gt]=bn[Xt]=bn[Zt]=bn[Jt]=bn[te]=bn[re]=!1;var xn={};xn[Ft]=xn[jt]=xn[oe]=xn[ae]=xn[Vt]=xn[Wt]=xn[ue]=xn[ce]=xn[se]=xn[le]=xn[fe]=xn[Kt]=xn[Gt]=xn[Xt]=xn[Zt]=xn[Jt]=xn[te]=xn[ee]=xn[pe]=xn[he]=xn[de]=xn[ve]=!0,xn[Ht]=xn[qt]=xn[re]=!1;var wn={\"À\":\"A\",\"Á\":\"A\",\"Â\":\"A\",\"Ã\":\"A\",\"Ä\":\"A\",\"Å\":\"A\",\"à\":\"a\",\"á\":\"a\",\"â\":\"a\",\"ã\":\"a\",\"ä\":\"a\",\"å\":\"a\",\"Ç\":\"C\",\"ç\":\"c\",\"Ð\":\"D\",\"ð\":\"d\",\"È\":\"E\",\"É\":\"E\",\"Ê\":\"E\",\"Ë\":\"E\",\"è\":\"e\",\"é\":\"e\",\"ê\":\"e\",\"ë\":\"e\",\"Ì\":\"I\",\"Í\":\"I\",\"Î\":\"I\",\"Ï\":\"I\",\"ì\":\"i\",\"í\":\"i\",\"î\":\"i\",\"ï\":\"i\",\"Ñ\":\"N\",\"ñ\":\"n\",\"Ò\":\"O\",\"Ó\":\"O\",\"Ô\":\"O\",\"Õ\":\"O\",\"Ö\":\"O\",\"Ø\":\"O\",\"ò\":\"o\",\"ó\":\"o\",\"ô\":\"o\",\"õ\":\"o\",\"ö\":\"o\",\"ø\":\"o\",\"Ù\":\"U\",\"Ú\":\"U\",\"Û\":\"U\",\"Ü\":\"U\",\"ù\":\"u\",\"ú\":\"u\",\"û\":\"u\",\"ü\":\"u\",\"Ý\":\"Y\",\"ý\":\"y\",\"ÿ\":\"y\",\"Æ\":\"Ae\",\"æ\":\"ae\",\"Þ\":\"Th\",\"þ\":\"th\",\"ß\":\"ss\",\"Ā\":\"A\",\"Ă\":\"A\",\"Ą\":\"A\",\"ā\":\"a\",\"ă\":\"a\",\"ą\":\"a\",\"Ć\":\"C\",\"Ĉ\":\"C\",\"Ċ\":\"C\",\"Č\":\"C\",\"ć\":\"c\",\"ĉ\":\"c\",\"ċ\":\"c\",\"č\":\"c\",\"Ď\":\"D\",\"Đ\":\"D\",\"ď\":\"d\",\"đ\":\"d\",\"Ē\":\"E\",\"Ĕ\":\"E\",\"Ė\":\"E\",\"Ę\":\"E\",\"Ě\":\"E\",\"ē\":\"e\",\"ĕ\":\"e\",\"ė\":\"e\",\"ę\":\"e\",\"ě\":\"e\",\"Ĝ\":\"G\",\"Ğ\":\"G\",\"Ġ\":\"G\",\"Ģ\":\"G\",\"ĝ\":\"g\",\"ğ\":\"g\",\"ġ\":\"g\",\"ģ\":\"g\",\"Ĥ\":\"H\",\"Ħ\":\"H\",\"ĥ\":\"h\",\"ħ\":\"h\",\"Ĩ\":\"I\",\"Ī\":\"I\",\"Ĭ\":\"I\",\"Į\":\"I\",\"İ\":\"I\",\"ĩ\":\"i\",\"ī\":\"i\",\"ĭ\":\"i\",\"į\":\"i\",\"ı\":\"i\",\"Ĵ\":\"J\",\"ĵ\":\"j\",\"Ķ\":\"K\",\"ķ\":\"k\",\"ĸ\":\"k\",\"Ĺ\":\"L\",\"Ļ\":\"L\",\"Ľ\":\"L\",\"Ŀ\":\"L\",\"Ł\":\"L\",\"ĺ\":\"l\",\"ļ\":\"l\",\"ľ\":\"l\",\"ŀ\":\"l\",\"ł\":\"l\",\"Ń\":\"N\",\"Ņ\":\"N\",\"Ň\":\"N\",\"Ŋ\":\"N\",\"ń\":\"n\",\"ņ\":\"n\",\"ň\":\"n\",\"ŋ\":\"n\",\"Ō\":\"O\",\"Ŏ\":\"O\",\"Ő\":\"O\",\"ō\":\"o\",\"ŏ\":\"o\",\"ő\":\"o\",\"Ŕ\":\"R\",\"Ŗ\":\"R\",\"Ř\":\"R\",\"ŕ\":\"r\",\"ŗ\":\"r\",\"ř\":\"r\",\"Ś\":\"S\",\"Ŝ\":\"S\",\"Ş\":\"S\",\"Š\":\"S\",\"ś\":\"s\",\"ŝ\":\"s\",\"ş\":\"s\",\"š\":\"s\",\"Ţ\":\"T\",\"Ť\":\"T\",\"Ŧ\":\"T\",\"ţ\":\"t\",\"ť\":\"t\",\"ŧ\":\"t\",\"Ũ\":\"U\",\"Ū\":\"U\",\"Ŭ\":\"U\",\"Ů\":\"U\",\"Ű\":\"U\",\"Ų\":\"U\",\"ũ\":\"u\",\"ū\":\"u\",\"ŭ\":\"u\",\"ů\":\"u\",\"ű\":\"u\",\"ų\":\"u\",\"Ŵ\":\"W\",\"ŵ\":\"w\",\"Ŷ\":\"Y\",\"ŷ\":\"y\",\"Ÿ\":\"Y\",\"Ź\":\"Z\",\"Ż\":\"Z\",\"Ž\":\"Z\",\"ź\":\"z\",\"ż\":\"z\",\"ž\":\"z\",\"Ĳ\":\"IJ\",\"ĳ\":\"ij\",\"Œ\":\"Oe\",\"œ\":\"oe\",\"ŉ\":\"'n\",\"ſ\":\"s\"},Cn={\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#39;\"},kn={\"&amp;\":\"&\",\"&lt;\":\"<\",\"&gt;\":\">\",\"&quot;\":'\"',\"&#39;\":\"'\"},En={\"\\\\\":\"\\\\\",\"'\":\"'\",\"\\n\":\"n\",\"\\r\":\"r\",\"\\u2028\":\"u2028\",\"\\u2029\":\"u2029\"},Mn=parseFloat,Tn=parseInt,Sn=\"object\"==typeof t&&t&&t.Object===Object&&t,Nn=\"object\"==typeof self&&self&&self.Object===Object&&self,An=Sn||Nn||Function(\"return this\")(),Pn=\"object\"==typeof e&&e&&!e.nodeType&&e,On=Pn&&\"object\"==typeof r&&r&&!r.nodeType&&r,In=On&&On.exports===Pn,Dn=In&&Sn.process,Rn=function(){try{var t=On&&On.require&&On.require(\"util\").types;return t||Dn&&Dn.binding&&Dn.binding(\"util\")}catch(t){}}(),Ln=Rn&&Rn.isArrayBuffer,Un=Rn&&Rn.isDate,Fn=Rn&&Rn.isMap,jn=Rn&&Rn.isRegExp,Bn=Rn&&Rn.isSet,Vn=Rn&&Rn.isTypedArray,Wn=M(\"length\"),zn=T(wn),Hn=T(Cn),qn=T(kn),Yn=function t(e){function n(t){if(ec(t)&&!hp(t)&&!(t instanceof y)){if(t instanceof i)return t;if(pl.call(t,\"__wrapped__\"))return Zo(t)}return new i(t)}function r(){}function i(t,e){this.__wrapped__=t,this.__actions__=[],this.__chain__=!!e,this.__index__=0,this.__values__=nt}function y(t){this.__wrapped__=t,this.__actions__=[],this.__dir__=1,this.__filtered__=!1,this.__iteratees__=[],this.__takeCount__=Dt,this.__views__=[]}function T(){var t=new y(this.__wrapped__);return t.__actions__=Oi(this.__actions__),t.__dir__=this.__dir__,t.__filtered__=this.__filtered__,t.__iteratees__=Oi(this.__iteratees__),t.__takeCount__=this.__takeCount__,t.__views__=Oi(this.__views__),t}function $(){if(this.__filtered__){var t=new y(this);t.__dir__=-1,t.__filtered__=!0}else t=this.clone(),t.__dir__*=-1;return t}function J(){var t=this.__wrapped__.value(),e=this.__dir__,n=hp(t),r=e<0,i=n?t.length:0,o=wo(0,i,this.__views__),a=o.start,u=o.end,c=u-a,s=r?u:a-1,l=this.__iteratees__,f=l.length,p=0,h=Wl(c,this.__takeCount__);if(!n||!r&&i==c&&h==c)return vi(t,this.__actions__);var d=[];t:for(;c--&&p<h;){s+=e;for(var v=-1,g=t[s];++v<f;){var m=l[v],y=m.iteratee,_=m.type,b=y(g);if(_==Nt)g=b;else if(!b){if(_==St)continue t;break t}}d[p++]=g}return d}function tt(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function Ue(){this.__data__=Zl?Zl(null):{},this.size=0}function $e(t){var e=this.has(t)&&delete this.__data__[t];return this.size-=e?1:0,e}function Xe(t){var e=this.__data__;if(Zl){var n=e[t];return n===at?nt:n}return pl.call(e,t)?e[t]:nt}function Qe(t){var e=this.__data__;return Zl?e[t]!==nt:pl.call(e,t)}function Ze(t,e){var n=this.__data__;return this.size+=this.has(t)?0:1,n[t]=Zl&&e===nt?at:e,this}function Je(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function tn(){this.__data__=[],this.size=0}function en(t){var e=this.__data__,n=Kn(e,t);return!(n<0)&&(n==e.length-1?e.pop():Ml.call(e,n,1),--this.size,!0)}function nn(t){var e=this.__data__,n=Kn(e,t);return n<0?nt:e[n][1]}function rn(t){return Kn(this.__data__,t)>-1}function on(t,e){var n=this.__data__,r=Kn(n,t);return r<0?(++this.size,n.push([t,e])):n[r][1]=e,this}function an(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function un(){this.size=0,this.__data__={hash:new tt,map:new(Gl||Je),string:new tt}}function cn(t){var e=yo(this,t).delete(t);return this.size-=e?1:0,e}function sn(t){return yo(this,t).get(t)}function ln(t){return yo(this,t).has(t)}function fn(t,e){var n=yo(this,t),r=n.size;return n.set(t,e),this.size+=n.size==r?0:1,this}function dn(t){var e=-1,n=null==t?0:t.length;for(this.__data__=new an;++e<n;)this.add(t[e])}function vn(t){return this.__data__.set(t,at),this}function gn(t){return this.__data__.has(t)}function mn(t){var e=this.__data__=new Je(t);this.size=e.size}function wn(){this.__data__=new Je,this.size=0}function Cn(t){var e=this.__data__,n=e.delete(t);return this.size=e.size,n}function kn(t){return this.__data__.get(t)}function En(t){return this.__data__.has(t)}function Sn(t,e){var n=this.__data__;if(n instanceof Je){var r=n.__data__;if(!Gl||r.length<rt-1)return r.push([t,e]),this.size=++n.size,this;n=this.__data__=new an(r)}return n.set(t,e),this.size=n.size,this}function Nn(t,e){var n=hp(t),r=!n&&pp(t),i=!n&&!r&&vp(t),o=!n&&!r&&!i&&bp(t),a=n||r||i||o,u=a?P(t.length,ol):[],c=u.length;for(var s in t)!e&&!pl.call(t,s)||a&&(\"length\"==s||i&&(\"offset\"==s||\"parent\"==s)||o&&(\"buffer\"==s||\"byteLength\"==s||\"byteOffset\"==s)||Ao(s,c))||u.push(s);return u}function Pn(t){var e=t.length;return e?t[Xr(0,e-1)]:nt}function On(t,e){return Go(Oi(t),Jn(e,0,t.length))}function Dn(t){return Go(Oi(t))}function Rn(t,e,n){(n===nt||Vu(t[e],n))&&(n!==nt||e in t)||Qn(t,e,n)}function Wn(t,e,n){var r=t[e];pl.call(t,e)&&Vu(r,n)&&(n!==nt||e in t)||Qn(t,e,n)}function Kn(t,e){for(var n=t.length;n--;)if(Vu(t[n][0],e))return n;return-1}function Gn(t,e,n,r){return ff(t,function(t,i,o){e(r,t,n(t),o)}),r}function $n(t,e){return t&&Ii(e,Lc(e),t)}function Xn(t,e){return t&&Ii(e,Uc(e),t)}function Qn(t,e,n){\"__proto__\"==e&&Al?Al(t,e,{configurable:!0,enumerable:!0,value:n,writable:!0}):t[e]=n}function Zn(t,e){for(var n=-1,r=e.length,i=Zs(r),o=null==t;++n<r;)i[n]=o?nt:Ic(t,e[n]);return i}function Jn(t,e,n){return t===t&&(n!==nt&&(t=t<=n?t:n),e!==nt&&(t=t>=e?t:e)),t}function tr(t,e,n,r,i,o){var a,c=e&st,s=e&lt,l=e&ft;if(n&&(a=i?n(t,r,i,o):n(t)),a!==nt)return a;if(!tc(t))return t;var f=hp(t);if(f){if(a=Eo(t),!c)return Oi(t,a)}else{var p=Cf(t),h=p==qt||p==Yt;if(vp(t))return wi(t,c);if(p==Xt||p==Ft||h&&!i){if(a=s||h?{}:Mo(t),!c)return s?Ri(t,Xn(a,t)):Di(t,$n(a,t))}else{if(!xn[p])return i?t:{};a=To(t,p,c)}}o||(o=new mn);var d=o.get(t);if(d)return d;if(o.set(t,a),_p(t))return t.forEach(function(r){a.add(tr(r,e,n,r,t,o))}),a;if(mp(t))return t.forEach(function(r,i){a.set(i,tr(r,e,n,i,t,o))}),a;var v=l?s?ho:po:s?Uc:Lc,g=f?nt:v(t);return u(g||t,function(r,i){g&&(i=r,r=t[i]),Wn(a,i,tr(r,e,n,i,t,o))}),a}function er(t){var e=Lc(t);return function(n){return nr(n,t,e)}}function nr(t,e,n){var r=n.length;if(null==t)return!r;for(t=rl(t);r--;){var i=n[r],o=e[i],a=t[i];if(a===nt&&!(i in t)||!o(a))return!1}return!0}function rr(t,e,n){if(\"function\"!=typeof t)throw new al(ot);return Mf(function(){t.apply(nt,n)},e)}function ir(t,e,n,r){var i=-1,o=f,a=!0,u=t.length,c=[],s=e.length;if(!u)return c;n&&(e=h(e,I(n))),r?(o=p,a=!1):e.length>=rt&&(o=R,a=!1,e=new dn(e));t:for(;++i<u;){var l=t[i],d=null==n?l:n(l);if(l=r||0!==l?l:0,a&&d===d){for(var v=s;v--;)if(e[v]===d)continue t;c.push(l)}else o(e,d,r)||c.push(l)}return c}function or(t,e){var n=!0;return ff(t,function(t,r,i){return n=!!e(t,r,i)}),n}function ar(t,e,n){for(var r=-1,i=t.length;++r<i;){var o=t[r],a=e(o);if(null!=a&&(u===nt?a===a&&!pc(a):n(a,u)))var u=a,c=o}return c}function ur(t,e,n,r){var i=t.length;for(n=yc(n),n<0&&(n=-n>i?0:i+n),r=r===nt||r>i?i:yc(r),r<0&&(r+=i),r=n>r?0:_c(r);n<r;)t[n++]=e;return t}function cr(t,e){var n=[];return ff(t,function(t,r,i){e(t,r,i)&&n.push(t)}),n}function sr(t,e,n,r,i){var o=-1,a=t.length;for(n||(n=No),i||(i=[]);++o<a;){var u=t[o];e>0&&n(u)?e>1?sr(u,e-1,n,r,i):d(i,u):r||(i[i.length]=u)}return i}function lr(t,e){return t&&hf(t,e,Lc)}function fr(t,e){return t&&df(t,e,Lc)}function pr(t,e){return l(e,function(e){return Qu(t[e])})}function hr(t,e){e=bi(e,t);for(var n=0,r=e.length;null!=t&&n<r;)t=t[$o(e[n++])];return n&&n==r?t:nt}function dr(t,e,n){var r=e(t);return hp(t)?r:d(r,n(t))}function vr(t){return null==t?t===nt?ne:$t:Nl&&Nl in rl(t)?xo(t):Vo(t)}function gr(t,e){return t>e}function mr(t,e){return null!=t&&pl.call(t,e)}function yr(t,e){return null!=t&&e in rl(t)}function _r(t,e,n){return t>=Wl(e,n)&&t<Vl(e,n)}function br(t,e,n){for(var r=n?p:f,i=t[0].length,o=t.length,a=o,u=Zs(o),c=1/0,s=[];a--;){var l=t[a];a&&e&&(l=h(l,I(e))),c=Wl(l.length,c),u[a]=!n&&(e||i>=120&&l.length>=120)?new dn(a&&l):nt}l=t[0];var d=-1,v=u[0];t:for(;++d<i&&s.length<c;){var g=l[d],m=e?e(g):g;if(g=n||0!==g?g:0,!(v?R(v,m):r(s,m,n))){for(a=o;--a;){var y=u[a];if(!(y?R(y,m):r(t[a],m,n)))continue t}v&&v.push(m),s.push(g)}}return s}function xr(t,e,n,r){return lr(t,function(t,i,o){e(r,n(t),i,o)}),r}function wr(t,e,n){e=bi(e,t),t=zo(t,e);var r=null==t?t:t[$o(ma(e))];return null==r?nt:o(r,t,n)}function Cr(t){return ec(t)&&vr(t)==Ft}function kr(t){return ec(t)&&vr(t)==oe}function Er(t){return ec(t)&&vr(t)==Wt}function Mr(t,e,n,r,i){return t===e||(null==t||null==e||!ec(t)&&!ec(e)?t!==t&&e!==e:Tr(t,e,n,r,Mr,i))}function Tr(t,e,n,r,i,o){var a=hp(t),u=hp(e),c=a?jt:Cf(t),s=u?jt:Cf(e);c=c==Ft?Xt:c,s=s==Ft?Xt:s;var l=c==Xt,f=s==Xt,p=c==s;if(p&&vp(t)){if(!vp(e))return!1;a=!0,l=!1}if(p&&!l)return o||(o=new mn),a||bp(t)?co(t,e,n,r,i,o):so(t,e,c,n,r,i,o);if(!(n&pt)){var h=l&&pl.call(t,\"__wrapped__\"),d=f&&pl.call(e,\"__wrapped__\");if(h||d){var v=h?t.value():t,g=d?e.value():e;return o||(o=new mn),i(v,g,n,r,o)}}return!!p&&(o||(o=new mn),lo(t,e,n,r,i,o))}function Sr(t){return ec(t)&&Cf(t)==Kt}function Nr(t,e,n,r){var i=n.length,o=i,a=!r;if(null==t)return!o;for(t=rl(t);i--;){var u=n[i];if(a&&u[2]?u[1]!==t[u[0]]:!(u[0]in t))return!1}for(;++i<o;){u=n[i];var c=u[0],s=t[c],l=u[1];if(a&&u[2]){if(s===nt&&!(c in t))return!1}else{var f=new mn;if(r)var p=r(s,l,c,t,e,f);if(!(p===nt?Mr(l,s,pt|ht,r,f):p))return!1}}return!0}function Ar(t){return!(!tc(t)||Ro(t))&&(Qu(t)?yl:ze).test(Xo(t))}function Pr(t){return ec(t)&&vr(t)==Zt}function Or(t){return ec(t)&&Cf(t)==Jt}function Ir(t){return ec(t)&&Ju(t.length)&&!!bn[vr(t)]}function Dr(t){return\"function\"==typeof t?t:null==t?Ms:\"object\"==typeof t?hp(t)?Br(t[0],t[1]):jr(t):Ds(t)}function Rr(t){if(!Lo(t))return Bl(t);var e=[];for(var n in rl(t))pl.call(t,n)&&\"constructor\"!=n&&e.push(n);return e}function Lr(t){if(!tc(t))return Bo(t);var e=Lo(t),n=[];for(var r in t)(\"constructor\"!=r||!e&&pl.call(t,r))&&n.push(r);return n}function Ur(t,e){return t<e}function Fr(t,e){var n=-1,r=Wu(t)?Zs(t.length):[];return ff(t,function(t,i,o){r[++n]=e(t,i,o)}),r}function jr(t){var e=_o(t);return 1==e.length&&e[0][2]?Fo(e[0][0],e[0][1]):function(n){return n===t||Nr(n,t,e)}}function Br(t,e){return Oo(t)&&Uo(e)?Fo($o(t),e):function(n){var r=Ic(n,t);return r===nt&&r===e?Rc(n,t):Mr(e,r,pt|ht)}}function Vr(t,e,n,r,i){t!==e&&hf(e,function(o,a){if(tc(o))i||(i=new mn),Wr(t,e,a,n,Vr,r,i);else{var u=r?r(qo(t,a),o,a+\"\",t,e,i):nt;u===nt&&(u=o),Rn(t,a,u)}},Uc)}function Wr(t,e,n,r,i,o,a){var u=qo(t,n),c=qo(e,n),s=a.get(c);if(s)return void Rn(t,n,s);var l=o?o(u,c,n+\"\",t,e,a):nt,f=l===nt;if(f){var p=hp(c),h=!p&&vp(c),d=!p&&!h&&bp(c);l=c,p||h||d?hp(u)?l=u:zu(u)?l=Oi(u):h?(f=!1,l=wi(c,!0)):d?(f=!1,l=Ti(c,!0)):l=[]:sc(c)||pp(c)?(l=u,pp(u)?l=xc(u):tc(u)&&!Qu(u)||(l=Mo(c))):f=!1}f&&(a.set(c,l),i(l,c,r,o,a),a.delete(c)),Rn(t,n,l)}function zr(t,e){var n=t.length;if(n)return e+=e<0?n:0,Ao(e,n)?t[e]:nt}function Hr(t,e,n){var r=-1;return e=h(e.length?e:[Ms],I(mo())),N(Fr(t,function(t,n,i){return{criteria:h(e,function(e){return e(t)}),index:++r,value:t}}),function(t,e){return Ni(t,e,n)})}function qr(t,e){return Yr(t,e,function(e,n){return Rc(t,n)})}function Yr(t,e,n){for(var r=-1,i=e.length,o={};++r<i;){var a=e[r],u=hr(t,a);n(u,a)&&ni(o,bi(a,t),u)}return o}function Kr(t){return function(e){return hr(e,t)}}function Gr(t,e,n,r){var i=r?C:w,o=-1,a=e.length,u=t;for(t===e&&(e=Oi(e)),n&&(u=h(t,I(n)));++o<a;)for(var c=0,s=e[o],l=n?n(s):s;(c=i(u,l,c,r))>-1;)u!==t&&Ml.call(u,c,1),Ml.call(t,c,1);return t}function $r(t,e){for(var n=t?e.length:0,r=n-1;n--;){var i=e[n];if(n==r||i!==o){var o=i;Ao(i)?Ml.call(t,i,1):pi(t,i)}}return t}function Xr(t,e){return t+Rl(ql()*(e-t+1))}function Qr(t,e,n,r){for(var i=-1,o=Vl(Dl((e-t)/(n||1)),0),a=Zs(o);o--;)a[r?o:++i]=t,t+=n;return a}function Zr(t,e){var n=\"\";if(!t||e<1||e>Pt)return n;do{e%2&&(n+=t),(e=Rl(e/2))&&(t+=t)}while(e);return n}function Jr(t,e){return Tf(Wo(t,e,Ms),t+\"\")}function ti(t){return Pn($c(t))}function ei(t,e){var n=$c(t);return Go(n,Jn(e,0,n.length))}function ni(t,e,n,r){if(!tc(t))return t;e=bi(e,t);for(var i=-1,o=e.length,a=o-1,u=t;null!=u&&++i<o;){var c=$o(e[i]),s=n;if(i!=a){var l=u[c];s=r?r(l,c,u):nt,s===nt&&(s=tc(l)?l:Ao(e[i+1])?[]:{})}Wn(u,c,s),u=u[c]}return t}function ri(t){return Go($c(t))}function ii(t,e,n){var r=-1,i=t.length;e<0&&(e=-e>i?0:i+e),n=n>i?i:n,n<0&&(n+=i),i=e>n?0:n-e>>>0,e>>>=0;for(var o=Zs(i);++r<i;)o[r]=t[r+e];return o}function oi(t,e){var n;return ff(t,function(t,r,i){return!(n=e(t,r,i))}),!!n}function ai(t,e,n){var r=0,i=null==t?r:t.length;if(\"number\"==typeof e&&e===e&&i<=Lt){for(;r<i;){var o=r+i>>>1,a=t[o];null!==a&&!pc(a)&&(n?a<=e:a<e)?r=o+1:i=o}return i}return ui(t,e,Ms,n)}function ui(t,e,n,r){e=n(e);for(var i=0,o=null==t?0:t.length,a=e!==e,u=null===e,c=pc(e),s=e===nt;i<o;){var l=Rl((i+o)/2),f=n(t[l]),p=f!==nt,h=null===f,d=f===f,v=pc(f);if(a)var g=r||d;else g=s?d&&(r||p):u?d&&p&&(r||!h):c?d&&p&&!h&&(r||!v):!h&&!v&&(r?f<=e:f<e);g?i=l+1:o=l}return Wl(o,Rt)}function ci(t,e){for(var n=-1,r=t.length,i=0,o=[];++n<r;){var a=t[n],u=e?e(a):a;if(!n||!Vu(u,c)){var c=u;o[i++]=0===a?0:a}}return o}function si(t){return\"number\"==typeof t?t:pc(t)?It:+t}function li(t){if(\"string\"==typeof t)return t;if(hp(t))return h(t,li)+\"\";if(pc(t))return sf?sf.call(t):\"\";var e=t+\"\";return\"0\"==e&&1/t==-At?\"-0\":e}function fi(t,e,n){var r=-1,i=f,o=t.length,a=!0,u=[],c=u;if(n)a=!1,i=p;else if(o>=rt){var s=e?null:_f(t);if(s)return K(s);a=!1,i=R,c=new dn}else c=e?[]:u;t:for(;++r<o;){var l=t[r],h=e?e(l):l;if(l=n||0!==l?l:0,a&&h===h){for(var d=c.length;d--;)if(c[d]===h)continue t;e&&c.push(h),u.push(l)}else i(c,h,n)||(c!==u&&c.push(h),u.push(l))}return u}function pi(t,e){return e=bi(e,t),null==(t=zo(t,e))||delete t[$o(ma(e))]}function hi(t,e,n,r){return ni(t,e,n(hr(t,e)),r)}function di(t,e,n,r){for(var i=t.length,o=r?i:-1;(r?o--:++o<i)&&e(t[o],o,t););return n?ii(t,r?0:o,r?o+1:i):ii(t,r?o+1:0,r?i:o)}function vi(t,e){var n=t;return n instanceof y&&(n=n.value()),v(e,function(t,e){return e.func.apply(e.thisArg,d([t],e.args))},n)}function gi(t,e,n){var r=t.length;if(r<2)return r?fi(t[0]):[];for(var i=-1,o=Zs(r);++i<r;)for(var a=t[i],u=-1;++u<r;)u!=i&&(o[i]=ir(o[i]||a,t[u],e,n));return fi(sr(o,1),e,n)}function mi(t,e,n){for(var r=-1,i=t.length,o=e.length,a={};++r<i;){var u=r<o?e[r]:nt;n(a,t[r],u)}return a}function yi(t){return zu(t)?t:[]}function _i(t){return\"function\"==typeof t?t:Ms}function bi(t,e){return hp(t)?t:Oo(t,e)?[t]:Sf(Cc(t))}function xi(t,e,n){var r=t.length;return n=n===nt?r:n,!e&&n>=r?t:ii(t,e,n)}function wi(t,e){if(e)return t.slice();var n=t.length,r=wl?wl(n):new t.constructor(n);return t.copy(r),r}function Ci(t){var e=new t.constructor(t.byteLength);return new xl(e).set(new xl(t)),e}function ki(t,e){var n=e?Ci(t.buffer):t.buffer;return new t.constructor(n,t.byteOffset,t.byteLength)}function Ei(t){var e=new t.constructor(t.source,Be.exec(t));return e.lastIndex=t.lastIndex,e}function Mi(t){return cf?rl(cf.call(t)):{}}function Ti(t,e){var n=e?Ci(t.buffer):t.buffer;return new t.constructor(n,t.byteOffset,t.length)}function Si(t,e){if(t!==e){var n=t!==nt,r=null===t,i=t===t,o=pc(t),a=e!==nt,u=null===e,c=e===e,s=pc(e);if(!u&&!s&&!o&&t>e||o&&a&&c&&!u&&!s||r&&a&&c||!n&&c||!i)return 1;if(!r&&!o&&!s&&t<e||s&&n&&i&&!r&&!o||u&&n&&i||!a&&i||!c)return-1}return 0}function Ni(t,e,n){for(var r=-1,i=t.criteria,o=e.criteria,a=i.length,u=n.length;++r<a;){var c=Si(i[r],o[r]);if(c){if(r>=u)return c;return c*(\"desc\"==n[r]?-1:1)}}return t.index-e.index}function Ai(t,e,n,r){for(var i=-1,o=t.length,a=n.length,u=-1,c=e.length,s=Vl(o-a,0),l=Zs(c+s),f=!r;++u<c;)l[u]=e[u];for(;++i<a;)(f||i<o)&&(l[n[i]]=t[i]);for(;s--;)l[u++]=t[i++];return l}function Pi(t,e,n,r){for(var i=-1,o=t.length,a=-1,u=n.length,c=-1,s=e.length,l=Vl(o-u,0),f=Zs(l+s),p=!r;++i<l;)f[i]=t[i];for(var h=i;++c<s;)f[h+c]=e[c];for(;++a<u;)(p||i<o)&&(f[h+n[a]]=t[i++]);return f}function Oi(t,e){var n=-1,r=t.length;for(e||(e=Zs(r));++n<r;)e[n]=t[n];return e}function Ii(t,e,n,r){var i=!n;n||(n={});for(var o=-1,a=e.length;++o<a;){var u=e[o],c=r?r(n[u],t[u],u,n,t):nt;c===nt&&(c=t[u]),i?Qn(n,u,c):Wn(n,u,c)}return n}function Di(t,e){return Ii(t,xf(t),e)}function Ri(t,e){return Ii(t,wf(t),e)}function Li(t,e){return function(n,r){var i=hp(n)?a:Gn,o=e?e():{};return i(n,t,mo(r,2),o)}}function Ui(t){return Jr(function(e,n){var r=-1,i=n.length,o=i>1?n[i-1]:nt,a=i>2?n[2]:nt;for(o=t.length>3&&\"function\"==typeof o?(i--,o):nt,a&&Po(n[0],n[1],a)&&(o=i<3?nt:o,i=1),e=rl(e);++r<i;){var u=n[r];u&&t(e,u,r,o)}return e})}function Fi(t,e){return function(n,r){if(null==n)return n;if(!Wu(n))return t(n,r);for(var i=n.length,o=e?i:-1,a=rl(n);(e?o--:++o<i)&&!1!==r(a[o],o,a););return n}}function ji(t){return function(e,n,r){for(var i=-1,o=rl(e),a=r(e),u=a.length;u--;){var c=a[t?u:++i];if(!1===n(o[c],c,o))break}return e}}function Bi(t,e,n){function r(){return(this&&this!==An&&this instanceof r?o:t).apply(i?n:this,arguments)}var i=e&dt,o=zi(t);return r}function Vi(t){return function(e){e=Cc(e);var n=V(e)?Z(e):nt,r=n?n[0]:e.charAt(0),i=n?xi(n,1).join(\"\"):e.slice(1);return r[t]()+i}}function Wi(t){return function(e){return v(xs(es(e).replace(pn,\"\")),t,\"\")}}function zi(t){return function(){var e=arguments;switch(e.length){case 0:return new t;case 1:return new t(e[0]);case 2:return new t(e[0],e[1]);case 3:return new t(e[0],e[1],e[2]);case 4:return new t(e[0],e[1],e[2],e[3]);case 5:return new t(e[0],e[1],e[2],e[3],e[4]);case 6:return new t(e[0],e[1],e[2],e[3],e[4],e[5]);case 7:return new t(e[0],e[1],e[2],e[3],e[4],e[5],e[6])}var n=lf(t.prototype),r=t.apply(n,e);return tc(r)?r:n}}function Hi(t,e,n){function r(){for(var a=arguments.length,u=Zs(a),c=a,s=go(r);c--;)u[c]=arguments[c];var l=a<3&&u[0]!==s&&u[a-1]!==s?[]:Y(u,s);return(a-=l.length)<n?eo(t,e,Ki,r.placeholder,nt,u,l,nt,nt,n-a):o(this&&this!==An&&this instanceof r?i:t,this,u)}var i=zi(t);return r}function qi(t){return function(e,n,r){var i=rl(e);if(!Wu(e)){var o=mo(n,3);e=Lc(e),n=function(t){return o(i[t],t,i)}}var a=t(e,n,r);return a>-1?i[o?e[a]:a]:nt}}function Yi(t){return fo(function(e){var n=e.length,r=n,o=i.prototype.thru;for(t&&e.reverse();r--;){var a=e[r];if(\"function\"!=typeof a)throw new al(ot);if(o&&!u&&\"wrapper\"==vo(a))var u=new i([],!0)}for(r=u?r:n;++r<n;){a=e[r];var c=vo(a),s=\"wrapper\"==c?bf(a):nt;u=s&&Do(s[0])&&s[1]==(xt|mt|_t|wt)&&!s[4].length&&1==s[9]?u[vo(s[0])].apply(u,s[3]):1==a.length&&Do(a)?u[c]():u.thru(a)}return function(){var t=arguments,r=t[0];if(u&&1==t.length&&hp(r))return u.plant(r).value();for(var i=0,o=n?e[i].apply(this,t):r;++i<n;)o=e[i].call(this,o);return o}})}function Ki(t,e,n,r,i,o,a,u,c,s){function l(){for(var m=arguments.length,y=Zs(m),_=m;_--;)y[_]=arguments[_];if(d)var b=go(l),x=F(y,b);if(r&&(y=Ai(y,r,i,d)),o&&(y=Pi(y,o,a,d)),m-=x,d&&m<s){var w=Y(y,b);return eo(t,e,Ki,l.placeholder,n,y,w,u,c,s-m)}var C=p?n:this,k=h?C[t]:t;return m=y.length,u?y=Ho(y,u):v&&m>1&&y.reverse(),f&&c<m&&(y.length=c),this&&this!==An&&this instanceof l&&(k=g||zi(k)),k.apply(C,y)}var f=e&xt,p=e&dt,h=e&vt,d=e&(mt|yt),v=e&Ct,g=h?nt:zi(t);return l}function Gi(t,e){return function(n,r){return xr(n,t,e(r),{})}}function $i(t,e){return function(n,r){var i;if(n===nt&&r===nt)return e;if(n!==nt&&(i=n),r!==nt){if(i===nt)return r;\"string\"==typeof n||\"string\"==typeof r?(n=li(n),r=li(r)):(n=si(n),r=si(r)),i=t(n,r)}return i}}function Xi(t){return fo(function(e){return e=h(e,I(mo())),Jr(function(n){var r=this;return t(e,function(t){return o(t,r,n)})})})}function Qi(t,e){e=e===nt?\" \":li(e);var n=e.length;if(n<2)return n?Zr(e,t):e;var r=Zr(e,Dl(t/Q(e)));return V(e)?xi(Z(r),0,t).join(\"\"):r.slice(0,t)}function Zi(t,e,n,r){function i(){for(var e=-1,c=arguments.length,s=-1,l=r.length,f=Zs(l+c),p=this&&this!==An&&this instanceof i?u:t;++s<l;)f[s]=r[s];for(;c--;)f[s++]=arguments[++e];return o(p,a?n:this,f)}var a=e&dt,u=zi(t);return i}function Ji(t){return function(e,n,r){return r&&\"number\"!=typeof r&&Po(e,n,r)&&(n=r=nt),e=mc(e),n===nt?(n=e,e=0):n=mc(n),r=r===nt?e<n?1:-1:mc(r),Qr(e,n,r,t)}}function to(t){return function(e,n){return\"string\"==typeof e&&\"string\"==typeof n||(e=bc(e),n=bc(n)),t(e,n)}}function eo(t,e,n,r,i,o,a,u,c,s){var l=e&mt,f=l?a:nt,p=l?nt:a,h=l?o:nt,d=l?nt:o;e|=l?_t:bt,(e&=~(l?bt:_t))&gt||(e&=~(dt|vt));var v=[t,e,i,h,f,d,p,u,c,s],g=n.apply(nt,v);return Do(t)&&Ef(g,v),g.placeholder=r,Yo(g,t,e)}function no(t){var e=nl[t];return function(t,n){if(t=bc(t),n=null==n?0:Wl(yc(n),292)){var r=(Cc(t)+\"e\").split(\"e\");return r=(Cc(e(r[0]+\"e\"+(+r[1]+n)))+\"e\").split(\"e\"),+(r[0]+\"e\"+(+r[1]-n))}return e(t)}}function ro(t){return function(e){var n=Cf(e);return n==Kt?H(e):n==Jt?G(e):O(e,t(e))}}function io(t,e,n,r,i,o,a,u){var c=e&vt;if(!c&&\"function\"!=typeof t)throw new al(ot);var s=r?r.length:0;if(s||(e&=~(_t|bt),r=i=nt),a=a===nt?a:Vl(yc(a),0),u=u===nt?u:yc(u),s-=i?i.length:0,e&bt){var l=r,f=i;r=i=nt}var p=c?nt:bf(t),h=[t,e,n,r,i,l,f,o,a,u];if(p&&jo(h,p),t=h[0],e=h[1],n=h[2],r=h[3],i=h[4],u=h[9]=h[9]===nt?c?0:t.length:Vl(h[9]-s,0),!u&&e&(mt|yt)&&(e&=~(mt|yt)),e&&e!=dt)d=e==mt||e==yt?Hi(t,e,u):e!=_t&&e!=(dt|_t)||i.length?Ki.apply(nt,h):Zi(t,e,n,r);else var d=Bi(t,e,n);return Yo((p?vf:Ef)(d,h),t,e)}function oo(t,e,n,r){return t===nt||Vu(t,sl[n])&&!pl.call(r,n)?e:t}function ao(t,e,n,r,i,o){return tc(t)&&tc(e)&&(o.set(e,t),Vr(t,e,nt,ao,o),o.delete(e)),t}function uo(t){return sc(t)?nt:t}function co(t,e,n,r,i,o){var a=n&pt,u=t.length,c=e.length;if(u!=c&&!(a&&c>u))return!1;var s=o.get(t);if(s&&o.get(e))return s==e;var l=-1,f=!0,p=n&ht?new dn:nt;for(o.set(t,e),o.set(e,t);++l<u;){var h=t[l],d=e[l];if(r)var v=a?r(d,h,l,e,t,o):r(h,d,l,t,e,o);if(v!==nt){if(v)continue;f=!1;break}if(p){if(!m(e,function(t,e){if(!R(p,e)&&(h===t||i(h,t,n,r,o)))return p.push(e)})){f=!1;break}}else if(h!==d&&!i(h,d,n,r,o)){f=!1;break}}return o.delete(t),o.delete(e),f}function so(t,e,n,r,i,o,a){switch(n){case ae:if(t.byteLength!=e.byteLength||t.byteOffset!=e.byteOffset)return!1;t=t.buffer,e=e.buffer;case oe:return!(t.byteLength!=e.byteLength||!o(new xl(t),new xl(e)));case Vt:case Wt:case Gt:return Vu(+t,+e);case Ht:return t.name==e.name&&t.message==e.message;case Zt:case te:return t==e+\"\";case Kt:var u=H;case Jt:var c=r&pt;if(u||(u=K),t.size!=e.size&&!c)return!1;var s=a.get(t);if(s)return s==e;r|=ht,a.set(t,e);var l=co(u(t),u(e),r,i,o,a);return a.delete(t),l;case ee:if(cf)return cf.call(t)==cf.call(e)}return!1}function lo(t,e,n,r,i,o){var a=n&pt,u=po(t),c=u.length;if(c!=po(e).length&&!a)return!1;for(var s=c;s--;){var l=u[s];if(!(a?l in e:pl.call(e,l)))return!1}var f=o.get(t);if(f&&o.get(e))return f==e;var p=!0;o.set(t,e),o.set(e,t);for(var h=a;++s<c;){l=u[s];var d=t[l],v=e[l];if(r)var g=a?r(v,d,l,e,t,o):r(d,v,l,t,e,o);if(!(g===nt?d===v||i(d,v,n,r,o):g)){p=!1;break}h||(h=\"constructor\"==l)}if(p&&!h){var m=t.constructor,y=e.constructor;m!=y&&\"constructor\"in t&&\"constructor\"in e&&!(\"function\"==typeof m&&m instanceof m&&\"function\"==typeof y&&y instanceof y)&&(p=!1)}return o.delete(t),o.delete(e),p}function fo(t){return Tf(Wo(t,nt,sa),t+\"\")}function po(t){return dr(t,Lc,xf)}function ho(t){return dr(t,Uc,wf)}function vo(t){for(var e=t.name+\"\",n=tf[e],r=pl.call(tf,e)?n.length:0;r--;){var i=n[r],o=i.func;if(null==o||o==t)return i.name}return e}function go(t){return(pl.call(n,\"placeholder\")?n:t).placeholder}function mo(){var t=n.iteratee||Ts;return t=t===Ts?Dr:t,arguments.length?t(arguments[0],arguments[1]):t}function yo(t,e){var n=t.__data__;return Io(e)?n[\"string\"==typeof e?\"string\":\"hash\"]:n.map}function _o(t){for(var e=Lc(t),n=e.length;n--;){var r=e[n],i=t[r];e[n]=[r,i,Uo(i)]}return e}function bo(t,e){var n=B(t,e);return Ar(n)?n:nt}function xo(t){var e=pl.call(t,Nl),n=t[Nl];try{t[Nl]=nt;var r=!0}catch(t){}var i=vl.call(t);return r&&(e?t[Nl]=n:delete t[Nl]),i}function wo(t,e,n){for(var r=-1,i=n.length;++r<i;){var o=n[r],a=o.size;switch(o.type){case\"drop\":t+=a;break;case\"dropRight\":e-=a;break;case\"take\":e=Wl(e,t+a);break;case\"takeRight\":t=Vl(t,e-a)}}return{start:t,end:e}}function Co(t){var e=t.match(Re);return e?e[1].split(Le):[]}function ko(t,e,n){e=bi(e,t);for(var r=-1,i=e.length,o=!1;++r<i;){var a=$o(e[r]);if(!(o=null!=t&&n(t,a)))break;t=t[a]}return o||++r!=i?o:!!(i=null==t?0:t.length)&&Ju(i)&&Ao(a,i)&&(hp(t)||pp(t))}function Eo(t){var e=t.length,n=new t.constructor(e);return e&&\"string\"==typeof t[0]&&pl.call(t,\"index\")&&(n.index=t.index,n.input=t.input),n}function Mo(t){return\"function\"!=typeof t.constructor||Lo(t)?{}:lf(Cl(t))}function To(t,e,n){var r=t.constructor;switch(e){case oe:return Ci(t);case Vt:case Wt:return new r(+t);case ae:return ki(t,n);case ue:case ce:case se:case le:case fe:case pe:case he:case de:case ve:return Ti(t,n);case Kt:return new r;case Gt:case te:return new r(t);case Zt:return Ei(t);case Jt:return new r;case ee:return Mi(t)}}function So(t,e){var n=e.length;if(!n)return t;var r=n-1;return e[r]=(n>1?\"& \":\"\")+e[r],e=e.join(n>2?\", \":\" \"),t.replace(De,\"{\\n/* [wrapped with \"+e+\"] */\\n\")}function No(t){return hp(t)||pp(t)||!!(Tl&&t&&t[Tl])}function Ao(t,e){var n=typeof t;return!!(e=null==e?Pt:e)&&(\"number\"==n||\"symbol\"!=n&&qe.test(t))&&t>-1&&t%1==0&&t<e}function Po(t,e,n){if(!tc(n))return!1;var r=typeof e;return!!(\"number\"==r?Wu(n)&&Ao(e,n.length):\"string\"==r&&e in n)&&Vu(n[e],t)}function Oo(t,e){if(hp(t))return!1;var n=typeof t;return!(\"number\"!=n&&\"symbol\"!=n&&\"boolean\"!=n&&null!=t&&!pc(t))||(Te.test(t)||!Me.test(t)||null!=e&&t in rl(e))}function Io(t){var e=typeof t;return\"string\"==e||\"number\"==e||\"symbol\"==e||\"boolean\"==e?\"__proto__\"!==t:null===t}function Do(t){var e=vo(t),r=n[e];if(\"function\"!=typeof r||!(e in y.prototype))return!1;if(t===r)return!0;var i=bf(r);return!!i&&t===i[0]}function Ro(t){return!!dl&&dl in t}function Lo(t){var e=t&&t.constructor;return t===(\"function\"==typeof e&&e.prototype||sl)}function Uo(t){return t===t&&!tc(t)}function Fo(t,e){return function(n){return null!=n&&(n[t]===e&&(e!==nt||t in rl(n)))}}function jo(t,e){var n=t[1],r=e[1],i=n|r,o=i<(dt|vt|xt),a=r==xt&&n==mt||r==xt&&n==wt&&t[7].length<=e[8]||r==(xt|wt)&&e[7].length<=e[8]&&n==mt;if(!o&&!a)return t;r&dt&&(t[2]=e[2],i|=n&dt?0:gt);var u=e[3];if(u){var c=t[3];t[3]=c?Ai(c,u,e[4]):u,t[4]=c?Y(t[3],ct):e[4]}return u=e[5],u&&(c=t[5],t[5]=c?Pi(c,u,e[6]):u,t[6]=c?Y(t[5],ct):e[6]),u=e[7],u&&(t[7]=u),r&xt&&(t[8]=null==t[8]?e[8]:Wl(t[8],e[8])),null==t[9]&&(t[9]=e[9]),t[0]=e[0],t[1]=i,t}function Bo(t){var e=[];if(null!=t)for(var n in rl(t))e.push(n);return e}function Vo(t){return vl.call(t)}function Wo(t,e,n){return e=Vl(e===nt?t.length-1:e,0),function(){for(var r=arguments,i=-1,a=Vl(r.length-e,0),u=Zs(a);++i<a;)u[i]=r[e+i];i=-1;for(var c=Zs(e+1);++i<e;)c[i]=r[i];return c[e]=n(u),o(t,this,c)}}function zo(t,e){return e.length<2?t:hr(t,ii(e,0,-1))}function Ho(t,e){for(var n=t.length,r=Wl(e.length,n),i=Oi(t);r--;){var o=e[r];t[r]=Ao(o,n)?i[o]:nt}return t}function qo(t,e){if(\"__proto__\"!=e)return t[e]}function Yo(t,e,n){var r=e+\"\";return Tf(t,So(r,Qo(Co(r),n)))}function Ko(t){var e=0,n=0;return function(){var r=zl(),i=Tt-(r-n);if(n=r,i>0){if(++e>=Mt)return arguments[0]}else e=0;return t.apply(nt,arguments)}}function Go(t,e){var n=-1,r=t.length,i=r-1;for(e=e===nt?r:e;++n<e;){var o=Xr(n,i),a=t[o];t[o]=t[n],t[n]=a}return t.length=e,t}function $o(t){if(\"string\"==typeof t||pc(t))return t;var e=t+\"\";return\"0\"==e&&1/t==-At?\"-0\":e}function Xo(t){if(null!=t){try{return fl.call(t)}catch(t){}try{return t+\"\"}catch(t){}}return\"\"}function Qo(t,e){return u(Ut,function(n){var r=\"_.\"+n[0];e&n[1]&&!f(t,r)&&t.push(r)}),t.sort()}function Zo(t){if(t instanceof y)return t.clone();var e=new i(t.__wrapped__,t.__chain__);return e.__actions__=Oi(t.__actions__),e.__index__=t.__index__,e.__values__=t.__values__,e}function Jo(t,e,n){e=(n?Po(t,e,n):e===nt)?1:Vl(yc(e),0);var r=null==t?0:t.length;if(!r||e<1)return[];for(var i=0,o=0,a=Zs(Dl(r/e));i<r;)a[o++]=ii(t,i,i+=e);return a}function ta(t){for(var e=-1,n=null==t?0:t.length,r=0,i=[];++e<n;){var o=t[e];o&&(i[r++]=o)}return i}function ea(){var t=arguments.length;if(!t)return[];for(var e=Zs(t-1),n=arguments[0],r=t;r--;)e[r-1]=arguments[r];return d(hp(n)?Oi(n):[n],sr(e,1))}function na(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===nt?1:yc(e),ii(t,e<0?0:e,r)):[]}function ra(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===nt?1:yc(e),e=r-e,ii(t,0,e<0?0:e)):[]}function ia(t,e){return t&&t.length?di(t,mo(e,3),!0,!0):[]}function oa(t,e){return t&&t.length?di(t,mo(e,3),!0):[]}function aa(t,e,n,r){var i=null==t?0:t.length;return i?(n&&\"number\"!=typeof n&&Po(t,e,n)&&(n=0,r=i),ur(t,e,n,r)):[]}function ua(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=null==n?0:yc(n);return i<0&&(i=Vl(r+i,0)),x(t,mo(e,3),i)}function ca(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=r-1;return n!==nt&&(i=yc(n),i=n<0?Vl(r+i,0):Wl(i,r-1)),x(t,mo(e,3),i,!0)}function sa(t){return(null==t?0:t.length)?sr(t,1):[]}function la(t){return(null==t?0:t.length)?sr(t,At):[]}function fa(t,e){return(null==t?0:t.length)?(e=e===nt?1:yc(e),sr(t,e)):[]}function pa(t){for(var e=-1,n=null==t?0:t.length,r={};++e<n;){var i=t[e];r[i[0]]=i[1]}return r}function ha(t){return t&&t.length?t[0]:nt}function da(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=null==n?0:yc(n);return i<0&&(i=Vl(r+i,0)),w(t,e,i)}function va(t){return(null==t?0:t.length)?ii(t,0,-1):[]}function ga(t,e){return null==t?\"\":jl.call(t,e)}function ma(t){var e=null==t?0:t.length;return e?t[e-1]:nt}function ya(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=r;return n!==nt&&(i=yc(n),i=i<0?Vl(r+i,0):Wl(i,r-1)),e===e?X(t,e,i):x(t,k,i,!0)}function _a(t,e){return t&&t.length?zr(t,yc(e)):nt}function ba(t,e){return t&&t.length&&e&&e.length?Gr(t,e):t}function xa(t,e,n){return t&&t.length&&e&&e.length?Gr(t,e,mo(n,2)):t}function wa(t,e,n){return t&&t.length&&e&&e.length?Gr(t,e,nt,n):t}function Ca(t,e){var n=[];if(!t||!t.length)return n;var r=-1,i=[],o=t.length;for(e=mo(e,3);++r<o;){var a=t[r];e(a,r,t)&&(n.push(a),i.push(r))}return $r(t,i),n}function ka(t){return null==t?t:Yl.call(t)}function Ea(t,e,n){var r=null==t?0:t.length;return r?(n&&\"number\"!=typeof n&&Po(t,e,n)?(e=0,n=r):(e=null==e?0:yc(e),n=n===nt?r:yc(n)),ii(t,e,n)):[]}function Ma(t,e){return ai(t,e)}function Ta(t,e,n){return ui(t,e,mo(n,2))}function Sa(t,e){var n=null==t?0:t.length;if(n){var r=ai(t,e);if(r<n&&Vu(t[r],e))return r}return-1}function Na(t,e){return ai(t,e,!0)}function Aa(t,e,n){return ui(t,e,mo(n,2),!0)}function Pa(t,e){if(null==t?0:t.length){var n=ai(t,e,!0)-1;if(Vu(t[n],e))return n}return-1}function Oa(t){return t&&t.length?ci(t):[]}function Ia(t,e){return t&&t.length?ci(t,mo(e,2)):[]}function Da(t){var e=null==t?0:t.length;return e?ii(t,1,e):[]}function Ra(t,e,n){return t&&t.length?(e=n||e===nt?1:yc(e),ii(t,0,e<0?0:e)):[]}function La(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===nt?1:yc(e),e=r-e,ii(t,e<0?0:e,r)):[]}function Ua(t,e){return t&&t.length?di(t,mo(e,3),!1,!0):[]}function Fa(t,e){return t&&t.length?di(t,mo(e,3)):[]}function ja(t){return t&&t.length?fi(t):[]}function Ba(t,e){return t&&t.length?fi(t,mo(e,2)):[]}function Va(t,e){return e=\"function\"==typeof e?e:nt,t&&t.length?fi(t,nt,e):[]}function Wa(t){if(!t||!t.length)return[];var e=0;return t=l(t,function(t){if(zu(t))return e=Vl(t.length,e),!0}),P(e,function(e){return h(t,M(e))})}function za(t,e){if(!t||!t.length)return[];var n=Wa(t);return null==e?n:h(n,function(t){return o(e,nt,t)})}function Ha(t,e){return mi(t||[],e||[],Wn)}function qa(t,e){return mi(t||[],e||[],ni)}function Ya(t){var e=n(t);return e.__chain__=!0,e}function Ka(t,e){return e(t),t}function Ga(t,e){return e(t)}function $a(){return Ya(this)}function Xa(){return new i(this.value(),this.__chain__)}function Qa(){this.__values__===nt&&(this.__values__=gc(this.value()));var t=this.__index__>=this.__values__.length;return{done:t,value:t?nt:this.__values__[this.__index__++]}}function Za(){return this}function Ja(t){for(var e,n=this;n instanceof r;){var i=Zo(n);i.__index__=0,i.__values__=nt,e?o.__wrapped__=i:e=i;var o=i;n=n.__wrapped__}return o.__wrapped__=t,e}function tu(){var t=this.__wrapped__;if(t instanceof y){var e=t;return this.__actions__.length&&(e=new y(this)),e=e.reverse(),e.__actions__.push({func:Ga,args:[ka],thisArg:nt}),new i(e,this.__chain__)}return this.thru(ka)}function eu(){return vi(this.__wrapped__,this.__actions__)}function nu(t,e,n){var r=hp(t)?s:or;return n&&Po(t,e,n)&&(e=nt),r(t,mo(e,3))}function ru(t,e){return(hp(t)?l:cr)(t,mo(e,3))}function iu(t,e){return sr(lu(t,e),1)}function ou(t,e){return sr(lu(t,e),At)}function au(t,e,n){return n=n===nt?1:yc(n),sr(lu(t,e),n)}function uu(t,e){return(hp(t)?u:ff)(t,mo(e,3))}function cu(t,e){return(hp(t)?c:pf)(t,mo(e,3))}function su(t,e,n,r){t=Wu(t)?t:$c(t),n=n&&!r?yc(n):0;var i=t.length;return n<0&&(n=Vl(i+n,0)),fc(t)?n<=i&&t.indexOf(e,n)>-1:!!i&&w(t,e,n)>-1}function lu(t,e){return(hp(t)?h:Fr)(t,mo(e,3))}function fu(t,e,n,r){return null==t?[]:(hp(e)||(e=null==e?[]:[e]),n=r?nt:n,hp(n)||(n=null==n?[]:[n]),Hr(t,e,n))}function pu(t,e,n){var r=hp(t)?v:S,i=arguments.length<3;return r(t,mo(e,4),n,i,ff)}function hu(t,e,n){var r=hp(t)?g:S,i=arguments.length<3;return r(t,mo(e,4),n,i,pf)}function du(t,e){return(hp(t)?l:cr)(t,Su(mo(e,3)))}function vu(t){return(hp(t)?Pn:ti)(t)}function gu(t,e,n){return e=(n?Po(t,e,n):e===nt)?1:yc(e),(hp(t)?On:ei)(t,e)}function mu(t){return(hp(t)?Dn:ri)(t)}function yu(t){if(null==t)return 0;if(Wu(t))return fc(t)?Q(t):t.length;var e=Cf(t);return e==Kt||e==Jt?t.size:Rr(t).length}function _u(t,e,n){var r=hp(t)?m:oi;return n&&Po(t,e,n)&&(e=nt),r(t,mo(e,3))}function bu(t,e){if(\"function\"!=typeof e)throw new al(ot);return t=yc(t),function(){if(--t<1)return e.apply(this,arguments)}}function xu(t,e,n){return e=n?nt:e,e=t&&null==e?t.length:e,io(t,xt,nt,nt,nt,nt,e)}function wu(t,e){var n;if(\"function\"!=typeof e)throw new al(ot);return t=yc(t),function(){return--t>0&&(n=e.apply(this,arguments)),t<=1&&(e=nt),n}}function Cu(t,e,n){e=n?nt:e;var r=io(t,mt,nt,nt,nt,nt,nt,e);return r.placeholder=Cu.placeholder,r}function ku(t,e,n){e=n?nt:e;var r=io(t,yt,nt,nt,nt,nt,nt,e);return r.placeholder=ku.placeholder,r}function Eu(t,e,n){function r(e){var n=p,r=h;return p=h=nt,y=e,v=t.apply(r,n)}function i(t){return y=t,g=Mf(u,e),_?r(t):v}function o(t){var n=t-m,r=t-y,i=e-n;return b?Wl(i,d-r):i}function a(t){var n=t-m,r=t-y;return m===nt||n>=e||n<0||b&&r>=d}function u(){var t=ep();if(a(t))return c(t);g=Mf(u,o(t))}function c(t){return g=nt,x&&p?r(t):(p=h=nt,v)}function s(){g!==nt&&yf(g),y=0,p=m=h=g=nt}function l(){return g===nt?v:c(ep())}function f(){var t=ep(),n=a(t);if(p=arguments,h=this,m=t,n){if(g===nt)return i(m);if(b)return g=Mf(u,e),r(m)}return g===nt&&(g=Mf(u,e)),v}var p,h,d,v,g,m,y=0,_=!1,b=!1,x=!0;if(\"function\"!=typeof t)throw new al(ot);return e=bc(e)||0,tc(n)&&(_=!!n.leading,b=\"maxWait\"in n,d=b?Vl(bc(n.maxWait)||0,e):d,x=\"trailing\"in n?!!n.trailing:x),f.cancel=s,f.flush=l,f}function Mu(t){return io(t,Ct)}function Tu(t,e){if(\"function\"!=typeof t||null!=e&&\"function\"!=typeof e)throw new al(ot);var n=function(){var r=arguments,i=e?e.apply(this,r):r[0],o=n.cache;if(o.has(i))return o.get(i);var a=t.apply(this,r);return n.cache=o.set(i,a)||o,a};return n.cache=new(Tu.Cache||an),n}function Su(t){if(\"function\"!=typeof t)throw new al(ot);return function(){var e=arguments;switch(e.length){case 0:return!t.call(this);case 1:return!t.call(this,e[0]);case 2:return!t.call(this,e[0],e[1]);case 3:return!t.call(this,e[0],e[1],e[2])}return!t.apply(this,e)}}function Nu(t){return wu(2,t)}function Au(t,e){if(\"function\"!=typeof t)throw new al(ot);return e=e===nt?e:yc(e),Jr(t,e)}function Pu(t,e){if(\"function\"!=typeof t)throw new al(ot);return e=null==e?0:Vl(yc(e),0),Jr(function(n){var r=n[e],i=xi(n,0,e);return r&&d(i,r),o(t,this,i)})}function Ou(t,e,n){var r=!0,i=!0;if(\"function\"!=typeof t)throw new al(ot);return tc(n)&&(r=\"leading\"in n?!!n.leading:r,i=\"trailing\"in n?!!n.trailing:i),Eu(t,e,{leading:r,maxWait:e,trailing:i})}function Iu(t){return xu(t,1)}function Du(t,e){return up(_i(e),t)}function Ru(){if(!arguments.length)return[];var t=arguments[0];return hp(t)?t:[t]}function Lu(t){return tr(t,ft)}function Uu(t,e){return e=\"function\"==typeof e?e:nt,tr(t,ft,e)}function Fu(t){return tr(t,st|ft)}function ju(t,e){return e=\"function\"==typeof e?e:nt,tr(t,st|ft,e)}function Bu(t,e){return null==e||nr(t,e,Lc(e))}function Vu(t,e){return t===e||t!==t&&e!==e}function Wu(t){return null!=t&&Ju(t.length)&&!Qu(t)}function zu(t){return ec(t)&&Wu(t)}function Hu(t){return!0===t||!1===t||ec(t)&&vr(t)==Vt}function qu(t){return ec(t)&&1===t.nodeType&&!sc(t)}function Yu(t){if(null==t)return!0;if(Wu(t)&&(hp(t)||\"string\"==typeof t||\"function\"==typeof t.splice||vp(t)||bp(t)||pp(t)))return!t.length;var e=Cf(t);if(e==Kt||e==Jt)return!t.size;if(Lo(t))return!Rr(t).length;for(var n in t)if(pl.call(t,n))return!1;return!0}function Ku(t,e){return Mr(t,e)}function Gu(t,e,n){n=\"function\"==typeof n?n:nt;var r=n?n(t,e):nt;return r===nt?Mr(t,e,nt,n):!!r}function $u(t){if(!ec(t))return!1;var e=vr(t);return e==Ht||e==zt||\"string\"==typeof t.message&&\"string\"==typeof t.name&&!sc(t)}function Xu(t){return\"number\"==typeof t&&Fl(t)}function Qu(t){if(!tc(t))return!1;var e=vr(t);return e==qt||e==Yt||e==Bt||e==Qt}function Zu(t){return\"number\"==typeof t&&t==yc(t)}function Ju(t){return\"number\"==typeof t&&t>-1&&t%1==0&&t<=Pt}function tc(t){var e=typeof t;return null!=t&&(\"object\"==e||\"function\"==e)}function ec(t){return null!=t&&\"object\"==typeof t}function nc(t,e){return t===e||Nr(t,e,_o(e))}function rc(t,e,n){return n=\"function\"==typeof n?n:nt,Nr(t,e,_o(e),n)}function ic(t){return cc(t)&&t!=+t}function oc(t){if(kf(t))throw new tl(it);return Ar(t)}function ac(t){return null===t}function uc(t){return null==t}function cc(t){return\"number\"==typeof t||ec(t)&&vr(t)==Gt}function sc(t){if(!ec(t)||vr(t)!=Xt)return!1;var e=Cl(t);if(null===e)return!0;var n=pl.call(e,\"constructor\")&&e.constructor;return\"function\"==typeof n&&n instanceof n&&fl.call(n)==gl}function lc(t){return Zu(t)&&t>=-Pt&&t<=Pt}function fc(t){return\"string\"==typeof t||!hp(t)&&ec(t)&&vr(t)==te}function pc(t){return\"symbol\"==typeof t||ec(t)&&vr(t)==ee}function hc(t){return t===nt}function dc(t){return ec(t)&&Cf(t)==re}function vc(t){return ec(t)&&vr(t)==ie}function gc(t){if(!t)return[];if(Wu(t))return fc(t)?Z(t):Oi(t);if(Sl&&t[Sl])return z(t[Sl]());var e=Cf(t);return(e==Kt?H:e==Jt?K:$c)(t)}function mc(t){if(!t)return 0===t?t:0;if((t=bc(t))===At||t===-At){return(t<0?-1:1)*Ot}return t===t?t:0}function yc(t){var e=mc(t),n=e%1;return e===e?n?e-n:e:0}function _c(t){return t?Jn(yc(t),0,Dt):0}function bc(t){if(\"number\"==typeof t)return t;if(pc(t))return It;if(tc(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=tc(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(Pe,\"\");var n=We.test(t);return n||He.test(t)?Tn(t.slice(2),n?2:8):Ve.test(t)?It:+t}function xc(t){return Ii(t,Uc(t))}function wc(t){return t?Jn(yc(t),-Pt,Pt):0===t?t:0}function Cc(t){return null==t?\"\":li(t)}function kc(t,e){var n=lf(t);return null==e?n:$n(n,e)}function Ec(t,e){return b(t,mo(e,3),lr)}function Mc(t,e){return b(t,mo(e,3),fr)}function Tc(t,e){return null==t?t:hf(t,mo(e,3),Uc)}function Sc(t,e){return null==t?t:df(t,mo(e,3),Uc)}function Nc(t,e){return t&&lr(t,mo(e,3))}function Ac(t,e){return t&&fr(t,mo(e,3))}function Pc(t){return null==t?[]:pr(t,Lc(t))}function Oc(t){return null==t?[]:pr(t,Uc(t))}function Ic(t,e,n){var r=null==t?nt:hr(t,e);return r===nt?n:r}function Dc(t,e){return null!=t&&ko(t,e,mr)}function Rc(t,e){return null!=t&&ko(t,e,yr)}function Lc(t){return Wu(t)?Nn(t):Rr(t)}function Uc(t){return Wu(t)?Nn(t,!0):Lr(t)}function Fc(t,e){var n={};return e=mo(e,3),lr(t,function(t,r,i){Qn(n,e(t,r,i),t)}),n}function jc(t,e){var n={};return e=mo(e,3),lr(t,function(t,r,i){Qn(n,r,e(t,r,i))}),n}function Bc(t,e){return Vc(t,Su(mo(e)))}function Vc(t,e){if(null==t)return{};var n=h(ho(t),function(t){return[t]});return e=mo(e),Yr(t,n,function(t,n){return e(t,n[0])})}function Wc(t,e,n){e=bi(e,t);var r=-1,i=e.length;for(i||(i=1,t=nt);++r<i;){var o=null==t?nt:t[$o(e[r])];o===nt&&(r=i,o=n),t=Qu(o)?o.call(t):o}return t}function zc(t,e,n){return null==t?t:ni(t,e,n)}function Hc(t,e,n,r){return r=\"function\"==typeof r?r:nt,null==t?t:ni(t,e,n,r)}function qc(t,e,n){var r=hp(t),i=r||vp(t)||bp(t);if(e=mo(e,4),null==n){var o=t&&t.constructor;n=i?r?new o:[]:tc(t)&&Qu(o)?lf(Cl(t)):{}}return(i?u:lr)(t,function(t,r,i){return e(n,t,r,i)}),n}function Yc(t,e){return null==t||pi(t,e)}function Kc(t,e,n){return null==t?t:hi(t,e,_i(n))}function Gc(t,e,n,r){return r=\"function\"==typeof r?r:nt,null==t?t:hi(t,e,_i(n),r)}function $c(t){return null==t?[]:D(t,Lc(t))}function Xc(t){return null==t?[]:D(t,Uc(t))}function Qc(t,e,n){return n===nt&&(n=e,e=nt),n!==nt&&(n=bc(n),n=n===n?n:0),e!==nt&&(e=bc(e),e=e===e?e:0),Jn(bc(t),e,n)}function Zc(t,e,n){return e=mc(e),n===nt?(n=e,e=0):n=mc(n),t=bc(t),_r(t,e,n)}function Jc(t,e,n){if(n&&\"boolean\"!=typeof n&&Po(t,e,n)&&(e=n=nt),n===nt&&(\"boolean\"==typeof e?(n=e,e=nt):\"boolean\"==typeof t&&(n=t,t=nt)),t===nt&&e===nt?(t=0,e=1):(t=mc(t),e===nt?(e=t,t=0):e=mc(e)),t>e){var r=t;t=e,e=r}if(n||t%1||e%1){var i=ql();return Wl(t+i*(e-t+Mn(\"1e-\"+((i+\"\").length-1))),e)}return Xr(t,e)}function ts(t){return Yp(Cc(t).toLowerCase())}function es(t){return(t=Cc(t))&&t.replace(Ye,zn).replace(hn,\"\")}function ns(t,e,n){t=Cc(t),e=li(e);var r=t.length;n=n===nt?r:Jn(yc(n),0,r);var i=n;return(n-=e.length)>=0&&t.slice(n,i)==e}function rs(t){return t=Cc(t),t&&we.test(t)?t.replace(be,Hn):t}function is(t){return t=Cc(t),t&&Ae.test(t)?t.replace(Ne,\"\\\\$&\"):t}function os(t,e,n){t=Cc(t),e=yc(e);var r=e?Q(t):0;if(!e||r>=e)return t;var i=(e-r)/2;return Qi(Rl(i),n)+t+Qi(Dl(i),n)}function as(t,e,n){t=Cc(t),e=yc(e);var r=e?Q(t):0;return e&&r<e?t+Qi(e-r,n):t}function us(t,e,n){t=Cc(t),e=yc(e);var r=e?Q(t):0;return e&&r<e?Qi(e-r,n)+t:t}function cs(t,e,n){return n||null==e?e=0:e&&(e=+e),Hl(Cc(t).replace(Oe,\"\"),e||0)}function ss(t,e,n){return e=(n?Po(t,e,n):e===nt)?1:yc(e),Zr(Cc(t),e)}function ls(){var t=arguments,e=Cc(t[0]);return t.length<3?e:e.replace(t[1],t[2])}function fs(t,e,n){return n&&\"number\"!=typeof n&&Po(t,e,n)&&(e=n=nt),(n=n===nt?Dt:n>>>0)?(t=Cc(t),t&&(\"string\"==typeof e||null!=e&&!yp(e))&&!(e=li(e))&&V(t)?xi(Z(t),0,n):t.split(e,n)):[]}function ps(t,e,n){return t=Cc(t),n=null==n?0:Jn(yc(n),0,t.length),e=li(e),t.slice(n,n+e.length)==e}function hs(t,e,r){var i=n.templateSettings;r&&Po(t,e,r)&&(e=nt),t=Cc(t),e=Ep({},e,i,oo);var o,a,u=Ep({},e.imports,i.imports,oo),c=Lc(u),s=D(u,c),l=0,f=e.interpolate||Ke,p=\"__p += '\",h=il((e.escape||Ke).source+\"|\"+f.source+\"|\"+(f===Ee?je:Ke).source+\"|\"+(e.evaluate||Ke).source+\"|$\",\"g\"),d=\"//# sourceURL=\"+(\"sourceURL\"in e?e.sourceURL:\"lodash.templateSources[\"+ ++_n+\"]\")+\"\\n\";t.replace(h,function(e,n,r,i,u,c){return r||(r=i),p+=t.slice(l,c).replace(Ge,j),n&&(o=!0,p+=\"' +\\n__e(\"+n+\") +\\n'\"),u&&(a=!0,p+=\"';\\n\"+u+\";\\n__p += '\"),r&&(p+=\"' +\\n((__t = (\"+r+\")) == null ? '' : __t) +\\n'\"),l=c+e.length,e}),p+=\"';\\n\";var v=e.variable;v||(p=\"with (obj) {\\n\"+p+\"\\n}\\n\"),p=(a?p.replace(ge,\"\"):p).replace(me,\"$1\").replace(ye,\"$1;\"),p=\"function(\"+(v||\"obj\")+\") {\\n\"+(v?\"\":\"obj || (obj = {});\\n\")+\"var __t, __p = ''\"+(o?\", __e = _.escape\":\"\")+(a?\", __j = Array.prototype.join;\\nfunction print() { __p += __j.call(arguments, '') }\\n\":\";\\n\")+p+\"return __p\\n}\";var g=Kp(function(){return el(c,d+\"return \"+p).apply(nt,s)});if(g.source=p,$u(g))throw g;return g}function ds(t){return Cc(t).toLowerCase()}function vs(t){return Cc(t).toUpperCase()}function gs(t,e,n){if((t=Cc(t))&&(n||e===nt))return t.replace(Pe,\"\");if(!t||!(e=li(e)))return t;var r=Z(t),i=Z(e);return xi(r,L(r,i),U(r,i)+1).join(\"\")}function ms(t,e,n){if((t=Cc(t))&&(n||e===nt))return t.replace(Ie,\"\");if(!t||!(e=li(e)))return t;var r=Z(t);return xi(r,0,U(r,Z(e))+1).join(\"\")}function ys(t,e,n){if((t=Cc(t))&&(n||e===nt))return t.replace(Oe,\"\");if(!t||!(e=li(e)))return t;var r=Z(t);return xi(r,L(r,Z(e))).join(\"\")}function _s(t,e){var n=kt,r=Et;if(tc(e)){var i=\"separator\"in e?e.separator:i;n=\"length\"in e?yc(e.length):n,r=\"omission\"in e?li(e.omission):r}t=Cc(t);var o=t.length;if(V(t)){var a=Z(t);o=a.length}if(n>=o)return t;var u=n-Q(r);if(u<1)return r;var c=a?xi(a,0,u).join(\"\"):t.slice(0,u);if(i===nt)return c+r;if(a&&(u+=c.length-u),yp(i)){if(t.slice(u).search(i)){var s,l=c;for(i.global||(i=il(i.source,Cc(Be.exec(i))+\"g\")),i.lastIndex=0;s=i.exec(l);)var f=s.index;c=c.slice(0,f===nt?u:f)}}else if(t.indexOf(li(i),u)!=u){var p=c.lastIndexOf(i);p>-1&&(c=c.slice(0,p))}return c+r}function bs(t){return t=Cc(t),t&&xe.test(t)?t.replace(_e,qn):t}function xs(t,e,n){return t=Cc(t),e=n?nt:e,e===nt?W(t)?et(t):_(t):t.match(e)||[]}function ws(t){var e=null==t?0:t.length,n=mo();return t=e?h(t,function(t){if(\"function\"!=typeof t[1])throw new al(ot);return[n(t[0]),t[1]]}):[],Jr(function(n){for(var r=-1;++r<e;){var i=t[r];if(o(i[0],this,n))return o(i[1],this,n)}})}function Cs(t){return er(tr(t,st))}function ks(t){return function(){return t}}function Es(t,e){return null==t||t!==t?e:t}function Ms(t){return t}function Ts(t){return Dr(\"function\"==typeof t?t:tr(t,st))}function Ss(t){return jr(tr(t,st))}function Ns(t,e){return Br(t,tr(e,st))}function As(t,e,n){var r=Lc(e),i=pr(e,r);null!=n||tc(e)&&(i.length||!r.length)||(n=e,e=t,t=this,i=pr(e,Lc(e)));var o=!(tc(n)&&\"chain\"in n&&!n.chain),a=Qu(t);return u(i,function(n){var r=e[n];t[n]=r,a&&(t.prototype[n]=function(){var e=this.__chain__;if(o||e){var n=t(this.__wrapped__);return(n.__actions__=Oi(this.__actions__)).push({func:r,args:arguments,thisArg:t}),n.__chain__=e,n}return r.apply(t,d([this.value()],arguments))})}),t}function Ps(){return An._===this&&(An._=ml),this}function Os(){}function Is(t){return t=yc(t),Jr(function(e){return zr(e,t)})}function Ds(t){return Oo(t)?M($o(t)):Kr(t)}function Rs(t){return function(e){return null==t?nt:hr(t,e)}}function Ls(){return[]}function Us(){return!1}function Fs(){return{}}function js(){return\"\"}function Bs(){return!0}function Vs(t,e){if((t=yc(t))<1||t>Pt)return[];var n=Dt,r=Wl(t,Dt);e=mo(e),t-=Dt;for(var i=P(r,e);++n<t;)e(n);return i}function Ws(t){return hp(t)?h(t,$o):pc(t)?[t]:Oi(Sf(Cc(t)))}function zs(t){var e=++hl;return Cc(t)+e}function Hs(t){return t&&t.length?ar(t,Ms,gr):nt}function qs(t,e){return t&&t.length?ar(t,mo(e,2),gr):nt}function Ys(t){return E(t,Ms)}function Ks(t,e){return E(t,mo(e,2))}function Gs(t){return t&&t.length?ar(t,Ms,Ur):nt}function $s(t,e){return t&&t.length?ar(t,mo(e,2),Ur):nt}function Xs(t){return t&&t.length?A(t,Ms):0}function Qs(t,e){return t&&t.length?A(t,mo(e,2)):0}e=null==e?An:Yn.defaults(An.Object(),e,Yn.pick(An,yn));var Zs=e.Array,Js=e.Date,tl=e.Error,el=e.Function,nl=e.Math,rl=e.Object,il=e.RegExp,ol=e.String,al=e.TypeError,ul=Zs.prototype,cl=el.prototype,sl=rl.prototype,ll=e[\"__core-js_shared__\"],fl=cl.toString,pl=sl.hasOwnProperty,hl=0,dl=function(){var t=/[^.]+$/.exec(ll&&ll.keys&&ll.keys.IE_PROTO||\"\");return t?\"Symbol(src)_1.\"+t:\"\"}(),vl=sl.toString,gl=fl.call(rl),ml=An._,yl=il(\"^\"+fl.call(pl).replace(Ne,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\"),_l=In?e.Buffer:nt,bl=e.Symbol,xl=e.Uint8Array,wl=_l?_l.allocUnsafe:nt,Cl=q(rl.getPrototypeOf,rl),kl=rl.create,El=sl.propertyIsEnumerable,Ml=ul.splice,Tl=bl?bl.isConcatSpreadable:nt,Sl=bl?bl.iterator:nt,Nl=bl?bl.toStringTag:nt,Al=function(){try{var t=bo(rl,\"defineProperty\");return t({},\"\",{}),t}catch(t){}}(),Pl=e.clearTimeout!==An.clearTimeout&&e.clearTimeout,Ol=Js&&Js.now!==An.Date.now&&Js.now,Il=e.setTimeout!==An.setTimeout&&e.setTimeout,Dl=nl.ceil,Rl=nl.floor,Ll=rl.getOwnPropertySymbols,Ul=_l?_l.isBuffer:nt,Fl=e.isFinite,jl=ul.join,Bl=q(rl.keys,rl),Vl=nl.max,Wl=nl.min,zl=Js.now,Hl=e.parseInt,ql=nl.random,Yl=ul.reverse,Kl=bo(e,\"DataView\"),Gl=bo(e,\"Map\"),$l=bo(e,\"Promise\"),Xl=bo(e,\"Set\"),Ql=bo(e,\"WeakMap\"),Zl=bo(rl,\"create\"),Jl=Ql&&new Ql,tf={},ef=Xo(Kl),nf=Xo(Gl),rf=Xo($l),of=Xo(Xl),af=Xo(Ql),uf=bl?bl.prototype:nt,cf=uf?uf.valueOf:nt,sf=uf?uf.toString:nt,lf=function(){function t(){}return function(e){if(!tc(e))return{};if(kl)return kl(e);t.prototype=e;var n=new t;return t.prototype=nt,n}}();n.templateSettings={escape:Ce,evaluate:ke,interpolate:Ee,variable:\"\",imports:{_:n}},n.prototype=r.prototype,n.prototype.constructor=n,i.prototype=lf(r.prototype),i.prototype.constructor=i,y.prototype=lf(r.prototype),y.prototype.constructor=y,tt.prototype.clear=Ue,tt.prototype.delete=$e,tt.prototype.get=Xe,tt.prototype.has=Qe,tt.prototype.set=Ze,Je.prototype.clear=tn,Je.prototype.delete=en,Je.prototype.get=nn,Je.prototype.has=rn,Je.prototype.set=on,an.prototype.clear=un,an.prototype.delete=cn,an.prototype.get=sn,an.prototype.has=ln,an.prototype.set=fn,dn.prototype.add=dn.prototype.push=vn,dn.prototype.has=gn,mn.prototype.clear=wn,mn.prototype.delete=Cn,mn.prototype.get=kn,mn.prototype.has=En,mn.prototype.set=Sn;var ff=Fi(lr),pf=Fi(fr,!0),hf=ji(),df=ji(!0),vf=Jl?function(t,e){return Jl.set(t,e),t}:Ms,gf=Al?function(t,e){return Al(t,\"toString\",{configurable:!0,enumerable:!1,value:ks(e),writable:!0})}:Ms,mf=Jr,yf=Pl||function(t){return An.clearTimeout(t)},_f=Xl&&1/K(new Xl([,-0]))[1]==At?function(t){return new Xl(t)}:Os,bf=Jl?function(t){return Jl.get(t)}:Os,xf=Ll?function(t){return null==t?[]:(t=rl(t),l(Ll(t),function(e){return El.call(t,e)}))}:Ls,wf=Ll?function(t){for(var e=[];t;)d(e,xf(t)),t=Cl(t);return e}:Ls,Cf=vr;(Kl&&Cf(new Kl(new ArrayBuffer(1)))!=ae||Gl&&Cf(new Gl)!=Kt||$l&&\"[object Promise]\"!=Cf($l.resolve())||Xl&&Cf(new Xl)!=Jt||Ql&&Cf(new Ql)!=re)&&(Cf=function(t){var e=vr(t),n=e==Xt?t.constructor:nt,r=n?Xo(n):\"\";if(r)switch(r){case ef:return ae;case nf:return Kt;case rf:return\"[object Promise]\";case of:return Jt;case af:return re}return e});var kf=ll?Qu:Us,Ef=Ko(vf),Mf=Il||function(t,e){return An.setTimeout(t,e)},Tf=Ko(gf),Sf=function(t){var e=Tu(t,function(t){return n.size===ut&&n.clear(),t}),n=e.cache;return e}(function(t){var e=[];return 46===t.charCodeAt(0)&&e.push(\"\"),t.replace(Se,function(t,n,r,i){e.push(r?i.replace(Fe,\"$1\"):n||t)}),e}),Nf=Jr(function(t,e){return zu(t)?ir(t,sr(e,1,zu,!0)):[]}),Af=Jr(function(t,e){var n=ma(e);return zu(n)&&(n=nt),zu(t)?ir(t,sr(e,1,zu,!0),mo(n,2)):[]}),Pf=Jr(function(t,e){var n=ma(e);return zu(n)&&(n=nt),zu(t)?ir(t,sr(e,1,zu,!0),nt,n):[]}),Of=Jr(function(t){var e=h(t,yi);return e.length&&e[0]===t[0]?br(e):[]}),If=Jr(function(t){var e=ma(t),n=h(t,yi);return e===ma(n)?e=nt:n.pop(),n.length&&n[0]===t[0]?br(n,mo(e,2)):[]}),Df=Jr(function(t){var e=ma(t),n=h(t,yi);return e=\"function\"==typeof e?e:nt,e&&n.pop(),n.length&&n[0]===t[0]?br(n,nt,e):[]}),Rf=Jr(ba),Lf=fo(function(t,e){var n=null==t?0:t.length,r=Zn(t,e);return $r(t,h(e,function(t){return Ao(t,n)?+t:t}).sort(Si)),r}),Uf=Jr(function(t){return fi(sr(t,1,zu,!0))}),Ff=Jr(function(t){var e=ma(t);return zu(e)&&(e=nt),fi(sr(t,1,zu,!0),mo(e,2))}),jf=Jr(function(t){var e=ma(t);return e=\"function\"==typeof e?e:nt,fi(sr(t,1,zu,!0),nt,e)}),Bf=Jr(function(t,e){return zu(t)?ir(t,e):[]}),Vf=Jr(function(t){return gi(l(t,zu))}),Wf=Jr(function(t){var e=ma(t);return zu(e)&&(e=nt),gi(l(t,zu),mo(e,2))}),zf=Jr(function(t){var e=ma(t);return e=\"function\"==typeof e?e:nt,gi(l(t,zu),nt,e)}),Hf=Jr(Wa),qf=Jr(function(t){var e=t.length,n=e>1?t[e-1]:nt;return n=\"function\"==typeof n?(t.pop(),n):nt,za(t,n)}),Yf=fo(function(t){var e=t.length,n=e?t[0]:0,r=this.__wrapped__,o=function(e){return Zn(e,t)};return!(e>1||this.__actions__.length)&&r instanceof y&&Ao(n)?(r=r.slice(n,+n+(e?1:0)),r.__actions__.push({func:Ga,args:[o],thisArg:nt}),new i(r,this.__chain__).thru(function(t){return e&&!t.length&&t.push(nt),t})):this.thru(o)}),Kf=Li(function(t,e,n){pl.call(t,n)?++t[n]:Qn(t,n,1)}),Gf=qi(ua),$f=qi(ca),Xf=Li(function(t,e,n){pl.call(t,n)?t[n].push(e):Qn(t,n,[e])}),Qf=Jr(function(t,e,n){var r=-1,i=\"function\"==typeof e,a=Wu(t)?Zs(t.length):[];return ff(t,function(t){a[++r]=i?o(e,t,n):wr(t,e,n)}),a}),Zf=Li(function(t,e,n){Qn(t,n,e)}),Jf=Li(function(t,e,n){t[n?0:1].push(e)},function(){return[[],[]]}),tp=Jr(function(t,e){if(null==t)return[];var n=e.length;return n>1&&Po(t,e[0],e[1])?e=[]:n>2&&Po(e[0],e[1],e[2])&&(e=[e[0]]),Hr(t,sr(e,1),[])}),ep=Ol||function(){return An.Date.now()},np=Jr(function(t,e,n){var r=dt;if(n.length){var i=Y(n,go(np));r|=_t}return io(t,r,e,n,i)}),rp=Jr(function(t,e,n){var r=dt|vt;if(n.length){var i=Y(n,go(rp));r|=_t}return io(e,r,t,n,i)}),ip=Jr(function(t,e){return rr(t,1,e)}),op=Jr(function(t,e,n){return rr(t,bc(e)||0,n)});Tu.Cache=an;var ap=mf(function(t,e){e=1==e.length&&hp(e[0])?h(e[0],I(mo())):h(sr(e,1),I(mo()));var n=e.length;return Jr(function(r){for(var i=-1,a=Wl(r.length,n);++i<a;)r[i]=e[i].call(this,r[i]);return o(t,this,r)})}),up=Jr(function(t,e){var n=Y(e,go(up));return io(t,_t,nt,e,n)}),cp=Jr(function(t,e){var n=Y(e,go(cp));return io(t,bt,nt,e,n)}),sp=fo(function(t,e){return io(t,wt,nt,nt,nt,e)}),lp=to(gr),fp=to(function(t,e){return t>=e}),pp=Cr(function(){return arguments}())?Cr:function(t){return ec(t)&&pl.call(t,\"callee\")&&!El.call(t,\"callee\")},hp=Zs.isArray,dp=Ln?I(Ln):kr,vp=Ul||Us,gp=Un?I(Un):Er,mp=Fn?I(Fn):Sr,yp=jn?I(jn):Pr,_p=Bn?I(Bn):Or,bp=Vn?I(Vn):Ir,xp=to(Ur),wp=to(function(t,e){return t<=e}),Cp=Ui(function(t,e){if(Lo(e)||Wu(e))return void Ii(e,Lc(e),t);for(var n in e)pl.call(e,n)&&Wn(t,n,e[n])}),kp=Ui(function(t,e){Ii(e,Uc(e),t)}),Ep=Ui(function(t,e,n,r){Ii(e,Uc(e),t,r)}),Mp=Ui(function(t,e,n,r){Ii(e,Lc(e),t,r)}),Tp=fo(Zn),Sp=Jr(function(t,e){t=rl(t);var n=-1,r=e.length,i=r>2?e[2]:nt;for(i&&Po(e[0],e[1],i)&&(r=1);++n<r;)for(var o=e[n],a=Uc(o),u=-1,c=a.length;++u<c;){var s=a[u],l=t[s];(l===nt||Vu(l,sl[s])&&!pl.call(t,s))&&(t[s]=o[s])}return t}),Np=Jr(function(t){return t.push(nt,ao),o(Dp,nt,t)}),Ap=Gi(function(t,e,n){null!=e&&\"function\"!=typeof e.toString&&(e=vl.call(e)),t[e]=n},ks(Ms)),Pp=Gi(function(t,e,n){null!=e&&\"function\"!=typeof e.toString&&(e=vl.call(e)),pl.call(t,e)?t[e].push(n):t[e]=[n]},mo),Op=Jr(wr),Ip=Ui(function(t,e,n){Vr(t,e,n)}),Dp=Ui(function(t,e,n,r){Vr(t,e,n,r)}),Rp=fo(function(t,e){var n={};if(null==t)return n;var r=!1;e=h(e,function(e){return e=bi(e,t),r||(r=e.length>1),e}),Ii(t,ho(t),n),r&&(n=tr(n,st|lt|ft,uo));for(var i=e.length;i--;)pi(n,e[i]);return n}),Lp=fo(function(t,e){return null==t?{}:qr(t,e)}),Up=ro(Lc),Fp=ro(Uc),jp=Wi(function(t,e,n){return e=e.toLowerCase(),t+(n?ts(e):e)}),Bp=Wi(function(t,e,n){return t+(n?\"-\":\"\")+e.toLowerCase()}),Vp=Wi(function(t,e,n){return t+(n?\" \":\"\")+e.toLowerCase()}),Wp=Vi(\"toLowerCase\"),zp=Wi(function(t,e,n){return t+(n?\"_\":\"\")+e.toLowerCase()}),Hp=Wi(function(t,e,n){return t+(n?\" \":\"\")+Yp(e)}),qp=Wi(function(t,e,n){return t+(n?\" \":\"\")+e.toUpperCase()}),Yp=Vi(\"toUpperCase\"),Kp=Jr(function(t,e){try{return o(t,nt,e)}catch(t){return $u(t)?t:new tl(t)}}),Gp=fo(function(t,e){return u(e,function(e){e=$o(e),Qn(t,e,np(t[e],t))}),t}),$p=Yi(),Xp=Yi(!0),Qp=Jr(function(t,e){return function(n){return wr(n,t,e)}}),Zp=Jr(function(t,e){return function(n){return wr(t,n,e)}}),Jp=Xi(h),th=Xi(s),eh=Xi(m),nh=Ji(),rh=Ji(!0),ih=$i(function(t,e){return t+e},0),oh=no(\"ceil\"),ah=$i(function(t,e){return t/e},1),uh=no(\"floor\"),ch=$i(function(t,e){return t*e},1),sh=no(\"round\"),lh=$i(function(t,e){return t-e},0);return n.after=bu,n.ary=xu,n.assign=Cp,n.assignIn=kp,n.assignInWith=Ep,n.assignWith=Mp,n.at=Tp,n.before=wu,n.bind=np,n.bindAll=Gp,n.bindKey=rp,n.castArray=Ru,n.chain=Ya,n.chunk=Jo,n.compact=ta,n.concat=ea,n.cond=ws,n.conforms=Cs,n.constant=ks,n.countBy=Kf,n.create=kc,n.curry=Cu,n.curryRight=ku,n.debounce=Eu,n.defaults=Sp,n.defaultsDeep=Np,n.defer=ip,n.delay=op,n.difference=Nf,n.differenceBy=Af,n.differenceWith=Pf,n.drop=na,n.dropRight=ra,n.dropRightWhile=ia,n.dropWhile=oa,n.fill=aa,n.filter=ru,n.flatMap=iu,n.flatMapDeep=ou,n.flatMapDepth=au,n.flatten=sa,n.flattenDeep=la,n.flattenDepth=fa,n.flip=Mu,n.flow=$p,n.flowRight=Xp,n.fromPairs=pa,n.functions=Pc,n.functionsIn=Oc,n.groupBy=Xf,n.initial=va,n.intersection=Of,n.intersectionBy=If,n.intersectionWith=Df,n.invert=Ap,n.invertBy=Pp,n.invokeMap=Qf,n.iteratee=Ts,n.keyBy=Zf,n.keys=Lc,n.keysIn=Uc,n.map=lu,n.mapKeys=Fc,n.mapValues=jc,n.matches=Ss,n.matchesProperty=Ns,n.memoize=Tu,n.merge=Ip,n.mergeWith=Dp,n.method=Qp,n.methodOf=Zp,n.mixin=As,n.negate=Su,n.nthArg=Is,n.omit=Rp,n.omitBy=Bc,n.once=Nu,n.orderBy=fu,n.over=Jp,n.overArgs=ap,n.overEvery=th,n.overSome=eh,n.partial=up,n.partialRight=cp,n.partition=Jf,n.pick=Lp,n.pickBy=Vc,n.property=Ds,n.propertyOf=Rs,n.pull=Rf,n.pullAll=ba,n.pullAllBy=xa,n.pullAllWith=wa,n.pullAt=Lf,n.range=nh,n.rangeRight=rh,n.rearg=sp,n.reject=du,n.remove=Ca,n.rest=Au,n.reverse=ka,n.sampleSize=gu,n.set=zc,n.setWith=Hc,n.shuffle=mu,n.slice=Ea,n.sortBy=tp,n.sortedUniq=Oa,n.sortedUniqBy=Ia,n.split=fs,n.spread=Pu,n.tail=Da,n.take=Ra,n.takeRight=La,n.takeRightWhile=Ua,n.takeWhile=Fa,n.tap=Ka,n.throttle=Ou,n.thru=Ga,n.toArray=gc,n.toPairs=Up,n.toPairsIn=Fp,n.toPath=Ws,n.toPlainObject=xc,n.transform=qc,n.unary=Iu,n.union=Uf,n.unionBy=Ff,n.unionWith=jf,n.uniq=ja,n.uniqBy=Ba,n.uniqWith=Va,n.unset=Yc,n.unzip=Wa,n.unzipWith=za,n.update=Kc,n.updateWith=Gc,n.values=$c,n.valuesIn=Xc,n.without=Bf,n.words=xs,n.wrap=Du,n.xor=Vf,n.xorBy=Wf,n.xorWith=zf,n.zip=Hf,n.zipObject=Ha,n.zipObjectDeep=qa,n.zipWith=qf,n.entries=Up,n.entriesIn=Fp,n.extend=kp,n.extendWith=Ep,As(n,n),n.add=ih,n.attempt=Kp,n.camelCase=jp,n.capitalize=ts,n.ceil=oh,n.clamp=Qc,n.clone=Lu,n.cloneDeep=Fu,n.cloneDeepWith=ju,n.cloneWith=Uu,n.conformsTo=Bu,n.deburr=es,n.defaultTo=Es,n.divide=ah,n.endsWith=ns,n.eq=Vu,n.escape=rs,n.escapeRegExp=is,n.every=nu,n.find=Gf,n.findIndex=ua,n.findKey=Ec,n.findLast=$f,n.findLastIndex=ca,n.findLastKey=Mc,n.floor=uh,n.forEach=uu,n.forEachRight=cu,n.forIn=Tc,n.forInRight=Sc,n.forOwn=Nc,n.forOwnRight=Ac,n.get=Ic,n.gt=lp,n.gte=fp,n.has=Dc,n.hasIn=Rc,n.head=ha,n.identity=Ms,n.includes=su,n.indexOf=da,n.inRange=Zc,n.invoke=Op,n.isArguments=pp,n.isArray=hp,n.isArrayBuffer=dp,n.isArrayLike=Wu,n.isArrayLikeObject=zu,n.isBoolean=Hu,n.isBuffer=vp,n.isDate=gp,n.isElement=qu,n.isEmpty=Yu,n.isEqual=Ku,n.isEqualWith=Gu,n.isError=$u,n.isFinite=Xu,n.isFunction=Qu,n.isInteger=Zu,n.isLength=Ju,n.isMap=mp,n.isMatch=nc,n.isMatchWith=rc,n.isNaN=ic,n.isNative=oc,n.isNil=uc,n.isNull=ac,n.isNumber=cc,n.isObject=tc,n.isObjectLike=ec,n.isPlainObject=sc,n.isRegExp=yp,n.isSafeInteger=lc,n.isSet=_p,n.isString=fc,n.isSymbol=pc,n.isTypedArray=bp,n.isUndefined=hc,n.isWeakMap=dc,n.isWeakSet=vc,n.join=ga,n.kebabCase=Bp,n.last=ma,n.lastIndexOf=ya,n.lowerCase=Vp,n.lowerFirst=Wp,n.lt=xp,n.lte=wp,n.max=Hs,n.maxBy=qs,n.mean=Ys,n.meanBy=Ks,n.min=Gs,n.minBy=$s,n.stubArray=Ls,n.stubFalse=Us,n.stubObject=Fs,n.stubString=js,n.stubTrue=Bs,n.multiply=ch,n.nth=_a,n.noConflict=Ps,n.noop=Os,n.now=ep,n.pad=os,n.padEnd=as,n.padStart=us,n.parseInt=cs,n.random=Jc,n.reduce=pu,n.reduceRight=hu,n.repeat=ss,n.replace=ls,n.result=Wc,n.round=sh,n.runInContext=t,n.sample=vu,n.size=yu,n.snakeCase=zp,n.some=_u,n.sortedIndex=Ma,n.sortedIndexBy=Ta,n.sortedIndexOf=Sa,n.sortedLastIndex=Na,n.sortedLastIndexBy=Aa,n.sortedLastIndexOf=Pa,n.startCase=Hp,n.startsWith=ps,n.subtract=lh,n.sum=Xs,n.sumBy=Qs,n.template=hs,n.times=Vs,n.toFinite=mc,n.toInteger=yc,n.toLength=_c,n.toLower=ds,n.toNumber=bc,n.toSafeInteger=wc,n.toString=Cc,n.toUpper=vs,n.trim=gs,n.trimEnd=ms,n.trimStart=ys,n.truncate=_s,n.unescape=bs,n.uniqueId=zs,n.upperCase=qp,n.upperFirst=Yp,n.each=uu,n.eachRight=cu,n.first=ha,As(n,function(){var t={};return lr(n,function(e,r){pl.call(n.prototype,r)||(t[r]=e)}),t}(),{chain:!1}),n.VERSION=\"4.17.11\",u([\"bind\",\"bindKey\",\"curry\",\"curryRight\",\"partial\",\"partialRight\"],function(t){n[t].placeholder=n}),u([\"drop\",\"take\"],function(t,e){y.prototype[t]=function(n){n=n===nt?1:Vl(yc(n),0);var r=this.__filtered__&&!e?new y(this):this.clone();return r.__filtered__?r.__takeCount__=Wl(n,r.__takeCount__):r.__views__.push({size:Wl(n,Dt),type:t+(r.__dir__<0?\"Right\":\"\")}),r},y.prototype[t+\"Right\"]=function(e){return this.reverse()[t](e).reverse()}}),u([\"filter\",\"map\",\"takeWhile\"],function(t,e){var n=e+1,r=n==St||3==n;y.prototype[t]=function(t){var e=this.clone();return e.__iteratees__.push({iteratee:mo(t,3),type:n}),e.__filtered__=e.__filtered__||r,e}}),u([\"head\",\"last\"],function(t,e){var n=\"take\"+(e?\"Right\":\"\");y.prototype[t]=function(){return this[n](1).value()[0]}}),u([\"initial\",\"tail\"],function(t,e){var n=\"drop\"+(e?\"\":\"Right\");y.prototype[t]=function(){return this.__filtered__?new y(this):this[n](1)}}),y.prototype.compact=function(){return this.filter(Ms)},y.prototype.find=function(t){return this.filter(t).head()},y.prototype.findLast=function(t){return this.reverse().find(t)},y.prototype.invokeMap=Jr(function(t,e){return\"function\"==typeof t?new y(this):this.map(function(n){return wr(n,t,e)})}),y.prototype.reject=function(t){return this.filter(Su(mo(t)))},y.prototype.slice=function(t,e){t=yc(t);var n=this;return n.__filtered__&&(t>0||e<0)?new y(n):(t<0?n=n.takeRight(-t):t&&(n=n.drop(t)),e!==nt&&(e=yc(e),n=e<0?n.dropRight(-e):n.take(e-t)),n)},y.prototype.takeRightWhile=function(t){return this.reverse().takeWhile(t).reverse()},y.prototype.toArray=function(){return this.take(Dt)},lr(y.prototype,function(t,e){var r=/^(?:filter|find|map|reject)|While$/.test(e),o=/^(?:head|last)$/.test(e),a=n[o?\"take\"+(\"last\"==e?\"Right\":\"\"):e],u=o||/^find/.test(e);a&&(n.prototype[e]=function(){var e=this.__wrapped__,c=o?[1]:arguments,s=e instanceof y,l=c[0],f=s||hp(e),p=function(t){var e=a.apply(n,d([t],c));return o&&h?e[0]:e};f&&r&&\"function\"==typeof l&&1!=l.length&&(s=f=!1);var h=this.__chain__,v=!!this.__actions__.length,g=u&&!h,m=s&&!v;if(!u&&f){e=m?e:new y(this);var _=t.apply(e,c);return _.__actions__.push({func:Ga,args:[p],thisArg:nt}),new i(_,h)}return g&&m?t.apply(this,c):(_=this.thru(p),g?o?_.value()[0]:_.value():_)})}),u([\"pop\",\"push\",\"shift\",\"sort\",\"splice\",\"unshift\"],function(t){var e=ul[t],r=/^(?:push|sort|unshift)$/.test(t)?\"tap\":\"thru\",i=/^(?:pop|shift)$/.test(t);n.prototype[t]=function(){var t=arguments;if(i&&!this.__chain__){var n=this.value();return e.apply(hp(n)?n:[],t)}return this[r](function(n){return e.apply(hp(n)?n:[],t)})}}),lr(y.prototype,function(t,e){var r=n[e];if(r){var i=r.name+\"\";(tf[i]||(tf[i]=[])).push({name:e,func:r})}}),tf[Ki(nt,vt).name]=[{name:\"wrapper\",func:nt}],y.prototype.clone=T,y.prototype.reverse=$,y.prototype.value=J,n.prototype.at=Yf,n.prototype.chain=$a,n.prototype.commit=Xa,n.prototype.next=Qa,n.prototype.plant=Ja,n.prototype.reverse=tu,n.prototype.toJSON=n.prototype.valueOf=n.prototype.value=eu,n.prototype.first=n.prototype.head,Sl&&(n.prototype[Sl]=Za),n}();An._=Yn,(i=function(){return Yn}.call(e,n,e,r))!==nt&&(r.exports=i)}).call(this)}).call(e,n(98),n(99)(t))},function(t,e,n){\"use strict\";var r={remove:function(t){t._reactInternalInstance=void 0},get:function(t){return t._reactInternalInstance},has:function(t){return void 0!==t._reactInternalInstance},set:function(t,e){t._reactInternalInstance=e}};t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e=arguments.length-1,n=\"Minified React error #\"+t+\"; visit http://facebook.github.io/react/docs/error-decoder.html?invariant=\"+t,r=0;r<e;r++)n+=\"&args[]=\"+encodeURIComponent(arguments[r+1]);n+=\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\";var i=new Error(n);throw i.name=\"Invariant Violation\",i.framesToPop=1,i}t.exports=r},function(t,e,n){\"use strict\";t.exports=n(26)},function(t,e,n){\"use strict\";var r=n(63);e.a=function(t){return t=n.i(r.a)(Math.abs(t)),t?t[1]:NaN}},function(t,e,n){\"use strict\";e.a=function(t,e){return t=+t,e-=t,function(n){return t+e*n}}},function(t,e,n){\"use strict\";function r(t,e){return(e-=t=+t)?function(n){return(n-t)/e}:n.i(h.a)(e)}function i(t){return function(e,n){var r=t(e=+e,n=+n);return function(t){return t<=e?0:t>=n?1:r(t)}}}function o(t){return function(e,n){var r=t(e=+e,n=+n);return function(t){return t<=0?e:t>=1?n:r(t)}}}function a(t,e,n,r){var i=t[0],o=t[1],a=e[0],u=e[1];return o<i?(i=n(o,i),a=r(u,a)):(i=n(i,o),a=r(a,u)),function(t){return a(i(t))}}function u(t,e,r,i){var o=Math.min(t.length,e.length)-1,a=new Array(o),u=new Array(o),c=-1;for(t[o]<t[0]&&(t=t.slice().reverse(),e=e.slice().reverse());++c<o;)a[c]=r(t[c],t[c+1]),u[c]=i(e[c],e[c+1]);return function(e){var r=n.i(l.bisect)(t,e,1,o)-1;return u[r](a[r](e))}}function c(t,e){return e.domain(t.domain()).range(t.range()).interpolate(t.interpolate()).clamp(t.clamp())}function s(t,e){function n(){return s=Math.min(g.length,m.length)>2?u:a,l=h=null,c}function c(e){return(l||(l=s(g,m,_?i(t):t,y)))(+e)}var s,l,h,g=v,m=v,y=f.b,_=!1;return c.invert=function(t){return(h||(h=s(m,g,r,_?o(e):e)))(+t)},c.domain=function(t){return arguments.length?(g=p.a.call(t,d.a),n()):g.slice()},c.range=function(t){return arguments.length?(m=p.b.call(t),n()):m.slice()},c.rangeRound=function(t){return m=p.b.call(t),y=f.c,n()},c.clamp=function(t){return arguments.length?(_=!!t,n()):_},c.interpolate=function(t){return arguments.length?(y=t,n()):y},n()}e.b=r,e.c=c,e.a=s;var l=n(7),f=n(30),p=n(16),h=n(67),d=n(126),v=[0,1]},function(t,e,n){\"use strict\";function r(t){return function(){var e=this.ownerDocument,n=this.namespaceURI;return n===a.b&&e.documentElement.namespaceURI===a.b?e.createElement(t):e.createElementNS(n,t)}}function i(t){return function(){return this.ownerDocument.createElementNS(t.space,t.local)}}var o=n(68),a=n(69);e.a=function(t){var e=n.i(o.a)(t);return(e.local?i:r)(e)}},function(t,e,n){\"use strict\";e.a=function(t,e){var n=t.ownerSVGElement||t;if(n.createSVGPoint){var r=n.createSVGPoint();return r.x=e.clientX,r.y=e.clientY,r=r.matrixTransform(t.getScreenCTM().inverse()),[r.x,r.y]}var i=t.getBoundingClientRect();return[e.clientX-i.left-t.clientLeft,e.clientY-i.top-t.clientTop]}},function(t,e,n){\"use strict\";function r(t,e,n){t._context.bezierCurveTo((2*t._x0+t._x1)/3,(2*t._y0+t._y1)/3,(t._x0+2*t._x1)/3,(t._y0+2*t._y1)/3,(t._x0+4*t._x1+e)/6,(t._y0+4*t._y1+n)/6)}function i(t){this._context=t}e.c=r,e.b=i,i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=NaN,this._point=0},lineEnd:function(){switch(this._point){case 3:r(this,this._x1,this._y1);case 2:this._context.lineTo(this._x1,this._y1)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3,this._context.lineTo((5*this._x0+this._x1)/6,(5*this._y0+this._y1)/6);default:r(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new i(t)}},function(t,e,n){\"use strict\";function r(t,e,n){t._context.bezierCurveTo(t._x1+t._k*(t._x2-t._x0),t._y1+t._k*(t._y2-t._y0),t._x2+t._k*(t._x1-e),t._y2+t._k*(t._y1-n),t._x2,t._y2)}function i(t,e){this._context=t,this._k=(1-e)/6}e.c=r,e.b=i,i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x2,this._y2);break;case 3:r(this,this._x1,this._y1)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2,this._x1=t,this._y1=e;break;case 2:this._point=3;default:r(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new i(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t){this._context=t}r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._point=0},lineEnd:function(){(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;default:this._context.lineTo(t,e)}}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";e.a=function(){}},function(t,e,n){\"use strict\";var r={};t.exports=r},function(t,e,n){\"use strict\";function r(t){return\"topMouseUp\"===t||\"topTouchEnd\"===t||\"topTouchCancel\"===t}function i(t){return\"topMouseMove\"===t||\"topTouchMove\"===t}function o(t){return\"topMouseDown\"===t||\"topTouchStart\"===t}function a(t,e,n,r){var i=t.type||\"unknown-event\";t.currentTarget=m.getNodeFromInstance(r),e?v.invokeGuardedCallbackWithCatch(i,n,t):v.invokeGuardedCallback(i,n,t),t.currentTarget=null}function u(t,e){var n=t._dispatchListeners,r=t._dispatchInstances;if(Array.isArray(n))for(var i=0;i<n.length&&!t.isPropagationStopped();i++)a(t,e,n[i],r[i]);else n&&a(t,e,n,r);t._dispatchListeners=null,t._dispatchInstances=null}function c(t){var e=t._dispatchListeners,n=t._dispatchInstances;if(Array.isArray(e)){for(var r=0;r<e.length&&!t.isPropagationStopped();r++)if(e[r](t,n[r]))return n[r]}else if(e&&e(t,n))return n;return null}function s(t){var e=c(t);return t._dispatchInstances=null,t._dispatchListeners=null,e}function l(t){var e=t._dispatchListeners,n=t._dispatchInstances;Array.isArray(e)&&d(\"103\"),t.currentTarget=e?m.getNodeFromInstance(n):null;var r=e?e(t):null;return t.currentTarget=null,t._dispatchListeners=null,t._dispatchInstances=null,r}function f(t){return!!t._dispatchListeners}var p,h,d=n(1),v=n(88),g=(n(0),n(2),{injectComponentTree:function(t){p=t},injectTreeTraversal:function(t){h=t}}),m={isEndish:r,isMoveish:i,isStartish:o,executeDirectDispatch:l,executeDispatchesInOrder:u,executeDispatchesInOrderStopAtTrue:s,hasDispatches:f,getInstanceFromNode:function(t){return p.getInstanceFromNode(t)},getNodeFromInstance:function(t){return p.getNodeFromInstance(t)},isAncestor:function(t,e){return h.isAncestor(t,e)},getLowestCommonAncestor:function(t,e){return h.getLowestCommonAncestor(t,e)},getParentInstance:function(t){return h.getParentInstance(t)},traverseTwoPhase:function(t,e,n){return h.traverseTwoPhase(t,e,n)},traverseEnterLeave:function(t,e,n,r,i){return h.traverseEnterLeave(t,e,n,r,i)},injection:g};t.exports=m},function(t,e,n){\"use strict\";function r(t){return Object.prototype.hasOwnProperty.call(t,v)||(t[v]=h++,f[t[v]]={}),f[t[v]]}var i,o=n(3),a=n(84),u=n(374),c=n(90),s=n(406),l=n(95),f={},p=!1,h=0,d={topAbort:\"abort\",topAnimationEnd:s(\"animationend\")||\"animationend\",topAnimationIteration:s(\"animationiteration\")||\"animationiteration\",topAnimationStart:s(\"animationstart\")||\"animationstart\",topBlur:\"blur\",topCanPlay:\"canplay\",topCanPlayThrough:\"canplaythrough\",topChange:\"change\",topClick:\"click\",topCompositionEnd:\"compositionend\",topCompositionStart:\"compositionstart\",topCompositionUpdate:\"compositionupdate\",topContextMenu:\"contextmenu\",topCopy:\"copy\",topCut:\"cut\",topDoubleClick:\"dblclick\",topDrag:\"drag\",topDragEnd:\"dragend\",topDragEnter:\"dragenter\",topDragExit:\"dragexit\",topDragLeave:\"dragleave\",topDragOver:\"dragover\",topDragStart:\"dragstart\",topDrop:\"drop\",topDurationChange:\"durationchange\",topEmptied:\"emptied\",topEncrypted:\"encrypted\",topEnded:\"ended\",topError:\"error\",topFocus:\"focus\",topInput:\"input\",topKeyDown:\"keydown\",topKeyPress:\"keypress\",topKeyUp:\"keyup\",topLoadedData:\"loadeddata\",topLoadedMetadata:\"loadedmetadata\",topLoadStart:\"loadstart\",topMouseDown:\"mousedown\",topMouseMove:\"mousemove\",topMouseOut:\"mouseout\",topMouseOver:\"mouseover\",topMouseUp:\"mouseup\",topPaste:\"paste\",topPause:\"pause\",topPlay:\"play\",topPlaying:\"playing\",topProgress:\"progress\",topRateChange:\"ratechange\",topScroll:\"scroll\",topSeeked:\"seeked\",topSeeking:\"seeking\",topSelectionChange:\"selectionchange\",topStalled:\"stalled\",topSuspend:\"suspend\",topTextInput:\"textInput\",topTimeUpdate:\"timeupdate\",topTouchCancel:\"touchcancel\",topTouchEnd:\"touchend\",topTouchMove:\"touchmove\",topTouchStart:\"touchstart\",topTransitionEnd:s(\"transitionend\")||\"transitionend\",topVolumeChange:\"volumechange\",topWaiting:\"waiting\",topWheel:\"wheel\"},v=\"_reactListenersID\"+String(Math.random()).slice(2),g=o({},u,{ReactEventListener:null,injection:{injectReactEventListener:function(t){t.setHandleTopLevel(g.handleTopLevel),g.ReactEventListener=t}},setEnabled:function(t){g.ReactEventListener&&g.ReactEventListener.setEnabled(t)},isEnabled:function(){return!(!g.ReactEventListener||!g.ReactEventListener.isEnabled())},listenTo:function(t,e){for(var n=e,i=r(n),o=a.registrationNameDependencies[t],u=0;u<o.length;u++){var c=o[u];i.hasOwnProperty(c)&&i[c]||(\"topWheel\"===c?l(\"wheel\")?g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"wheel\",n):l(\"mousewheel\")?g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"mousewheel\",n):g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"DOMMouseScroll\",n):\"topScroll\"===c?l(\"scroll\",!0)?g.ReactEventListener.trapCapturedEvent(\"topScroll\",\"scroll\",n):g.ReactEventListener.trapBubbledEvent(\"topScroll\",\"scroll\",g.ReactEventListener.WINDOW_HANDLE):\"topFocus\"===c||\"topBlur\"===c?(l(\"focus\",!0)?(g.ReactEventListener.trapCapturedEvent(\"topFocus\",\"focus\",n),g.ReactEventListener.trapCapturedEvent(\"topBlur\",\"blur\",n)):l(\"focusin\")&&(g.ReactEventListener.trapBubbledEvent(\"topFocus\",\"focusin\",n),g.ReactEventListener.trapBubbledEvent(\"topBlur\",\"focusout\",n)),i.topBlur=!0,i.topFocus=!0):d.hasOwnProperty(c)&&g.ReactEventListener.trapBubbledEvent(c,d[c],n),i[c]=!0)}},trapBubbledEvent:function(t,e,n){return g.ReactEventListener.trapBubbledEvent(t,e,n)},trapCapturedEvent:function(t,e,n){return g.ReactEventListener.trapCapturedEvent(t,e,n)},supportsEventPageXY:function(){if(!document.createEvent)return!1;var t=document.createEvent(\"MouseEvent\");return null!=t&&\"pageX\"in t},ensureScrollValueMonitoring:function(){if(void 0===i&&(i=g.supportsEventPageXY()),!i&&!p){var t=c.refreshScrollValues;g.ReactEventListener.monitorScrollValue(t),p=!0}}});t.exports=g},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(90),a=n(93),u={screenX:null,screenY:null,clientX:null,clientY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:a,button:function(t){var e=t.button;return\"which\"in t?e:2===e?2:4===e?1:0},buttons:null,relatedTarget:function(t){return t.relatedTarget||(t.fromElement===t.srcElement?t.toElement:t.fromElement)},pageX:function(t){return\"pageX\"in t?t.pageX:t.clientX+o.currentScrollLeft},pageY:function(t){return\"pageY\"in t?t.pageY:t.clientY+o.currentScrollTop}};i.augmentClass(r,u),t.exports=r},function(t,e,n){\"use strict\";var r=n(1),i=(n(0),{}),o={reinitializeTransaction:function(){this.transactionWrappers=this.getTransactionWrappers(),this.wrapperInitData?this.wrapperInitData.length=0:this.wrapperInitData=[],this._isInTransaction=!1},_isInTransaction:!1,getTransactionWrappers:null,isInTransaction:function(){return!!this._isInTransaction},perform:function(t,e,n,i,o,a,u,c){this.isInTransaction()&&r(\"27\");var s,l;try{this._isInTransaction=!0,s=!0,this.initializeAll(0),l=t.call(e,n,i,o,a,u,c),s=!1}finally{try{if(s)try{this.closeAll(0)}catch(t){}else this.closeAll(0)}finally{this._isInTransaction=!1}}return l},initializeAll:function(t){for(var e=this.transactionWrappers,n=t;n<e.length;n++){var r=e[n];try{this.wrapperInitData[n]=i,this.wrapperInitData[n]=r.initialize?r.initialize.call(this):null}finally{if(this.wrapperInitData[n]===i)try{this.initializeAll(n+1)}catch(t){}}}},closeAll:function(t){this.isInTransaction()||r(\"28\");for(var e=this.transactionWrappers,n=t;n<e.length;n++){var o,a=e[n],u=this.wrapperInitData[n];try{o=!0,u!==i&&a.close&&a.close.call(this,u),o=!1}finally{if(o)try{this.closeAll(n+1)}catch(t){}}}this.wrapperInitData.length=0}};t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=\"\"+t,n=o.exec(e);if(!n)return e;var r,i=\"\",a=0,u=0;for(a=n.index;a<e.length;a++){switch(e.charCodeAt(a)){case 34:r=\"&quot;\";break;case 38:r=\"&amp;\";break;case 39:r=\"&#x27;\";break;case 60:r=\"&lt;\";break;case 62:r=\"&gt;\";break;default:continue}u!==a&&(i+=e.substring(u,a)),u=a+1,i+=r}return u!==a?i+e.substring(u,a):i}function i(t){return\"boolean\"==typeof t||\"number\"==typeof t?\"\"+t:r(t)}var o=/[\"'&<>]/;t.exports=i},function(t,e,n){\"use strict\";var r,i=n(6),o=n(83),a=/^[ \\r\\n\\t\\f]/,u=/<(!--|link|noscript|meta|script|style)[ \\r\\n\\t\\f\\/>]/,c=n(91),s=c(function(t,e){if(t.namespaceURI!==o.svg||\"innerHTML\"in t)t.innerHTML=e;else{r=r||document.createElement(\"div\"),r.innerHTML=\"<svg>\"+e+\"</svg>\";for(var n=r.firstChild;n.firstChild;)t.appendChild(n.firstChild)}});if(i.canUseDOM){var l=document.createElement(\"div\");l.innerHTML=\" \",\"\"===l.innerHTML&&(s=function(t,e){if(t.parentNode&&t.parentNode.replaceChild(t,t),a.test(e)||\"<\"===e[0]&&u.test(e)){t.innerHTML=String.fromCharCode(65279)+e;var n=t.firstChild;1===n.data.length?t.removeChild(n):n.deleteData(0,1)}else t.innerHTML=e}),l=null}t.exports=s},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.default={colors:{RdBu:[\"rgb(255, 13, 87)\",\"rgb(30, 136, 229)\"],GnPR:[\"rgb(24, 196, 93)\",\"rgb(124, 82, 255)\"],CyPU:[\"#0099C6\",\"#990099\"],PkYg:[\"#DD4477\",\"#66AA00\"],DrDb:[\"#B82E2E\",\"#316395\"],LpLb:[\"#994499\",\"#22AA99\"],YlDp:[\"#AAAA11\",\"#6633CC\"],OrId:[\"#E67300\",\"#3E0099\"]},gray:\"#777\"}},function(t,e,n){\"use strict\";var r=n(28);e.a=function(t,e,n){if(null==n&&(n=r.a),i=t.length){if((e=+e)<=0||i<2)return+n(t[0],0,t);if(e>=1)return+n(t[i-1],i-1,t);var i,o=(i-1)*e,a=Math.floor(o),u=+n(t[a],a,t);return u+(+n(t[a+1],a+1,t)-u)*(o-a)}}},function(t,e,n){\"use strict\";function r(){}function i(t,e){var n=new r;if(t instanceof r)t.each(function(t,e){n.set(e,t)});else if(Array.isArray(t)){var i,o=-1,a=t.length;if(null==e)for(;++o<a;)n.set(o,t[o]);else for(;++o<a;)n.set(e(i=t[o],o,t),i)}else if(t)for(var u in t)n.set(u,t[u]);return n}n.d(e,\"b\",function(){return o});var o=\"$\";r.prototype=i.prototype={constructor:r,has:function(t){return o+t in this},get:function(t){return this[o+t]},set:function(t,e){return this[o+t]=e,this},remove:function(t){var e=o+t;return e in this&&delete this[e]},clear:function(){for(var t in this)t[0]===o&&delete this[t]},keys:function(){var t=[];for(var e in this)e[0]===o&&t.push(e.slice(1));return t},values:function(){var t=[];for(var e in this)e[0]===o&&t.push(this[e]);return t},entries:function(){var t=[];for(var e in this)e[0]===o&&t.push({key:e.slice(1),value:this[e]});return t},size:function(){var t=0;for(var e in this)e[0]===o&&++t;return t},empty:function(){for(var t in this)if(t[0]===o)return!1;return!0},each:function(t){for(var e in this)e[0]===o&&t(this[e],e.slice(1),this)}},e.a=i},function(t,e,n){\"use strict\";function r(){}function i(t){var e;return t=(t+\"\").trim().toLowerCase(),(e=x.exec(t))?(e=parseInt(e[1],16),new s(e>>8&15|e>>4&240,e>>4&15|240&e,(15&e)<<4|15&e,1)):(e=w.exec(t))?o(parseInt(e[1],16)):(e=C.exec(t))?new s(e[1],e[2],e[3],1):(e=k.exec(t))?new s(255*e[1]/100,255*e[2]/100,255*e[3]/100,1):(e=E.exec(t))?a(e[1],e[2],e[3],e[4]):(e=M.exec(t))?a(255*e[1]/100,255*e[2]/100,255*e[3]/100,e[4]):(e=T.exec(t))?l(e[1],e[2]/100,e[3]/100,1):(e=S.exec(t))?l(e[1],e[2]/100,e[3]/100,e[4]):N.hasOwnProperty(t)?o(N[t]):\"transparent\"===t?new s(NaN,NaN,NaN,0):null}function o(t){return new s(t>>16&255,t>>8&255,255&t,1)}function a(t,e,n,r){return r<=0&&(t=e=n=NaN),new s(t,e,n,r)}function u(t){return t instanceof r||(t=i(t)),t?(t=t.rgb(),new s(t.r,t.g,t.b,t.opacity)):new s}function c(t,e,n,r){return 1===arguments.length?u(t):new s(t,e,n,null==r?1:r)}function s(t,e,n,r){this.r=+t,this.g=+e,this.b=+n,this.opacity=+r}function l(t,e,n,r){return r<=0?t=e=n=NaN:n<=0||n>=1?t=e=NaN:e<=0&&(t=NaN),new h(t,e,n,r)}function f(t){if(t instanceof h)return new h(t.h,t.s,t.l,t.opacity);if(t instanceof r||(t=i(t)),!t)return new h;if(t instanceof h)return t;t=t.rgb();var e=t.r/255,n=t.g/255,o=t.b/255,a=Math.min(e,n,o),u=Math.max(e,n,o),c=NaN,s=u-a,l=(u+a)/2;return s?(c=e===u?(n-o)/s+6*(n<o):n===u?(o-e)/s+2:(e-n)/s+4,s/=l<.5?u+a:2-u-a,c*=60):s=l>0&&l<1?0:c,new h(c,s,l,t.opacity)}function p(t,e,n,r){return 1===arguments.length?f(t):new h(t,e,n,null==r?1:r)}function h(t,e,n,r){this.h=+t,this.s=+e,this.l=+n,this.opacity=+r}function d(t,e,n){return 255*(t<60?e+(n-e)*t/60:t<180?n:t<240?e+(n-e)*(240-t)/60:e)}e.f=r,n.d(e,\"h\",function(){return g}),n.d(e,\"g\",function(){return m}),e.a=i,e.e=u,e.b=c,e.d=s,e.c=p;var v=n(62),g=.7,m=1/g,y=\"\\\\s*([+-]?\\\\d+)\\\\s*\",_=\"\\\\s*([+-]?\\\\d*\\\\.?\\\\d+(?:[eE][+-]?\\\\d+)?)\\\\s*\",b=\"\\\\s*([+-]?\\\\d*\\\\.?\\\\d+(?:[eE][+-]?\\\\d+)?)%\\\\s*\",x=/^#([0-9a-f]{3})$/,w=/^#([0-9a-f]{6})$/,C=new RegExp(\"^rgb\\\\(\"+[y,y,y]+\"\\\\)$\"),k=new RegExp(\"^rgb\\\\(\"+[b,b,b]+\"\\\\)$\"),E=new RegExp(\"^rgba\\\\(\"+[y,y,y,_]+\"\\\\)$\"),M=new RegExp(\"^rgba\\\\(\"+[b,b,b,_]+\"\\\\)$\"),T=new RegExp(\"^hsl\\\\(\"+[_,b,b]+\"\\\\)$\"),S=new RegExp(\"^hsla\\\\(\"+[_,b,b,_]+\"\\\\)$\"),N={aliceblue:15792383,antiquewhite:16444375,aqua:65535,aquamarine:8388564,azure:15794175,beige:16119260,bisque:16770244,black:0,blanchedalmond:16772045,blue:255,blueviolet:9055202,brown:10824234,burlywood:14596231,cadetblue:6266528,chartreuse:8388352,chocolate:13789470,coral:16744272,cornflowerblue:6591981,cornsilk:16775388,crimson:14423100,cyan:65535,darkblue:139,darkcyan:35723,darkgoldenrod:12092939,darkgray:11119017,darkgreen:25600,darkgrey:11119017,darkkhaki:12433259,darkmagenta:9109643,darkolivegreen:5597999,darkorange:16747520,darkorchid:10040012,darkred:9109504,darksalmon:15308410,darkseagreen:9419919,darkslateblue:4734347,darkslategray:3100495,darkslategrey:3100495,darkturquoise:52945,darkviolet:9699539,deeppink:16716947,deepskyblue:49151,dimgray:6908265,dimgrey:6908265,dodgerblue:2003199,firebrick:11674146,floralwhite:16775920,forestgreen:2263842,fuchsia:16711935,gainsboro:14474460,ghostwhite:16316671,gold:16766720,goldenrod:14329120,gray:8421504,green:32768,greenyellow:11403055,grey:8421504,honeydew:15794160,hotpink:16738740,indianred:13458524,indigo:4915330,ivory:16777200,khaki:15787660,lavender:15132410,lavenderblush:16773365,lawngreen:8190976,lemonchiffon:16775885,lightblue:11393254,lightcoral:15761536,lightcyan:14745599,lightgoldenrodyellow:16448210,lightgray:13882323,lightgreen:9498256,lightgrey:13882323,lightpink:16758465,lightsalmon:16752762,lightseagreen:2142890,lightskyblue:8900346,lightslategray:7833753,lightslategrey:7833753,lightsteelblue:11584734,lightyellow:16777184,lime:65280,limegreen:3329330,linen:16445670,magenta:16711935,maroon:8388608,mediumaquamarine:6737322,mediumblue:205,mediumorchid:12211667,mediumpurple:9662683,mediumseagreen:3978097,mediumslateblue:8087790,mediumspringgreen:64154,mediumturquoise:4772300,mediumvioletred:13047173,midnightblue:1644912,mintcream:16121850,mistyrose:16770273,moccasin:16770229,navajowhite:16768685,navy:128,oldlace:16643558,olive:8421376,olivedrab:7048739,orange:16753920,orangered:16729344,orchid:14315734,palegoldenrod:15657130,palegreen:10025880,paleturquoise:11529966,palevioletred:14381203,papayawhip:16773077,peachpuff:16767673,peru:13468991,pink:16761035,plum:14524637,powderblue:11591910,purple:8388736,rebeccapurple:6697881,red:16711680,rosybrown:12357519,royalblue:4286945,saddlebrown:9127187,salmon:16416882,sandybrown:16032864,seagreen:3050327,seashell:16774638,sienna:10506797,silver:12632256,skyblue:8900331,slateblue:6970061,slategray:7372944,slategrey:7372944,snow:16775930,springgreen:65407,steelblue:4620980,tan:13808780,teal:32896,thistle:14204888,tomato:16737095,turquoise:4251856,violet:15631086,wheat:16113331,white:16777215,whitesmoke:16119285,yellow:16776960,yellowgreen:10145074};n.i(v.a)(r,i,{displayable:function(){return this.rgb().displayable()},toString:function(){return this.rgb()+\"\"}}),n.i(v.a)(s,c,n.i(v.b)(r,{brighter:function(t){return t=null==t?m:Math.pow(m,t),new s(this.r*t,this.g*t,this.b*t,this.opacity)},darker:function(t){return t=null==t?g:Math.pow(g,t),new s(this.r*t,this.g*t,this.b*t,this.opacity)},rgb:function(){return this},displayable:function(){return 0<=this.r&&this.r<=255&&0<=this.g&&this.g<=255&&0<=this.b&&this.b<=255&&0<=this.opacity&&this.opacity<=1},toString:function(){var t=this.opacity;return t=isNaN(t)?1:Math.max(0,Math.min(1,t)),(1===t?\"rgb(\":\"rgba(\")+Math.max(0,Math.min(255,Math.round(this.r)||0))+\", \"+Math.max(0,Math.min(255,Math.round(this.g)||0))+\", \"+Math.max(0,Math.min(255,Math.round(this.b)||0))+(1===t?\")\":\", \"+t+\")\")}})),n.i(v.a)(h,p,n.i(v.b)(r,{brighter:function(t){return t=null==t?m:Math.pow(m,t),new h(this.h,this.s,this.l*t,this.opacity)},darker:function(t){return t=null==t?g:Math.pow(g,t),new h(this.h,this.s,this.l*t,this.opacity)},rgb:function(){var t=this.h%360+360*(this.h<0),e=isNaN(t)||isNaN(this.s)?0:this.s,n=this.l,r=n+(n<.5?n:1-n)*e,i=2*n-r;return new s(d(t>=240?t-240:t+120,i,r),d(t,i,r),d(t<120?t+240:t-120,i,r),this.opacity)},displayable:function(){return(0<=this.s&&this.s<=1||isNaN(this.s))&&0<=this.l&&this.l<=1&&0<=this.opacity&&this.opacity<=1}}))},function(t,e,n){\"use strict\";function r(t,e){var n=Object.create(t.prototype);for(var r in e)n[r]=e[r];return n}e.b=r,e.a=function(t,e,n){t.prototype=e.prototype=n,n.constructor=t}},function(t,e,n){\"use strict\";e.a=function(t,e){if((n=(t=e?t.toExponential(e-1):t.toExponential()).indexOf(\"e\"))<0)return null;var n,r=t.slice(0,n);return[r.length>1?r[0]+r.slice(2):r,+t.slice(n+1)]}},function(t,e,n){\"use strict\";function r(t,e,n,r,i){var o=t*t,a=o*t;return((1-3*t+3*o-a)*e+(4-6*o+3*a)*n+(1+3*t+3*o-3*a)*r+a*i)/6}e.b=r,e.a=function(t){var e=t.length-1;return function(n){var i=n<=0?n=0:n>=1?(n=1,e-1):Math.floor(n*e),o=t[i],a=t[i+1],u=i>0?t[i-1]:2*o-a,c=i<e-1?t[i+2]:2*a-o;return r((n-i/e)*e,u,o,a,c)}}},function(t,e,n){\"use strict\";var r=n(10),i=n(123),o=n(118),a=n(121),u=n(43),c=n(122),s=n(124),l=n(120);e.a=function(t,e){var f,p=typeof e;return null==e||\"boolean\"===p?n.i(l.a)(e):(\"number\"===p?u.a:\"string\"===p?(f=n.i(r.color)(e))?(e=f,i.a):s.a:e instanceof r.color?i.a:e instanceof Date?a.a:Array.isArray(e)?o.a:\"function\"!=typeof e.valueOf&&\"function\"!=typeof e.toString||isNaN(e)?c.a:u.a)(t,e)}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(239);n.d(e,\"scaleBand\",function(){return r.a}),n.d(e,\"scalePoint\",function(){return r.b});var i=n(245);n.d(e,\"scaleIdentity\",function(){return i.a});var o=n(34);n.d(e,\"scaleLinear\",function(){return o.a});var a=n(246);n.d(e,\"scaleLog\",function(){return a.a});var u=n(127);n.d(e,\"scaleOrdinal\",function(){return u.a}),n.d(e,\"scaleImplicit\",function(){return u.b});var c=n(247);n.d(e,\"scalePow\",function(){return c.a}),n.d(e,\"scaleSqrt\",function(){return c.b});var s=n(248);n.d(e,\"scaleQuantile\",function(){return s.a});var l=n(249);n.d(e,\"scaleQuantize\",function(){return l.a});var f=n(252);n.d(e,\"scaleThreshold\",function(){return f.a});var p=n(128);n.d(e,\"scaleTime\",function(){return p.a});var h=n(254);n.d(e,\"scaleUtc\",function(){return h.a});var d=n(240);n.d(e,\"schemeCategory10\",function(){return d.a});var v=n(242);n.d(e,\"schemeCategory20b\",function(){return v.a});var g=n(243);n.d(e,\"schemeCategory20c\",function(){return g.a});var m=n(241);n.d(e,\"schemeCategory20\",function(){return m.a});var y=n(244);n.d(e,\"interpolateCubehelixDefault\",function(){return y.a});var _=n(250);n.d(e,\"interpolateRainbow\",function(){return _.a}),n.d(e,\"interpolateWarm\",function(){return _.b}),n.d(e,\"interpolateCool\",function(){return _.c});var b=n(255);n.d(e,\"interpolateViridis\",function(){return b.a}),n.d(e,\"interpolateMagma\",function(){return b.b}),n.d(e,\"interpolateInferno\",function(){return b.c}),n.d(e,\"interpolatePlasma\",function(){return b.d});var x=n(251);n.d(e,\"scaleSequential\",function(){return x.a})},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";var r=n(69);e.a=function(t){var e=t+=\"\",n=e.indexOf(\":\");return n>=0&&\"xmlns\"!==(e=t.slice(0,n))&&(t=t.slice(n+1)),r.a.hasOwnProperty(e)?{space:r.a[e],local:t}:t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r});var r=\"http://www.w3.org/1999/xhtml\";e.a={svg:\"http://www.w3.org/2000/svg\",xhtml:r,xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\",xmlns:\"http://www.w3.org/2000/xmlns/\"}},function(t,e,n){\"use strict\";function r(t,e,n){return t=i(t,e,n),function(e){var n=e.relatedTarget;n&&(n===this||8&n.compareDocumentPosition(this))||t.call(this,e)}}function i(t,e,n){return function(r){var i=l;l=r;try{t.call(this,this.__data__,e,n)}finally{l=i}}}function o(t){return t.trim().split(/^|\\s+/).map(function(t){var e=\"\",n=t.indexOf(\".\");return n>=0&&(e=t.slice(n+1),t=t.slice(0,n)),{type:t,name:e}})}function a(t){return function(){var e=this.__on;if(e){for(var n,r=0,i=-1,o=e.length;r<o;++r)n=e[r],t.type&&n.type!==t.type||n.name!==t.name?e[++i]=n:this.removeEventListener(n.type,n.listener,n.capture);++i?e.length=i:delete this.__on}}}function u(t,e,n){var o=s.hasOwnProperty(t.type)?r:i;return function(r,i,a){var u,c=this.__on,s=o(e,i,a);if(c)for(var l=0,f=c.length;l<f;++l)if((u=c[l]).type===t.type&&u.name===t.name)return this.removeEventListener(u.type,u.listener,u.capture),this.addEventListener(u.type,u.listener=s,u.capture=n),void(u.value=e);this.addEventListener(t.type,s,n),u={type:t.type,name:t.name,value:e,listener:s,capture:n},c?c.push(u):this.__on=[u]}}function c(t,e,n,r){var i=l;t.sourceEvent=l,l=t;try{return e.apply(n,r)}finally{l=i}}n.d(e,\"a\",function(){return l}),e.b=c;var s={},l=null;if(\"undefined\"!=typeof document){\"onmouseenter\"in document.documentElement||(s={mouseenter:\"mouseover\",mouseleave:\"mouseout\"})}e.c=function(t,e,n){var r,i,c=o(t+\"\"),s=c.length;{if(!(arguments.length<2)){for(l=e?u:a,null==n&&(n=!1),r=0;r<s;++r)this.each(l(c[r],e,n));return this}var l=this.node().__on;if(l)for(var f,p=0,h=l.length;p<h;++p)for(r=0,f=l[p];r<s;++r)if((i=c[r]).type===f.type&&i.name===f.name)return f.value}}},function(t,e,n){\"use strict\";function r(){}e.a=function(t){return null==t?r:function(){return this.querySelector(t)}}},function(t,e,n){\"use strict\";var r=n(70);e.a=function(){for(var t,e=r.a;t=e.sourceEvent;)e=t;return e}},function(t,e,n){\"use strict\";e.a=function(t){return t.ownerDocument&&t.ownerDocument.defaultView||t.document&&t||t.defaultView}},function(t,e,n){\"use strict\";function r(t,e,n){var r=t._x1,i=t._y1,a=t._x2,u=t._y2;if(t._l01_a>o.a){var c=2*t._l01_2a+3*t._l01_a*t._l12_a+t._l12_2a,s=3*t._l01_a*(t._l01_a+t._l12_a);r=(r*c-t._x0*t._l12_2a+t._x2*t._l01_2a)/s,i=(i*c-t._y0*t._l12_2a+t._y2*t._l01_2a)/s}if(t._l23_a>o.a){var l=2*t._l23_2a+3*t._l23_a*t._l12_a+t._l12_2a,f=3*t._l23_a*(t._l23_a+t._l12_a);a=(a*l+t._x1*t._l23_2a-e*t._l12_2a)/f,u=(u*l+t._y1*t._l23_2a-n*t._l12_2a)/f}t._context.bezierCurveTo(r,i,a,u,t._x2,t._y2)}function i(t,e){this._context=t,this._alpha=e}e.b=r;var o=n(35),a=n(48);i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x2,this._y2);break;case 3:this.point(this._x2,this._y2)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){if(t=+t,e=+e,this._point){var n=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(n*n+i*i,this._alpha))}switch(this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3;default:r(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new i(t,e):new a.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";var r=n(32),i=n(17),o=n(49),a=n(77);e.a=function(){function t(t){var i,o,a,p=t.length,h=!1;for(null==s&&(f=l(a=n.i(r.a)())),i=0;i<=p;++i)!(i<p&&c(o=t[i],i,t))===h&&((h=!h)?f.lineStart():f.lineEnd()),h&&f.point(+e(o,i,t),+u(o,i,t));if(a)return f=null,a+\"\"||null}var e=a.a,u=a.b,c=n.i(i.a)(!0),s=null,l=o.a,f=null;return t.x=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(i.a)(+r),t):e},t.y=function(e){return arguments.length?(u=\"function\"==typeof e?e:n.i(i.a)(+e),t):u},t.defined=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(!!e),t):c},t.curve=function(e){return arguments.length?(l=e,null!=s&&(f=l(s)),t):l},t.context=function(e){return arguments.length?(null==e?s=f=null:f=l(s=e),t):s},t}},function(t,e,n){\"use strict\";function r(t){for(var e,n=0,r=-1,i=t.length;++r<i;)(e=+t[r][1])&&(n+=e);return n}e.b=r;var i=n(37);e.a=function(t){var e=t.map(r);return n.i(i.a)(t).sort(function(t,n){return e[t]-e[n]})}},function(t,e,n){\"use strict\";function r(t){return t[0]}function i(t){return t[1]}e.a=r,e.b=i},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(79);n.d(e,\"timeFormatDefaultLocale\",function(){return r.a}),n.d(e,\"timeFormat\",function(){return r.b}),n.d(e,\"timeParse\",function(){return r.c}),n.d(e,\"utcFormat\",function(){return r.d}),n.d(e,\"utcParse\",function(){return r.e});var i=n(152);n.d(e,\"timeFormatLocale\",function(){return i.a});var o=n(151);n.d(e,\"isoFormat\",function(){return o.a});var a=n(314);n.d(e,\"isoParse\",function(){return a.a})},function(t,e,n){\"use strict\";function r(t){return i=n.i(s.a)(t),o=i.format,a=i.parse,u=i.utcFormat,c=i.utcParse,i}n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a}),n.d(e,\"d\",function(){return u}),n.d(e,\"e\",function(){return c}),e.a=r;var i,o,a,u,c,s=n(152);r({dateTime:\"%x, %X\",date:\"%-m/%-d/%Y\",time:\"%-I:%M:%S %p\",periods:[\"AM\",\"PM\"],days:[\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"],shortDays:[\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"],months:[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],shortMonths:[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]})},function(t,e,n){\"use strict\";var r=(n(5),n(317));n.d(e,\"v\",function(){return r.a}),n.d(e,\"p\",function(){return r.a});var i=n(320);n.d(e,\"u\",function(){return i.a}),n.d(e,\"o\",function(){return i.a});var o=n(318);n.d(e,\"t\",function(){return o.a});var a=n(316);n.d(e,\"s\",function(){return a.a});var u=n(315);n.d(e,\"d\",function(){return u.a});var c=n(327);n.d(e,\"r\",function(){return c.a}),n.d(e,\"f\",function(){return c.a}),n.d(e,\"c\",function(){return c.b}),n.d(e,\"g\",function(){return c.c});var s=n(319);n.d(e,\"q\",function(){return s.a});var l=n(328);n.d(e,\"e\",function(){return l.a});var f=n(323);n.d(e,\"n\",function(){return f.a});var p=n(322);n.d(e,\"m\",function(){return p.a});var h=n(321);n.d(e,\"b\",function(){return h.a});var d=n(325);n.d(e,\"l\",function(){return d.a}),n.d(e,\"i\",function(){return d.a}),n.d(e,\"a\",function(){return d.b}),n.d(e,\"j\",function(){return d.c});var v=n(324);n.d(e,\"k\",function(){return v.a});var g=n(326);n.d(e,\"h\",function(){return g.a})},function(t,e,n){\"use strict\";function r(t,e){return t===e?0!==t||0!==e||1/t==1/e:t!==t&&e!==e}function i(t,e){if(r(t,e))return!0;if(\"object\"!=typeof t||null===t||\"object\"!=typeof e||null===e)return!1;var n=Object.keys(t),i=Object.keys(e);if(n.length!==i.length)return!1;for(var a=0;a<n.length;a++)if(!o.call(e,n[a])||!r(t[n[a]],e[n[a]]))return!1;return!0}var o=Object.prototype.hasOwnProperty;t.exports=i},function(t,e,n){\"use strict\";function r(t,e){return Array.isArray(e)&&(e=e[1]),e?e.nextSibling:t.firstChild}function i(t,e,n){l.insertTreeBefore(t,e,n)}function o(t,e,n){Array.isArray(e)?u(t,e[0],e[1],n):v(t,e,n)}function a(t,e){if(Array.isArray(e)){var n=e[1];e=e[0],c(t,e,n),t.removeChild(n)}t.removeChild(e)}function u(t,e,n,r){for(var i=e;;){var o=i.nextSibling;if(v(t,i,r),i===n)break;i=o}}function c(t,e,n){for(;;){var r=e.nextSibling;if(r===n)break;t.removeChild(r)}}function s(t,e,n){var r=t.parentNode,i=t.nextSibling;i===e?n&&v(r,document.createTextNode(n),i):n?(d(i,n),c(r,i,e)):c(r,t,e)}var l=n(20),f=n(350),p=(n(4),n(9),n(91)),h=n(57),d=n(176),v=p(function(t,e,n){t.insertBefore(e,n)}),g=f.dangerouslyReplaceNodeWithMarkup,m={dangerouslyReplaceNodeWithMarkup:g,replaceDelimitedText:s,processUpdates:function(t,e){for(var n=0;n<e.length;n++){var u=e[n];switch(u.type){case\"INSERT_MARKUP\":i(t,u.content,r(t,u.afterNode));break;case\"MOVE_EXISTING\":o(t,u.fromNode,r(t,u.afterNode));break;case\"SET_MARKUP\":h(t,u.content);break;case\"TEXT_CONTENT\":d(t,u.content);break;case\"REMOVE_NODE\":a(t,u.fromNode)}}}};t.exports=m},function(t,e,n){\"use strict\";var r={html:\"http://www.w3.org/1999/xhtml\",mathml:\"http://www.w3.org/1998/Math/MathML\",svg:\"http://www.w3.org/2000/svg\"};t.exports=r},function(t,e,n){\"use strict\";function r(){if(u)for(var t in c){var e=c[t],n=u.indexOf(t);if(n>-1||a(\"96\",t),!s.plugins[n]){e.extractEvents||a(\"97\",t),s.plugins[n]=e;var r=e.eventTypes;for(var o in r)i(r[o],e,o)||a(\"98\",o,t)}}}function i(t,e,n){s.eventNameDispatchConfigs.hasOwnProperty(n)&&a(\"99\",n),s.eventNameDispatchConfigs[n]=t;var r=t.phasedRegistrationNames;if(r){for(var i in r)if(r.hasOwnProperty(i)){var u=r[i];o(u,e,n)}return!0}return!!t.registrationName&&(o(t.registrationName,e,n),!0)}function o(t,e,n){s.registrationNameModules[t]&&a(\"100\",t),s.registrationNameModules[t]=e,s.registrationNameDependencies[t]=e.eventTypes[n].dependencies}var a=n(1),u=(n(0),null),c={},s={plugins:[],eventNameDispatchConfigs:{},registrationNameModules:{},registrationNameDependencies:{},possibleRegistrationNames:null,injectEventPluginOrder:function(t){u&&a(\"101\"),u=Array.prototype.slice.call(t),r()},injectEventPluginsByName:function(t){var e=!1;for(var n in t)if(t.hasOwnProperty(n)){var i=t[n];c.hasOwnProperty(n)&&c[n]===i||(c[n]&&a(\"102\",n),c[n]=i,e=!0)}e&&r()},getPluginModuleForEvent:function(t){var e=t.dispatchConfig;if(e.registrationName)return s.registrationNameModules[e.registrationName]||null;if(void 0!==e.phasedRegistrationNames){var n=e.phasedRegistrationNames;for(var r in n)if(n.hasOwnProperty(r)){var i=s.registrationNameModules[n[r]];if(i)return i}}return null},_resetEventPlugins:function(){u=null;for(var t in c)c.hasOwnProperty(t)&&delete c[t];s.plugins.length=0;var e=s.eventNameDispatchConfigs;for(var n in e)e.hasOwnProperty(n)&&delete e[n];var r=s.registrationNameModules;for(var i in r)r.hasOwnProperty(i)&&delete r[i]}};t.exports=s},function(t,e,n){\"use strict\";function r(t){var e={\"=\":\"=0\",\":\":\"=2\"};return\"$\"+(\"\"+t).replace(/[=:]/g,function(t){return e[t]})}function i(t){var e=/(=0|=2)/g,n={\"=0\":\"=\",\"=2\":\":\"};return(\"\"+(\".\"===t[0]&&\"$\"===t[1]?t.substring(2):t.substring(1))).replace(e,function(t){return n[t]})}var o={escape:r,unescape:i};t.exports=o},function(t,e,n){\"use strict\";function r(t){null!=t.checkedLink&&null!=t.valueLink&&u(\"87\")}function i(t){r(t),(null!=t.value||null!=t.onChange)&&u(\"88\")}function o(t){r(t),(null!=t.checked||null!=t.onChange)&&u(\"89\")}function a(t){if(t){var e=t.getName();if(e)return\" Check the render method of `\"+e+\"`.\"}return\"\"}var u=n(1),c=n(380),s=n(157),l=n(26),f=s(l.isValidElement),p=(n(0),n(2),{button:!0,checkbox:!0,image:!0,hidden:!0,radio:!0,reset:!0,submit:!0}),h={value:function(t,e,n){return!t[e]||p[t.type]||t.onChange||t.readOnly||t.disabled?null:new Error(\"You provided a `value` prop to a form field without an `onChange` handler. This will render a read-only field. If the field should be mutable use `defaultValue`. Otherwise, set either `onChange` or `readOnly`.\")},checked:function(t,e,n){return!t[e]||t.onChange||t.readOnly||t.disabled?null:new Error(\"You provided a `checked` prop to a form field without an `onChange` handler. This will render a read-only field. If the field should be mutable use `defaultChecked`. Otherwise, set either `onChange` or `readOnly`.\")},onChange:f.func},d={},v={checkPropTypes:function(t,e,n){for(var r in h){if(h.hasOwnProperty(r))var i=h[r](e,r,t,\"prop\",null,c);if(i instanceof Error&&!(i.message in d)){d[i.message]=!0;a(n)}}},getValue:function(t){return t.valueLink?(i(t),t.valueLink.value):t.value},getChecked:function(t){return t.checkedLink?(o(t),t.checkedLink.value):t.checked},executeOnChange:function(t,e){return t.valueLink?(i(t),t.valueLink.requestChange(e.target.value)):t.checkedLink?(o(t),t.checkedLink.requestChange(e.target.checked)):t.onChange?t.onChange.call(void 0,e):void 0}};t.exports=v},function(t,e,n){\"use strict\";var r=n(1),i=(n(0),!1),o={replaceNodeWithMarkup:null,processChildrenUpdates:null,injection:{injectEnvironment:function(t){i&&r(\"104\"),o.replaceNodeWithMarkup=t.replaceNodeWithMarkup,o.processChildrenUpdates=t.processChildrenUpdates,i=!0}}};t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n){try{e(n)}catch(t){null===i&&(i=t)}}var i=null,o={invokeGuardedCallback:r,invokeGuardedCallbackWithCatch:r,rethrowCaughtError:function(){if(i){var t=i;throw i=null,t}}};t.exports=o},function(t,e,n){\"use strict\";function r(t){c.enqueueUpdate(t)}function i(t){var e=typeof t;if(\"object\"!==e)return e;var n=t.constructor&&t.constructor.name||e,r=Object.keys(t);return r.length>0&&r.length<20?n+\" (keys: \"+r.join(\", \")+\")\":n}function o(t,e){var n=u.get(t);if(!n){return null}return n}var a=n(1),u=(n(15),n(39)),c=(n(9),n(12)),s=(n(0),n(2),{isMounted:function(t){var e=u.get(t);return!!e&&!!e._renderedComponent},enqueueCallback:function(t,e,n){s.validateCallback(e,n);var i=o(t);if(!i)return null;i._pendingCallbacks?i._pendingCallbacks.push(e):i._pendingCallbacks=[e],r(i)},enqueueCallbackInternal:function(t,e){t._pendingCallbacks?t._pendingCallbacks.push(e):t._pendingCallbacks=[e],r(t)},enqueueForceUpdate:function(t){var e=o(t,\"forceUpdate\");e&&(e._pendingForceUpdate=!0,r(e))},enqueueReplaceState:function(t,e,n){var i=o(t,\"replaceState\");i&&(i._pendingStateQueue=[e],i._pendingReplaceState=!0,void 0!==n&&null!==n&&(s.validateCallback(n,\"replaceState\"),i._pendingCallbacks?i._pendingCallbacks.push(n):i._pendingCallbacks=[n]),r(i))},enqueueSetState:function(t,e){var n=o(t,\"setState\");if(n){(n._pendingStateQueue||(n._pendingStateQueue=[])).push(e),r(n)}},enqueueElementInternal:function(t,e,n){t._pendingElement=e,t._context=n,r(t)},validateCallback:function(t,e){t&&\"function\"!=typeof t&&a(\"122\",e,i(t))}});t.exports=s},function(t,e,n){\"use strict\";var r={currentScrollLeft:0,currentScrollTop:0,refreshScrollValues:function(t){r.currentScrollLeft=t.x,r.currentScrollTop=t.y}};t.exports=r},function(t,e,n){\"use strict\";var r=function(t){return\"undefined\"!=typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,n,r,i){MSApp.execUnsafeLocalFunction(function(){return t(e,n,r,i)})}:t};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e,n=t.keyCode;return\"charCode\"in t?0===(e=t.charCode)&&13===n&&(e=13):e=n,e>=32||13===e?e:0}t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=this,n=e.nativeEvent;if(n.getModifierState)return n.getModifierState(t);var r=o[t];return!!r&&!!n[r]}function i(t){return r}var o={Alt:\"altKey\",Control:\"ctrlKey\",Meta:\"metaKey\",Shift:\"shiftKey\"};t.exports=i},function(t,e,n){\"use strict\";function r(t){var e=t.target||t.srcElement||window;return e.correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}t.exports=r},function(t,e,n){\"use strict\";/**\n",
       " * Checks if an event is supported in the current execution environment.\n",
       " *\n",
       " * NOTE: This will not work correctly for non-generic events such as `change`,\n",
       " * `reset`, `load`, `error`, and `select`.\n",
       " *\n",
       " * Borrows from Modernizr.\n",
       " *\n",
       " * @param {string} eventNameSuffix Event name, e.g. \"click\".\n",
       " * @param {?boolean} capture Check if the capture phase is supported.\n",
       " * @return {boolean} True if the event is supported.\n",
       " * @internal\n",
       " * @license Modernizr 3.0.0pre (Custom Build) | MIT\n",
       " */\n",
       "function r(t,e){if(!o.canUseDOM||e&&!(\"addEventListener\"in document))return!1;var n=\"on\"+t,r=n in document;if(!r){var a=document.createElement(\"div\");a.setAttribute(n,\"return;\"),r=\"function\"==typeof a[n]}return!r&&i&&\"wheel\"===t&&(r=document.implementation.hasFeature(\"Events.wheel\",\"3.0\")),r}var i,o=n(6);o.canUseDOM&&(i=document.implementation&&document.implementation.hasFeature&&!0!==document.implementation.hasFeature(\"\",\"\")),t.exports=r},function(t,e,n){\"use strict\";function r(t,e){var n=null===t||!1===t,r=null===e||!1===e;if(n||r)return n===r;var i=typeof t,o=typeof e;return\"string\"===i||\"number\"===i?\"string\"===o||\"number\"===o:\"object\"===o&&t.type===e.type&&t.key===e.key}t.exports=r},function(t,e,n){\"use strict\";var r=(n(3),n(11)),i=(n(2),r);t.exports=i},function(t,e){var n;n=function(){return this}();try{n=n||Function(\"return this\")()||(0,eval)(\"this\")}catch(t){\"object\"==typeof window&&(n=window)}t.exports=n},function(t,e){t.exports=function(t){return t.webpackPolyfill||(t.deprecate=function(){},t.paths=[],t.children||(t.children=[]),Object.defineProperty(t,\"loaded\",{enumerable:!0,get:function(){return t.l}}),Object.defineProperty(t,\"id\",{enumerable:!0,get:function(){return t.i}}),t.webpackPolyfill=1),t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return i}),n.d(e,\"a\",function(){return o});var r=Array.prototype,i=r.slice,o=r.map},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return a}),n.d(e,\"c\",function(){return u});var r=n(19),i=n(102),o=n.i(i.a)(r.a),a=o.right,u=o.left;e.a=a},function(t,e,n){\"use strict\";function r(t){return function(e,r){return n.i(i.a)(t(e),r)}}var i=n(19);e.a=function(t){return 1===t.length&&(t=r(t)),{left:function(e,n,r,i){for(null==r&&(r=0),null==i&&(i=e.length);r<i;){var o=r+i>>>1;t(e[o],n)<0?r=o+1:i=o}return r},right:function(e,n,r,i){for(null==r&&(r=0),null==i&&(i=e.length);r<i;){var o=r+i>>>1;t(e[o],n)>0?i=o:r=o+1}return r}}}},function(t,e,n){\"use strict\";var r=n(111);e.a=function(t,e){var i=n.i(r.a)(t,e);return i?Math.sqrt(i):i}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i,o=t.length,a=-1;if(null==e){for(;++a<o;)if(null!=(n=t[a])&&n>=n)for(r=i=n;++a<o;)null!=(n=t[a])&&(r>n&&(r=n),i<n&&(i=n))}else for(;++a<o;)if(null!=(n=e(t[a],a,t))&&n>=n)for(r=i=n;++a<o;)null!=(n=e(t[a],a,t))&&(r>n&&(r=n),i<n&&(i=n));return[r,i]}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i=t.length,o=-1;if(null==e){for(;++o<i;)if(null!=(n=t[o])&&n>=n)for(r=n;++o<i;)null!=(n=t[o])&&r>n&&(r=n)}else for(;++o<i;)if(null!=(n=e(t[o],o,t))&&n>=n)for(r=n;++o<i;)null!=(n=e(t[o],o,t))&&r>n&&(r=n);return r}},function(t,e,n){\"use strict\";function r(t,e){return[t,e]}e.b=r,e.a=function(t,e){null==e&&(e=r);for(var n=0,i=t.length-1,o=t[0],a=new Array(i<0?0:i);n<i;)a[n]=e(o,o=t[++n]);return a}},function(t,e,n){\"use strict\";e.a=function(t,e,n){t=+t,e=+e,n=(i=arguments.length)<2?(e=t,t=0,1):i<3?1:+n;for(var r=-1,i=0|Math.max(0,Math.ceil((e-t)/n)),o=new Array(i);++r<i;)o[r]=t+r*n;return o}},function(t,e,n){\"use strict\";e.a=function(t){return Math.ceil(Math.log(t.length)/Math.LN2)+1}},function(t,e,n){\"use strict\";function r(t,e,n){var r=(e-t)/Math.max(0,n),i=Math.floor(Math.log(r)/Math.LN10),c=r/Math.pow(10,i);return i>=0?(c>=o?10:c>=a?5:c>=u?2:1)*Math.pow(10,i):-Math.pow(10,-i)/(c>=o?10:c>=a?5:c>=u?2:1)}function i(t,e,n){var r=Math.abs(e-t)/Math.max(0,n),i=Math.pow(10,Math.floor(Math.log(r)/Math.LN10)),c=r/i;return c>=o?i*=10:c>=a?i*=5:c>=u&&(i*=2),e<t?-i:i}e.b=r,e.c=i;var o=Math.sqrt(50),a=Math.sqrt(10),u=Math.sqrt(2);e.a=function(t,e,n){var i,o,a,u,c=-1;if(e=+e,t=+t,n=+n,t===e&&n>0)return[t];if((i=e<t)&&(o=t,t=e,e=o),0===(u=r(t,e,n))||!isFinite(u))return[];if(u>0)for(t=Math.ceil(t/u),e=Math.floor(e/u),a=new Array(o=Math.ceil(e-t+1));++c<o;)a[c]=(t+c)*u;else for(t=Math.floor(t*u),e=Math.ceil(e*u),a=new Array(o=Math.ceil(t-e+1));++c<o;)a[c]=(t-c)/u;return i&&a.reverse(),a}},function(t,e,n){\"use strict\";function r(t){return t.length}var i=n(105);e.a=function(t){if(!(u=t.length))return[];for(var e=-1,o=n.i(i.a)(t,r),a=new Array(o);++e<o;)for(var u,c=-1,s=a[e]=new Array(u);++c<u;)s[c]=t[c][e];return a}},function(t,e,n){\"use strict\";var r=n(28);e.a=function(t,e){var i,o,a=t.length,u=0,c=-1,s=0,l=0;if(null==e)for(;++c<a;)isNaN(i=n.i(r.a)(t[c]))||(o=i-s,s+=o/++u,l+=o*(i-s));else for(;++c<a;)isNaN(i=n.i(r.a)(e(t[c],c,t)))||(o=i-s,s+=o/++u,l+=o*(i-s));if(u>1)return l/(u-1)}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(209);n.d(e,\"axisTop\",function(){return r.a}),n.d(e,\"axisRight\",function(){return r.b}),n.d(e,\"axisBottom\",function(){return r.c}),n.d(e,\"axisLeft\",function(){return r.d})},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r}),n.d(e,\"a\",function(){return i});var r=Math.PI/180,i=180/Math.PI},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r});var r,i=n(63);e.a=function(t,e){var o=n.i(i.a)(t,e);if(!o)return t+\"\";var a=o[0],u=o[1],c=u-(r=3*Math.max(-8,Math.min(8,Math.floor(u/3))))+1,s=a.length;return c===s?a:c>s?a+new Array(c-s+1).join(\"0\"):c>0?a.slice(0,c)+\".\"+a.slice(c):\"0.\"+new Array(1-c).join(\"0\")+n.i(i.a)(t,Math.max(0,e+c-1))[0]}},function(t,e,n){\"use strict\";function r(t){return new i(t)}function i(t){if(!(e=a.exec(t)))throw new Error(\"invalid format: \"+t);var e,n=e[1]||\" \",r=e[2]||\">\",i=e[3]||\"-\",u=e[4]||\"\",c=!!e[5],s=e[6]&&+e[6],l=!!e[7],f=e[8]&&+e[8].slice(1),p=e[9]||\"\";\"n\"===p?(l=!0,p=\"g\"):o.a[p]||(p=\"\"),(c||\"0\"===n&&\"=\"===r)&&(c=!0,n=\"0\",r=\"=\"),this.fill=n,this.align=r,this.sign=i,this.symbol=u,this.zero=c,this.width=s,this.comma=l,this.precision=f,this.type=p}e.a=r;var o=n(116),a=/^(?:(.)?([<>=^]))?([+\\-\\( ])?([$#])?(0)?(\\d+)?(,)?(\\.\\d+)?([a-z%])?$/i;r.prototype=i.prototype,i.prototype.toString=function(){return this.fill+this.align+this.sign+this.symbol+(this.zero?\"0\":\"\")+(null==this.width?\"\":Math.max(1,0|this.width))+(this.comma?\",\":\"\")+(null==this.precision?\"\":\".\"+Math.max(0,0|this.precision))+this.type}},function(t,e,n){\"use strict\";var r=n(220),i=n(114),o=n(223);e.a={\"\":r.a,\"%\":function(t,e){return(100*t).toFixed(e)},b:function(t){return Math.round(t).toString(2)},c:function(t){return t+\"\"},d:function(t){return Math.round(t).toString(10)},e:function(t,e){return t.toExponential(e)},f:function(t,e){return t.toFixed(e)},g:function(t,e){return t.toPrecision(e)},o:function(t){return Math.round(t).toString(8)},p:function(t,e){return n.i(o.a)(100*t,e)},r:o.a,s:i.a,X:function(t){return Math.round(t).toString(16).toUpperCase()},x:function(t){return Math.round(t).toString(16)}}},function(t,e,n){\"use strict\";var r=n(42),i=n(221),o=n(222),a=n(115),u=n(116),c=n(114),s=n(224),l=[\"y\",\"z\",\"a\",\"f\",\"p\",\"n\",\"µ\",\"m\",\"\",\"k\",\"M\",\"G\",\"T\",\"P\",\"E\",\"Z\",\"Y\"];e.a=function(t){function e(t){function e(t){var e,n,a,u=x,s=w;if(\"c\"===b)s=C(t)+s,t=\"\";else{t=+t;var h=t<0;if(t=C(Math.abs(t),_),h&&0==+t&&(h=!1),u=(h?\"(\"===o?o:\"-\":\"-\"===o||\"(\"===o?\"\":o)+u,s=(\"s\"===b?l[8+c.b/3]:\"\")+s+(h&&\"(\"===o?\")\":\"\"),k)for(e=-1,n=t.length;++e<n;)if(48>(a=t.charCodeAt(e))||a>57){s=(46===a?d+t.slice(e+1):t.slice(e))+s,t=t.slice(0,e);break}}y&&!f&&(t=p(t,1/0));var g=u.length+t.length+s.length,E=g<m?new Array(m-g+1).join(r):\"\";switch(y&&f&&(t=p(E+t,E.length?m-s.length:1/0),E=\"\"),i){case\"<\":t=u+t+s+E;break;case\"=\":t=u+E+t+s;break;case\"^\":t=E.slice(0,g=E.length>>1)+u+t+s+E.slice(g);break;default:t=E+u+t+s}return v(t)}t=n.i(a.a)(t);var r=t.fill,i=t.align,o=t.sign,s=t.symbol,f=t.zero,m=t.width,y=t.comma,_=t.precision,b=t.type,x=\"$\"===s?h[0]:\"#\"===s&&/[boxX]/.test(b)?\"0\"+b.toLowerCase():\"\",w=\"$\"===s?h[1]:/[%p]/.test(b)?g:\"\",C=u.a[b],k=!b||/[defgprs%]/.test(b);return _=null==_?b?6:12:/[gprs]/.test(b)?Math.max(1,Math.min(21,_)):Math.max(0,Math.min(20,_)),e.toString=function(){return t+\"\"},e}function f(t,i){var o=e((t=n.i(a.a)(t),t.type=\"f\",t)),u=3*Math.max(-8,Math.min(8,Math.floor(n.i(r.a)(i)/3))),c=Math.pow(10,-u),s=l[8+u/3];return function(t){return o(c*t)+s}}var p=t.grouping&&t.thousands?n.i(i.a)(t.grouping,t.thousands):s.a,h=t.currency,d=t.decimal,v=t.numerals?n.i(o.a)(t.numerals):s.a,g=t.percent||\"%\";return{format:e,formatPrefix:f}}},function(t,e,n){\"use strict\";var r=n(65);e.a=function(t,e){var i,o=e?e.length:0,a=t?Math.min(o,t.length):0,u=new Array(a),c=new Array(o);for(i=0;i<a;++i)u[i]=n.i(r.a)(t[i],e[i]);for(;i<o;++i)c[i]=e[i];return function(t){for(i=0;i<a;++i)c[i]=u[i](t);return c}}},function(t,e,n){\"use strict\";var r=n(64);e.a=function(t){var e=t.length;return function(i){var o=Math.floor(((i%=1)<0?++i:i)*e),a=t[(o+e-1)%e],u=t[o%e],c=t[(o+1)%e],s=t[(o+2)%e];return n.i(r.b)((i-o/e)*e,a,u,c,s)}}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";e.a=function(t,e){var n=new Date;return t=+t,e-=t,function(r){return n.setTime(t+e*r),n}}},function(t,e,n){\"use strict\";var r=n(65);e.a=function(t,e){var i,o={},a={};null!==t&&\"object\"==typeof t||(t={}),null!==e&&\"object\"==typeof e||(e={});for(i in e)i in t?o[i]=n.i(r.a)(t[i],e[i]):a[i]=e[i];return function(t){for(i in o)a[i]=o[i](t);return a}}},function(t,e,n){\"use strict\";function r(t){return function(e){var r,o,a=e.length,u=new Array(a),c=new Array(a),s=new Array(a);for(r=0;r<a;++r)o=n.i(i.rgb)(e[r]),u[r]=o.r||0,c[r]=o.g||0,s[r]=o.b||0;return u=t(u),c=t(c),s=t(s),o.opacity=1,function(t){return o.r=u(t),o.g=c(t),o.b=s(t),o+\"\"}}}var i=n(10),o=n(64),a=n(119),u=n(31);e.a=function t(e){function r(t,e){var r=o((t=n.i(i.rgb)(t)).r,(e=n.i(i.rgb)(e)).r),a=o(t.g,e.g),c=o(t.b,e.b),s=n.i(u.a)(t.opacity,e.opacity);return function(e){return t.r=r(e),t.g=a(e),t.b=c(e),t.opacity=s(e),t+\"\"}}var o=n.i(u.c)(e);return r.gamma=t,r}(1);r(o.a),r(a.a)},function(t,e,n){\"use strict\";function r(t){return function(){return t}}function i(t){return function(e){return t(e)+\"\"}}var o=n(43),a=/[-+]?(?:\\d+\\.?\\d*|\\.?\\d+)(?:[eE][-+]?\\d+)?/g,u=new RegExp(a.source,\"g\");e.a=function(t,e){var c,s,l,f=a.lastIndex=u.lastIndex=0,p=-1,h=[],d=[];for(t+=\"\",e+=\"\";(c=a.exec(t))&&(s=u.exec(e));)(l=s.index)>f&&(l=e.slice(f,l),h[p]?h[p]+=l:h[++p]=l),(c=c[0])===(s=s[0])?h[p]?h[p]+=s:h[++p]=s:(h[++p]=null,d.push({i:p,x:n.i(o.a)(c,s)})),f=u.lastIndex;return f<e.length&&(l=e.slice(f),h[p]?h[p]+=l:h[++p]=l),h.length<2?d[0]?i(d[0].x):r(e):(e=d.length,function(t){for(var n,r=0;r<e;++r)h[(n=d[r]).i]=n.x(t);return h.join(\"\")})}},function(t,e,n){\"use strict\";e.a=function(t,e){t=t.slice();var n,r=0,i=t.length-1,o=t[r],a=t[i];return a<o&&(n=r,r=i,i=n,n=o,o=a,a=n),t[r]=e.floor(o),t[i]=e.ceil(a),t}},function(t,e,n){\"use strict\";e.a=function(t){return+t}},function(t,e,n){\"use strict\";function r(t){function e(e){var n=e+\"\",r=u.get(n);if(!r){if(s!==a)return s;u.set(n,r=c.push(e))}return t[(r-1)%t.length]}var u=n.i(i.a)(),c=[],s=a;return t=null==t?[]:o.b.call(t),e.domain=function(t){if(!arguments.length)return c.slice();c=[],u=n.i(i.a)();for(var r,o,a=-1,s=t.length;++a<s;)u.has(o=(r=t[a])+\"\")||u.set(o,c.push(r));return e},e.range=function(n){return arguments.length?(t=o.b.call(n),e):t.slice()},e.unknown=function(t){return arguments.length?(s=t,e):s},e.copy=function(){return r().domain(c).range(t).unknown(s)},e}n.d(e,\"b\",function(){return a}),e.a=r;var i=n(211),o=n(16),a={name:\"implicit\"}},function(t,e,n){\"use strict\";function r(t){return new Date(t)}function i(t){return t instanceof Date?+t:+new Date(+t)}function o(t,e,c,s,b,x,w,C,k){function E(n){return(w(n)<n?A:x(n)<n?P:b(n)<n?O:s(n)<n?I:e(n)<n?c(n)<n?D:R:t(n)<n?L:U)(n)}function M(e,r,i,o){if(null==e&&(e=10),\"number\"==typeof e){var u=Math.abs(i-r)/e,c=n.i(a.bisector)(function(t){return t[2]}).right(F,u);c===F.length?(o=n.i(a.tickStep)(r/_,i/_,e),e=t):c?(c=F[u/F[c-1][2]<F[c][2]/u?c-1:c],o=c[1],e=c[0]):(o=Math.max(n.i(a.tickStep)(r,i,e),1),e=C)}return null==o?e:e.every(o)}var T=n.i(f.a)(f.b,u.a),S=T.invert,N=T.domain,A=k(\".%L\"),P=k(\":%S\"),O=k(\"%I:%M\"),I=k(\"%I %p\"),D=k(\"%a %d\"),R=k(\"%b %d\"),L=k(\"%B\"),U=k(\"%Y\"),F=[[w,1,h],[w,5,5*h],[w,15,15*h],[w,30,30*h],[x,1,d],[x,5,5*d],[x,15,15*d],[x,30,30*d],[b,1,v],[b,3,3*v],[b,6,6*v],[b,12,12*v],[s,1,g],[s,2,2*g],[c,1,m],[e,1,y],[e,3,3*y],[t,1,_]];return T.invert=function(t){return new Date(S(t))},T.domain=function(t){return arguments.length?N(l.a.call(t,i)):N().map(r)},T.ticks=function(t,e){var n,r=N(),i=r[0],o=r[r.length-1],a=o<i;return a&&(n=i,i=o,o=n),n=M(t,i,o,e),n=n?n.range(i,o+1):[],a?n.reverse():n},T.tickFormat=function(t,e){return null==e?E:k(e)},T.nice=function(t,e){var r=N();return(t=M(t,r[0],r[r.length-1],e))?N(n.i(p.a)(r,t)):T},T.copy=function(){return n.i(f.c)(T,o(t,e,c,s,b,x,w,C,k))},T}e.b=o;var a=n(7),u=n(30),c=n(80),s=n(78),l=n(16),f=n(44),p=n(125),h=1e3,d=60*h,v=60*d,g=24*v,m=7*g,y=30*g,_=365*g;e.a=function(){return o(c.e,c.q,c.r,c.d,c.s,c.t,c.u,c.v,s.timeFormat).domain([new Date(2e3,0,1),new Date(2e3,0,2)])}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(257);n.d(e,\"create\",function(){return r.a});var i=n(45);n.d(e,\"creator\",function(){return i.a});var o=n(258);n.d(e,\"local\",function(){return o.a});var a=n(130);n.d(e,\"matcher\",function(){return a.a});var u=n(259);n.d(e,\"mouse\",function(){return u.a});var c=n(68);n.d(e,\"namespace\",function(){return c.a});var s=n(69);n.d(e,\"namespaces\",function(){return s.a});var l=n(46);n.d(e,\"clientPoint\",function(){return l.a});var f=n(131);n.d(e,\"select\",function(){return f.a});var p=n(260);n.d(e,\"selectAll\",function(){return p.a});var h=n(8);n.d(e,\"selection\",function(){return h.a});var d=n(71);n.d(e,\"selector\",function(){return d.a});var v=n(135);n.d(e,\"selectorAll\",function(){return v.a});var g=n(134);n.d(e,\"style\",function(){return g.a});var m=n(288);n.d(e,\"touch\",function(){return m.a});var y=n(289);n.d(e,\"touches\",function(){return y.a});var _=n(73);n.d(e,\"window\",function(){return _.a});var b=n(70);n.d(e,\"event\",function(){return b.a}),n.d(e,\"customEvent\",function(){return b.b})},function(t,e,n){\"use strict\";var r=function(t){return function(){return this.matches(t)}};if(\"undefined\"!=typeof document){var i=document.documentElement;if(!i.matches){var o=i.webkitMatchesSelector||i.msMatchesSelector||i.mozMatchesSelector||i.oMatchesSelector;r=function(t){return function(){return o.call(this,t)}}}}e.a=r},function(t,e,n){\"use strict\";var r=n(8);e.a=function(t){return\"string\"==typeof t?new r.b([[document.querySelector(t)]],[document.documentElement]):new r.b([[t]],r.c)}},function(t,e,n){\"use strict\";function r(t,e){this.ownerDocument=t.ownerDocument,this.namespaceURI=t.namespaceURI,this._next=null,this._parent=t,this.__data__=e}e.b=r;var i=n(133),o=n(8);e.a=function(){return new o.b(this._enter||this._groups.map(i.a),this._parents)},r.prototype={constructor:r,appendChild:function(t){return this._parent.insertBefore(t,this._next)},insertBefore:function(t,e){return this._parent.insertBefore(t,e)},querySelector:function(t){return this._parent.querySelector(t)},querySelectorAll:function(t){return this._parent.querySelectorAll(t)}}},function(t,e,n){\"use strict\";e.a=function(t){return new Array(t.length)}},function(t,e,n){\"use strict\";function r(t){return function(){this.style.removeProperty(t)}}function i(t,e,n){return function(){this.style.setProperty(t,e,n)}}function o(t,e,n){return function(){var r=e.apply(this,arguments);null==r?this.style.removeProperty(t):this.style.setProperty(t,r,n)}}function a(t,e){return t.style.getPropertyValue(e)||n.i(u.a)(t).getComputedStyle(t,null).getPropertyValue(e)}e.a=a;var u=n(73);e.b=function(t,e,n){return arguments.length>1?this.each((null==e?r:\"function\"==typeof e?o:i)(t,e,null==n?\"\":n)):a(this.node(),t)}},function(t,e,n){\"use strict\";function r(){return[]}e.a=function(t){return null==t?r:function(){return this.querySelectorAll(t)}}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(290);n.d(e,\"arc\",function(){return r.a});var i=n(137);n.d(e,\"area\",function(){return i.a});var o=n(75);n.d(e,\"line\",function(){return o.a});var a=n(311);n.d(e,\"pie\",function(){return a.a});var u=n(291);n.d(e,\"areaRadial\",function(){return u.a}),n.d(e,\"radialArea\",function(){return u.a});var c=n(142);n.d(e,\"lineRadial\",function(){return c.a}),n.d(e,\"radialLine\",function(){return c.a});var s=n(143);n.d(e,\"pointRadial\",function(){return s.a});var l=n(303);n.d(e,\"linkHorizontal\",function(){return l.a}),n.d(e,\"linkVertical\",function(){return l.b}),n.d(e,\"linkRadial\",function(){return l.c});var f=n(313);n.d(e,\"symbol\",function(){return f.a}),n.d(e,\"symbols\",function(){return f.b});var p=n(144);n.d(e,\"symbolCircle\",function(){return p.a});var h=n(145);n.d(e,\"symbolCross\",function(){return h.a});var d=n(146);n.d(e,\"symbolDiamond\",function(){return d.a});var v=n(147);n.d(e,\"symbolSquare\",function(){return v.a});var g=n(148);n.d(e,\"symbolStar\",function(){return g.a});var m=n(149);n.d(e,\"symbolTriangle\",function(){return m.a});var y=n(150);n.d(e,\"symbolWye\",function(){return y.a});var _=n(292);n.d(e,\"curveBasisClosed\",function(){return _.a});var b=n(293);n.d(e,\"curveBasisOpen\",function(){return b.a});var x=n(47);n.d(e,\"curveBasis\",function(){return x.a});var w=n(294);n.d(e,\"curveBundle\",function(){return w.a});var C=n(139);n.d(e,\"curveCardinalClosed\",function(){return C.a});var k=n(140);n.d(e,\"curveCardinalOpen\",function(){return k.a});var E=n(48);n.d(e,\"curveCardinal\",function(){return E.a});var M=n(295);n.d(e,\"curveCatmullRomClosed\",function(){return M.a});var T=n(296);n.d(e,\"curveCatmullRomOpen\",function(){return T.a});var S=n(74);n.d(e,\"curveCatmullRom\",function(){return S.a});var N=n(297);n.d(e,\"curveLinearClosed\",function(){return N.a});var A=n(49);n.d(e,\"curveLinear\",function(){return A.a});var P=n(298);n.d(e,\"curveMonotoneX\",function(){return P.a}),n.d(e,\"curveMonotoneY\",function(){return P.b});var O=n(299);n.d(e,\"curveNatural\",function(){return O.a});var I=n(300);n.d(e,\"curveStep\",function(){return I.a}),n.d(e,\"curveStepAfter\",function(){return I.b}),n.d(e,\"curveStepBefore\",function(){return I.c});var D=n(312);n.d(e,\"stack\",function(){return D.a});var R=n(305);n.d(e,\"stackOffsetExpand\",function(){return R.a});var L=n(304);n.d(e,\"stackOffsetDiverging\",function(){return L.a});var U=n(36);n.d(e,\"stackOffsetNone\",function(){return U.a});var F=n(306);n.d(e,\"stackOffsetSilhouette\",function(){return F.a});var j=n(307);n.d(e,\"stackOffsetWiggle\",function(){return j.a});var B=n(76);n.d(e,\"stackOrderAscending\",function(){return B.a});var V=n(308);n.d(e,\"stackOrderDescending\",function(){return V.a});var W=n(309);n.d(e,\"stackOrderInsideOut\",function(){return W.a});var z=n(37);n.d(e,\"stackOrderNone\",function(){return z.a});var H=n(310);n.d(e,\"stackOrderReverse\",function(){return H.a})},function(t,e,n){\"use strict\";var r=n(32),i=n(17),o=n(49),a=n(75),u=n(77);e.a=function(){function t(t){var e,i,o,a,u,g=t.length,m=!1,y=new Array(g),_=new Array(g);for(null==h&&(v=d(u=n.i(r.a)())),e=0;e<=g;++e){if(!(e<g&&p(a=t[e],e,t))===m)if(m=!m)i=e,v.areaStart(),v.lineStart();else{for(v.lineEnd(),v.lineStart(),o=e-1;o>=i;--o)v.point(y[o],_[o]);v.lineEnd(),v.areaEnd()}m&&(y[e]=+c(a,e,t),_[e]=+l(a,e,t),v.point(s?+s(a,e,t):y[e],f?+f(a,e,t):_[e]))}if(u)return v=null,u+\"\"||null}function e(){return n.i(a.a)().defined(p).curve(d).context(h)}var c=u.a,s=null,l=n.i(i.a)(0),f=u.b,p=n.i(i.a)(!0),h=null,d=o.a,v=null;return t.x=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(+e),s=null,t):c},t.x0=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(+e),t):c},t.x1=function(e){return arguments.length?(s=null==e?null:\"function\"==typeof e?e:n.i(i.a)(+e),t):s},t.y=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(i.a)(+e),f=null,t):l},t.y0=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(i.a)(+e),t):l},t.y1=function(e){return arguments.length?(f=null==e?null:\"function\"==typeof e?e:n.i(i.a)(+e),t):f},t.lineX0=t.lineY0=function(){return e().x(c).y(l)},t.lineY1=function(){return e().x(c).y(f)},t.lineX1=function(){return e().x(s).y(l)},t.defined=function(e){return arguments.length?(p=\"function\"==typeof e?e:n.i(i.a)(!!e),t):p},t.curve=function(e){return arguments.length?(d=e,null!=h&&(v=d(h)),t):d},t.context=function(e){return arguments.length?(null==e?h=v=null:v=d(h=e),t):h},t}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r});var r=Array.prototype.slice},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._k=(1-e)/6}e.b=r;var i=n(50),o=n(48);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._x5=this._y0=this._y1=this._y2=this._y3=this._y4=this._y5=NaN,this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x3,this._y3),this._context.closePath();break;case 2:this._context.lineTo(this._x3,this._y3),this._context.closePath();break;case 3:this.point(this._x3,this._y3),this.point(this._x4,this._y4),this.point(this._x5,this._y5)}},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._x3=t,this._y3=e;break;case 1:this._point=2,this._context.moveTo(this._x4=t,this._y4=e);break;case 2:this._point=3,this._x5=t,this._y5=e;break;default:n.i(o.c)(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new r(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._k=(1-e)/6}e.b=r;var i=n(48);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3,this._line?this._context.lineTo(this._x2,this._y2):this._context.moveTo(this._x2,this._y2);break;case 3:this._point=4;default:n.i(i.c)(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new r(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t){this._curve=t}function i(t){function e(e){return new r(t(e))}return e._curve=t,e}n.d(e,\"b\",function(){return a}),e.a=i;var o=n(49),a=i(o.a);r.prototype={areaStart:function(){this._curve.areaStart()},areaEnd:function(){this._curve.areaEnd()},lineStart:function(){this._curve.lineStart()},lineEnd:function(){this._curve.lineEnd()},point:function(t,e){this._curve.point(e*Math.sin(t),e*-Math.cos(t))}}},function(t,e,n){\"use strict\";function r(t){var e=t.curve;return t.angle=t.x,delete t.x,t.radius=t.y,delete t.y,t.curve=function(t){return arguments.length?e(n.i(i.a)(t)):e()._curve},t}e.b=r;var i=n(141),o=n(75);e.a=function(){return r(n.i(o.a)().curve(i.b))}},function(t,e,n){\"use strict\";e.a=function(t,e){return[(e=+e)*Math.cos(t-=Math.PI/2),e*Math.sin(t)]}},function(t,e,n){\"use strict\";var r=n(35);e.a={draw:function(t,e){var n=Math.sqrt(e/r.b);t.moveTo(n,0),t.arc(0,0,n,0,r.c)}}},function(t,e,n){\"use strict\";e.a={draw:function(t,e){var n=Math.sqrt(e/5)/2;t.moveTo(-3*n,-n),t.lineTo(-n,-n),t.lineTo(-n,-3*n),t.lineTo(n,-3*n),t.lineTo(n,-n),t.lineTo(3*n,-n),t.lineTo(3*n,n),t.lineTo(n,n),t.lineTo(n,3*n),t.lineTo(-n,3*n),t.lineTo(-n,n),t.lineTo(-3*n,n),t.closePath()}}},function(t,e,n){\"use strict\";var r=Math.sqrt(1/3),i=2*r;e.a={draw:function(t,e){var n=Math.sqrt(e/i),o=n*r;t.moveTo(0,-n),t.lineTo(o,0),t.lineTo(0,n),t.lineTo(-o,0),t.closePath()}}},function(t,e,n){\"use strict\";e.a={draw:function(t,e){var n=Math.sqrt(e),r=-n/2;t.rect(r,r,n,n)}}},function(t,e,n){\"use strict\";var r=n(35),i=Math.sin(r.b/10)/Math.sin(7*r.b/10),o=Math.sin(r.c/10)*i,a=-Math.cos(r.c/10)*i;e.a={draw:function(t,e){var n=Math.sqrt(.8908130915292852*e),i=o*n,u=a*n;t.moveTo(0,-n),t.lineTo(i,u);for(var c=1;c<5;++c){var s=r.c*c/5,l=Math.cos(s),f=Math.sin(s);t.lineTo(f*n,-l*n),t.lineTo(l*i-f*u,f*i+l*u)}t.closePath()}}},function(t,e,n){\"use strict\";var r=Math.sqrt(3);e.a={draw:function(t,e){var n=-Math.sqrt(e/(3*r));t.moveTo(0,2*n),t.lineTo(-r*n,-n),t.lineTo(r*n,-n),t.closePath()}}},function(t,e,n){\"use strict\";var r=-.5,i=Math.sqrt(3)/2,o=1/Math.sqrt(12),a=3*(o/2+1);e.a={draw:function(t,e){var n=Math.sqrt(e/a),u=n/2,c=n*o,s=u,l=n*o+n,f=-s,p=l;t.moveTo(u,c),t.lineTo(s,l),t.lineTo(f,p),t.lineTo(r*u-i*c,i*u+r*c),t.lineTo(r*s-i*l,i*s+r*l),t.lineTo(r*f-i*p,i*f+r*p),t.lineTo(r*u+i*c,r*c-i*u),t.lineTo(r*s+i*l,r*l-i*s),t.lineTo(r*f+i*p,r*p-i*f),t.closePath()}}},function(t,e,n){\"use strict\";function r(t){return t.toISOString()}n.d(e,\"b\",function(){return o});var i=n(79),o=\"%Y-%m-%dT%H:%M:%S.%LZ\",a=Date.prototype.toISOString?r:n.i(i.d)(o);e.a=a},function(t,e,n){\"use strict\";function r(t){if(0<=t.y&&t.y<100){var e=new Date(-1,t.m,t.d,t.H,t.M,t.S,t.L);return e.setFullYear(t.y),e}return new Date(t.y,t.m,t.d,t.H,t.M,t.S,t.L)}function i(t){if(0<=t.y&&t.y<100){var e=new Date(Date.UTC(-1,t.m,t.d,t.H,t.M,t.S,t.L));return e.setUTCFullYear(t.y),e}return new Date(Date.UTC(t.y,t.m,t.d,t.H,t.M,t.S,t.L))}function o(t){return{y:t,m:0,d:1,H:0,M:0,S:0,L:0}}function a(t){function e(t,e){return function(n){var r,i,o,a=[],u=-1,c=0,s=t.length;for(n instanceof Date||(n=new Date(+n));++u<s;)37===t.charCodeAt(u)&&(a.push(t.slice(c,u)),null!=(i=dt[r=t.charAt(++u)])?r=t.charAt(++u):i=\"e\"===r?\" \":\"0\",(o=e[r])&&(r=o(n,i)),a.push(r),c=u+1);return a.push(t.slice(c,u)),a.join(\"\")}}function a(t,e){return function(r){var a,c,s=o(1900),l=u(s,t,r+=\"\",0);if(l!=r.length)return null;if(\"Q\"in s)return new Date(s.Q);if(\"p\"in s&&(s.H=s.H%12+12*s.p),\"V\"in s){if(s.V<1||s.V>53)return null;\"w\"in s||(s.w=1),\"Z\"in s?(a=i(o(s.y)),c=a.getUTCDay(),a=c>4||0===c?ht.a.ceil(a):n.i(ht.a)(a),a=ht.b.offset(a,7*(s.V-1)),s.y=a.getUTCFullYear(),s.m=a.getUTCMonth(),s.d=a.getUTCDate()+(s.w+6)%7):(a=e(o(s.y)),c=a.getDay(),a=c>4||0===c?ht.c.ceil(a):n.i(ht.c)(a),a=ht.d.offset(a,7*(s.V-1)),s.y=a.getFullYear(),s.m=a.getMonth(),s.d=a.getDate()+(s.w+6)%7)}else(\"W\"in s||\"U\"in s)&&(\"w\"in s||(s.w=\"u\"in s?s.u%7:\"W\"in s?1:0),c=\"Z\"in s?i(o(s.y)).getUTCDay():e(o(s.y)).getDay(),s.m=0,s.d=\"W\"in s?(s.w+6)%7+7*s.W-(c+5)%7:s.w+7*s.U-(c+6)%7);return\"Z\"in s?(s.H+=s.Z/100|0,s.M+=s.Z%100,i(s)):e(s)}}function u(t,e,n,r){for(var i,o,a=0,u=e.length,c=n.length;a<u;){if(r>=c)return-1;if(37===(i=e.charCodeAt(a++))){if(i=e.charAt(a++),!(o=Zt[i in dt?e.charAt(a++):i])||(r=o(t,n,r))<0)return-1}else if(i!=n.charCodeAt(r++))return-1}return r}function c(t,e,n){var r=Bt.exec(e.slice(n));return r?(t.p=Vt[r[0].toLowerCase()],n+r[0].length):-1}function vt(t,e,n){var r=Ht.exec(e.slice(n));return r?(t.w=qt[r[0].toLowerCase()],n+r[0].length):-1}function gt(t,e,n){var r=Wt.exec(e.slice(n));return r?(t.w=zt[r[0].toLowerCase()],n+r[0].length):-1}function mt(t,e,n){var r=Gt.exec(e.slice(n));return r?(t.m=$t[r[0].toLowerCase()],n+r[0].length):-1}function yt(t,e,n){var r=Yt.exec(e.slice(n));return r?(t.m=Kt[r[0].toLowerCase()],n+r[0].length):-1}function _t(t,e,n){return u(t,Ot,e,n)}function bt(t,e,n){return u(t,It,e,n)}function xt(t,e,n){return u(t,Dt,e,n)}function wt(t){return Ut[t.getDay()]}function Ct(t){return Lt[t.getDay()]}function kt(t){return jt[t.getMonth()]}function Et(t){return Ft[t.getMonth()]}function Mt(t){return Rt[+(t.getHours()>=12)]}function Tt(t){return Ut[t.getUTCDay()]}function St(t){return Lt[t.getUTCDay()]}function Nt(t){return jt[t.getUTCMonth()]}function At(t){return Ft[t.getUTCMonth()]}function Pt(t){return Rt[+(t.getUTCHours()>=12)]}var Ot=t.dateTime,It=t.date,Dt=t.time,Rt=t.periods,Lt=t.days,Ut=t.shortDays,Ft=t.months,jt=t.shortMonths,Bt=s(Rt),Vt=l(Rt),Wt=s(Lt),zt=l(Lt),Ht=s(Ut),qt=l(Ut),Yt=s(Ft),Kt=l(Ft),Gt=s(jt),$t=l(jt),Xt={a:wt,A:Ct,b:kt,B:Et,c:null,d:A,e:A,f:R,H:P,I:O,j:I,L:D,m:L,M:U,p:Mt,Q:ft,s:pt,S:F,u:j,U:B,V:V,w:W,W:z,x:null,X:null,y:H,Y:q,Z:Y,\"%\":lt},Qt={a:Tt,A:St,b:Nt,B:At,c:null,d:K,e:K,f:Z,H:G,I:$,j:X,L:Q,m:J,M:tt,p:Pt,Q:ft,s:pt,S:et,u:nt,U:rt,V:it,w:ot,W:at,x:null,X:null,y:ut,Y:ct,Z:st,\"%\":lt},Zt={a:vt,A:gt,b:mt,B:yt,c:_t,d:b,e:b,f:M,H:w,I:w,j:x,L:E,m:_,M:C,p:c,Q:S,s:N,S:k,u:p,U:h,V:d,w:f,W:v,x:bt,X:xt,y:m,Y:g,Z:y,\"%\":T};return Xt.x=e(It,Xt),Xt.X=e(Dt,Xt),Xt.c=e(Ot,Xt),Qt.x=e(It,Qt),Qt.X=e(Dt,Qt),Qt.c=e(Ot,Qt),{format:function(t){var n=e(t+=\"\",Xt);return n.toString=function(){return t},n},parse:function(t){var e=a(t+=\"\",r);return e.toString=function(){return t},e},utcFormat:function(t){var n=e(t+=\"\",Qt);return n.toString=function(){return t},n},utcParse:function(t){var e=a(t,i);return e.toString=function(){return t},e}}}function u(t,e,n){var r=t<0?\"-\":\"\",i=(r?-t:t)+\"\",o=i.length;return r+(o<n?new Array(n-o+1).join(e)+i:i)}function c(t){return t.replace(mt,\"\\\\$&\")}function s(t){return new RegExp(\"^(?:\"+t.map(c).join(\"|\")+\")\",\"i\")}function l(t){for(var e={},n=-1,r=t.length;++n<r;)e[t[n].toLowerCase()]=n;return e}function f(t,e,n){var r=vt.exec(e.slice(n,n+1));return r?(t.w=+r[0],n+r[0].length):-1}function p(t,e,n){var r=vt.exec(e.slice(n,n+1));return r?(t.u=+r[0],n+r[0].length):-1}function h(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.U=+r[0],n+r[0].length):-1}function d(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.V=+r[0],n+r[0].length):-1}function v(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.W=+r[0],n+r[0].length):-1}function g(t,e,n){var r=vt.exec(e.slice(n,n+4));return r?(t.y=+r[0],n+r[0].length):-1}function m(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.y=+r[0]+(+r[0]>68?1900:2e3),n+r[0].length):-1}function y(t,e,n){var r=/^(Z)|([+-]\\d\\d)(?::?(\\d\\d))?/.exec(e.slice(n,n+6));return r?(t.Z=r[1]?0:-(r[2]+(r[3]||\"00\")),n+r[0].length):-1}function _(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.m=r[0]-1,n+r[0].length):-1}function b(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.d=+r[0],n+r[0].length):-1}function x(t,e,n){var r=vt.exec(e.slice(n,n+3));return r?(t.m=0,t.d=+r[0],n+r[0].length):-1}function w(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.H=+r[0],n+r[0].length):-1}function C(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.M=+r[0],n+r[0].length):-1}function k(t,e,n){var r=vt.exec(e.slice(n,n+2));return r?(t.S=+r[0],n+r[0].length):-1}function E(t,e,n){var r=vt.exec(e.slice(n,n+3));return r?(t.L=+r[0],n+r[0].length):-1}function M(t,e,n){var r=vt.exec(e.slice(n,n+6));return r?(t.L=Math.floor(r[0]/1e3),n+r[0].length):-1}function T(t,e,n){var r=gt.exec(e.slice(n,n+1));return r?n+r[0].length:-1}function S(t,e,n){var r=vt.exec(e.slice(n));return r?(t.Q=+r[0],n+r[0].length):-1}function N(t,e,n){var r=vt.exec(e.slice(n));return r?(t.Q=1e3*+r[0],n+r[0].length):-1}function A(t,e){return u(t.getDate(),e,2)}function P(t,e){return u(t.getHours(),e,2)}function O(t,e){return u(t.getHours()%12||12,e,2)}function I(t,e){return u(1+ht.d.count(n.i(ht.e)(t),t),e,3)}function D(t,e){return u(t.getMilliseconds(),e,3)}function R(t,e){return D(t,e)+\"000\"}function L(t,e){return u(t.getMonth()+1,e,2)}function U(t,e){return u(t.getMinutes(),e,2)}function F(t,e){return u(t.getSeconds(),e,2)}function j(t){var e=t.getDay();return 0===e?7:e}function B(t,e){return u(ht.f.count(n.i(ht.e)(t),t),e,2)}function V(t,e){var r=t.getDay();return t=r>=4||0===r?n.i(ht.g)(t):ht.g.ceil(t),u(ht.g.count(n.i(ht.e)(t),t)+(4===n.i(ht.e)(t).getDay()),e,2)}function W(t){return t.getDay()}function z(t,e){return u(ht.c.count(n.i(ht.e)(t),t),e,2)}function H(t,e){return u(t.getFullYear()%100,e,2)}function q(t,e){return u(t.getFullYear()%1e4,e,4)}function Y(t){var e=t.getTimezoneOffset();return(e>0?\"-\":(e*=-1,\"+\"))+u(e/60|0,\"0\",2)+u(e%60,\"0\",2)}function K(t,e){return u(t.getUTCDate(),e,2)}function G(t,e){return u(t.getUTCHours(),e,2)}function $(t,e){return u(t.getUTCHours()%12||12,e,2)}function X(t,e){return u(1+ht.b.count(n.i(ht.h)(t),t),e,3)}function Q(t,e){return u(t.getUTCMilliseconds(),e,3)}function Z(t,e){return Q(t,e)+\"000\"}function J(t,e){return u(t.getUTCMonth()+1,e,2)}function tt(t,e){return u(t.getUTCMinutes(),e,2)}function et(t,e){return u(t.getUTCSeconds(),e,2)}function nt(t){var e=t.getUTCDay();return 0===e?7:e}function rt(t,e){return u(ht.i.count(n.i(ht.h)(t),t),e,2)}function it(t,e){var r=t.getUTCDay();return t=r>=4||0===r?n.i(ht.j)(t):ht.j.ceil(t),u(ht.j.count(n.i(ht.h)(t),t)+(4===n.i(ht.h)(t).getUTCDay()),e,2)}function ot(t){return t.getUTCDay()}function at(t,e){return u(ht.a.count(n.i(ht.h)(t),t),e,2)}function ut(t,e){return u(t.getUTCFullYear()%100,e,2)}function ct(t,e){return u(t.getUTCFullYear()%1e4,e,4)}function st(){return\"+0000\"}function lt(){return\"%\"}function ft(t){return+t}function pt(t){return Math.floor(+t/1e3)}e.a=a;var ht=n(80),dt={\"-\":\"\",_:\" \",0:\"0\"},vt=/^\\s*\\d+/,gt=/^%/,mt=/[\\\\^$*+?|[\\]().{}]/g},function(t,e,n){\"use strict\";var r=n(11),i={listen:function(t,e,n){return t.addEventListener?(t.addEventListener(e,n,!1),{remove:function(){t.removeEventListener(e,n,!1)}}):t.attachEvent?(t.attachEvent(\"on\"+e,n),{remove:function(){t.detachEvent(\"on\"+e,n)}}):void 0},capture:function(t,e,n){return t.addEventListener?(t.addEventListener(e,n,!0),{remove:function(){t.removeEventListener(e,n,!0)}}):{remove:r}},registerDefault:function(){}};t.exports=i},function(t,e,n){\"use strict\";function r(t){try{t.focus()}catch(t){}}t.exports=r},function(t,e,n){\"use strict\";function r(t){if(void 0===(t=t||(\"undefined\"!=typeof document?document:void 0)))return null;try{return t.activeElement||t.body}catch(e){return t.body}}t.exports=r},function(t,e){function n(){throw new Error(\"setTimeout has not been defined\")}function r(){throw new Error(\"clearTimeout has not been defined\")}function i(t){if(l===setTimeout)return setTimeout(t,0);if((l===n||!l)&&setTimeout)return l=setTimeout,setTimeout(t,0);try{return l(t,0)}catch(e){try{return l.call(null,t,0)}catch(e){return l.call(this,t,0)}}}function o(t){if(f===clearTimeout)return clearTimeout(t);if((f===r||!f)&&clearTimeout)return f=clearTimeout,clearTimeout(t);try{return f(t)}catch(e){try{return f.call(null,t)}catch(e){return f.call(this,t)}}}function a(){v&&h&&(v=!1,h.length?d=h.concat(d):g=-1,d.length&&u())}function u(){if(!v){var t=i(a);v=!0;for(var e=d.length;e;){for(h=d,d=[];++g<e;)h&&h[g].run();g=-1,e=d.length}h=null,v=!1,o(t)}}function c(t,e){this.fun=t,this.array=e}function s(){}var l,f,p=t.exports={};!function(){try{l=\"function\"==typeof setTimeout?setTimeout:n}catch(t){l=n}try{f=\"function\"==typeof clearTimeout?clearTimeout:r}catch(t){f=r}}();var h,d=[],v=!1,g=-1;p.nextTick=function(t){var e=new Array(arguments.length-1);if(arguments.length>1)for(var n=1;n<arguments.length;n++)e[n-1]=arguments[n];d.push(new c(t,e)),1!==d.length||v||i(u)},c.prototype.run=function(){this.fun.apply(null,this.array)},p.title=\"browser\",p.browser=!0,p.env={},p.argv=[],p.version=\"\",p.versions={},p.on=s,p.addListener=s,p.once=s,p.off=s,p.removeListener=s,p.removeAllListeners=s,p.emit=s,p.prependListener=s,p.prependOnceListener=s,p.listeners=function(t){return[]},p.binding=function(t){throw new Error(\"process.binding is not supported\")},p.cwd=function(){return\"/\"},p.chdir=function(t){throw new Error(\"process.chdir is not supported\")},p.umask=function(){return 0}},function(t,e,n){\"use strict\";var r=n(343);t.exports=function(t){return r(t,!1)}},function(t,e,n){\"use strict\";function r(t,e){return t+e.charAt(0).toUpperCase()+e.substring(1)}var i={animationIterationCount:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},o=[\"Webkit\",\"ms\",\"Moz\",\"O\"];Object.keys(i).forEach(function(t){o.forEach(function(e){i[r(e,t)]=i[t]})});var a={background:{backgroundAttachment:!0,backgroundColor:!0,backgroundImage:!0,backgroundPositionX:!0,backgroundPositionY:!0,backgroundRepeat:!0},backgroundPosition:{backgroundPositionX:!0,backgroundPositionY:!0},border:{borderWidth:!0,borderStyle:!0,borderColor:!0},borderBottom:{borderBottomWidth:!0,borderBottomStyle:!0,borderBottomColor:!0},borderLeft:{borderLeftWidth:!0,borderLeftStyle:!0,borderLeftColor:!0},borderRight:{borderRightWidth:!0,borderRightStyle:!0,borderRightColor:!0},borderTop:{borderTopWidth:!0,borderTopStyle:!0,borderTopColor:!0},font:{fontStyle:!0,fontVariant:!0,fontWeight:!0,fontSize:!0,lineHeight:!0,fontFamily:!0},outline:{outlineWidth:!0,outlineStyle:!0,outlineColor:!0}},u={isUnitlessNumber:i,shorthandPropertyExpansions:a};t.exports=u},function(t,e,n){\"use strict\";function r(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}var i=n(1),o=n(18),a=(n(0),function(){function t(e){r(this,t),this._callbacks=null,this._contexts=null,this._arg=e}return t.prototype.enqueue=function(t,e){this._callbacks=this._callbacks||[],this._callbacks.push(t),this._contexts=this._contexts||[],this._contexts.push(e)},t.prototype.notifyAll=function(){var t=this._callbacks,e=this._contexts,n=this._arg;if(t&&e){t.length!==e.length&&i(\"24\"),this._callbacks=null,this._contexts=null;for(var r=0;r<t.length;r++)t[r].call(e[r],n);t.length=0,e.length=0}},t.prototype.checkpoint=function(){return this._callbacks?this._callbacks.length:0},t.prototype.rollback=function(t){this._callbacks&&this._contexts&&(this._callbacks.length=t,this._contexts.length=t)},t.prototype.reset=function(){this._callbacks=null,this._contexts=null},t.prototype.destructor=function(){this.reset()},t}());t.exports=o.addPoolingTo(a)},function(t,e,n){\"use strict\";function r(t){return!!s.hasOwnProperty(t)||!c.hasOwnProperty(t)&&(u.test(t)?(s[t]=!0,!0):(c[t]=!0,!1))}function i(t,e){return null==e||t.hasBooleanValue&&!e||t.hasNumericValue&&isNaN(e)||t.hasPositiveNumericValue&&e<1||t.hasOverloadedBooleanValue&&!1===e}var o=n(21),a=(n(4),n(9),n(407)),u=(n(2),new RegExp(\"^[\"+o.ATTRIBUTE_NAME_START_CHAR+\"][\"+o.ATTRIBUTE_NAME_CHAR+\"]*$\")),c={},s={},l={createMarkupForID:function(t){return o.ID_ATTRIBUTE_NAME+\"=\"+a(t)},setAttributeForID:function(t,e){t.setAttribute(o.ID_ATTRIBUTE_NAME,e)},createMarkupForRoot:function(){return o.ROOT_ATTRIBUTE_NAME+'=\"\"'},setAttributeForRoot:function(t){t.setAttribute(o.ROOT_ATTRIBUTE_NAME,\"\")},createMarkupForProperty:function(t,e){var n=o.properties.hasOwnProperty(t)?o.properties[t]:null;if(n){if(i(n,e))return\"\";var r=n.attributeName;return n.hasBooleanValue||n.hasOverloadedBooleanValue&&!0===e?r+'=\"\"':r+\"=\"+a(e)}return o.isCustomAttribute(t)?null==e?\"\":t+\"=\"+a(e):null},createMarkupForCustomAttribute:function(t,e){return r(t)&&null!=e?t+\"=\"+a(e):\"\"},setValueForProperty:function(t,e,n){var r=o.properties.hasOwnProperty(e)?o.properties[e]:null;if(r){var a=r.mutationMethod;if(a)a(t,n);else{if(i(r,n))return void this.deleteValueForProperty(t,e);if(r.mustUseProperty)t[r.propertyName]=n;else{var u=r.attributeName,c=r.attributeNamespace;c?t.setAttributeNS(c,u,\"\"+n):r.hasBooleanValue||r.hasOverloadedBooleanValue&&!0===n?t.setAttribute(u,\"\"):t.setAttribute(u,\"\"+n)}}}else if(o.isCustomAttribute(e))return void l.setValueForAttribute(t,e,n)},setValueForAttribute:function(t,e,n){if(r(e)){null==n?t.removeAttribute(e):t.setAttribute(e,\"\"+n)}},deleteValueForAttribute:function(t,e){t.removeAttribute(e)},deleteValueForProperty:function(t,e){var n=o.properties.hasOwnProperty(e)?o.properties[e]:null;if(n){var r=n.mutationMethod;if(r)r(t,void 0);else if(n.mustUseProperty){var i=n.propertyName;n.hasBooleanValue?t[i]=!1:t[i]=\"\"}else t.removeAttribute(n.attributeName)}else o.isCustomAttribute(e)&&t.removeAttribute(e)}};t.exports=l},function(t,e,n){\"use strict\";var r={hasCachedChildNodes:1};t.exports=r},function(t,e,n){\"use strict\";function r(){if(this._rootNodeID&&this._wrapperState.pendingUpdate){this._wrapperState.pendingUpdate=!1;var t=this._currentElement.props,e=u.getValue(t);null!=e&&i(this,Boolean(t.multiple),e)}}function i(t,e,n){var r,i,o=c.getNodeFromInstance(t).options;if(e){for(r={},i=0;i<n.length;i++)r[\"\"+n[i]]=!0;for(i=0;i<o.length;i++){var a=r.hasOwnProperty(o[i].value);o[i].selected!==a&&(o[i].selected=a)}}else{for(r=\"\"+n,i=0;i<o.length;i++)if(o[i].value===r)return void(o[i].selected=!0);o.length&&(o[0].selected=!0)}}function o(t){var e=this._currentElement.props,n=u.executeOnChange(e,t);return this._rootNodeID&&(this._wrapperState.pendingUpdate=!0),s.asap(r,this),n}var a=n(3),u=n(86),c=n(4),s=n(12),l=(n(2),!1),f={getHostProps:function(t,e){return a({},e,{onChange:t._wrapperState.onChange,value:void 0})},mountWrapper:function(t,e){var n=u.getValue(e);t._wrapperState={pendingUpdate:!1,initialValue:null!=n?n:e.defaultValue,listeners:null,onChange:o.bind(t),wasMultiple:Boolean(e.multiple)},void 0===e.value||void 0===e.defaultValue||l||(l=!0)},getSelectValueContext:function(t){return t._wrapperState.initialValue},postUpdateWrapper:function(t){var e=t._currentElement.props;t._wrapperState.initialValue=void 0;var n=t._wrapperState.wasMultiple;t._wrapperState.wasMultiple=Boolean(e.multiple);var r=u.getValue(e);null!=r?(t._wrapperState.pendingUpdate=!1,i(t,Boolean(e.multiple),r)):n!==Boolean(e.multiple)&&(null!=e.defaultValue?i(t,Boolean(e.multiple),e.defaultValue):i(t,Boolean(e.multiple),e.multiple?[]:\"\"))}};t.exports=f},function(t,e,n){\"use strict\";var r,i={injectEmptyComponentFactory:function(t){r=t}},o={create:function(t){return r(t)}};o.injection=i,t.exports=o},function(t,e,n){\"use strict\";var r={logTopLevelRenders:!1};t.exports=r},function(t,e,n){\"use strict\";function r(t){return u||a(\"111\",t.type),new u(t)}function i(t){return new c(t)}function o(t){return t instanceof c}var a=n(1),u=(n(0),null),c=null,s={injectGenericComponentClass:function(t){u=t},injectTextComponentClass:function(t){c=t}},l={createInternalComponent:r,createInstanceForText:i,isTextComponent:o,injection:s};t.exports=l},function(t,e,n){\"use strict\";function r(t){return o(document.documentElement,t)}var i=n(367),o=n(331),a=n(154),u=n(155),c={hasSelectionCapabilities:function(t){var e=t&&t.nodeName&&t.nodeName.toLowerCase();return e&&(\"input\"===e&&\"text\"===t.type||\"textarea\"===e||\"true\"===t.contentEditable)},getSelectionInformation:function(){var t=u();return{focusedElem:t,selectionRange:c.hasSelectionCapabilities(t)?c.getSelection(t):null}},restoreSelection:function(t){var e=u(),n=t.focusedElem,i=t.selectionRange;e!==n&&r(n)&&(c.hasSelectionCapabilities(n)&&c.setSelection(n,i),a(n))},getSelection:function(t){var e;if(\"selectionStart\"in t)e={start:t.selectionStart,end:t.selectionEnd};else if(document.selection&&t.nodeName&&\"input\"===t.nodeName.toLowerCase()){var n=document.selection.createRange();n.parentElement()===t&&(e={start:-n.moveStart(\"character\",-t.value.length),end:-n.moveEnd(\"character\",-t.value.length)})}else e=i.getOffsets(t);return e||{start:0,end:0}},setSelection:function(t,e){var n=e.start,r=e.end;if(void 0===r&&(r=n),\"selectionStart\"in t)t.selectionStart=n,t.selectionEnd=Math.min(r,t.value.length);else if(document.selection&&t.nodeName&&\"input\"===t.nodeName.toLowerCase()){var o=t.createTextRange();o.collapse(!0),o.moveStart(\"character\",n),o.moveEnd(\"character\",r-n),o.select()}else i.setOffsets(t,e)}};t.exports=c},function(t,e,n){\"use strict\";function r(t,e){for(var n=Math.min(t.length,e.length),r=0;r<n;r++)if(t.charAt(r)!==e.charAt(r))return r;return t.length===e.length?-1:n}function i(t){return t?t.nodeType===D?t.documentElement:t.firstChild:null}function o(t){return t.getAttribute&&t.getAttribute(P)||\"\"}function a(t,e,n,r,i){var o;if(x.logTopLevelRenders){var a=t._currentElement.props.child,u=a.type;o=\"React mount: \"+(\"string\"==typeof u?u:u.displayName||u.name),console.time(o)}var c=k.mountComponent(t,n,null,_(t,e),i,0);o&&console.timeEnd(o),t._renderedComponent._topLevelWrapper=t,j._mountImageIntoNode(c,e,t,r,n)}function u(t,e,n,r){var i=M.ReactReconcileTransaction.getPooled(!n&&b.useCreateElement);i.perform(a,null,t,e,i,n,r),M.ReactReconcileTransaction.release(i)}function c(t,e,n){for(k.unmountComponent(t,n),e.nodeType===D&&(e=e.documentElement);e.lastChild;)e.removeChild(e.lastChild)}function s(t){var e=i(t);if(e){var n=y.getInstanceFromNode(e);return!(!n||!n._hostParent)}}function l(t){return!(!t||t.nodeType!==I&&t.nodeType!==D&&t.nodeType!==R)}function f(t){var e=i(t),n=e&&y.getInstanceFromNode(e);return n&&!n._hostParent?n:null}function p(t){var e=f(t);return e?e._hostContainerInfo._topLevelWrapper:null}var h=n(1),d=n(20),v=n(21),g=n(26),m=n(53),y=(n(15),n(4)),_=n(361),b=n(363),x=n(164),w=n(39),C=(n(9),n(377)),k=n(24),E=n(89),M=n(12),T=n(51),S=n(174),N=(n(0),n(57)),A=n(96),P=(n(2),v.ID_ATTRIBUTE_NAME),O=v.ROOT_ATTRIBUTE_NAME,I=1,D=9,R=11,L={},U=1,F=function(){this.rootID=U++};F.prototype.isReactComponent={},F.prototype.render=function(){return this.props.child},F.isReactTopLevelWrapper=!0;var j={TopLevelWrapper:F,_instancesByReactRootID:L,scrollMonitor:function(t,e){e()},_updateRootComponent:function(t,e,n,r,i){return j.scrollMonitor(r,function(){E.enqueueElementInternal(t,e,n),i&&E.enqueueCallbackInternal(t,i)}),t},_renderNewRootComponent:function(t,e,n,r){l(e)||h(\"37\"),m.ensureScrollValueMonitoring();var i=S(t,!1);M.batchedUpdates(u,i,e,n,r);var o=i._instance.rootID;return L[o]=i,i},renderSubtreeIntoContainer:function(t,e,n,r){return null!=t&&w.has(t)||h(\"38\"),j._renderSubtreeIntoContainer(t,e,n,r)},_renderSubtreeIntoContainer:function(t,e,n,r){E.validateCallback(r,\"ReactDOM.render\"),g.isValidElement(e)||h(\"39\",\"string\"==typeof e?\" Instead of passing a string like 'div', pass React.createElement('div') or <div />.\":\"function\"==typeof e?\" Instead of passing a class like Foo, pass React.createElement(Foo) or <Foo />.\":null!=e&&void 0!==e.props?\" This may be caused by unintentionally loading two independent copies of React.\":\"\");var a,u=g.createElement(F,{child:e});if(t){var c=w.get(t);a=c._processChildContext(c._context)}else a=T;var l=p(n);if(l){var f=l._currentElement,d=f.props.child;if(A(d,e)){var v=l._renderedComponent.getPublicInstance(),m=r&&function(){r.call(v)};return j._updateRootComponent(l,u,a,n,m),v}j.unmountComponentAtNode(n)}var y=i(n),_=y&&!!o(y),b=s(n),x=_&&!l&&!b,C=j._renderNewRootComponent(u,n,x,a)._renderedComponent.getPublicInstance();return r&&r.call(C),C},render:function(t,e,n){return j._renderSubtreeIntoContainer(null,t,e,n)},unmountComponentAtNode:function(t){l(t)||h(\"40\");var e=p(t);if(!e){s(t),1===t.nodeType&&t.hasAttribute(O);return!1}return delete L[e._instance.rootID],M.batchedUpdates(c,e,t,!1),!0},_mountImageIntoNode:function(t,e,n,o,a){if(l(e)||h(\"41\"),o){var u=i(e);if(C.canReuseMarkup(t,u))return void y.precacheNode(n,u);var c=u.getAttribute(C.CHECKSUM_ATTR_NAME);u.removeAttribute(C.CHECKSUM_ATTR_NAME);var s=u.outerHTML;u.setAttribute(C.CHECKSUM_ATTR_NAME,c);var f=t,p=r(f,s),v=\" (client) \"+f.substring(p-20,p+20)+\"\\n (server) \"+s.substring(p-20,p+20);e.nodeType===D&&h(\"42\",v)}if(e.nodeType===D&&h(\"43\"),a.useCreateElement){for(;e.lastChild;)e.removeChild(e.lastChild);d.insertTreeBefore(e,t,null)}else N(e,t),y.precacheNode(n,e.firstChild)}};t.exports=j},function(t,e,n){\"use strict\";var r=n(1),i=n(26),o=(n(0),{HOST:0,COMPOSITE:1,EMPTY:2,getType:function(t){return null===t||!1===t?o.EMPTY:i.isValidElement(t)?\"function\"==typeof t.type?o.COMPOSITE:o.HOST:void r(\"26\",t)}});t.exports=o},function(t,e,n){\"use strict\";function r(t,e){return null==e&&i(\"30\"),null==t?e:Array.isArray(t)?Array.isArray(e)?(t.push.apply(t,e),t):(t.push(e),t):Array.isArray(e)?[t].concat(e):[t,e]}var i=n(1);n(0);t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){Array.isArray(t)?t.forEach(e,n):t&&e.call(n,t)}t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e;(e=t._renderedNodeType)===i.COMPOSITE;)t=t._renderedComponent;return e===i.HOST?t._renderedComponent:e===i.EMPTY?null:void 0}var i=n(168);t.exports=r},function(t,e,n){\"use strict\";function r(){return!o&&i.canUseDOM&&(o=\"textContent\"in document.documentElement?\"textContent\":\"innerText\"),o}var i=n(6),o=null;t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t.type,n=t.nodeName;return n&&\"input\"===n.toLowerCase()&&(\"checkbox\"===e||\"radio\"===e)}function i(t){return t._wrapperState.valueTracker}function o(t,e){t._wrapperState.valueTracker=e}function a(t){t._wrapperState.valueTracker=null}function u(t){var e;return t&&(e=r(t)?\"\"+t.checked:t.value),e}var c=n(4),s={_getTrackerFromNode:function(t){return i(c.getInstanceFromNode(t))},track:function(t){if(!i(t)){var e=c.getNodeFromInstance(t),n=r(e)?\"checked\":\"value\",u=Object.getOwnPropertyDescriptor(e.constructor.prototype,n),s=\"\"+e[n];e.hasOwnProperty(n)||\"function\"!=typeof u.get||\"function\"!=typeof u.set||(Object.defineProperty(e,n,{enumerable:u.enumerable,configurable:!0,get:function(){return u.get.call(this)},set:function(t){s=\"\"+t,u.set.call(this,t)}}),o(t,{getValue:function(){return s},setValue:function(t){s=\"\"+t},stopTracking:function(){a(t),delete e[n]}}))}},updateValueIfChanged:function(t){if(!t)return!1;var e=i(t);if(!e)return s.track(t),!0;var n=e.getValue(),r=u(c.getNodeFromInstance(t));return r!==n&&(e.setValue(r),!0)},stopTracking:function(t){var e=i(t);e&&e.stopTracking()}};t.exports=s},function(t,e,n){\"use strict\";function r(t){if(t){var e=t.getName();if(e)return\" Check the render method of `\"+e+\"`.\"}return\"\"}function i(t){return\"function\"==typeof t&&void 0!==t.prototype&&\"function\"==typeof t.prototype.mountComponent&&\"function\"==typeof t.prototype.receiveComponent}function o(t,e){var n;if(null===t||!1===t)n=s.create(o);else if(\"object\"==typeof t){var u=t,c=u.type;if(\"function\"!=typeof c&&\"string\"!=typeof c){var p=\"\";p+=r(u._owner),a(\"130\",null==c?c:typeof c,p)}\"string\"==typeof u.type?n=l.createInternalComponent(u):i(u.type)?(n=new u.type(u),n.getHostNode||(n.getHostNode=n.getNativeNode)):n=new f(u)}else\"string\"==typeof t||\"number\"==typeof t?n=l.createInstanceForText(t):a(\"131\",typeof t);return n._mountIndex=0,n._mountImage=null,n}var a=n(1),u=n(3),c=n(358),s=n(163),l=n(165),f=(n(420),n(0),n(2),function(t){this.construct(t)});u(f.prototype,c,{_instantiateReactComponent:o}),t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=t&&t.nodeName&&t.nodeName.toLowerCase();return\"input\"===e?!!i[t.type]:\"textarea\"===e}var i={color:!0,date:!0,datetime:!0,\"datetime-local\":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};t.exports=r},function(t,e,n){\"use strict\";var r=n(6),i=n(56),o=n(57),a=function(t,e){if(e){var n=t.firstChild;if(n&&n===t.lastChild&&3===n.nodeType)return void(n.nodeValue=e)}t.textContent=e};r.canUseDOM&&(\"textContent\"in document.documentElement||(a=function(t,e){if(3===t.nodeType)return void(t.nodeValue=e);o(t,i(e))})),t.exports=a},function(t,e,n){\"use strict\";function r(t,e){return t&&\"object\"==typeof t&&null!=t.key?s.escape(t.key):e.toString(36)}function i(t,e,n,o){var p=typeof t;if(\"undefined\"!==p&&\"boolean\"!==p||(t=null),null===t||\"string\"===p||\"number\"===p||\"object\"===p&&t.$$typeof===u)return n(o,t,\"\"===e?l+r(t,0):e),1;var h,d,v=0,g=\"\"===e?l:e+f;if(Array.isArray(t))for(var m=0;m<t.length;m++)h=t[m],d=g+r(h,m),v+=i(h,d,n,o);else{var y=c(t);if(y){var _,b=y.call(t);if(y!==t.entries)for(var x=0;!(_=b.next()).done;)h=_.value,d=g+r(h,x++),v+=i(h,d,n,o);else for(;!(_=b.next()).done;){var w=_.value;w&&(h=w[1],d=g+s.escape(w[0])+f+r(h,0),v+=i(h,d,n,o))}}else if(\"object\"===p){var C=\"\",k=String(t);a(\"31\",\"[object Object]\"===k?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":k,C)}}return v}function o(t,e,n){return null==t?0:i(t,\"\",e,n)}var a=n(1),u=(n(15),n(373)),c=n(404),s=(n(0),n(85)),l=(n(2),\".\"),f=\":\";t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n){this.props=t,this.context=e,this.refs=s,this.updater=n||c}function i(t,e,n){this.props=t,this.context=e,this.refs=s,this.updater=n||c}function o(){}var a=n(40),u=n(3),c=n(181),s=(n(182),n(51));n(0),n(421);r.prototype.isReactComponent={},r.prototype.setState=function(t,e){\"object\"!=typeof t&&\"function\"!=typeof t&&null!=t&&a(\"85\"),this.updater.enqueueSetState(this,t),e&&this.updater.enqueueCallback(this,e,\"setState\")},r.prototype.forceUpdate=function(t){this.updater.enqueueForceUpdate(this),t&&this.updater.enqueueCallback(this,t,\"forceUpdate\")};o.prototype=r.prototype,i.prototype=new o,i.prototype.constructor=i,u(i.prototype,r.prototype),i.prototype.isPureReactComponent=!0,t.exports={Component:r,PureComponent:i}},function(t,e,n){\"use strict\";function r(t){var e=Function.prototype.toString,n=Object.prototype.hasOwnProperty,r=RegExp(\"^\"+e.call(n).replace(/[\\\\^$.*+?()[\\]{}|]/g,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\");try{var i=e.call(t);return r.test(i)}catch(t){return!1}}function i(t){var e=s(t);if(e){var n=e.childIDs;l(t),n.forEach(i)}}function o(t,e,n){return\"\\n    in \"+(t||\"Unknown\")+(e?\" (at \"+e.fileName.replace(/^.*[\\\\\\/]/,\"\")+\":\"+e.lineNumber+\")\":n?\" (created by \"+n+\")\":\"\")}function a(t){return null==t?\"#empty\":\"string\"==typeof t||\"number\"==typeof t?\"#text\":\"string\"==typeof t.type?t.type:t.type.displayName||t.type.name||\"Unknown\"}function u(t){var e,n=E.getDisplayName(t),r=E.getElement(t),i=E.getOwnerID(t);return i&&(e=E.getDisplayName(i)),o(n,r&&r._source,e)}var c,s,l,f,p,h,d,v=n(40),g=n(15),m=(n(0),n(2),\"function\"==typeof Array.from&&\"function\"==typeof Map&&r(Map)&&null!=Map.prototype&&\"function\"==typeof Map.prototype.keys&&r(Map.prototype.keys)&&\"function\"==typeof Set&&r(Set)&&null!=Set.prototype&&\"function\"==typeof Set.prototype.keys&&r(Set.prototype.keys));if(m){var y=new Map,_=new Set;c=function(t,e){y.set(t,e)},s=function(t){return y.get(t)},l=function(t){y.delete(t)},f=function(){return Array.from(y.keys())},p=function(t){_.add(t)},h=function(t){_.delete(t)},d=function(){return Array.from(_.keys())}}else{var b={},x={},w=function(t){return\".\"+t},C=function(t){return parseInt(t.substr(1),10)};c=function(t,e){var n=w(t);b[n]=e},s=function(t){var e=w(t);return b[e]},l=function(t){var e=w(t);delete b[e]},f=function(){return Object.keys(b).map(C)},p=function(t){var e=w(t);x[e]=!0},h=function(t){var e=w(t);delete x[e]},d=function(){return Object.keys(x).map(C)}}var k=[],E={onSetChildren:function(t,e){var n=s(t);n||v(\"144\"),n.childIDs=e;for(var r=0;r<e.length;r++){var i=e[r],o=s(i);o||v(\"140\"),null==o.childIDs&&\"object\"==typeof o.element&&null!=o.element&&v(\"141\"),o.isMounted||v(\"71\"),null==o.parentID&&(o.parentID=t),o.parentID!==t&&v(\"142\",i,o.parentID,t)}},onBeforeMountComponent:function(t,e,n){c(t,{element:e,parentID:n,text:null,childIDs:[],isMounted:!1,updateCount:0})},onBeforeUpdateComponent:function(t,e){var n=s(t);n&&n.isMounted&&(n.element=e)},onMountComponent:function(t){var e=s(t);e||v(\"144\"),e.isMounted=!0,0===e.parentID&&p(t)},onUpdateComponent:function(t){var e=s(t);e&&e.isMounted&&e.updateCount++},onUnmountComponent:function(t){var e=s(t);if(e){e.isMounted=!1;0===e.parentID&&h(t)}k.push(t)},purgeUnmountedComponents:function(){if(!E._preventPurging){for(var t=0;t<k.length;t++){i(k[t])}k.length=0}},isMounted:function(t){var e=s(t);return!!e&&e.isMounted},getCurrentStackAddendum:function(t){var e=\"\";if(t){var n=a(t),r=t._owner;e+=o(n,t._source,r&&r.getName())}var i=g.current,u=i&&i._debugID;return e+=E.getStackAddendumByID(u)},getStackAddendumByID:function(t){for(var e=\"\";t;)e+=u(t),t=E.getParentID(t);return e},getChildIDs:function(t){var e=s(t);return e?e.childIDs:[]},getDisplayName:function(t){var e=E.getElement(t);return e?a(e):null},getElement:function(t){var e=s(t);return e?e.element:null},getOwnerID:function(t){var e=E.getElement(t);return e&&e._owner?e._owner._debugID:null},getParentID:function(t){var e=s(t);return e?e.parentID:null},getSource:function(t){var e=s(t),n=e?e.element:null;return null!=n?n._source:null},getText:function(t){var e=E.getElement(t);return\"string\"==typeof e?e:\"number\"==typeof e?\"\"+e:null},getUpdateCount:function(t){var e=s(t);return e?e.updateCount:0},getRootIDs:d,getRegisteredIDs:f,pushNonStandardWarningStack:function(t,e){if(\"function\"==typeof console.reactStack){var n=[],r=g.current,i=r&&r._debugID;try{for(t&&n.push({name:i?E.getDisplayName(i):null,fileName:e?e.fileName:null,lineNumber:e?e.lineNumber:null});i;){var o=E.getElement(i),a=E.getParentID(i),u=E.getOwnerID(i),c=u?E.getDisplayName(u):null,s=o&&o._source;n.push({name:c,fileName:s?s.fileName:null,lineNumber:s?s.lineNumber:null}),i=a}}catch(t){}console.reactStack(n)}},popNonStandardWarningStack:function(){\"function\"==typeof console.reactStackEnd&&console.reactStackEnd()}};t.exports=E},function(t,e,n){\"use strict\";var r=\"function\"==typeof Symbol&&Symbol.for&&Symbol.for(\"react.element\")||60103;t.exports=r},function(t,e,n){\"use strict\";var r=(n(2),{isMounted:function(t){return!1},enqueueCallback:function(t,e){},enqueueForceUpdate:function(t){},enqueueReplaceState:function(t,e){},enqueueSetState:function(t,e){}});t.exports=r},function(t,e,n){\"use strict\";var r=!1;t.exports=r},,function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(t){return typeof t}:function(t){return t&&\"function\"==typeof Symbol&&t.constructor===Symbol&&t!==Symbol.prototype?\"symbol\":typeof t},c=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),s=n(41),l=r(s),f=n(129),p=n(66),h=(n(7),n(29)),d=n(78),v=n(112),g=n(136),m=n(10),y=n(38),_=n(58),b=r(_),x=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return window.lastAdditiveForceArrayVisualizer=t,t.topOffset=28,t.leftOffset=80,t.height=350,t.effectFormat=(0,h.format)(\".2\"),t.redraw=(0,y.debounce)(function(){return t.draw()},200),t}return a(e,t),c(e,[{key:\"componentDidMount\",value:function(){var t=this;this.mainGroup=this.svg.append(\"g\"),this.onTopGroup=this.svg.append(\"g\"),this.xaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-xaxis\"),this.yaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-yaxis\"),this.hoverGroup1=this.svg.append(\"g\"),this.hoverGroup2=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.hoverLine=this.svg.append(\"line\"),this.hoverxOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hoverx=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.hoverxTitle=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"opacity\",.6).attr(\"font-size\",\"12px\"),this.hoveryOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hovery=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.xlabel=this.wrapper.select(\".additive-force-array-xlabel\"),this.ylabel=this.wrapper.select(\".additive-force-array-ylabel\");var e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in b.default.colors?e=b.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=b.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),this.colors=e.map(function(t){return(0,m.hsl)(t)}),this.brighterColors=[1.45,1.6].map(function(e,n){return t.colors[n].brighter(e)});var n=(0,h.format)(\",.4\");if(null!=this.props.ordering_keys&&null!=this.props.ordering_keys_time_format){var r=function(t){return\"object\"==(void 0===t?\"undefined\":u(t))?this.formatTime(t):n(t)};this.parseTime=(0,d.timeParse)(this.props.ordering_keys_time_format),this.formatTime=(0,d.timeFormat)(this.props.ordering_keys_time_format),this.xtickFormat=r}else this.parseTime=null,this.formatTime=null,this.xtickFormat=n;this.xscale=(0,p.scaleLinear)(),this.xaxis=(0,v.axisBottom)().scale(this.xscale).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.xtickFormat(e)}).tickPadding(-18),this.ytickFormat=n,this.yscale=(0,p.scaleLinear)(),this.yaxis=(0,v.axisLeft)().scale(this.yscale).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.ytickFormat(t.invLinkFunction(e))}).tickPadding(2),this.xlabel.node().onchange=function(){return t.internalDraw()},this.ylabel.node().onchange=function(){return t.internalDraw()},this.svg.on(\"mousemove\",function(e){return t.mouseMoved(e)}),this.svg.on(\"click\",function(e){return alert(\"This original index of the sample you clicked is \"+t.nearestExpIndex)}),this.svg.on(\"mouseout\",function(e){return t.mouseOut(e)}),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"mouseOut\",value:function(){this.hoverLine.attr(\"display\",\"none\"),this.hoverx.attr(\"display\",\"none\"),this.hoverxOutline.attr(\"display\",\"none\"),this.hoverxTitle.attr(\"display\",\"none\"),this.hovery.attr(\"display\",\"none\"),this.hoveryOutline.attr(\"display\",\"none\"),this.hoverGroup1.attr(\"display\",\"none\"),this.hoverGroup2.attr(\"display\",\"none\")}},{key:\"mouseMoved\",value:function(t){var e=this,n=void 0,r=void 0;this.hoverLine.attr(\"display\",\"\"),this.hoverx.attr(\"display\",\"\"),this.hoverxOutline.attr(\"display\",\"\"),this.hoverxTitle.attr(\"display\",\"\"),this.hovery.attr(\"display\",\"\"),this.hoveryOutline.attr(\"display\",\"\"),this.hoverGroup1.attr(\"display\",\"\"),this.hoverGroup2.attr(\"display\",\"\");var i=(0,f.mouse)(this.svg.node())[0];if(this.props.explanations){for(n=0;n<this.props.explanations.length;++n)(!r||Math.abs(r.xmapScaled-i)>Math.abs(this.props.explanations[n].xmapScaled-i))&&(r=this.props.explanations[n],this.nearestExpIndex=n);this.hoverLine.attr(\"x1\",r.xmapScaled).attr(\"x2\",r.xmapScaled).attr(\"y1\",0+this.topOffset).attr(\"y2\",this.height),this.hoverx.attr(\"x\",r.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(r.xmap)),this.hoverxOutline.attr(\"x\",r.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(r.xmap)),this.hoverxTitle.attr(\"x\",r.xmapScaled).attr(\"y\",this.topOffset-18).text(r.count>1?r.count+\" averaged samples\":\"\"),this.hovery.attr(\"x\",this.leftOffset-6).attr(\"y\",r.joinPointy).text(this.ytickFormat(this.invLinkFunction(r.joinPoint))),this.hoveryOutline.attr(\"x\",this.leftOffset-6).attr(\"y\",r.joinPointy).text(this.ytickFormat(this.invLinkFunction(r.joinPoint)));for(var o=(this.props.featureNames.length,[]),a=void 0,u=void 0,c=this.currPosOrderedFeatures.length-1;c>=0;--c){var s=this.currPosOrderedFeatures[c],l=r.features[s];u=5+(l.posyTop+l.posyBottom)/2,(!a||u-a>=15)&&l.posyTop-l.posyBottom>=6&&(o.push(l),a=u)}var p=[];a=void 0;var h=!0,d=!1,v=void 0;try{for(var g,m=this.currNegOrderedFeatures[Symbol.iterator]();!(h=(g=m.next()).done);h=!0){var y=g.value,_=r.features[y];u=5+(_.negyTop+_.negyBottom)/2,(!a||a-u>=15)&&_.negyTop-_.negyBottom>=6&&(p.push(_),a=u)}}catch(t){d=!0,v=t}finally{try{!h&&m.return&&m.return()}finally{if(d)throw v}}var b=function(t){var n=\"\";return null!==t.value&&void 0!==t.value&&(n=\" = \"+(isNaN(t.value)?t.value:e.ytickFormat(t.value))),r.count>1?\"mean(\"+e.props.featureNames[t.ind]+\")\"+n:e.props.featureNames[t.ind]+n},x=this.hoverGroup1.selectAll(\".pos-values\").data(o);x.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(x).attr(\"x\",r.xmapScaled+5).attr(\"y\",function(t){return 4+(t.posyTop+t.posyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(b),x.exit().remove();var w=this.hoverGroup2.selectAll(\".pos-values\").data(o);w.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(w).attr(\"x\",r.xmapScaled+5).attr(\"y\",function(t){return 4+(t.posyTop+t.posyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[0]).text(b),w.exit().remove();var C=this.hoverGroup1.selectAll(\".neg-values\").data(p);C.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(C).attr(\"x\",r.xmapScaled+5).attr(\"y\",function(t){return 4+(t.negyTop+t.negyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(b),C.exit().remove();var k=this.hoverGroup2.selectAll(\".neg-values\").data(p);k.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(k).attr(\"x\",r.xmapScaled+5).attr(\"y\",function(t){return 4+(t.negyTop+t.negyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[1]).text(b),k.exit().remove()}}},{key:\"draw\",value:function(){var t=this;if(this.props.explanations&&0!==this.props.explanations.length){(0,y.each)(this.props.explanations,function(t,e){return t.origInd=e});var e={},n={},r={},i=!0,o=!1,a=void 0;try{for(var u,c=this.props.explanations[Symbol.iterator]();!(i=(u=c.next()).done);i=!0){var s=u.value;for(var l in s.features)void 0===e[l]&&(e[l]=0,n[l]=0,r[l]=0),s.features[l].effect>0?e[l]+=s.features[l].effect:n[l]-=s.features[l].effect,null!==s.features[l].value&&void 0!==s.features[l].value&&(r[l]+=1)}}catch(t){o=!0,a=t}finally{try{!i&&c.return&&c.return()}finally{if(o)throw a}}this.usedFeatures=(0,y.sortBy)((0,y.keys)(e),function(t){return-(e[t]+n[t])}),console.log(\"found \",this.usedFeatures.length,\" used features\"),this.posOrderedFeatures=(0,y.sortBy)(this.usedFeatures,function(t){return e[t]}),this.negOrderedFeatures=(0,y.sortBy)(this.usedFeatures,function(t){return-n[t]}),this.singleValueFeatures=(0,y.filter)(this.usedFeatures,function(t){return r[t]>0});var f=[\"sample order by similarity\",\"sample order by output value\",\"original sample ordering\"].concat(this.singleValueFeatures.map(function(e){return t.props.featureNames[e]}));null!=this.props.ordering_keys&&f.unshift(\"sample order by key\");var p=this.xlabel.selectAll(\"option\").data(f);p.enter().append(\"option\").merge(p).attr(\"value\",function(t){return t}).text(function(t){return t}),p.exit().remove();var h=this.props.outNames[0]?this.props.outNames[0]:\"model output value\";f=(0,y.map)(this.usedFeatures,function(e){return[t.props.featureNames[e],t.props.featureNames[e]+\" effects\"]}),f.unshift([\"model output value\",h]);var d=this.ylabel.selectAll(\"option\").data(f);d.enter().append(\"option\").merge(d).attr(\"value\",function(t){return t[0]}).text(function(t){return t[1]}),d.exit().remove(),this.ylabel.style(\"top\",(this.height-10-this.topOffset)/2+this.topOffset+\"px\").style(\"left\",10-this.ylabel.node().offsetWidth/2+\"px\"),this.internalDraw()}}},{key:\"internalDraw\",value:function(){var t=this,e=!0,n=!1,r=void 0;try{for(var i,o=this.props.explanations[Symbol.iterator]();!(e=(i=o.next()).done);e=!0){var a=i.value,u=!0,c=!1,s=void 0;try{for(var l,f=this.usedFeatures[Symbol.iterator]();!(u=(l=f.next()).done);u=!0){var h=l.value;a.features.hasOwnProperty(h)||(a.features[h]={effect:0,value:0}),a.features[h].ind=h}}catch(t){c=!0,s=t}finally{try{!u&&f.return&&f.return()}finally{if(c)throw s}}}}catch(t){n=!0,r=t}finally{try{!e&&o.return&&o.return()}finally{if(n)throw r}}var d=void 0,v=this.xlabel.node().value,m=\"sample order by key\"===v&&null!=this.props.ordering_keys_time_format;if(this.xscale=m?(0,p.scaleTime)():(0,p.scaleLinear)(),this.xaxis.scale(this.xscale),\"sample order by similarity\"===v)d=(0,y.sortBy)(this.props.explanations,function(t){return t.simIndex}),(0,y.each)(d,function(t,e){return t.xmap=e});else if(\"sample order by output value\"===v)d=(0,y.sortBy)(this.props.explanations,function(t){return-t.outValue}),(0,y.each)(d,function(t,e){return t.xmap=e});else if(\"original sample ordering\"===v)d=(0,y.sortBy)(this.props.explanations,function(t){return t.origInd}),(0,y.each)(d,function(t,e){return t.xmap=e});else if(\"sample order by key\"===v)d=this.props.explanations,m?(0,y.each)(d,function(e,n){return e.xmap=t.parseTime(t.props.ordering_keys[n])}):(0,y.each)(d,function(e,n){return e.xmap=t.props.ordering_keys[n]}),d=(0,y.sortBy)(d,function(t){return t.xmap});else{var _=(0,y.findKey)(this.props.featureNames,function(t){return t===v});(0,y.each)(this.props.explanations,function(t,e){return t.xmap=t.features[_].value});var b=(0,y.sortBy)(this.props.explanations,function(t){return t.xmap}),x=(0,y.map)(b,function(t){return t.xmap});if(\"string\"==typeof x[0])return void alert(\"Ordering by category names is not yet supported.\");var w=(0,y.min)(x),C=(0,y.max)(x),k=(C-w)/100;d=[];for(var E=void 0,M=void 0,T=0;T<b.length;++T){var S=b[T];if(E&&!M&&S.xmap-E.xmap<=k||M&&S.xmap-M.xmap<=k){M||(M=(0,y.cloneDeep)(E),M.count=1);var N=!0,A=!1,P=void 0;try{for(var O,I=this.usedFeatures[Symbol.iterator]();!(N=(O=I.next()).done);N=!0){var D=O.value;M.features[D].effect+=S.features[D].effect,M.features[D].value+=S.features[D].value}}catch(t){A=!0,P=t}finally{try{!N&&I.return&&I.return()}finally{if(A)throw P}}M.count+=1}else if(E)if(M){var R=!0,L=!1,U=void 0;try{for(var F,j=this.usedFeatures[Symbol.iterator]();!(R=(F=j.next()).done);R=!0){var B=F.value;M.features[B].effect/=M.count,M.features[B].value/=M.count}}catch(t){L=!0,U=t}finally{try{!R&&j.return&&j.return()}finally{if(L)throw U}}d.push(M),M=void 0}else d.push(E);E=S}E.xmap-d[d.length-1].xmap>k&&d.push(E)}this.currUsedFeatures=this.usedFeatures,this.currPosOrderedFeatures=this.posOrderedFeatures,this.currNegOrderedFeatures=this.negOrderedFeatures;var V=this.ylabel.node().value;if(\"model output value\"!==V){d=(0,y.cloneDeep)(d);for(var W=(0,y.findKey)(this.props.featureNames,function(t){return t===V}),z=0;z<d.length;++z){var H=d[z].features[W];d[z].features={},d[z].features[W]=H}this.currUsedFeatures=[W],this.currPosOrderedFeatures=[W],this.currNegOrderedFeatures=[W]}this.currExplanations=d,\"identity\"===this.props.link?this.invLinkFunction=function(e){return t.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(t.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link),this.predValues=(0,y.map)(d,function(t){return(0,y.sum)((0,y.map)(t.features,function(t){return t.effect}))});var q=this.wrapper.node().offsetWidth;if(0==q)return setTimeout(function(){return t.draw(d)},500);this.svg.style(\"height\",this.height+\"px\"),this.svg.style(\"width\",q+\"px\");var Y=(0,y.map)(d,function(t){return t.xmap});this.xscale.domain([(0,y.min)(Y),(0,y.max)(Y)]).range([this.leftOffset,q]).clamp(!0),this.xaxisElement.attr(\"transform\",\"translate(0,\"+this.topOffset+\")\").call(this.xaxis);for(var K=0;K<this.currExplanations.length;++K)this.currExplanations[K].xmapScaled=this.xscale(this.currExplanations[K].xmap);for(var G=d.length,$=0,X=0;X<G;++X){var Q=d[X].features,Z=(0,y.sum)((0,y.map)((0,y.filter)(Q,function(t){return t.effect>0}),function(t){return t.effect}))||0,J=(0,y.sum)((0,y.map)((0,y.filter)(Q,function(t){return t.effect<0}),function(t){return-t.effect}))||0;$=Math.max($,2.2*Math.max(Z,J))}this.yscale.domain([-$/2,$/2]).range([this.height-10,this.topOffset]),this.yaxisElement.attr(\"transform\",\"translate(\"+this.leftOffset+\",0)\").call(this.yaxis);for(var tt=0;tt<G;++tt){var et=d[tt].features,nt=((0,y.sum)((0,y.map)(et,function(t){return Math.abs(t.effect)})),(0,y.sum)((0,y.map)((0,y.filter)(et,function(t){return t.effect<0}),function(t){return-t.effect}))||0),rt=-nt,it=void 0,ot=!0,at=!1,ut=void 0;try{for(var ct,st=this.currPosOrderedFeatures[Symbol.iterator]();!(ot=(ct=st.next()).done);ot=!0)it=ct.value,et[it].posyTop=this.yscale(rt),et[it].effect>0&&(rt+=et[it].effect),et[it].posyBottom=this.yscale(rt),et[it].ind=it}catch(t){at=!0,ut=t}finally{try{!ot&&st.return&&st.return()}finally{if(at)throw ut}}var lt=rt,ft=!0,pt=!1,ht=void 0;try{for(var dt,vt=this.currNegOrderedFeatures[Symbol.iterator]();!(ft=(dt=vt.next()).done);ft=!0)it=dt.value,et[it].negyTop=this.yscale(rt),et[it].effect<0&&(rt-=et[it].effect),et[it].negyBottom=this.yscale(rt)}catch(t){pt=!0,ht=t}finally{try{!ft&&vt.return&&vt.return()}finally{if(pt)throw ht}}d[tt].joinPoint=lt,d[tt].joinPointy=this.yscale(lt)}var gt=(0,g.line)().x(function(t){return t[0]}).y(function(t){return t[1]}),mt=this.mainGroup.selectAll(\".force-bar-array-area-pos\").data(this.currUsedFeatures);mt.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-pos\").merge(mt).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(G),function(e){return[d[e].xmapScaled,d[e].features[t].posyTop]}),n=(0,y.map)((0,y.rangeRight)(G),function(e){return[d[e].xmapScaled,d[e].features[t].posyBottom]});return gt(e.concat(n))}).attr(\"fill\",this.colors[0]),mt.exit().remove();var yt=this.mainGroup.selectAll(\".force-bar-array-area-neg\").data(this.currUsedFeatures);yt.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-neg\").merge(yt).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(G),function(e){return[d[e].xmapScaled,d[e].features[t].negyTop]}),n=(0,y.map)((0,y.rangeRight)(G),function(e){return[d[e].xmapScaled,d[e].features[t].negyBottom]});return gt(e.concat(n))}).attr(\"fill\",this.colors[1]),yt.exit().remove();var _t=this.mainGroup.selectAll(\".force-bar-array-divider-pos\").data(this.currUsedFeatures);_t.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-pos\").merge(_t).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(G),function(e){return[d[e].xmapScaled,d[e].features[t].posyBottom]});return gt(e)}).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",function(e){return t.colors[0].brighter(1.2)}),_t.exit().remove();var bt=this.mainGroup.selectAll(\".force-bar-array-divider-neg\").data(this.currUsedFeatures);bt.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-neg\").merge(bt).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(G),function(e){return[d[e].xmapScaled,d[e].features[t].negyTop]});return gt(e)}).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",function(e){return t.colors[1].brighter(1.5)}),bt.exit().remove();for(var xt=function(t,e,n,r,i){var o=void 0,a=void 0;\"pos\"===i?(o=t[n].features[e].posyBottom,a=t[n].features[e].posyTop):(o=t[n].features[e].negyBottom,a=t[n].features[e].negyTop);for(var u=void 0,c=void 0,s=n+1;s<=r;++s)\"pos\"===i?(u=t[s].features[e].posyBottom,c=t[s].features[e].posyTop):(u=t[s].features[e].negyBottom,c=t[s].features[e].negyTop),u>o&&(o=u),c<a&&(a=c);return{top:o,bottom:a}},wt=[],Ct=[\"pos\",\"neg\"],kt=0;kt<Ct.length;kt++){var Et=Ct[kt],Mt=!0,Tt=!1,St=void 0;try{for(var Nt,At=this.currUsedFeatures[Symbol.iterator]();!(Mt=(Nt=At.next()).done);Mt=!0)for(var Pt=Nt.value,Ot=0,It=0,Dt=0,Rt={top:0,bottom:0},Lt=void 0;It<G-1;){for(;Dt<100&&It<G-1;)++It,Dt=d[It].xmapScaled-d[Ot].xmapScaled;for(Rt=xt(d,Pt,Ot,It,Et);Rt.bottom-Rt.top<20&&Ot<It;)++Ot,Rt=xt(d,Pt,Ot,It,Et);if(Dt=d[It].xmapScaled-d[Ot].xmapScaled,Rt.bottom-Rt.top>=20&&Dt>=100){for(;It<G-1;){if(++It,Lt=xt(d,Pt,Ot,It,Et),!(Lt.bottom-Lt.top>20)){--It;break}Rt=Lt}Dt=d[It].xmapScaled-d[Ot].xmapScaled,wt.push([(d[It].xmapScaled+d[Ot].xmapScaled)/2,(Rt.top+Rt.bottom)/2,this.props.featureNames[Pt]]);var Ut=d[It].xmapScaled;for(Ot=It;Ut+100>d[Ot].xmapScaled&&Ot<G-1;)++Ot;It=Ot}}}catch(t){Tt=!0,St=t}finally{try{!Mt&&At.return&&At.return()}finally{if(Tt)throw St}}}var Ft=this.onTopGroup.selectAll(\".force-bar-array-flabels\").data(wt);Ft.enter().append(\"text\").attr(\"class\",\"force-bar-array-flabels\").merge(Ft).attr(\"x\",function(t){return t[0]}).attr(\"y\",function(t){return t[1]+4}).text(function(t){return t[2]}),Ft.exit().remove()}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return l.default.createElement(\"div\",{ref:function(e){return t.wrapper=(0,f.select)(e)},style:{textAlign:\"center\"}},l.default.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-array-wrapper {\\n            text-align: center;\\n          }\\n          .force-bar-array-xaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-xaxis .domain {\\n            opacity: 0;\\n          }\\n          .force-bar-array-xaxis paths {\\n            display: none;\\n          }\\n          .force-bar-array-yaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-yaxis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\\n          .force-bar-array-flabels {\\n            font-size: 12px;\\n            fill: #fff;\\n            text-anchor: middle;\\n          }\\n          .additive-force-array-xlabel {\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            margin-left: 80px;\\n            max-width: 300px;\\n          }\\n          .additive-force-array-xlabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-ylabel {\\n            position: relative;\\n            top: 0px;\\n            left: 0px;\\n            transform: rotate(-90deg);\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            max-width: 150px;\\n          }\\n          .additive-force-array-ylabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-hoverLine {\\n            stroke-width: 1px;\\n            stroke: #fff;\\n            opacity: 1;\\n          }\"}}),l.default.createElement(\"select\",{className:\"additive-force-array-xlabel\"}),l.default.createElement(\"div\",{style:{height:\"0px\",textAlign:\"left\"}},l.default.createElement(\"select\",{className:\"additive-force-array-ylabel\"})),l.default.createElement(\"svg\",{ref:function(e){return t.svg=(0,f.select)(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}}))}}]),e}(l.default.Component);x.defaultProps={plot_cmap:\"RdBu\",ordering_keys:null,ordering_keys_time_format:null},e.default=x},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),c=n(41),s=r(c),l=n(129),f=n(66),p=(n(7),n(29)),h=n(112),d=n(136),v=n(10),g=n(38),m=n(58),y=r(m),b=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return window.lastAdditiveForceVisualizer=t,t.effectFormat=(0,p.format)(\".2\"),t.redraw=(0,g.debounce)(function(){return t.draw()},200),t}return a(e,t),u(e,[{key:\"componentDidMount\",value:function(){var t=this;this.mainGroup=this.svg.append(\"g\"),this.axisElement=this.mainGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-axis\"),this.onTopGroup=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.joinPointLine=this.svg.append(\"line\"),this.joinPointLabelOutline=this.svg.append(\"text\"),this.joinPointLabel=this.svg.append(\"text\"),this.joinPointTitleLeft=this.svg.append(\"text\"),this.joinPointTitleLeftArrow=this.svg.append(\"text\"),this.joinPointTitle=this.svg.append(\"text\"),this.joinPointTitleRightArrow=this.svg.append(\"text\"),this.joinPointTitleRight=this.svg.append(\"text\"),this.hoverLabelBacking=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").text(\"\").on(\"mouseover\",function(e){t.hoverLabel.attr(\"opacity\",1),t.hoverLabelBacking.attr(\"opacity\",1)}).on(\"mouseout\",function(e){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)}),this.hoverLabel=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"fill\",\"#0f0\").text(\"\").on(\"mouseover\",function(e){t.hoverLabel.attr(\"opacity\",1),t.hoverLabelBacking.attr(\"opacity\",1)}).on(\"mouseout\",function(e){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)});var e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in y.default.colors?e=y.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=y.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),this.colors=e.map(function(t){return(0,v.hsl)(t)}),this.brighterColors=[1.45,1.6].map(function(e,n){return t.colors[n].brighter(e)}),this.colors.map(function(e,n){var r=t.svg.append(\"linearGradient\").attr(\"id\",\"linear-grad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");r.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",e).attr(\"stop-opacity\",.6),r.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",e).attr(\"stop-opacity\",0);var i=t.svg.append(\"linearGradient\").attr(\"id\",\"linear-backgrad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");i.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",e).attr(\"stop-opacity\",.5),i.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",e).attr(\"stop-opacity\",0)}),this.tickFormat=(0,p.format)(\",.4\"),this.scaleCentered=(0,f.scaleLinear)(),this.axis=(0,h.axisBottom)().scale(this.scaleCentered).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.tickFormat(t.invLinkFunction(e))}).tickPadding(-18),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"draw\",value:function(){var t=this;(0,g.each)(this.props.featureNames,function(e,n){t.props.features[n]&&(t.props.features[n].name=e)}),\"identity\"===this.props.link?this.invLinkFunction=function(e){return t.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(t.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link);var e=this.svg.node().parentNode.offsetWidth;if(0==e)return setTimeout(function(){return t.draw(t.props)},500);this.svg.style(\"height\",\"150px\"),this.svg.style(\"width\",e+\"px\");var n=(0,g.sortBy)(this.props.features,function(t){return-1/(t.effect+1e-10)}),r=(0,g.sum)((0,g.map)(n,function(t){return Math.abs(t.effect)})),i=(0,g.sum)((0,g.map)((0,g.filter)(n,function(t){return t.effect>0}),function(t){return t.effect}))||0,o=(0,g.sum)((0,g.map)((0,g.filter)(n,function(t){return t.effect<0}),function(t){return-t.effect}))||0;this.domainSize=3*Math.max(i,o);var a=(0,f.scaleLinear)().domain([0,this.domainSize]).range([0,e]),u=e/2-a(o);this.scaleCentered.domain([-this.domainSize/2,this.domainSize/2]).range([0,e]).clamp(!0),this.axisElement.attr(\"transform\",\"translate(0,50)\").call(this.axis);var c=0,s=void 0,l=void 0,h=void 0;for(s=0;s<n.length;++s)n[s].x=c,n[s].effect<0&&void 0===l&&(l=c,h=s),c+=Math.abs(n[s].effect);void 0===l&&(l=c,h=s);var v=(0,d.line)().x(function(t){return t[0]}).y(function(t){return t[1]}),m=function(e){return void 0!==e.value&&null!==e.value&&\"\"!==e.value?e.name+\" = \"+(isNaN(e.value)?e.value:t.tickFormat(e.value)):e.name};n=this.props.hideBars?[]:n;var y=this.mainGroup.selectAll(\".force-bar-blocks\").data(n);y.enter().append(\"path\").attr(\"class\",\"force-bar-blocks\").merge(y).attr(\"d\",function(t,e){var n=a(t.x)+u,r=a(Math.abs(t.effect)),i=t.effect<0?-4:4,o=i;return e===h&&(i=0),e===h-1&&(o=0),v([[n,56],[n+r,56],[n+r+o,64.5],[n+r,73],[n,73],[n+i,64.5]])}).attr(\"fill\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}).on(\"mouseover\",function(e){if(a(Math.abs(e.effect))<a(r)/50||a(Math.abs(e.effect))<10){var n=a(e.x)+u,i=a(Math.abs(e.effect));t.hoverLabel.attr(\"opacity\",1).attr(\"x\",n+i/2).attr(\"y\",50.5).attr(\"fill\",e.effect>0?t.colors[0]:t.colors[1]).text(m(e)),t.hoverLabelBacking.attr(\"opacity\",1).attr(\"x\",n+i/2).attr(\"y\",50.5).text(m(e))}}).on(\"mouseout\",function(e){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)}),y.exit().remove();var b=_.filter(n,function(t){return a(Math.abs(t.effect))>a(r)/50&&a(Math.abs(t.effect))>10}),x=this.onTopGroup.selectAll(\".force-bar-labels\").data(b);if(x.exit().remove(),x=x.enter().append(\"text\").attr(\"class\",\"force-bar-labels\").attr(\"font-size\",\"12px\").attr(\"y\",function(t){return 98}).merge(x).text(function(e){return void 0!==e.value&&null!==e.value&&\"\"!==e.value?e.name+\" = \"+(isNaN(e.value)?e.value:t.tickFormat(e.value)):e.name}).attr(\"fill\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}).attr(\"stroke\",function(t,e){return t.textWidth=Math.max(this.getComputedTextLength(),a(Math.abs(t.effect))-10),t.innerTextWidth=this.getComputedTextLength(),\"none\"}),this.filteredData=b,n.length>0){c=l+a.invert(5);for(var w=h;w<n.length;++w)n[w].textx=c,c+=a.invert(n[w].textWidth+10);c=l-a.invert(5);for(var C=h-1;C>=0;--C)n[C].textx=c,c-=a.invert(n[C].textWidth+10)}x.attr(\"x\",function(t){return a(t.textx)+u+(t.effect>0?-t.textWidth/2:t.textWidth/2)}).attr(\"text-anchor\",\"middle\"),b=(0,g.filter)(b,function(n){return a(n.textx)+u>t.props.labelMargin&&a(n.textx)+u<e-t.props.labelMargin}),this.filteredData2=b;var k=b.slice(),E=(0,g.findIndex)(n,b[0])-1;E>=0&&k.unshift(n[E]);var M=this.mainGroup.selectAll(\".force-bar-labelBacking\").data(b);M.enter().append(\"path\").attr(\"class\",\"force-bar-labelBacking\").attr(\"stroke\",\"none\").attr(\"opacity\",.2).merge(M).attr(\"d\",function(t){return v([[a(t.x)+a(Math.abs(t.effect))+u,73],[(t.effect>0?a(t.textx):a(t.textx)+t.textWidth)+u+5,83],[(t.effect>0?a(t.textx):a(t.textx)+t.textWidth)+u+5,104],[(t.effect>0?a(t.textx)-t.textWidth:a(t.textx))+u-5,104],[(t.effect>0?a(t.textx)-t.textWidth:a(t.textx))+u-5,83],[a(t.x)+u,73]])}).attr(\"fill\",function(t){return\"url(#linear-backgrad-\"+(t.effect>0?0:1)+\")\"}),M.exit().remove();var T=this.mainGroup.selectAll(\".force-bar-labelDividers\").data(b.slice(0,-1));T.enter().append(\"rect\").attr(\"class\",\"force-bar-labelDividers\").attr(\"height\",\"21px\").attr(\"width\",\"1px\").attr(\"y\",83).merge(T).attr(\"x\",function(t){return(t.effect>0?a(t.textx):a(t.textx)+t.textWidth)+u+4.5}).attr(\"fill\",function(t){return\"url(#linear-grad-\"+(t.effect>0?0:1)+\")\"}),T.exit().remove();var S=this.mainGroup.selectAll(\".force-bar-labelLinks\").data(b.slice(0,-1));S.enter().append(\"line\").attr(\"class\",\"force-bar-labelLinks\").attr(\"y1\",73).attr(\"y2\",83).attr(\"stroke-opacity\",.5).attr(\"stroke-width\",1).merge(S).attr(\"x1\",function(t){return a(t.x)+a(Math.abs(t.effect))+u}).attr(\"x2\",function(t){return(t.effect>0?a(t.textx):a(t.textx)+t.textWidth)+u+5}).attr(\"stroke\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}),S.exit().remove();var N=this.mainGroup.selectAll(\".force-bar-blockDividers\").data(n.slice(0,-1));N.enter().append(\"path\").attr(\"class\",\"force-bar-blockDividers\").attr(\"stroke-width\",2).attr(\"fill\",\"none\").merge(N).attr(\"d\",function(t){var e=a(t.x)+a(Math.abs(t.effect))+u;return v([[e,56],[e+(t.effect<0?-4:4),64.5],[e,73]])}).attr(\"stroke\",function(e,n){return h===n+1||Math.abs(e.effect)<1e-8?\"#rgba(0,0,0,0)\":e.effect>0?t.brighterColors[0]:t.brighterColors[1]}),N.exit().remove(),this.joinPointLine.attr(\"x1\",a(l)+u).attr(\"x2\",a(l)+u).attr(\"y1\",50).attr(\"y2\",56).attr(\"stroke\",\"#F2F2F2\").attr(\"stroke-width\",1).attr(\"opacity\",1),this.joinPointLabelOutline.attr(\"x\",a(l)+u).attr(\"y\",45).attr(\"color\",\"#fff\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",6).text((0,p.format)(\",.2f\")(this.invLinkFunction(l-o))).attr(\"opacity\",1),console.log(\"joinPoint\",l,u,50,o),this.joinPointLabel.attr(\"x\",a(l)+u).attr(\"y\",45).attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").text((0,p.format)(\",.2f\")(this.invLinkFunction(l-o))).attr(\"opacity\",1),this.joinPointTitle.attr(\"x\",a(l)+u).attr(\"y\",28).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(this.props.outNames[0]).attr(\"opacity\",.5),this.props.hideBars||(this.joinPointTitleLeft.attr(\"x\",a(l)+u-16).attr(\"y\",12).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"higher\").attr(\"opacity\",1),this.joinPointTitleRight.attr(\"x\",a(l)+u+16).attr(\"y\",12).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"lower\").attr(\"opacity\",1),this.joinPointTitleLeftArrow.attr(\"x\",a(l)+u+7).attr(\"y\",8).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"→\").attr(\"opacity\",1),this.joinPointTitleRightArrow.attr(\"x\",a(l)+u-7).attr(\"y\",14).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"←\").attr(\"opacity\",1)),this.props.hideBaseValueLabel||this.baseValueTitle.attr(\"x\",this.scaleCentered(0)).attr(\"y\",28).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(\"base value\").attr(\"opacity\",.5)}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return s.default.createElement(\"svg\",{ref:function(e){return t.svg=(0,l.select)(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}},s.default.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-axis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-axis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\"}}))}}]),e}(s.default.Component);b.defaultProps={plot_cmap:\"RdBu\"},e.default=b},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),c=n(41),s=r(c),l=n(66),f=(n(7),n(29)),p=n(38),h=n(58),d=r(h),v=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return t.width=100,window.lastSimpleListInstance=t,t.effectFormat=(0,f.format)(\".2\"),t}return a(e,t),u(e,[{key:\"render\",value:function(){var t=this,e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in d.default.colors?e=d.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=d.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),console.log(this.props.features,this.props.features),this.scale=(0,l.scaleLinear)().domain([0,(0,p.max)((0,p.map)(this.props.features,function(t){return Math.abs(t.effect)}))]).range([0,this.width]);var n=(0,p.reverse)((0,p.sortBy)(Object.keys(this.props.features),function(e){return Math.abs(t.props.features[e].effect)})),r=n.map(function(n){var r=t.props.features[n],i=t.props.featureNames[n],o={width:t.scale(Math.abs(r.effect)),height:\"20px\",background:r.effect<0?e[0]:e[1],display:\"inline-block\"},a=void 0,u=void 0,c={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginRight:\"5px\",textAlign:\"right\"},l={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginLeft:\"5px\"};return r.effect<0?(u=s.default.createElement(\"span\",{style:l},i),c.width=40+t.width-t.scale(Math.abs(r.effect)),c.textAlign=\"right\",c.color=\"#999\",c.fontSize=\"13px\",a=s.default.createElement(\"span\",{style:c},t.effectFormat(r.effect))):(c.textAlign=\"right\",a=s.default.createElement(\"span\",{style:c},i),l.width=40,l.textAlign=\"left\",l.color=\"#999\",l.fontSize=\"13px\",u=s.default.createElement(\"span\",{style:l},t.effectFormat(r.effect))),s.default.createElement(\"div\",{key:n,style:{marginTop:\"2px\"}},a,s.default.createElement(\"div\",{style:o}),u)});return s.default.createElement(\"span\",null,r)}}]),e}(s.default.Component);v.defaultProps={plot_cmap:\"RdBu\"},e.default=v},function(t,e,n){\"use strict\";t.exports=n(359)},function(t,e,n){var r=(n(0),n(411)),i=!1;t.exports=function(t){t=t||{};var e=t.shouldRejectClick||r;i=!0,n(22).injection.injectEventPluginsByName({TapEventPlugin:n(409)(e)})}},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}var i=n(41),o=r(i),a=n(187),u=r(a),c=n(188),s=r(c),l=n(186),f=r(l),p=n(185),h=r(p),d=n(184),v=r(d);(0,s.default)(),window.SHAP={SimpleListVisualizer:f.default,AdditiveForceVisualizer:h.default,AdditiveForceArrayVisualizer:v.default,React:o.default,ReactDom:u.default}},,function(t,e,n){\"use strict\";function r(t){return t}function i(t,e,n){function i(t,e){var n=y.hasOwnProperty(e)?y[e]:null;C.hasOwnProperty(e)&&u(\"OVERRIDE_BASE\"===n,\"ReactClassInterface: You are attempting to override `%s` from your class specification. Ensure that your method names do not overlap with React methods.\",e),t&&u(\"DEFINE_MANY\"===n||\"DEFINE_MANY_MERGED\"===n,\"ReactClassInterface: You are attempting to define `%s` on your component more than once. This conflict may be due to a mixin.\",e)}function s(t,n){if(n){u(\"function\"!=typeof n,\"ReactClass: You're attempting to use a component class or function as a mixin. Instead, just use a regular object.\"),u(!e(n),\"ReactClass: You're attempting to use a component as a mixin. Instead, just use a regular object.\");var r=t.prototype,o=r.__reactAutoBindPairs;n.hasOwnProperty(c)&&b.mixins(t,n.mixins);for(var a in n)if(n.hasOwnProperty(a)&&a!==c){var s=n[a],l=r.hasOwnProperty(a);if(i(l,a),b.hasOwnProperty(a))b[a](t,s);else{var f=y.hasOwnProperty(a),d=\"function\"==typeof s,v=d&&!f&&!l&&!1!==n.autobind;if(v)o.push(a,s),r[a]=s;else if(l){var g=y[a];u(f&&(\"DEFINE_MANY_MERGED\"===g||\"DEFINE_MANY\"===g),\"ReactClass: Unexpected spec policy %s for key %s when mixing in component specs.\",g,a),\"DEFINE_MANY_MERGED\"===g?r[a]=p(r[a],s):\"DEFINE_MANY\"===g&&(r[a]=h(r[a],s))}else r[a]=s}}}else;}function l(t,e){if(e)for(var n in e){var r=e[n];if(e.hasOwnProperty(n)){var i=n in b;u(!i,'ReactClass: You are attempting to define a reserved property, `%s`, that shouldn\\'t be on the \"statics\" key. Define it as an instance property instead; it will still be accessible on the constructor.',n);var o=n in t;if(o){var a=_.hasOwnProperty(n)?_[n]:null;return u(\"DEFINE_MANY_MERGED\"===a,\"ReactClass: You are attempting to define `%s` on your component more than once. This conflict may be due to a mixin.\",n),void(t[n]=p(t[n],r))}t[n]=r}}}function f(t,e){u(t&&e&&\"object\"==typeof t&&\"object\"==typeof e,\"mergeIntoWithNoDuplicateKeys(): Cannot merge non-objects.\");for(var n in e)e.hasOwnProperty(n)&&(u(void 0===t[n],\"mergeIntoWithNoDuplicateKeys(): Tried to merge two objects with the same key: `%s`. This conflict may be due to a mixin; in particular, this may be caused by two getInitialState() or getDefaultProps() methods returning objects with clashing keys.\",n),t[n]=e[n]);return t}function p(t,e){return function(){var n=t.apply(this,arguments),r=e.apply(this,arguments);if(null==n)return r;if(null==r)return n;var i={};return f(i,n),f(i,r),i}}function h(t,e){return function(){t.apply(this,arguments),e.apply(this,arguments)}}function d(t,e){var n=e.bind(t);return n}function v(t){for(var e=t.__reactAutoBindPairs,n=0;n<e.length;n+=2){var r=e[n],i=e[n+1];t[r]=d(t,i)}}function g(t){var e=r(function(t,r,i){this.__reactAutoBindPairs.length&&v(this),this.props=t,this.context=r,this.refs=a,this.updater=i||n,this.state=null;var o=this.getInitialState?this.getInitialState():null;u(\"object\"==typeof o&&!Array.isArray(o),\"%s.getInitialState(): must return an object or null\",e.displayName||\"ReactCompositeComponent\"),this.state=o});e.prototype=new k,e.prototype.constructor=e,e.prototype.__reactAutoBindPairs=[],m.forEach(s.bind(null,e)),s(e,x),s(e,t),s(e,w),e.getDefaultProps&&(e.defaultProps=e.getDefaultProps()),u(e.prototype.render,\"createClass(...): Class specification must implement a `render` method.\");for(var i in y)e.prototype[i]||(e.prototype[i]=null);return e}var m=[],y={mixins:\"DEFINE_MANY\",statics:\"DEFINE_MANY\",propTypes:\"DEFINE_MANY\",contextTypes:\"DEFINE_MANY\",childContextTypes:\"DEFINE_MANY\",getDefaultProps:\"DEFINE_MANY_MERGED\",getInitialState:\"DEFINE_MANY_MERGED\",getChildContext:\"DEFINE_MANY_MERGED\",render:\"DEFINE_ONCE\",componentWillMount:\"DEFINE_MANY\",componentDidMount:\"DEFINE_MANY\",componentWillReceiveProps:\"DEFINE_MANY\",shouldComponentUpdate:\"DEFINE_ONCE\",componentWillUpdate:\"DEFINE_MANY\",componentDidUpdate:\"DEFINE_MANY\",componentWillUnmount:\"DEFINE_MANY\",UNSAFE_componentWillMount:\"DEFINE_MANY\",UNSAFE_componentWillReceiveProps:\"DEFINE_MANY\",UNSAFE_componentWillUpdate:\"DEFINE_MANY\",updateComponent:\"OVERRIDE_BASE\"},_={getDerivedStateFromProps:\"DEFINE_MANY_MERGED\"},b={displayName:function(t,e){t.displayName=e},mixins:function(t,e){if(e)for(var n=0;n<e.length;n++)s(t,e[n])},childContextTypes:function(t,e){t.childContextTypes=o({},t.childContextTypes,e)},contextTypes:function(t,e){t.contextTypes=o({},t.contextTypes,e)},getDefaultProps:function(t,e){t.getDefaultProps?t.getDefaultProps=p(t.getDefaultProps,e):t.getDefaultProps=e},propTypes:function(t,e){t.propTypes=o({},t.propTypes,e)},statics:function(t,e){l(t,e)},autobind:function(){}},x={componentDidMount:function(){this.__isMounted=!0}},w={componentWillUnmount:function(){this.__isMounted=!1}},C={replaceState:function(t,e){this.updater.enqueueReplaceState(this,t,e)},isMounted:function(){return!!this.__isMounted}},k=function(){};return o(k.prototype,t.prototype,C),g}var o=n(3),a=n(51),u=n(0),c=\"mixins\";t.exports=i},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";var r=n(106);e.a=function(t,e,n){var i,o,a,u,c=t.length,s=e.length,l=new Array(c*s);for(null==n&&(n=r.b),i=a=0;i<c;++i)for(u=t[i],o=0;o<s;++o,++a)l[a]=n(u,e[o]);return l}},function(t,e,n){\"use strict\";e.a=function(t,e){return e<t?-1:e>t?1:e>=t?0:NaN}},function(t,e,n){\"use strict\";var r=n(100),i=n(101),o=n(192),a=n(104),u=n(196),c=n(107),s=n(109),l=n(108);e.a=function(){function t(t){var r,o,a=t.length,u=new Array(a);for(r=0;r<a;++r)u[r]=e(t[r],r,t);var l=f(u),h=l[0],d=l[1],v=p(u,h,d);Array.isArray(v)||(v=n.i(s.c)(h,d,v),v=n.i(c.a)(Math.ceil(h/v)*v,Math.floor(d/v)*v,v));for(var g=v.length;v[0]<=h;)v.shift(),--g;for(;v[g-1]>d;)v.pop(),--g;var m,y=new Array(g+1);for(r=0;r<=g;++r)m=y[r]=[],m.x0=r>0?v[r-1]:h,m.x1=r<g?v[r]:d;for(r=0;r<a;++r)o=u[r],h<=o&&o<=d&&y[n.i(i.a)(v,o,0,g)].push(t[r]);return y}var e=u.a,f=a.a,p=l.a;return t.value=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(o.a)(r),t):e},t.domain=function(e){return arguments.length?(f=\"function\"==typeof e?e:n.i(o.a)([e[0],e[1]]),t):f},t.thresholds=function(e){return arguments.length?(p=\"function\"==typeof e?e:Array.isArray(e)?n.i(o.a)(r.b.call(e)):n.i(o.a)(e),t):p},t}},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i=t.length,o=-1;if(null==e){for(;++o<i;)if(null!=(n=t[o])&&n>=n)for(r=n;++o<i;)null!=(n=t[o])&&n>r&&(r=n)}else for(;++o<i;)if(null!=(n=e(t[o],o,t))&&n>=n)for(r=n;++o<i;)null!=(n=e(t[o],o,t))&&n>r&&(r=n);return r}},function(t,e,n){\"use strict\";var r=n(28);e.a=function(t,e){var i,o=t.length,a=o,u=-1,c=0;if(null==e)for(;++u<o;)isNaN(i=n.i(r.a)(t[u]))?--a:c+=i;else for(;++u<o;)isNaN(i=n.i(r.a)(e(t[u],u,t)))?--a:c+=i;if(a)return c/a}},function(t,e,n){\"use strict\";var r=n(19),i=n(28),o=n(59);e.a=function(t,e){var a,u=t.length,c=-1,s=[];if(null==e)for(;++c<u;)isNaN(a=n.i(i.a)(t[c]))||s.push(a);else for(;++c<u;)isNaN(a=n.i(i.a)(e(t[c],c,t)))||s.push(a);return n.i(o.a)(s.sort(r.a),.5)}},function(t,e,n){\"use strict\";e.a=function(t){for(var e,n,r,i=t.length,o=-1,a=0;++o<i;)a+=t[o].length;for(n=new Array(a);--i>=0;)for(r=t[i],e=r.length;--e>=0;)n[--a]=r[e];return n}},function(t,e,n){\"use strict\";e.a=function(t,e){for(var n=e.length,r=new Array(n);n--;)r[n]=t[e[n]];return r}},function(t,e,n){\"use strict\";var r=n(19);e.a=function(t,e){if(n=t.length){var n,i,o=0,a=0,u=t[a];for(null==e&&(e=r.a);++o<n;)(e(i=t[o],u)<0||0!==e(u,u))&&(u=i,a=o);return 0===e(u,u)?a:void 0}}},function(t,e,n){\"use strict\";e.a=function(t,e,n){for(var r,i,o=(null==n?t.length:n)-(e=null==e?0:+e);o;)i=Math.random()*o--|0,r=t[o+e],t[o+e]=t[i+e],t[i+e]=r;return t}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r=t.length,i=-1,o=0;if(null==e)for(;++i<r;)(n=+t[i])&&(o+=n);else for(;++i<r;)(n=+e(t[i],i,t))&&(o+=n);return o}},function(t,e,n){\"use strict\";var r=n(100),i=n(19),o=n(28),a=n(59);e.a=function(t,e,u){return t=r.a.call(t,o.a).sort(i.a),Math.ceil((u-e)/(2*(n.i(a.a)(t,.75)-n.i(a.a)(t,.25))*Math.pow(t.length,-1/3)))}},function(t,e,n){\"use strict\";var r=n(103);e.a=function(t,e,i){return Math.ceil((i-e)/(3.5*n.i(r.a)(t)*Math.pow(t.length,-1/3)))}},function(t,e,n){\"use strict\";var r=n(110);e.a=function(){return n.i(r.a)(arguments)}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r});var r=Array.prototype.slice},function(t,e,n){\"use strict\";function r(t){return\"translate(\"+(t+.5)+\",0)\"}function i(t){return\"translate(0,\"+(t+.5)+\")\"}function o(t){return function(e){return+t(e)}}function a(t){var e=Math.max(0,t.bandwidth()-1)/2;return t.round()&&(e=Math.round(e)),function(n){return+t(n)+e}}function u(){return!this.__axis}function c(t,e){function n(n){var r=null==s?e.ticks?e.ticks.apply(e,c):e.domain():s,i=null==l?e.tickFormat?e.tickFormat.apply(e,c):d.a:l,h=Math.max(f,0)+b,k=e.range(),E=+k[0]+.5,M=+k[k.length-1]+.5,T=(e.bandwidth?a:o)(e.copy()),S=n.selection?n.selection():n,N=S.selectAll(\".domain\").data([null]),A=S.selectAll(\".tick\").data(r,e).order(),P=A.exit(),O=A.enter().append(\"g\").attr(\"class\",\"tick\"),I=A.select(\"line\"),D=A.select(\"text\");N=N.merge(N.enter().insert(\"path\",\".tick\").attr(\"class\",\"domain\").attr(\"stroke\",\"#000\")),A=A.merge(O),I=I.merge(O.append(\"line\").attr(\"stroke\",\"#000\").attr(w+\"2\",x*f)),D=D.merge(O.append(\"text\").attr(\"fill\",\"#000\").attr(w,x*h).attr(\"dy\",t===v?\"0em\":t===m?\"0.71em\":\"0.32em\")),n!==S&&(N=N.transition(n),A=A.transition(n),I=I.transition(n),D=D.transition(n),P=P.transition(n).attr(\"opacity\",_).attr(\"transform\",function(t){return isFinite(t=T(t))?C(t):this.getAttribute(\"transform\")}),O.attr(\"opacity\",_).attr(\"transform\",function(t){var e=this.parentNode.__axis;return C(e&&isFinite(e=e(t))?e:T(t))})),P.remove(),N.attr(\"d\",t===y||t==g?\"M\"+x*p+\",\"+E+\"H0.5V\"+M+\"H\"+x*p:\"M\"+E+\",\"+x*p+\"V0.5H\"+M+\"V\"+x*p),A.attr(\"opacity\",1).attr(\"transform\",function(t){return C(T(t))}),I.attr(w+\"2\",x*f),D.attr(w,x*h).text(i),S.filter(u).attr(\"fill\",\"none\").attr(\"font-size\",10).attr(\"font-family\",\"sans-serif\").attr(\"text-anchor\",t===g?\"start\":t===y?\"end\":\"middle\"),S.each(function(){this.__axis=T})}var c=[],s=null,l=null,f=6,p=6,b=3,x=t===v||t===y?-1:1,w=t===y||t===g?\"x\":\"y\",C=t===v||t===m?r:i;return n.scale=function(t){return arguments.length?(e=t,n):e},n.ticks=function(){return c=h.a.call(arguments),n},n.tickArguments=function(t){return arguments.length?(c=null==t?[]:h.a.call(t),n):c.slice()},n.tickValues=function(t){return arguments.length?(s=null==t?null:h.a.call(t),n):s&&s.slice()},n.tickFormat=function(t){return arguments.length?(l=t,n):l},n.tickSize=function(t){return arguments.length?(f=p=+t,n):f},n.tickSizeInner=function(t){return arguments.length?(f=+t,n):f},n.tickSizeOuter=function(t){return arguments.length?(p=+t,n):p},n.tickPadding=function(t){return arguments.length?(b=+t,n):b},n}function s(t){return c(v,t)}function l(t){return c(g,t)}function f(t){return c(m,t)}function p(t){return c(y,t)}e.a=s,e.b=l,e.c=f,e.d=p;var h=n(208),d=n(210),v=1,g=2,m=3,y=4,_=1e-6},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";var r=(n(214),n(215),n(60));n.d(e,\"a\",function(){return r.a});n(213),n(216),n(212)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(60)},function(t,e,n){\"use strict\";function r(){}function i(t,e){var n=new r;if(t instanceof r)t.each(function(t){n.add(t)});else if(t){var i=-1,o=t.length;if(null==e)for(;++i<o;)n.add(t[i]);else for(;++i<o;)n.add(e(t[i],i,t))}return n}var o=n(60),a=o.a.prototype;r.prototype=i.prototype={constructor:r,has:a.has,add:function(t){return t+=\"\",this[o.b+t]=t,this},remove:a.remove,clear:a.clear,values:a.keys,size:a.size,empty:a.empty,each:a.each}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";function r(t){if(t instanceof o)return new o(t.h,t.s,t.l,t.opacity);t instanceof u.d||(t=n.i(u.e)(t));var e=t.r/255,r=t.g/255,i=t.b/255,a=(g*i+d*e-v*r)/(g+d-v),s=i-a,l=(h*(r-a)-f*s)/p,m=Math.sqrt(l*l+s*s)/(h*a*(1-a)),y=m?Math.atan2(l,s)*c.a-120:NaN;return new o(y<0?y+360:y,m,a,t.opacity)}function i(t,e,n,i){return 1===arguments.length?r(t):new o(t,e,n,null==i?1:i)}function o(t,e,n,r){this.h=+t,this.s=+e,this.l=+n,this.opacity=+r}e.a=i;var a=n(62),u=n(61),c=n(113),s=-.14861,l=1.78277,f=-.29227,p=-.90649,h=1.97294,d=h*p,v=h*l,g=l*f-p*s;n.i(a.a)(o,i,n.i(a.b)(u.f,{brighter:function(t){return t=null==t?u.g:Math.pow(u.g,t),new o(this.h,this.s,this.l*t,this.opacity)},darker:function(t){return t=null==t?u.h:Math.pow(u.h,t),new o(this.h,this.s,this.l*t,this.opacity)},rgb:function(){var t=isNaN(this.h)?0:(this.h+120)*c.b,e=+this.l,n=isNaN(this.s)?0:this.s*e*(1-e),r=Math.cos(t),i=Math.sin(t);return new u.d(255*(e+n*(s*r+l*i)),255*(e+n*(f*r+p*i)),255*(e+n*(h*r)),this.opacity)}}))},function(t,e,n){\"use strict\";function r(t){if(t instanceof o)return new o(t.l,t.a,t.b,t.opacity);if(t instanceof p){var e=t.h*v.b;return new o(t.l,Math.cos(e)*t.c,Math.sin(e)*t.c,t.opacity)}t instanceof d.d||(t=n.i(d.e)(t));var r=s(t.r),i=s(t.g),u=s(t.b),c=a((.4124564*r+.3575761*i+.1804375*u)/g),l=a((.2126729*r+.7151522*i+.072175*u)/m);return new o(116*l-16,500*(c-l),200*(l-a((.0193339*r+.119192*i+.9503041*u)/y)),t.opacity)}function i(t,e,n,i){return 1===arguments.length?r(t):new o(t,e,n,null==i?1:i)}function o(t,e,n,r){this.l=+t,this.a=+e,this.b=+n,this.opacity=+r}function a(t){return t>w?Math.pow(t,1/3):t/x+_}function u(t){return t>b?t*t*t:x*(t-_)}function c(t){return 255*(t<=.0031308?12.92*t:1.055*Math.pow(t,1/2.4)-.055)}function s(t){return(t/=255)<=.04045?t/12.92:Math.pow((t+.055)/1.055,2.4)}function l(t){if(t instanceof p)return new p(t.h,t.c,t.l,t.opacity);t instanceof o||(t=r(t));var e=Math.atan2(t.b,t.a)*v.a;return new p(e<0?e+360:e,Math.sqrt(t.a*t.a+t.b*t.b),t.l,t.opacity)}function f(t,e,n,r){return 1===arguments.length?l(t):new p(t,e,n,null==r?1:r)}function p(t,e,n,r){this.h=+t,this.c=+e,this.l=+n,this.opacity=+r}e.a=i,e.b=f;var h=n(62),d=n(61),v=n(113),g=.95047,m=1,y=1.08883,_=4/29,b=6/29,x=3*b*b,w=b*b*b;n.i(h.a)(o,i,n.i(h.b)(d.f,{brighter:function(t){return new o(this.l+18*(null==t?1:t),this.a,this.b,this.opacity)},darker:function(t){return new o(this.l-18*(null==t?1:t),this.a,this.b,this.opacity)},rgb:function(){var t=(this.l+16)/116,e=isNaN(this.a)?t:t+this.a/500,n=isNaN(this.b)?t:t-this.b/200;return t=m*u(t),e=g*u(e),n=y*u(n),new d.d(c(3.2404542*e-1.5371385*t-.4985314*n),c(-.969266*e+1.8760108*t+.041556*n),c(.0556434*e-.2040259*t+1.0572252*n),this.opacity)}})),n.i(h.a)(p,f,n.i(h.b)(d.f,{brighter:function(t){return new p(this.h,this.c,this.l+18*(null==t?1:t),this.opacity)},darker:function(t){return new p(this.h,this.c,this.l-18*(null==t?1:t),this.opacity)},rgb:function(){return r(this).rgb()}}))},function(t,e,n){\"use strict\";function r(t){return i=n.i(u.a)(t),o=i.format,a=i.formatPrefix,i}n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a}),e.a=r;var i,o,a,u=n(117);r({decimal:\".\",thousands:\",\",grouping:[3],currency:[\"$\",\"\"]})},function(t,e,n){\"use strict\";e.a=function(t,e){t=t.toPrecision(e);t:for(var n,r=t.length,i=1,o=-1;i<r;++i)switch(t[i]){case\".\":o=n=i;break;case\"0\":0===o&&(o=i),n=i;break;case\"e\":break t;default:o>0&&(o=0)}return o>0?t.slice(0,o)+t.slice(n+1):t}},function(t,e,n){\"use strict\";e.a=function(t,e){return function(n,r){for(var i=n.length,o=[],a=0,u=t[0],c=0;i>0&&u>0&&(c+u+1>r&&(u=Math.max(1,r-c)),o.push(n.substring(i-=u,i+u)),!((c+=u+1)>r));)u=t[a=(a+1)%t.length];return o.reverse().join(e)}}},function(t,e,n){\"use strict\";e.a=function(t){return function(e){return e.replace(/[0-9]/g,function(e){return t[+e]})}}},function(t,e,n){\"use strict\";var r=n(63);e.a=function(t,e){var i=n.i(r.a)(t,e);if(!i)return t+\"\";var o=i[0],a=i[1];return a<0?\"0.\"+new Array(-a).join(\"0\")+o:o.length>a+1?o.slice(0,a+1)+\".\"+o.slice(a+1):o+new Array(a-o.length+2).join(\"0\")}},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t){return Math.max(0,-n.i(r.a)(Math.abs(t)))}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t,e){return Math.max(0,3*Math.max(-8,Math.min(8,Math.floor(n.i(r.a)(e)/3)))-n.i(r.a)(Math.abs(t)))}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t,e){return t=Math.abs(t),e=Math.abs(e)-t,Math.max(0,n.i(r.a)(e)-n.i(r.a)(t))+1}},function(t,e,n){\"use strict\";function r(t){return function e(r){function a(e,a){var u=t((e=n.i(i.cubehelix)(e)).h,(a=n.i(i.cubehelix)(a)).h),c=n.i(o.a)(e.s,a.s),s=n.i(o.a)(e.l,a.l),l=n.i(o.a)(e.opacity,a.opacity);return function(t){return e.h=u(t),e.s=c(t),e.l=s(Math.pow(t,r)),e.opacity=l(t),e+\"\"}}return r=+r,a.gamma=e,a}(1)}n.d(e,\"a\",function(){return a});var i=n(10),o=n(31),a=(r(o.b),r(o.a))},function(t,e,n){\"use strict\";function r(t){return function(e,r){var a=t((e=n.i(i.hcl)(e)).h,(r=n.i(i.hcl)(r)).h),u=n.i(o.a)(e.c,r.c),c=n.i(o.a)(e.l,r.l),s=n.i(o.a)(e.opacity,r.opacity);return function(t){return e.h=a(t),e.c=u(t),e.l=c(t),e.opacity=s(t),e+\"\"}}}var i=n(10),o=n(31);r(o.b),r(o.a)},function(t,e,n){\"use strict\";function r(t){return function(e,r){var a=t((e=n.i(i.hsl)(e)).h,(r=n.i(i.hsl)(r)).h),u=n.i(o.a)(e.s,r.s),c=n.i(o.a)(e.l,r.l),s=n.i(o.a)(e.opacity,r.opacity);return function(t){return e.h=a(t),e.s=u(t),e.l=c(t),e.opacity=s(t),e+\"\"}}}var i=n(10),o=n(31);r(o.b),r(o.a)},function(t,e,n){\"use strict\";n(10),n(31)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";e.a=function(t,e){return t=+t,e-=t,function(n){return Math.round(t+e*n)}}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return i});var r=180/Math.PI,i={translateX:0,translateY:0,rotate:0,skewX:0,scaleX:1,scaleY:1};e.b=function(t,e,n,i,o,a){var u,c,s;return(u=Math.sqrt(t*t+e*e))&&(t/=u,e/=u),(s=t*n+e*i)&&(n-=t*s,i-=e*s),(c=Math.sqrt(n*n+i*i))&&(n/=c,i/=c,s/=c),t*i<e*n&&(t=-t,e=-e,s=-s,u=-u),{translateX:o,translateY:a,rotate:Math.atan2(e,t)*r,skewX:Math.atan(s)*r,scaleX:u,scaleY:c}}},function(t,e,n){\"use strict\";function r(t,e,r,o){function a(t){return t.length?t.pop()+\" \":\"\"}function u(t,o,a,u,c,s){if(t!==a||o!==u){var l=c.push(\"translate(\",null,e,null,r);s.push({i:l-4,x:n.i(i.a)(t,a)},{i:l-2,x:n.i(i.a)(o,u)})}else(a||u)&&c.push(\"translate(\"+a+e+u+r)}function c(t,e,r,u){t!==e?(t-e>180?e+=360:e-t>180&&(t+=360),u.push({i:r.push(a(r)+\"rotate(\",null,o)-2,x:n.i(i.a)(t,e)})):e&&r.push(a(r)+\"rotate(\"+e+o)}function s(t,e,r,u){t!==e?u.push({i:r.push(a(r)+\"skewX(\",null,o)-2,x:n.i(i.a)(t,e)}):e&&r.push(a(r)+\"skewX(\"+e+o)}function l(t,e,r,o,u,c){if(t!==r||e!==o){var s=u.push(a(u)+\"scale(\",null,\",\",null,\")\");c.push({i:s-4,x:n.i(i.a)(t,r)},{i:s-2,x:n.i(i.a)(e,o)})}else 1===r&&1===o||u.push(a(u)+\"scale(\"+r+\",\"+o+\")\")}return function(e,n){var r=[],i=[];return e=t(e),n=t(n),u(e.translateX,e.translateY,n.translateX,n.translateY,r,i),c(e.rotate,n.rotate,r,i),s(e.skewX,n.skewX,r,i),l(e.scaleX,e.scaleY,n.scaleX,n.scaleY,r,i),e=n=null,function(t){for(var e,n=-1,o=i.length;++n<o;)r[(e=i[n]).i]=e.x(t);return r.join(\"\")}}}var i=n(43),o=n(236);r(o.a,\"px, \",\"px)\",\"deg)\"),r(o.b,\", \",\")\",\")\")},function(t,e,n){\"use strict\";function r(t){return\"none\"===t?s.a:(o||(o=document.createElement(\"DIV\"),a=document.documentElement,u=document.defaultView),o.style.transform=t,t=u.getComputedStyle(a.appendChild(o),null).getPropertyValue(\"transform\"),a.removeChild(o),t=t.slice(7,-1).split(\",\"),n.i(s.b)(+t[0],+t[1],+t[2],+t[3],+t[4],+t[5]))}function i(t){return null==t?s.a:(c||(c=document.createElementNS(\"http://www.w3.org/2000/svg\",\"g\")),c.setAttribute(\"transform\",t),(t=c.transform.baseVal.consolidate())?(t=t.matrix,n.i(s.b)(t.a,t.b,t.c,t.d,t.e,t.f)):s.a)}e.a=r,e.b=i;var o,a,u,c,s=n(234)},function(t,e,n){\"use strict\";Math.SQRT2},function(t,e,n){\"use strict\";function r(){this._x0=this._y0=this._x1=this._y1=null,this._=\"\"}function i(){return new r}var o=Math.PI,a=2*o,u=a-1e-6;r.prototype=i.prototype={constructor:r,moveTo:function(t,e){this._+=\"M\"+(this._x0=this._x1=+t)+\",\"+(this._y0=this._y1=+e)},closePath:function(){null!==this._x1&&(this._x1=this._x0,this._y1=this._y0,this._+=\"Z\")},lineTo:function(t,e){this._+=\"L\"+(this._x1=+t)+\",\"+(this._y1=+e)},quadraticCurveTo:function(t,e,n,r){this._+=\"Q\"+ +t+\",\"+ +e+\",\"+(this._x1=+n)+\",\"+(this._y1=+r)},bezierCurveTo:function(t,e,n,r,i,o){this._+=\"C\"+ +t+\",\"+ +e+\",\"+ +n+\",\"+ +r+\",\"+(this._x1=+i)+\",\"+(this._y1=+o)},arcTo:function(t,e,n,r,i){t=+t,e=+e,n=+n,r=+r,i=+i;var a=this._x1,u=this._y1,c=n-t,s=r-e,l=a-t,f=u-e,p=l*l+f*f;if(i<0)throw new Error(\"negative radius: \"+i);if(null===this._x1)this._+=\"M\"+(this._x1=t)+\",\"+(this._y1=e);else if(p>1e-6)if(Math.abs(f*c-s*l)>1e-6&&i){var h=n-a,d=r-u,v=c*c+s*s,g=h*h+d*d,m=Math.sqrt(v),y=Math.sqrt(p),_=i*Math.tan((o-Math.acos((v+p-g)/(2*m*y)))/2),b=_/y,x=_/m;Math.abs(b-1)>1e-6&&(this._+=\"L\"+(t+b*l)+\",\"+(e+b*f)),this._+=\"A\"+i+\",\"+i+\",0,0,\"+ +(f*h>l*d)+\",\"+(this._x1=t+x*c)+\",\"+(this._y1=e+x*s)}else this._+=\"L\"+(this._x1=t)+\",\"+(this._y1=e);else;},arc:function(t,e,n,r,i,c){t=+t,e=+e,n=+n;var s=n*Math.cos(r),l=n*Math.sin(r),f=t+s,p=e+l,h=1^c,d=c?r-i:i-r;if(n<0)throw new Error(\"negative radius: \"+n);null===this._x1?this._+=\"M\"+f+\",\"+p:(Math.abs(this._x1-f)>1e-6||Math.abs(this._y1-p)>1e-6)&&(this._+=\"L\"+f+\",\"+p),n&&(d<0&&(d=d%a+a),d>u?this._+=\"A\"+n+\",\"+n+\",0,1,\"+h+\",\"+(t-s)+\",\"+(e-l)+\"A\"+n+\",\"+n+\",0,1,\"+h+\",\"+(this._x1=f)+\",\"+(this._y1=p):d>1e-6&&(this._+=\"A\"+n+\",\"+n+\",0,\"+ +(d>=o)+\",\"+h+\",\"+(this._x1=t+n*Math.cos(i))+\",\"+(this._y1=e+n*Math.sin(i))))},rect:function(t,e,n,r){this._+=\"M\"+(this._x0=this._x1=+t)+\",\"+(this._y0=this._y1=+e)+\"h\"+ +n+\"v\"+ +r+\"h\"+-n+\"Z\"},toString:function(){return this._}},e.a=i},function(t,e,n){\"use strict\";function r(){function t(){var t=c().length,r=l[1]<l[0],o=l[r-0],u=l[1-r];e=(u-o)/Math.max(1,t-p+2*h),f&&(e=Math.floor(e)),o+=(u-o-e*(t-p))*d,i=e*(1-p),f&&(o=Math.round(o),i=Math.round(i));var v=n.i(a.range)(t).map(function(t){return o+e*t});return s(r?v.reverse():v)}var e,i,o=n.i(u.a)().unknown(void 0),c=o.domain,s=o.range,l=[0,1],f=!1,p=0,h=0,d=.5;return delete o.unknown,o.domain=function(e){return arguments.length?(c(e),t()):c()},o.range=function(e){return arguments.length?(l=[+e[0],+e[1]],t()):l.slice()},o.rangeRound=function(e){return l=[+e[0],+e[1]],f=!0,t()},o.bandwidth=function(){return i},o.step=function(){return e},o.round=function(e){return arguments.length?(f=!!e,t()):f},o.padding=function(e){return arguments.length?(p=h=Math.max(0,Math.min(1,e)),t()):p},o.paddingInner=function(e){return arguments.length?(p=Math.max(0,Math.min(1,e)),t()):p},o.paddingOuter=function(e){return arguments.length?(h=Math.max(0,Math.min(1,e)),t()):h},o.align=function(e){return arguments.length?(d=Math.max(0,Math.min(1,e)),t()):d},o.copy=function(){return r().domain(c()).range(l).round(f).paddingInner(p).paddingOuter(h).align(d)},t()}function i(t){var e=t.copy;return t.padding=t.paddingOuter,delete t.paddingInner,delete t.paddingOuter,t.copy=function(){return i(e())},t}function o(){return i(r().paddingInner(1))}e.a=r,e.b=o;var a=n(7),u=n(127)},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"1f77b4ff7f0e2ca02cd627289467bd8c564be377c27f7f7fbcbd2217becf\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"1f77b4aec7e8ff7f0effbb782ca02c98df8ad62728ff98969467bdc5b0d58c564bc49c94e377c2f7b6d27f7f7fc7c7c7bcbd22dbdb8d17becf9edae5\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"393b795254a36b6ecf9c9ede6379398ca252b5cf6bcedb9c8c6d31bd9e39e7ba52e7cb94843c39ad494ad6616be7969c7b4173a55194ce6dbdde9ed6\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"3182bd6baed69ecae1c6dbefe6550dfd8d3cfdae6bfdd0a231a35474c476a1d99bc7e9c0756bb19e9ac8bcbddcdadaeb636363969696bdbdbdd9d9d9\")},function(t,e,n){\"use strict\";var r=n(10),i=n(30);e.a=n.i(i.d)(n.i(r.cubehelix)(300,.5,0),n.i(r.cubehelix)(-240,.5,1))},function(t,e,n){\"use strict\";function r(){function t(t){return+t}var e=[0,1];return t.invert=t,t.domain=t.range=function(n){return arguments.length?(e=i.a.call(n,a.a),t):e.slice()},t.copy=function(){return r().domain(e)},n.i(o.b)(t)}e.a=r;var i=n(16),o=n(34),a=n(126)},function(t,e,n){\"use strict\";function r(t,e){return(e=Math.log(e/t))?function(n){return Math.log(n/t)/e}:n.i(p.a)(e)}function i(t,e){return t<0?function(n){return-Math.pow(-e,n)*Math.pow(-t,1-n)}:function(n){return Math.pow(e,n)*Math.pow(t,1-n)}}function o(t){return isFinite(t)?+(\"1e\"+t):t<0?0:t}function a(t){return 10===t?o:t===Math.E?Math.exp:function(e){return Math.pow(t,e)}}function u(t){return t===Math.E?Math.log:10===t&&Math.log10||2===t&&Math.log2||(t=Math.log(t),function(e){return Math.log(e)/t})}function c(t){return function(e){return-t(-e)}}function s(){function t(){return v=u(p),g=a(p),o()[0]<0&&(v=c(v),g=c(g)),e}var e=n.i(d.a)(r,i).domain([1,10]),o=e.domain,p=10,v=u(10),g=a(10);return e.base=function(e){return arguments.length?(p=+e,t()):p},e.domain=function(e){return arguments.length?(o(e),t()):o()},e.ticks=function(t){var e,r=o(),i=r[0],a=r[r.length-1];(e=a<i)&&(f=i,i=a,a=f);var u,c,s,f=v(i),h=v(a),d=null==t?10:+t,m=[];if(!(p%1)&&h-f<d){if(f=Math.round(f)-1,h=Math.round(h)+1,i>0){for(;f<h;++f)for(c=1,u=g(f);c<p;++c)if(!((s=u*c)<i)){if(s>a)break;m.push(s)}}else for(;f<h;++f)for(c=p-1,u=g(f);c>=1;--c)if(!((s=u*c)<i)){if(s>a)break;m.push(s)}}else m=n.i(l.ticks)(f,h,Math.min(h-f,d)).map(g);return e?m.reverse():m},e.tickFormat=function(t,r){if(null==r&&(r=10===p?\".0e\":\",\"),\"function\"!=typeof r&&(r=n.i(f.format)(r)),t===1/0)return r;null==t&&(t=10);var i=Math.max(1,p*t/e.ticks().length);return function(t){var e=t/g(Math.round(v(t)));return e*p<p-.5&&(e*=p),e<=i?r(t):\"\"}},e.nice=function(){return o(n.i(h.a)(o(),{floor:function(t){return g(Math.floor(v(t)))},ceil:function(t){return g(Math.ceil(v(t)))}}))},e.copy=function(){return n.i(d.c)(e,s().base(p))},e}e.a=s;var l=n(7),f=n(29),p=n(67),h=n(125),d=n(44)},function(t,e,n){\"use strict\";function r(t,e){return t<0?-Math.pow(-t,e):Math.pow(t,e)}function i(){function t(t,e){return(e=r(e,o)-(t=r(t,o)))?function(n){return(r(n,o)-t)/e}:n.i(a.a)(e)}function e(t,e){return e=r(e,o)-(t=r(t,o)),function(n){return r(t+e*n,1/o)}}var o=1,s=n.i(c.a)(t,e),l=s.domain;return s.exponent=function(t){return arguments.length?(o=+t,l(l())):o},s.copy=function(){return n.i(c.c)(s,i().exponent(o))},n.i(u.b)(s)}function o(){return i().exponent(.5)}e.a=i,e.b=o;var a=n(67),u=n(34),c=n(44)},function(t,e,n){\"use strict\";function r(){function t(){var t=0,r=Math.max(1,u.length);for(c=new Array(r-1);++t<r;)c[t-1]=n.i(i.quantile)(a,t/r);return e}function e(t){if(!isNaN(t=+t))return u[n.i(i.bisect)(c,t)]}var a=[],u=[],c=[];return e.invertExtent=function(t){var e=u.indexOf(t);return e<0?[NaN,NaN]:[e>0?c[e-1]:a[0],e<c.length?c[e]:a[a.length-1]]},e.domain=function(e){if(!arguments.length)return a.slice();a=[];for(var n,r=0,o=e.length;r<o;++r)null==(n=e[r])||isNaN(n=+n)||a.push(n);return a.sort(i.ascending),t()},e.range=function(e){return arguments.length?(u=o.b.call(e),t()):u.slice()},e.quantiles=function(){return c.slice()},e.copy=function(){return r().domain(a).range(u)},e}e.a=r;var i=n(7),o=n(16)},function(t,e,n){\"use strict\";function r(){function t(t){if(t<=t)return f[n.i(i.bisect)(l,t,0,s)]}function e(){var e=-1;for(l=new Array(s);++e<s;)l[e]=((e+1)*c-(e-s)*u)/(s+1);return t}var u=0,c=1,s=1,l=[.5],f=[0,1];return t.domain=function(t){return arguments.length?(u=+t[0],c=+t[1],e()):[u,c]},t.range=function(t){return arguments.length?(s=(f=o.b.call(t)).length-1,e()):f.slice()},t.invertExtent=function(t){var e=f.indexOf(t);return e<0?[NaN,NaN]:e<1?[u,l[0]]:e>=s?[l[s-1],c]:[l[e-1],l[e]]},t.copy=function(){return r().domain([u,c]).range(f)},n.i(a.b)(t)}e.a=r;var i=n(7),o=n(16),a=n(34)},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a});var r=n(10),i=n(30),o=n.i(i.d)(n.i(r.cubehelix)(-100,.75,.35),n.i(r.cubehelix)(80,1.5,.8)),a=n.i(i.d)(n.i(r.cubehelix)(260,.75,.35),n.i(r.cubehelix)(80,1.5,.8)),u=n.i(r.cubehelix)();e.a=function(t){(t<0||t>1)&&(t-=Math.floor(t));var e=Math.abs(t-.5);return u.h=360*t-100,u.s=1.5-1.5*e,u.l=.8-.9*e,u+\"\"}},function(t,e,n){\"use strict\";function r(t){function e(e){var n=(e-o)/(a-o);return t(u?Math.max(0,Math.min(1,n)):n)}var o=0,a=1,u=!1;return e.domain=function(t){return arguments.length?(o=+t[0],a=+t[1],e):[o,a]},e.clamp=function(t){return arguments.length?(u=!!t,e):u},e.interpolator=function(n){return arguments.length?(t=n,e):t},e.copy=function(){return r(t).domain([o,a]).clamp(u)},n.i(i.b)(e)}e.a=r;var i=n(34)},function(t,e,n){\"use strict\";function r(){function t(t){if(t<=t)return a[n.i(i.bisect)(e,t,0,u)]}var e=[.5],a=[0,1],u=1;return t.domain=function(n){return arguments.length?(e=o.b.call(n),u=Math.min(e.length,a.length-1),t):e.slice()},t.range=function(n){return arguments.length?(a=o.b.call(n),u=Math.min(e.length,a.length-1),t):a.slice()},t.invertExtent=function(t){var n=a.indexOf(t);return[e[n-1],e[n]]},t.copy=function(){return r().domain(e).range(a)},t}e.a=r;var i=n(7),o=n(16)},function(t,e,n){\"use strict\";var r=n(7),i=n(29);e.a=function(t,e,o){var a,u=t[0],c=t[t.length-1],s=n.i(r.tickStep)(u,c,null==e?10:e);switch(o=n.i(i.formatSpecifier)(null==o?\",f\":o),o.type){case\"s\":var l=Math.max(Math.abs(u),Math.abs(c));return null!=o.precision||isNaN(a=n.i(i.precisionPrefix)(s,l))||(o.precision=a),n.i(i.formatPrefix)(o,l);case\"\":case\"e\":case\"g\":case\"p\":case\"r\":null!=o.precision||isNaN(a=n.i(i.precisionRound)(s,Math.max(Math.abs(u),Math.abs(c))))||(o.precision=a-(\"e\"===o.type));break;case\"f\":case\"%\":null!=o.precision||isNaN(a=n.i(i.precisionFixed)(s))||(o.precision=a-2*(\"%\"===o.type))}return n.i(i.format)(o)}},function(t,e,n){\"use strict\";var r=n(128),i=n(78),o=n(80);e.a=function(){return n.i(r.b)(o.h,o.k,o.l,o.b,o.m,o.n,o.o,o.p,i.utcFormat).domain([Date.UTC(2e3,0,1),Date.UTC(2e3,0,2)])}},function(t,e,n){\"use strict\";function r(t){var e=t.length;return function(n){return t[Math.max(0,Math.min(e-1,Math.floor(n*e)))]}}n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a}),n.d(e,\"d\",function(){return u});var i=n(33);e.a=r(n.i(i.a)(\"44015444025645045745055946075a46085c460a5d460b5e470d60470e6147106347116447136548146748166848176948186a481a6c481b6d481c6e481d6f481f70482071482173482374482475482576482677482878482979472a7a472c7a472d7b472e7c472f7d46307e46327e46337f463480453581453781453882443983443a83443b84433d84433e85423f854240864241864142874144874045884046883f47883f48893e49893e4a893e4c8a3d4d8a3d4e8a3c4f8a3c508b3b518b3b528b3a538b3a548c39558c39568c38588c38598c375a8c375b8d365c8d365d8d355e8d355f8d34608d34618d33628d33638d32648e32658e31668e31678e31688e30698e306a8e2f6b8e2f6c8e2e6d8e2e6e8e2e6f8e2d708e2d718e2c718e2c728e2c738e2b748e2b758e2a768e2a778e2a788e29798e297a8e297b8e287c8e287d8e277e8e277f8e27808e26818e26828e26828e25838e25848e25858e24868e24878e23888e23898e238a8d228b8d228c8d228d8d218e8d218f8d21908d21918c20928c20928c20938c1f948c1f958b1f968b1f978b1f988b1f998a1f9a8a1e9b8a1e9c891e9d891f9e891f9f881fa0881fa1881fa1871fa28720a38620a48621a58521a68522a78522a88423a98324aa8325ab8225ac8226ad8127ad8128ae8029af7f2ab07f2cb17e2db27d2eb37c2fb47c31b57b32b67a34b67935b77937b87838b9773aba763bbb753dbc743fbc7340bd7242be7144bf7046c06f48c16e4ac16d4cc26c4ec36b50c46a52c56954c56856c66758c7655ac8645cc8635ec96260ca6063cb5f65cb5e67cc5c69cd5b6ccd5a6ece5870cf5773d05675d05477d1537ad1517cd2507fd34e81d34d84d44b86d54989d5488bd6468ed64590d74393d74195d84098d83e9bd93c9dd93ba0da39a2da37a5db36a8db34aadc32addc30b0dd2fb2dd2db5de2bb8de29bade28bddf26c0df25c2df23c5e021c8e020cae11fcde11dd0e11cd2e21bd5e21ad8e219dae319dde318dfe318e2e418e5e419e7e419eae51aece51befe51cf1e51df4e61ef6e620f8e621fbe723fde725\"));var o=r(n.i(i.a)(\"00000401000501010601010802010902020b02020d03030f03031204041405041606051806051a07061c08071e0907200a08220b09240c09260d0a290e0b2b100b2d110c2f120d31130d34140e36150e38160f3b180f3d19103f1a10421c10441d11471e114920114b21114e22115024125325125527125829115a2a115c2c115f2d11612f116331116533106734106936106b38106c390f6e3b0f703d0f713f0f72400f74420f75440f764510774710784910784a10794c117a4e117b4f127b51127c52137c54137d56147d57157e59157e5a167e5c167f5d177f5f187f601880621980641a80651a80671b80681c816a1c816b1d816d1d816e1e81701f81721f817320817521817621817822817922827b23827c23827e24828025828125818326818426818627818827818928818b29818c29818e2a81902a81912b81932b80942c80962c80982d80992d809b2e7f9c2e7f9e2f7fa02f7fa1307ea3307ea5317ea6317da8327daa337dab337cad347cae347bb0357bb2357bb3367ab5367ab73779b83779ba3878bc3978bd3977bf3a77c03a76c23b75c43c75c53c74c73d73c83e73ca3e72cc3f71cd4071cf4070d0416fd2426fd3436ed5446dd6456cd8456cd9466bdb476adc4869de4968df4a68e04c67e24d66e34e65e44f64e55064e75263e85362e95462ea5661eb5760ec5860ed5a5fee5b5eef5d5ef05f5ef1605df2625df2645cf3655cf4675cf4695cf56b5cf66c5cf66e5cf7705cf7725cf8745cf8765cf9785df9795df97b5dfa7d5efa7f5efa815ffb835ffb8560fb8761fc8961fc8a62fc8c63fc8e64fc9065fd9266fd9467fd9668fd9869fd9a6afd9b6bfe9d6cfe9f6dfea16efea36ffea571fea772fea973feaa74feac76feae77feb078feb27afeb47bfeb67cfeb77efeb97ffebb81febd82febf84fec185fec287fec488fec68afec88cfeca8dfecc8ffecd90fecf92fed194fed395fed597fed799fed89afdda9cfddc9efddea0fde0a1fde2a3fde3a5fde5a7fde7a9fde9aafdebacfcecaefceeb0fcf0b2fcf2b4fcf4b6fcf6b8fcf7b9fcf9bbfcfbbdfcfdbf\")),a=r(n.i(i.a)(\"00000401000501010601010802010a02020c02020e03021004031204031405041706041907051b08051d09061f0a07220b07240c08260d08290e092b10092d110a30120a32140b34150b37160b39180c3c190c3e1b0c411c0c431e0c451f0c48210c4a230c4c240c4f260c51280b53290b552b0b572d0b592f0a5b310a5c320a5e340a5f3609613809623909633b09643d09653e0966400a67420a68440a68450a69470b6a490b6a4a0c6b4c0c6b4d0d6c4f0d6c510e6c520e6d540f6d550f6d57106e59106e5a116e5c126e5d126e5f136e61136e62146e64156e65156e67166e69166e6a176e6c186e6d186e6f196e71196e721a6e741a6e751b6e771c6d781c6d7a1d6d7c1d6d7d1e6d7f1e6c801f6c82206c84206b85216b87216b88226a8a226a8c23698d23698f24699025689225689326679526679727669827669a28659b29649d29649f2a63a02a63a22b62a32c61a52c60a62d60a82e5fa92e5eab2f5ead305dae305cb0315bb1325ab3325ab43359b63458b73557b93556ba3655bc3754bd3853bf3952c03a51c13a50c33b4fc43c4ec63d4dc73e4cc83f4bca404acb4149cc4248ce4347cf4446d04545d24644d34743d44842d54a41d74b3fd84c3ed94d3dda4e3cdb503bdd513ade5238df5337e05536e15635e25734e35933e45a31e55c30e65d2fe75e2ee8602de9612bea632aeb6429eb6628ec6726ed6925ee6a24ef6c23ef6e21f06f20f1711ff1731df2741cf3761bf37819f47918f57b17f57d15f67e14f68013f78212f78410f8850ff8870ef8890cf98b0bf98c0af98e09fa9008fa9207fa9407fb9606fb9706fb9906fb9b06fb9d07fc9f07fca108fca309fca50afca60cfca80dfcaa0ffcac11fcae12fcb014fcb216fcb418fbb61afbb81dfbba1ffbbc21fbbe23fac026fac228fac42afac62df9c72ff9c932f9cb35f8cd37f8cf3af7d13df7d340f6d543f6d746f5d949f5db4cf4dd4ff4df53f4e156f3e35af3e55df2e661f2e865f2ea69f1ec6df1ed71f1ef75f1f179f2f27df2f482f3f586f3f68af4f88ef5f992f6fa96f8fb9af9fc9dfafda1fcffa4\")),u=r(n.i(i.a)(\"0d088710078813078916078a19068c1b068d1d068e20068f2206902406912605912805922a05932c05942e05952f059631059733059735049837049938049a3a049a3c049b3e049c3f049c41049d43039e44039e46039f48039f4903a04b03a14c02a14e02a25002a25102a35302a35502a45601a45801a45901a55b01a55c01a65e01a66001a66100a76300a76400a76600a76700a86900a86a00a86c00a86e00a86f00a87100a87201a87401a87501a87701a87801a87a02a87b02a87d03a87e03a88004a88104a78305a78405a78606a68707a68808a68a09a58b0aa58d0ba58e0ca48f0da4910ea3920fa39410a29511a19613a19814a099159f9a169f9c179e9d189d9e199da01a9ca11b9ba21d9aa31e9aa51f99a62098a72197a82296aa2395ab2494ac2694ad2793ae2892b02991b12a90b22b8fb32c8eb42e8db52f8cb6308bb7318ab83289ba3388bb3488bc3587bd3786be3885bf3984c03a83c13b82c23c81c33d80c43e7fc5407ec6417dc7427cc8437bc9447aca457acb4679cc4778cc4977cd4a76ce4b75cf4c74d04d73d14e72d24f71d35171d45270d5536fd5546ed6556dd7566cd8576bd9586ada5a6ada5b69db5c68dc5d67dd5e66de5f65de6164df6263e06363e16462e26561e26660e3685fe4695ee56a5de56b5de66c5ce76e5be76f5ae87059e97158e97257ea7457eb7556eb7655ec7754ed7953ed7a52ee7b51ef7c51ef7e50f07f4ff0804ef1814df1834cf2844bf3854bf3874af48849f48948f58b47f58c46f68d45f68f44f79044f79143f79342f89441f89540f9973ff9983ef99a3efa9b3dfa9c3cfa9e3bfb9f3afba139fba238fca338fca537fca636fca835fca934fdab33fdac33fdae32fdaf31fdb130fdb22ffdb42ffdb52efeb72dfeb82cfeba2cfebb2bfebd2afebe2afec029fdc229fdc328fdc527fdc627fdc827fdca26fdcb26fccd25fcce25fcd025fcd225fbd324fbd524fbd724fad824fada24f9dc24f9dd25f8df25f8e125f7e225f7e425f6e626f6e826f5e926f5eb27f4ed27f3ee27f3f027f2f227f1f426f1f525f0f724f0f921\"))},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";var r=n(45),i=n(131);e.a=function(t){return n.i(i.a)(n.i(r.a)(t).call(document.documentElement))}},function(t,e,n){\"use strict\";function r(){return new i}function i(){this._=\"@\"+(++o).toString(36)}e.a=r;var o=0;i.prototype=r.prototype={constructor:i,get:function(t){for(var e=this._;!(e in t);)if(!(t=t.parentNode))return;return t[e]},set:function(t,e){return t[this._]=e},remove:function(t){return this._ in t&&delete t[this._]},toString:function(){return this._}}},function(t,e,n){\"use strict\";var r=n(72),i=n(46);e.a=function(t){var e=n.i(r.a)();return e.changedTouches&&(e=e.changedTouches[0]),n.i(i.a)(t,e)}},function(t,e,n){\"use strict\";var r=n(8);e.a=function(t){return\"string\"==typeof t?new r.b([document.querySelectorAll(t)],[document.documentElement]):new r.b([null==t?[]:t],r.c)}},function(t,e,n){\"use strict\";var r=n(45);e.a=function(t){var e=\"function\"==typeof t?t:n.i(r.a)(t);return this.select(function(){return this.appendChild(e.apply(this,arguments))})}},function(t,e,n){\"use strict\";function r(t){return function(){this.removeAttribute(t)}}function i(t){return function(){this.removeAttributeNS(t.space,t.local)}}function o(t,e){return function(){this.setAttribute(t,e)}}function a(t,e){return function(){this.setAttributeNS(t.space,t.local,e)}}function u(t,e){return function(){var n=e.apply(this,arguments);null==n?this.removeAttribute(t):this.setAttribute(t,n)}}function c(t,e){return function(){var n=e.apply(this,arguments);null==n?this.removeAttributeNS(t.space,t.local):this.setAttributeNS(t.space,t.local,n)}}var s=n(68);e.a=function(t,e){var l=n.i(s.a)(t);if(arguments.length<2){var f=this.node();return l.local?f.getAttributeNS(l.space,l.local):f.getAttribute(l)}return this.each((null==e?l.local?i:r:\"function\"==typeof e?l.local?c:u:l.local?a:o)(l,e))}},function(t,e,n){\"use strict\";e.a=function(){var t=arguments[0];return arguments[0]=this,t.apply(null,arguments),this}},function(t,e,n){\"use strict\";function r(t){return t.trim().split(/^|\\s+/)}function i(t){return t.classList||new o(t)}function o(t){this._node=t,this._names=r(t.getAttribute(\"class\")||\"\")}function a(t,e){for(var n=i(t),r=-1,o=e.length;++r<o;)n.add(e[r])}function u(t,e){for(var n=i(t),r=-1,o=e.length;++r<o;)n.remove(e[r])}function c(t){return function(){a(this,t)}}function s(t){return function(){u(this,t)}}function l(t,e){return function(){(e.apply(this,arguments)?a:u)(this,t)}}o.prototype={add:function(t){this._names.indexOf(t)<0&&(this._names.push(t),this._node.setAttribute(\"class\",this._names.join(\" \")))},remove:function(t){var e=this._names.indexOf(t);e>=0&&(this._names.splice(e,1),this._node.setAttribute(\"class\",this._names.join(\" \")))},contains:function(t){return this._names.indexOf(t)>=0}},e.a=function(t,e){var n=r(t+\"\");if(arguments.length<2){for(var o=i(this.node()),a=-1,u=n.length;++a<u;)if(!o.contains(n[a]))return!1;return!0}return this.each((\"function\"==typeof e?l:e?c:s)(n,e))}},function(t,e,n){\"use strict\";function r(){return this.parentNode.insertBefore(this.cloneNode(!1),this.nextSibling)}function i(){return this.parentNode.insertBefore(this.cloneNode(!0),this.nextSibling)}e.a=function(t){return this.select(t?i:r)}},function(t,e,n){\"use strict\";function r(t,e,n,r,i,o){for(var u,c=0,s=e.length,l=o.length;c<l;++c)(u=e[c])?(u.__data__=o[c],r[c]=u):n[c]=new a.b(t,o[c]);for(;c<s;++c)(u=e[c])&&(i[c]=u)}function i(t,e,n,r,i,o,u){var s,l,f,p={},h=e.length,d=o.length,v=new Array(h);for(s=0;s<h;++s)(l=e[s])&&(v[s]=f=c+u.call(l,l.__data__,s,e),f in p?i[s]=l:p[f]=l);for(s=0;s<d;++s)f=c+u.call(t,o[s],s,o),(l=p[f])?(r[s]=l,l.__data__=o[s],p[f]=null):n[s]=new a.b(t,o[s]);for(s=0;s<h;++s)(l=e[s])&&p[v[s]]===l&&(i[s]=l)}var o=n(8),a=n(132),u=n(256),c=\"$\";e.a=function(t,e){if(!t)return y=new Array(this.size()),d=-1,this.each(function(t){y[++d]=t}),y;var a=e?i:r,c=this._parents,s=this._groups;\"function\"!=typeof t&&(t=n.i(u.a)(t));for(var l=s.length,f=new Array(l),p=new Array(l),h=new Array(l),d=0;d<l;++d){var v=c[d],g=s[d],m=g.length,y=t.call(v,v&&v.__data__,d,c),_=y.length,b=p[d]=new Array(_),x=f[d]=new Array(_);a(v,g,b,x,h[d]=new Array(m),y,e);for(var w,C,k=0,E=0;k<_;++k)if(w=b[k]){for(k>=E&&(E=k+1);!(C=x[E])&&++E<_;);w._next=C||null}}return f=new o.b(f,c),f._enter=p,f._exit=h,f}},function(t,e,n){\"use strict\";e.a=function(t){return arguments.length?this.property(\"__data__\",t):this.node().__data__}},function(t,e,n){\"use strict\";function r(t,e,r){var i=n.i(a.a)(t),o=i.CustomEvent;\"function\"==typeof o?o=new o(e,r):(o=i.document.createEvent(\"Event\"),r?(o.initEvent(e,r.bubbles,r.cancelable),o.detail=r.detail):o.initEvent(e,!1,!1)),t.dispatchEvent(o)}function i(t,e){return function(){return r(this,t,e)}}function o(t,e){return function(){return r(this,t,e.apply(this,arguments))}}var a=n(73);e.a=function(t,e){return this.each((\"function\"==typeof e?o:i)(t,e))}},function(t,e,n){\"use strict\";e.a=function(t){for(var e=this._groups,n=0,r=e.length;n<r;++n)for(var i,o=e[n],a=0,u=o.length;a<u;++a)(i=o[a])&&t.call(i,i.__data__,a,o);return this}},function(t,e,n){\"use strict\";e.a=function(){return!this.node()}},function(t,e,n){\"use strict\";var r=n(133),i=n(8);e.a=function(){return new i.b(this._exit||this._groups.map(r.a),this._parents)}},function(t,e,n){\"use strict\";var r=n(8),i=n(130);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=new Array(o),u=0;u<o;++u)for(var c,s=e[u],l=s.length,f=a[u]=[],p=0;p<l;++p)(c=s[p])&&t.call(c,c.__data__,p,s)&&f.push(c);return new r.b(a,this._parents)}},function(t,e,n){\"use strict\";function r(){this.innerHTML=\"\"}function i(t){return function(){this.innerHTML=t}}function o(t){return function(){var e=t.apply(this,arguments);this.innerHTML=null==e?\"\":e}}e.a=function(t){return arguments.length?this.each(null==t?r:(\"function\"==typeof t?o:i)(t)):this.node().innerHTML}},function(t,e,n){\"use strict\";function r(){return null}var i=n(45),o=n(71);e.a=function(t,e){var a=\"function\"==typeof t?t:n.i(i.a)(t),u=null==e?r:\"function\"==typeof e?e:n.i(o.a)(e);return this.select(function(){return this.insertBefore(a.apply(this,arguments),u.apply(this,arguments)||null)})}},function(t,e,n){\"use strict\";function r(){this.previousSibling&&this.parentNode.insertBefore(this,this.parentNode.firstChild)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";var r=n(8);e.a=function(t){for(var e=this._groups,n=t._groups,i=e.length,o=n.length,a=Math.min(i,o),u=new Array(i),c=0;c<a;++c)for(var s,l=e[c],f=n[c],p=l.length,h=u[c]=new Array(p),d=0;d<p;++d)(s=l[d]||f[d])&&(h[d]=s);for(;c<i;++c)u[c]=e[c];return new r.b(u,this._parents)}},function(t,e,n){\"use strict\";e.a=function(){for(var t=this._groups,e=0,n=t.length;e<n;++e)for(var r=t[e],i=0,o=r.length;i<o;++i){var a=r[i];if(a)return a}return null}},function(t,e,n){\"use strict\";e.a=function(){var t=new Array(this.size()),e=-1;return this.each(function(){t[++e]=this}),t}},function(t,e,n){\"use strict\";e.a=function(){for(var t=this._groups,e=-1,n=t.length;++e<n;)for(var r,i=t[e],o=i.length-1,a=i[o];--o>=0;)(r=i[o])&&(a&&a!==r.nextSibling&&a.parentNode.insertBefore(r,a),a=r);return this}},function(t,e,n){\"use strict\";function r(t){return function(){delete this[t]}}function i(t,e){return function(){this[t]=e}}function o(t,e){return function(){var n=e.apply(this,arguments);null==n?delete this[t]:this[t]=n}}e.a=function(t,e){return arguments.length>1?this.each((null==e?r:\"function\"==typeof e?o:i)(t,e)):this.node()[t]}},function(t,e,n){\"use strict\";function r(){this.nextSibling&&this.parentNode.appendChild(this)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";function r(){var t=this.parentNode;t&&t.removeChild(this)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";var r=n(8),i=n(71);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=new Array(o),u=0;u<o;++u)for(var c,s,l=e[u],f=l.length,p=a[u]=new Array(f),h=0;h<f;++h)(c=l[h])&&(s=t.call(c,c.__data__,h,l))&&(\"__data__\"in c&&(s.__data__=c.__data__),p[h]=s);return new r.b(a,this._parents)}},function(t,e,n){\"use strict\";var r=n(8),i=n(135);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=[],u=[],c=0;c<o;++c)for(var s,l=e[c],f=l.length,p=0;p<f;++p)(s=l[p])&&(a.push(t.call(s,s.__data__,p,l)),u.push(s));return new r.b(a,u)}},function(t,e,n){\"use strict\";e.a=function(){var t=0;return this.each(function(){++t}),t}},function(t,e,n){\"use strict\";function r(t,e){return t<e?-1:t>e?1:t>=e?0:NaN}var i=n(8);e.a=function(t){function e(e,n){return e&&n?t(e.__data__,n.__data__):!e-!n}t||(t=r);for(var n=this._groups,o=n.length,a=new Array(o),u=0;u<o;++u){for(var c,s=n[u],l=s.length,f=a[u]=new Array(l),p=0;p<l;++p)(c=s[p])&&(f[p]=c);f.sort(e)}return new i.b(a,this._parents).order()}},function(t,e,n){\"use strict\";function r(){this.textContent=\"\"}function i(t){return function(){this.textContent=t}}function o(t){return function(){var e=t.apply(this,arguments);this.textContent=null==e?\"\":e}}e.a=function(t){return arguments.length?this.each(null==t?r:(\"function\"==typeof t?o:i)(t)):this.node().textContent}},function(t,e,n){\"use strict\";var r=n(72),i=n(46);e.a=function(t,e,o){arguments.length<3&&(o=e,e=n.i(r.a)().changedTouches);for(var a,u=0,c=e?e.length:0;u<c;++u)if((a=e[u]).identifier===o)return n.i(i.a)(t,a);return null}},function(t,e,n){\"use strict\";var r=n(72),i=n(46);e.a=function(t,e){null==e&&(e=n.i(r.a)().touches);for(var o=0,a=e?e.length:0,u=new Array(a);o<a;++o)u[o]=n.i(i.a)(t,e[o]);return u}},function(t,e,n){\"use strict\";function r(t){return t.innerRadius}function i(t){return t.outerRadius}function o(t){return t.startAngle}function a(t){return t.endAngle}function u(t){return t&&t.padAngle}function c(t,e,n,r,i,o,a,u){var c=n-t,s=r-e,l=a-i,f=u-o,p=(l*(e-o)-f*(t-i))/(f*c-l*s);return[t+p*c,e+p*s]}function s(t,e,r,i,o,a,u){var c=t-r,s=e-i,l=(u?a:-a)/n.i(p.d)(c*c+s*s),f=l*s,h=-l*c,d=t+f,v=e+h,g=r+f,m=i+h,y=(d+g)/2,_=(v+m)/2,b=g-d,x=m-v,w=b*b+x*x,C=o-a,k=d*m-g*v,E=(x<0?-1:1)*n.i(p.d)(n.i(p.e)(0,C*C*w-k*k)),M=(k*x-b*E)/w,T=(-k*b-x*E)/w,S=(k*x+b*E)/w,N=(-k*b+x*E)/w,A=M-y,P=T-_,O=S-y,I=N-_;return A*A+P*P>O*O+I*I&&(M=S,T=N),{cx:M,cy:T,x01:-f,y01:-h,x11:M*(o/C-1),y11:T*(o/C-1)}}var l=n(32),f=n(17),p=n(35);e.a=function(){function t(){var t,r,i=+e.apply(this,arguments),o=+h.apply(this,arguments),a=g.apply(this,arguments)-p.f,u=m.apply(this,arguments)-p.f,f=n.i(p.g)(u-a),b=u>a;if(_||(_=t=n.i(l.a)()),o<i&&(r=o,o=i,i=r),o>p.a)if(f>p.c-p.a)_.moveTo(o*n.i(p.h)(a),o*n.i(p.i)(a)),_.arc(0,0,o,a,u,!b),i>p.a&&(_.moveTo(i*n.i(p.h)(u),i*n.i(p.i)(u)),_.arc(0,0,i,u,a,b));else{var x,w,C=a,k=u,E=a,M=u,T=f,S=f,N=y.apply(this,arguments)/2,A=N>p.a&&(v?+v.apply(this,arguments):n.i(p.d)(i*i+o*o)),P=n.i(p.j)(n.i(p.g)(o-i)/2,+d.apply(this,arguments)),O=P,I=P;if(A>p.a){var D=n.i(p.k)(A/i*n.i(p.i)(N)),R=n.i(p.k)(A/o*n.i(p.i)(N));(T-=2*D)>p.a?(D*=b?1:-1,E+=D,M-=D):(T=0,E=M=(a+u)/2),(S-=2*R)>p.a?(R*=b?1:-1,C+=R,k-=R):(S=0,C=k=(a+u)/2)}var L=o*n.i(p.h)(C),U=o*n.i(p.i)(C),F=i*n.i(p.h)(M),j=i*n.i(p.i)(M);if(P>p.a){var B=o*n.i(p.h)(k),V=o*n.i(p.i)(k),W=i*n.i(p.h)(E),z=i*n.i(p.i)(E);if(f<p.b){var H=T>p.a?c(L,U,W,z,B,V,F,j):[F,j],q=L-H[0],Y=U-H[1],K=B-H[0],G=V-H[1],$=1/n.i(p.i)(n.i(p.l)((q*K+Y*G)/(n.i(p.d)(q*q+Y*Y)*n.i(p.d)(K*K+G*G)))/2),X=n.i(p.d)(H[0]*H[0]+H[1]*H[1]);O=n.i(p.j)(P,(i-X)/($-1)),I=n.i(p.j)(P,(o-X)/($+1))}}S>p.a?I>p.a?(x=s(W,z,L,U,o,I,b),w=s(B,V,F,j,o,I,b),_.moveTo(x.cx+x.x01,x.cy+x.y01),I<P?_.arc(x.cx,x.cy,I,n.i(p.m)(x.y01,x.x01),n.i(p.m)(w.y01,w.x01),!b):(_.arc(x.cx,x.cy,I,n.i(p.m)(x.y01,x.x01),n.i(p.m)(x.y11,x.x11),!b),_.arc(0,0,o,n.i(p.m)(x.cy+x.y11,x.cx+x.x11),n.i(p.m)(w.cy+w.y11,w.cx+w.x11),!b),_.arc(w.cx,w.cy,I,n.i(p.m)(w.y11,w.x11),n.i(p.m)(w.y01,w.x01),!b))):(_.moveTo(L,U),_.arc(0,0,o,C,k,!b)):_.moveTo(L,U),i>p.a&&T>p.a?O>p.a?(x=s(F,j,B,V,i,-O,b),w=s(L,U,W,z,i,-O,b),_.lineTo(x.cx+x.x01,x.cy+x.y01),O<P?_.arc(x.cx,x.cy,O,n.i(p.m)(x.y01,x.x01),n.i(p.m)(w.y01,w.x01),!b):(_.arc(x.cx,x.cy,O,n.i(p.m)(x.y01,x.x01),n.i(p.m)(x.y11,x.x11),!b),_.arc(0,0,i,n.i(p.m)(x.cy+x.y11,x.cx+x.x11),n.i(p.m)(w.cy+w.y11,w.cx+w.x11),b),_.arc(w.cx,w.cy,O,n.i(p.m)(w.y11,w.x11),n.i(p.m)(w.y01,w.x01),!b))):_.arc(0,0,i,M,E,b):_.lineTo(F,j)}else _.moveTo(0,0);if(_.closePath(),t)return _=null,t+\"\"||null}var e=r,h=i,d=n.i(f.a)(0),v=null,g=o,m=a,y=u,_=null;return t.centroid=function(){var t=(+e.apply(this,arguments)+ +h.apply(this,arguments))/2,r=(+g.apply(this,arguments)+ +m.apply(this,arguments))/2-p.b/2;return[n.i(p.h)(r)*t,n.i(p.i)(r)*t]},t.innerRadius=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(f.a)(+r),t):e},t.outerRadius=function(e){return arguments.length?(h=\"function\"==typeof e?e:n.i(f.a)(+e),t):h},t.cornerRadius=function(e){return arguments.length?(d=\"function\"==typeof e?e:n.i(f.a)(+e),t):d},t.padRadius=function(e){return arguments.length?(v=null==e?null:\"function\"==typeof e?e:n.i(f.a)(+e),t):v},t.startAngle=function(e){return arguments.length?(g=\"function\"==typeof e?e:n.i(f.a)(+e),t):g},t.endAngle=function(e){return arguments.length?(m=\"function\"==typeof e?e:n.i(f.a)(+e),t):m},t.padAngle=function(e){return arguments.length?(y=\"function\"==typeof e?e:n.i(f.a)(+e),t):y},t.context=function(e){return arguments.length?(_=null==e?null:e,t):_},t}},function(t,e,n){\"use strict\";var r=n(141),i=n(137),o=n(142);e.a=function(){var t=n.i(i.a)().curve(r.b),e=t.curve,a=t.lineX0,u=t.lineX1,c=t.lineY0,s=t.lineY1;return t.angle=t.x,delete t.x,t.startAngle=t.x0,delete t.x0,t.endAngle=t.x1,delete t.x1,t.radius=t.y,delete t.y,t.innerRadius=t.y0,delete t.y0,t.outerRadius=t.y1,delete t.y1,t.lineStartAngle=function(){return n.i(o.b)(a())},delete t.lineX0,t.lineEndAngle=function(){return n.i(o.b)(u())},delete t.lineX1,t.lineInnerRadius=function(){return n.i(o.b)(c())},delete t.lineY0,t.lineOuterRadius=function(){return n.i(o.b)(s())},delete t.lineY1,t.curve=function(t){return arguments.length?e(n.i(r.a)(t)):e()._curve},t}},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(50),o=n(47);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._y0=this._y1=this._y2=this._y3=this._y4=NaN,this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x2,this._y2),this._context.closePath();break;case 2:this._context.moveTo((this._x2+2*this._x3)/3,(this._y2+2*this._y3)/3),this._context.lineTo((this._x3+2*this._x2)/3,(this._y3+2*this._y2)/3),this._context.closePath();break;case 3:this.point(this._x2,this._y2),this.point(this._x3,this._y3),this.point(this._x4,this._y4)}},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._x2=t,this._y2=e;break;case 1:this._point=2,this._x3=t,this._y3=e;break;case 2:this._point=3,this._x4=t,this._y4=e,this._context.moveTo((this._x0+4*this._x1+t)/6,(this._y0+4*this._y1+e)/6);break;default:n.i(o.c)(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(47);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=NaN,this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3;var r=(this._x0+4*this._x1+t)/6,o=(this._y0+4*this._y1+e)/6;this._line?this._context.lineTo(r,o):this._context.moveTo(r,o);break;case 3:this._point=4;default:n.i(i.c)(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t,e){this._basis=new i.b(t),this._beta=e}var i=n(47);r.prototype={lineStart:function(){this._x=[],this._y=[],this._basis.lineStart()},lineEnd:function(){var t=this._x,e=this._y,n=t.length-1;if(n>0)for(var r,i=t[0],o=e[0],a=t[n]-i,u=e[n]-o,c=-1;++c<=n;)r=c/n,this._basis.point(this._beta*t[c]+(1-this._beta)*(i+r*a),this._beta*e[c]+(1-this._beta)*(o+r*u));this._x=this._y=null,this._basis.lineEnd()},point:function(t,e){this._x.push(+t),this._y.push(+e)}},e.a=function t(e){function n(t){return 1===e?new i.b(t):new r(t,e)}return n.beta=function(e){return t(+e)},n}(.85)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._alpha=e}var i=n(139),o=n(50),a=n(74);r.prototype={areaStart:o.a,areaEnd:o.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._x5=this._y0=this._y1=this._y2=this._y3=this._y4=this._y5=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x3,this._y3),this._context.closePath();break;case 2:this._context.lineTo(this._x3,this._y3),this._context.closePath();break;case 3:this.point(this._x3,this._y3),this.point(this._x4,this._y4),this.point(this._x5,this._y5)}},point:function(t,e){if(t=+t,e=+e,this._point){var r=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(r*r+i*i,this._alpha))}switch(this._point){case 0:this._point=1,this._x3=t,this._y3=e;break;case 1:this._point=2,this._context.moveTo(this._x4=t,this._y4=e);break;case 2:this._point=3,this._x5=t,this._y5=e;break;default:n.i(a.b)(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new r(t,e):new i.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._alpha=e}var i=n(140),o=n(74);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){if(t=+t,e=+e,this._point){var r=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(r*r+i*i,this._alpha))}switch(this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3,this._line?this._context.lineTo(this._x2,this._y2):this._context.moveTo(this._x2,this._y2);break;case 3:this._point=4;default:n.i(o.b)(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new r(t,e):new i.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(50);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._point=0},lineEnd:function(){this._point&&this._context.closePath()},point:function(t,e){t=+t,e=+e,this._point?this._context.lineTo(t,e):(this._point=1,this._context.moveTo(t,e))}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t){return t<0?-1:1}function i(t,e,n){var i=t._x1-t._x0,o=e-t._x1,a=(t._y1-t._y0)/(i||o<0&&-0),u=(n-t._y1)/(o||i<0&&-0),c=(a*o+u*i)/(i+o);return(r(a)+r(u))*Math.min(Math.abs(a),Math.abs(u),.5*Math.abs(c))||0}function o(t,e){var n=t._x1-t._x0;return n?(3*(t._y1-t._y0)/n-e)/2:e}function a(t,e,n){var r=t._x0,i=t._y0,o=t._x1,a=t._y1,u=(o-r)/3;t._context.bezierCurveTo(r+u,i+u*e,o-u,a-u*n,o,a)}function u(t){this._context=t}function c(t){this._context=new s(t)}function s(t){this._context=t}function l(t){return new u(t)}function f(t){return new c(t)}e.a=l,e.b=f,u.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=this._t0=NaN,this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x1,this._y1);break;case 3:a(this,this._t0,o(this,this._t0))}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){var n=NaN;if(t=+t,e=+e,t!==this._x1||e!==this._y1){switch(this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3,a(this,o(this,n=i(this,t,e)),n);break;default:a(this,this._t0,n=i(this,t,e))}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e,this._t0=n}}},(c.prototype=Object.create(u.prototype)).point=function(t,e){u.prototype.point.call(this,e,t)},s.prototype={moveTo:function(t,e){this._context.moveTo(e,t)},closePath:function(){this._context.closePath()},lineTo:function(t,e){this._context.lineTo(e,t)},bezierCurveTo:function(t,e,n,r,i,o){this._context.bezierCurveTo(e,t,r,n,o,i)}}},function(t,e,n){\"use strict\";function r(t){this._context=t}function i(t){var e,n,r=t.length-1,i=new Array(r),o=new Array(r),a=new Array(r);for(i[0]=0,o[0]=2,a[0]=t[0]+2*t[1],e=1;e<r-1;++e)i[e]=1,o[e]=4,a[e]=4*t[e]+2*t[e+1];for(i[r-1]=2,o[r-1]=7,a[r-1]=8*t[r-1]+t[r],e=1;e<r;++e)n=i[e]/o[e-1],o[e]-=n,a[e]-=n*a[e-1];for(i[r-1]=a[r-1]/o[r-1],e=r-2;e>=0;--e)i[e]=(a[e]-i[e+1])/o[e];for(o[r-1]=(t[r]+i[r-1])/2,e=0;e<r-1;++e)o[e]=2*t[e+1]-i[e+1];return[i,o]}r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x=[],this._y=[]},lineEnd:function(){var t=this._x,e=this._y,n=t.length;if(n)if(this._line?this._context.lineTo(t[0],e[0]):this._context.moveTo(t[0],e[0]),2===n)this._context.lineTo(t[1],e[1]);else for(var r=i(t),o=i(e),a=0,u=1;u<n;++a,++u)this._context.bezierCurveTo(r[0][a],o[0][a],r[1][a],o[1][a],t[u],e[u]);(this._line||0!==this._line&&1===n)&&this._context.closePath(),this._line=1-this._line,this._x=this._y=null},point:function(t,e){this._x.push(+t),this._y.push(+e)}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._t=e}function i(t){return new r(t,0)}function o(t){return new r(t,1)}e.c=i,e.b=o,r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x=this._y=NaN,this._point=0},lineEnd:function(){0<this._t&&this._t<1&&2===this._point&&this._context.lineTo(this._x,this._y),(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line>=0&&(this._t=1-this._t,this._line=1-this._line)},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;default:if(this._t<=0)this._context.lineTo(this._x,e),this._context.lineTo(t,e);else{var n=this._x*(1-this._t)+t*this._t;this._context.lineTo(n,this._y),this._context.lineTo(n,e)}}this._x=t,this._y=e}},e.a=function(t){return new r(t,.5)}},function(t,e,n){\"use strict\";e.a=function(t,e){return e<t?-1:e>t?1:e>=t?0:NaN}},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";function r(t){return t.source}function i(t){return t.target}function o(t){function e(){var e,r=h.a.call(arguments),i=o.apply(this,r),l=a.apply(this,r);if(s||(s=e=n.i(p.a)()),t(s,+u.apply(this,(r[0]=i,r)),+c.apply(this,r),+u.apply(this,(r[0]=l,r)),+c.apply(this,r)),e)return s=null,e+\"\"||null}var o=r,a=i,u=v.a,c=v.b,s=null;return e.source=function(t){return arguments.length?(o=t,e):o},e.target=function(t){return arguments.length?(a=t,e):a},e.x=function(t){return arguments.length?(u=\"function\"==typeof t?t:n.i(d.a)(+t),e):u},e.y=function(t){return arguments.length?(c=\"function\"==typeof t?t:n.i(d.a)(+t),e):c},e.context=function(t){return arguments.length?(s=null==t?null:t,e):s},e}function a(t,e,n,r,i){t.moveTo(e,n),t.bezierCurveTo(e=(e+r)/2,n,e,i,r,i)}function u(t,e,n,r,i){t.moveTo(e,n),t.bezierCurveTo(e,n=(n+i)/2,r,n,r,i)}function c(t,e,r,i,o){var a=n.i(g.a)(e,r),u=n.i(g.a)(e,r=(r+o)/2),c=n.i(g.a)(i,r),s=n.i(g.a)(i,o);t.moveTo(a[0],a[1]),t.bezierCurveTo(u[0],u[1],c[0],c[1],s[0],s[1])}function s(){return o(a)}function l(){return o(u)}function f(){var t=o(c);return t.angle=t.x,delete t.x,t.radius=t.y,delete t.y,t}e.a=s,e.b=l,e.c=f;var p=n(32),h=n(138),d=n(17),v=n(77),g=n(143)},function(t,e,n){\"use strict\";e.a=function(t,e){if((u=t.length)>1)for(var n,r,i,o,a,u,c=0,s=t[e[0]].length;c<s;++c)for(o=a=0,n=0;n<u;++n)(i=(r=t[e[n]][c])[1]-r[0])>=0?(r[0]=o,r[1]=o+=i):i<0?(r[1]=a,r[0]=a+=i):r[0]=o}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((o=t.length)>0){for(var i,o,a,u=0,c=t[0].length;u<c;++u){for(a=i=0;i<o;++i)a+=t[i][u][1]||0;if(a)for(i=0;i<o;++i)t[i][u][1]/=a}n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((i=t.length)>0){for(var i,o=0,a=t[e[0]],u=a.length;o<u;++o){for(var c=0,s=0;c<i;++c)s+=t[c][o][1]||0;a[o][1]+=a[o][0]=-s/2}n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((a=t.length)>0&&(o=(i=t[e[0]]).length)>0){for(var i,o,a,u=0,c=1;c<o;++c){for(var s=0,l=0,f=0;s<a;++s){for(var p=t[e[s]],h=p[c][1]||0,d=p[c-1][1]||0,v=(h-d)/2,g=0;g<s;++g){var m=t[e[g]];v+=(m[c][1]||0)-(m[c-1][1]||0)}l+=h,f+=v*h}i[c-1][1]+=i[c-1][0]=u,l&&(u-=f/l)}i[c-1][1]+=i[c-1][0]=u,n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(76);e.a=function(t){return n.i(r.a)(t).reverse()}},function(t,e,n){\"use strict\";var r=n(37),i=n(76);e.a=function(t){var e,o,a=t.length,u=t.map(i.b),c=n.i(r.a)(t).sort(function(t,e){return u[e]-u[t]}),s=0,l=0,f=[],p=[];for(e=0;e<a;++e)o=c[e],s<l?(s+=u[o],f.push(o)):(l+=u[o],p.push(o));return p.reverse().concat(f)}},function(t,e,n){\"use strict\";var r=n(37);e.a=function(t){return n.i(r.a)(t).reverse()}},function(t,e,n){\"use strict\";var r=n(17),i=n(301),o=n(302),a=n(35);e.a=function(){function t(t){var n,r,i,o,p,h=t.length,d=0,v=new Array(h),g=new Array(h),m=+s.apply(this,arguments),y=Math.min(a.c,Math.max(-a.c,l.apply(this,arguments)-m)),_=Math.min(Math.abs(y)/h,f.apply(this,arguments)),b=_*(y<0?-1:1);for(n=0;n<h;++n)(p=g[v[n]=n]=+e(t[n],n,t))>0&&(d+=p);for(null!=u?v.sort(function(t,e){return u(g[t],g[e])}):null!=c&&v.sort(function(e,n){return c(t[e],t[n])}),n=0,i=d?(y-h*b)/d:0;n<h;++n,m=o)r=v[n],p=g[r],o=m+(p>0?p*i:0)+b,g[r]={data:t[r],index:n,value:p,startAngle:m,endAngle:o,padAngle:_};return g}var e=o.a,u=i.a,c=null,s=n.i(r.a)(0),l=n.i(r.a)(a.c),f=n.i(r.a)(0);return t.value=function(i){return arguments.length?(e=\"function\"==typeof i?i:n.i(r.a)(+i),t):e},t.sortValues=function(e){return arguments.length?(u=e,c=null,t):u},t.sort=function(e){return arguments.length?(c=e,u=null,t):c},t.startAngle=function(e){return arguments.length?(s=\"function\"==typeof e?e:n.i(r.a)(+e),t):s},t.endAngle=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(r.a)(+e),t):l},t.padAngle=function(e){return arguments.length?(f=\"function\"==typeof e?e:n.i(r.a)(+e),t):f},t}},function(t,e,n){\"use strict\";function r(t,e){return t[e]}var i=n(138),o=n(17),a=n(36),u=n(37);e.a=function(){function t(t){var n,r,i=e.apply(this,arguments),o=t.length,a=i.length,u=new Array(a);for(n=0;n<a;++n){for(var f,p=i[n],h=u[n]=new Array(o),d=0;d<o;++d)h[d]=f=[0,+l(t[d],p,d,t)],f.data=t[d];h.key=p}for(n=0,r=c(u);n<a;++n)u[r[n]].index=n;return s(u,r),u}var e=n.i(o.a)([]),c=u.a,s=a.a,l=r;return t.keys=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(o.a)(i.a.call(r)),t):e},t.value=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(o.a)(+e),t):l},t.order=function(e){return arguments.length?(c=null==e?u.a:\"function\"==typeof e?e:n.i(o.a)(i.a.call(e)),t):c},t.offset=function(e){return arguments.length?(s=null==e?a.a:e,t):s},t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return p});var r=n(32),i=n(144),o=n(145),a=n(146),u=n(148),c=n(147),s=n(149),l=n(150),f=n(17),p=[i.a,o.a,a.a,c.a,u.a,s.a,l.a];e.a=function(){function t(){var t;if(a||(a=t=n.i(r.a)()),e.apply(this,arguments).draw(a,+o.apply(this,arguments)),t)return a=null,t+\"\"||null}var e=n.i(f.a)(i.a),o=n.i(f.a)(64),a=null;return t.type=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(f.a)(r),t):e},t.size=function(e){return arguments.length?(o=\"function\"==typeof e?e:n.i(f.a)(+e),t):o},t.context=function(e){return arguments.length?(a=null==e?null:e,t):a},t}},function(t,e,n){\"use strict\";function r(t){var e=new Date(t);return isNaN(e)?null:e}var i=n(151),o=n(79),a=+new Date(\"2000-01-01T00:00:00.000Z\")?r:n.i(o.e)(i.b);e.a=a},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setHours(0,0,0,0)},function(t,e){t.setDate(t.getDate()+e)},function(t,e){return(e-t-(e.getTimezoneOffset()-t.getTimezoneOffset())*i.d)/i.b},function(t){return t.getDate()-1});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){var e=t.getTimezoneOffset()*i.d%i.c;e<0&&(e+=i.c),t.setTime(Math.floor((+t-e)/i.c)*i.c+e)},function(t,e){t.setTime(+t+e*i.c)},function(t,e){return(e-t)/i.c},function(t){return t.getHours()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(){},function(t,e){t.setTime(+t+e)},function(t,e){return e-t});i.every=function(t){return t=Math.floor(t),isFinite(t)&&t>0?t>1?n.i(r.a)(function(e){e.setTime(Math.floor(e/t)*t)},function(e,n){e.setTime(+e+n*t)},function(e,n){return(n-e)/t}):i:null},e.a=i;i.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setTime(Math.floor(t/i.d)*i.d)},function(t,e){t.setTime(+t+e*i.d)},function(t,e){return(e-t)/i.d},function(t){return t.getMinutes()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setDate(1),t.setHours(0,0,0,0)},function(t,e){t.setMonth(t.getMonth()+e)},function(t,e){return e.getMonth()-t.getMonth()+12*(e.getFullYear()-t.getFullYear())},function(t){return t.getMonth()});e.a=i;i.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setTime(Math.floor(t/i.e)*i.e)},function(t,e){t.setTime(+t+e*i.e)},function(t,e){return(e-t)/i.e},function(t){return t.getUTCSeconds()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCDate(t.getUTCDate()+e)},function(t,e){return(e-t)/i.b},function(t){return t.getUTCDate()-1});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCMinutes(0,0,0)},function(t,e){t.setTime(+t+e*i.c)},function(t,e){return(e-t)/i.c},function(t){return t.getUTCHours()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCSeconds(0,0)},function(t,e){t.setTime(+t+e*i.d)},function(t,e){return(e-t)/i.d},function(t){return t.getUTCMinutes()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setUTCDate(1),t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCMonth(t.getUTCMonth()+e)},function(t,e){return e.getUTCMonth()-t.getUTCMonth()+12*(e.getUTCFullYear()-t.getUTCFullYear())},function(t){return t.getUTCMonth()});e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return n.i(i.a)(function(e){e.setUTCDate(e.getUTCDate()-(e.getUTCDay()+7-t)%7),e.setUTCHours(0,0,0,0)},function(t,e){t.setUTCDate(t.getUTCDate()+7*e)},function(t,e){return(e-t)/o.a})}n.d(e,\"a\",function(){return a}),n.d(e,\"b\",function(){return u}),n.d(e,\"c\",function(){return l});var i=n(5),o=n(13),a=r(0),u=r(1),c=r(2),s=r(3),l=r(4),f=r(5),p=r(6);a.range,u.range,c.range,s.range,l.range,f.range,p.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setUTCMonth(0,1),t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCFullYear(t.getUTCFullYear()+e)},function(t,e){return e.getUTCFullYear()-t.getUTCFullYear()},function(t){return t.getUTCFullYear()});i.every=function(t){return isFinite(t=Math.floor(t))&&t>0?n.i(r.a)(function(e){e.setUTCFullYear(Math.floor(e.getUTCFullYear()/t)*t),e.setUTCMonth(0,1),e.setUTCHours(0,0,0,0)},function(e,n){e.setUTCFullYear(e.getUTCFullYear()+n*t)}):null},e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return n.i(i.a)(function(e){e.setDate(e.getDate()-(e.getDay()+7-t)%7),e.setHours(0,0,0,0)},function(t,e){t.setDate(t.getDate()+7*e)},function(t,e){return(e-t-(e.getTimezoneOffset()-t.getTimezoneOffset())*o.d)/o.a})}n.d(e,\"a\",function(){return a}),n.d(e,\"b\",function(){return u}),n.d(e,\"c\",function(){return l});var i=n(5),o=n(13),a=r(0),u=r(1),c=r(2),s=r(3),l=r(4),f=r(5),p=r(6);a.range,u.range,c.range,s.range,l.range,f.range,p.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setMonth(0,1),t.setHours(0,0,0,0)},function(t,e){t.setFullYear(t.getFullYear()+e)},function(t,e){return e.getFullYear()-t.getFullYear()},function(t){return t.getFullYear()});i.every=function(t){return isFinite(t=Math.floor(t))&&t>0?n.i(r.a)(function(e){e.setFullYear(Math.floor(e.getFullYear()/t)*t),e.setMonth(0,1),e.setHours(0,0,0,0)},function(e,n){e.setFullYear(e.getFullYear()+n*t)}):null},e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return t.replace(i,function(t,e){return e.toUpperCase()})}var i=/-(.)/g;t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t.replace(o,\"ms-\"))}var i=n(329),o=/^-ms-/;t.exports=r},function(t,e,n){\"use strict\";function r(t,e){return!(!t||!e)&&(t===e||!i(t)&&(i(e)?r(t,e.parentNode):\"contains\"in t?t.contains(e):!!t.compareDocumentPosition&&!!(16&t.compareDocumentPosition(e))))}var i=n(339);t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t.length;if((Array.isArray(t)||\"object\"!=typeof t&&\"function\"!=typeof t)&&a(!1),\"number\"!=typeof e&&a(!1),0===e||e-1 in t||a(!1),\"function\"==typeof t.callee&&a(!1),t.hasOwnProperty)try{return Array.prototype.slice.call(t)}catch(t){}for(var n=Array(e),r=0;r<e;r++)n[r]=t[r];return n}function i(t){return!!t&&(\"object\"==typeof t||\"function\"==typeof t)&&\"length\"in t&&!(\"setInterval\"in t)&&\"number\"!=typeof t.nodeType&&(Array.isArray(t)||\"callee\"in t||\"item\"in t)}function o(t){return i(t)?Array.isArray(t)?t.slice():r(t):[t]}var a=n(0);t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=t.match(l);return e&&e[1].toLowerCase()}function i(t,e){var n=s;s||c(!1);var i=r(t),o=i&&u(i);if(o){n.innerHTML=o[1]+t+o[2];for(var l=o[0];l--;)n=n.lastChild}else n.innerHTML=t;var f=n.getElementsByTagName(\"script\");f.length&&(e||c(!1),a(f).forEach(e));for(var p=Array.from(n.childNodes);n.lastChild;)n.removeChild(n.lastChild);return p}var o=n(6),a=n(332),u=n(334),c=n(0),s=o.canUseDOM?document.createElement(\"div\"):null,l=/^\\s*<(\\w+)/;t.exports=i},function(t,e,n){\"use strict\";function r(t){return a||o(!1),p.hasOwnProperty(t)||(t=\"*\"),u.hasOwnProperty(t)||(a.innerHTML=\"*\"===t?\"<link />\":\"<\"+t+\"></\"+t+\">\",u[t]=!a.firstChild),u[t]?p[t]:null}var i=n(6),o=n(0),a=i.canUseDOM?document.createElement(\"div\"):null,u={},c=[1,'<select multiple=\"true\">',\"</select>\"],s=[1,\"<table>\",\"</table>\"],l=[3,\"<table><tbody><tr>\",\"</tr></tbody></table>\"],f=[1,'<svg xmlns=\"http://www.w3.org/2000/svg\">',\"</svg>\"],p={\"*\":[1,\"?<div>\",\"</div>\"],area:[1,\"<map>\",\"</map>\"],col:[2,\"<table><tbody></tbody><colgroup>\",\"</colgroup></table>\"],legend:[1,\"<fieldset>\",\"</fieldset>\"],param:[1,\"<object>\",\"</object>\"],tr:[2,\"<table><tbody>\",\"</tbody></table>\"],optgroup:c,option:c,caption:s,colgroup:s,tbody:s,tfoot:s,thead:s,td:l,th:l};[\"circle\",\"clipPath\",\"defs\",\"ellipse\",\"g\",\"image\",\"line\",\"linearGradient\",\"mask\",\"path\",\"pattern\",\"polygon\",\"polyline\",\"radialGradient\",\"rect\",\"stop\",\"text\",\"tspan\"].forEach(function(t){p[t]=f,u[t]=!0}),t.exports=r},function(t,e,n){\"use strict\";function r(t){return t.Window&&t instanceof t.Window?{x:t.pageXOffset||t.document.documentElement.scrollLeft,y:t.pageYOffset||t.document.documentElement.scrollTop}:{x:t.scrollLeft,y:t.scrollTop}}t.exports=r},function(t,e,n){\"use strict\";function r(t){return t.replace(i,\"-$1\").toLowerCase()}var i=/([A-Z])/g;t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t).replace(o,\"-ms-\")}var i=n(336),o=/^ms-/;t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t?t.ownerDocument||t:document,n=e.defaultView||window;return!(!t||!(\"function\"==typeof n.Node?t instanceof n.Node:\"object\"==typeof t&&\"number\"==typeof t.nodeType&&\"string\"==typeof t.nodeName))}t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t)&&3==t.nodeType}var i=n(338);t.exports=r},function(t,e,n){\"use strict\";var r=function(t){var e;for(e in t)if(t.hasOwnProperty(e))return e;return null};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e={};return function(n){return e.hasOwnProperty(n)||(e[n]=t.call(this,n)),e[n]}}t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r,i){}t.exports=r},function(t,e,n){\"use strict\";function r(){return null}var i=n(3),o=n(344),a=n(342),u=function(){};t.exports=function(t,e){function n(t){var e=t&&(E&&t[E]||t[M]);if(\"function\"==typeof e)return e}function c(t,e){return t===e?0!==t||1/t==1/e:t!==t&&e!==e}function s(t){this.message=t,this.stack=\"\"}function l(t){function n(n,r,i,a,u,c,l){if(a=a||T,c=c||i,l!==o){if(e){var f=new Error(\"Calling PropTypes validators directly is not supported by the `prop-types` package. Use `PropTypes.checkPropTypes()` to call them. Read more at http://fb.me/use-check-prop-types\");throw f.name=\"Invariant Violation\",f}}return null==r[i]?n?new s(null===r[i]?\"The \"+u+\" `\"+c+\"` is marked as required in `\"+a+\"`, but its value is `null`.\":\"The \"+u+\" `\"+c+\"` is marked as required in `\"+a+\"`, but its value is `undefined`.\"):null:t(r,i,a,u,c)}var r=n.bind(null,!1);return r.isRequired=n.bind(null,!0),r}function f(t){function e(e,n,r,i,o,a){var u=e[n];if(x(u)!==t)return new s(\"Invalid \"+i+\" `\"+o+\"` of type `\"+w(u)+\"` supplied to `\"+r+\"`, expected `\"+t+\"`.\");return null}return l(e)}function p(t){function e(e,n,r,i,a){if(\"function\"!=typeof t)return new s(\"Property `\"+a+\"` of component `\"+r+\"` has invalid PropType notation inside arrayOf.\");var u=e[n];if(!Array.isArray(u)){return new s(\"Invalid \"+i+\" `\"+a+\"` of type `\"+x(u)+\"` supplied to `\"+r+\"`, expected an array.\")}for(var c=0;c<u.length;c++){var l=t(u,c,r,i,a+\"[\"+c+\"]\",o);if(l instanceof Error)return l}return null}return l(e)}function h(t){function e(e,n,r,i,o){if(!(e[n]instanceof t)){var a=t.name||T;return new s(\"Invalid \"+i+\" `\"+o+\"` of type `\"+k(e[n])+\"` supplied to `\"+r+\"`, expected instance of `\"+a+\"`.\")}return null}return l(e)}function d(t){function e(e,n,r,i,o){for(var a=e[n],u=0;u<t.length;u++)if(c(a,t[u]))return null;return new s(\"Invalid \"+i+\" `\"+o+\"` of value `\"+a+\"` supplied to `\"+r+\"`, expected one of \"+JSON.stringify(t)+\".\")}return Array.isArray(t)?l(e):r}function v(t){function e(e,n,r,i,a){if(\"function\"!=typeof t)return new s(\"Property `\"+a+\"` of component `\"+r+\"` has invalid PropType notation inside objectOf.\");var u=e[n],c=x(u);if(\"object\"!==c)return new s(\"Invalid \"+i+\" `\"+a+\"` of type `\"+c+\"` supplied to `\"+r+\"`, expected an object.\");for(var l in u)if(u.hasOwnProperty(l)){var f=t(u,l,r,i,a+\".\"+l,o);if(f instanceof Error)return f}return null}return l(e)}function g(t){function e(e,n,r,i,a){for(var u=0;u<t.length;u++){if(null==(0,t[u])(e,n,r,i,a,o))return null}return new s(\"Invalid \"+i+\" `\"+a+\"` supplied to `\"+r+\"`.\")}if(!Array.isArray(t))return r;for(var n=0;n<t.length;n++){var i=t[n];if(\"function\"!=typeof i)return u(\"Invalid argument supplied to oneOfType. Expected an array of check functions, but received \"+C(i)+\" at index \"+n+\".\"),r}return l(e)}function m(t){function e(e,n,r,i,a){var u=e[n],c=x(u);if(\"object\"!==c)return new s(\"Invalid \"+i+\" `\"+a+\"` of type `\"+c+\"` supplied to `\"+r+\"`, expected `object`.\");for(var l in t){var f=t[l];if(f){var p=f(u,l,r,i,a+\".\"+l,o);if(p)return p}}return null}return l(e)}function y(t){function e(e,n,r,a,u){var c=e[n],l=x(c);if(\"object\"!==l)return new s(\"Invalid \"+a+\" `\"+u+\"` of type `\"+l+\"` supplied to `\"+r+\"`, expected `object`.\");var f=i({},e[n],t);for(var p in f){var h=t[p];if(!h)return new s(\"Invalid \"+a+\" `\"+u+\"` key `\"+p+\"` supplied to `\"+r+\"`.\\nBad object: \"+JSON.stringify(e[n],null,\"  \")+\"\\nValid keys: \"+JSON.stringify(Object.keys(t),null,\"  \"));var d=h(c,p,r,a,u+\".\"+p,o);if(d)return d}return null}return l(e)}function _(e){switch(typeof e){case\"number\":case\"string\":case\"undefined\":return!0;case\"boolean\":return!e;case\"object\":if(Array.isArray(e))return e.every(_);if(null===e||t(e))return!0;var r=n(e);if(!r)return!1;var i,o=r.call(e);if(r!==e.entries){for(;!(i=o.next()).done;)if(!_(i.value))return!1}else for(;!(i=o.next()).done;){var a=i.value;if(a&&!_(a[1]))return!1}return!0;default:return!1}}function b(t,e){return\"symbol\"===t||(\"Symbol\"===e[\"@@toStringTag\"]||\"function\"==typeof Symbol&&e instanceof Symbol)}function x(t){var e=typeof t;return Array.isArray(t)?\"array\":t instanceof RegExp?\"object\":b(e,t)?\"symbol\":e}function w(t){if(void 0===t||null===t)return\"\"+t;var e=x(t);if(\"object\"===e){if(t instanceof Date)return\"date\";if(t instanceof RegExp)return\"regexp\"}return e}function C(t){var e=w(t);switch(e){case\"array\":case\"object\":return\"an \"+e;case\"boolean\":case\"date\":case\"regexp\":return\"a \"+e;default:return e}}function k(t){return t.constructor&&t.constructor.name?t.constructor.name:T}var E=\"function\"==typeof Symbol&&Symbol.iterator,M=\"@@iterator\",T=\"<<anonymous>>\",S={array:f(\"array\"),bool:f(\"boolean\"),func:f(\"function\"),number:f(\"number\"),object:f(\"object\"),string:f(\"string\"),symbol:f(\"symbol\"),any:function(){return l(r)}(),arrayOf:p,element:function(){function e(e,n,r,i,o){var a=e[n];if(!t(a)){return new s(\"Invalid \"+i+\" `\"+o+\"` of type `\"+x(a)+\"` supplied to `\"+r+\"`, expected a single ReactElement.\")}return null}return l(e)}(),instanceOf:h,node:function(){function t(t,e,n,r,i){return _(t[e])?null:new s(\"Invalid \"+r+\" `\"+i+\"` supplied to `\"+n+\"`, expected a ReactNode.\")}return l(t)}(),objectOf:v,oneOf:d,oneOfType:g,shape:m,exact:y};return s.prototype=Error.prototype,S.checkPropTypes=a,S.PropTypes=S,S}},function(t,e,n){\"use strict\";t.exports=\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\"},function(t,e,n){\"use strict\";var r={Properties:{\"aria-current\":0,\"aria-details\":0,\"aria-disabled\":0,\"aria-hidden\":0,\"aria-invalid\":0,\"aria-keyshortcuts\":0,\"aria-label\":0,\"aria-roledescription\":0,\"aria-autocomplete\":0,\"aria-checked\":0,\"aria-expanded\":0,\"aria-haspopup\":0,\"aria-level\":0,\"aria-modal\":0,\"aria-multiline\":0,\"aria-multiselectable\":0,\"aria-orientation\":0,\"aria-placeholder\":0,\"aria-pressed\":0,\"aria-readonly\":0,\"aria-required\":0,\"aria-selected\":0,\"aria-sort\":0,\"aria-valuemax\":0,\"aria-valuemin\":0,\"aria-valuenow\":0,\"aria-valuetext\":0,\"aria-atomic\":0,\"aria-busy\":0,\"aria-live\":0,\"aria-relevant\":0,\"aria-dropeffect\":0,\"aria-grabbed\":0,\"aria-activedescendant\":0,\"aria-colcount\":0,\"aria-colindex\":0,\"aria-colspan\":0,\"aria-controls\":0,\"aria-describedby\":0,\"aria-errormessage\":0,\"aria-flowto\":0,\"aria-labelledby\":0,\"aria-owns\":0,\"aria-posinset\":0,\"aria-rowcount\":0,\"aria-rowindex\":0,\"aria-rowspan\":0,\"aria-setsize\":0},DOMAttributeNames:{},DOMPropertyNames:{}};t.exports=r},function(t,e,n){\"use strict\";var r=n(4),i=n(154),o={focusDOMComponent:function(){i(r.getNodeFromInstance(this))}};t.exports=o},function(t,e,n){\"use strict\";function r(t){return(t.ctrlKey||t.altKey||t.metaKey)&&!(t.ctrlKey&&t.altKey)}function i(t){switch(t){case\"topCompositionStart\":return E.compositionStart;case\"topCompositionEnd\":return E.compositionEnd;case\"topCompositionUpdate\":return E.compositionUpdate}}function o(t,e){return\"topKeyDown\"===t&&e.keyCode===y}function a(t,e){switch(t){case\"topKeyUp\":return-1!==m.indexOf(e.keyCode);case\"topKeyDown\":return e.keyCode!==y;case\"topKeyPress\":case\"topMouseDown\":case\"topBlur\":return!0;default:return!1}}function u(t){var e=t.detail;return\"object\"==typeof e&&\"data\"in e?e.data:null}function c(t,e,n,r){var c,s;if(_?c=i(t):T?a(t,n)&&(c=E.compositionEnd):o(t,n)&&(c=E.compositionStart),!c)return null;w&&(T||c!==E.compositionStart?c===E.compositionEnd&&T&&(s=T.getData()):T=d.getPooled(r));var l=v.getPooled(c,e,n,r);if(s)l.data=s;else{var f=u(n);null!==f&&(l.data=f)}return p.accumulateTwoPhaseDispatches(l),l}function s(t,e){switch(t){case\"topCompositionEnd\":return u(e);case\"topKeyPress\":return e.which!==C?null:(M=!0,k);case\"topTextInput\":var n=e.data;return n===k&&M?null:n;default:return null}}function l(t,e){if(T){if(\"topCompositionEnd\"===t||!_&&a(t,e)){var n=T.getData();return d.release(T),T=null,n}return null}switch(t){case\"topPaste\":return null;case\"topKeyPress\":return e.which&&!r(e)?String.fromCharCode(e.which):null;case\"topCompositionEnd\":return w?null:e.data;default:return null}}function f(t,e,n,r){var i;if(!(i=x?s(t,n):l(t,n)))return null;var o=g.getPooled(E.beforeInput,e,n,r);return o.data=i,p.accumulateTwoPhaseDispatches(o),o}var p=n(23),h=n(6),d=n(354),v=n(391),g=n(394),m=[9,13,27,32],y=229,_=h.canUseDOM&&\"CompositionEvent\"in window,b=null;h.canUseDOM&&\"documentMode\"in document&&(b=document.documentMode);var x=h.canUseDOM&&\"TextEvent\"in window&&!b&&!function(){var t=window.opera;return\"object\"==typeof t&&\"function\"==typeof t.version&&parseInt(t.version(),10)<=12}(),w=h.canUseDOM&&(!_||b&&b>8&&b<=11),C=32,k=String.fromCharCode(C),E={beforeInput:{phasedRegistrationNames:{bubbled:\"onBeforeInput\",captured:\"onBeforeInputCapture\"},dependencies:[\"topCompositionEnd\",\"topKeyPress\",\"topTextInput\",\"topPaste\"]},compositionEnd:{phasedRegistrationNames:{bubbled:\"onCompositionEnd\",captured:\"onCompositionEndCapture\"},dependencies:[\"topBlur\",\"topCompositionEnd\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]},compositionStart:{phasedRegistrationNames:{bubbled:\"onCompositionStart\",captured:\"onCompositionStartCapture\"},dependencies:[\"topBlur\",\"topCompositionStart\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]},compositionUpdate:{phasedRegistrationNames:{bubbled:\"onCompositionUpdate\",captured:\"onCompositionUpdateCapture\"},dependencies:[\"topBlur\",\"topCompositionUpdate\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]}},M=!1,T=null,S={eventTypes:E,extractEvents:function(t,e,n,r){return[c(t,e,n,r),f(t,e,n,r)]}};t.exports=S},function(t,e,n){\"use strict\";var r=n(158),i=n(6),o=(n(9),n(330),n(400)),a=n(337),u=n(341),c=(n(2),u(function(t){return a(t)})),s=!1,l=\"cssFloat\";if(i.canUseDOM){var f=document.createElement(\"div\").style;try{f.font=\"\"}catch(t){s=!0}void 0===document.documentElement.style.cssFloat&&(l=\"styleFloat\")}var p={createMarkupForStyles:function(t,e){var n=\"\";for(var r in t)if(t.hasOwnProperty(r)){var i=0===r.indexOf(\"--\"),a=t[r];null!=a&&(n+=c(r)+\":\",n+=o(r,a,e,i)+\";\")}return n||null},setValueForStyles:function(t,e,n){var i=t.style;for(var a in e)if(e.hasOwnProperty(a)){var u=0===a.indexOf(\"--\"),c=o(a,e[a],n,u);if(\"float\"!==a&&\"cssFloat\"!==a||(a=l),u)i.setProperty(a,c);else if(c)i[a]=c;else{var f=s&&r.shorthandPropertyExpansions[a];if(f)for(var p in f)i[p]=\"\";else i[a]=\"\"}}}};t.exports=p},function(t,e,n){\"use strict\";function r(t,e,n){var r=M.getPooled(P.change,t,e,n);return r.type=\"change\",w.accumulateTwoPhaseDispatches(r),r}function i(t){var e=t.nodeName&&t.nodeName.toLowerCase();return\"select\"===e||\"input\"===e&&\"file\"===t.type}function o(t){var e=r(I,t,S(t));E.batchedUpdates(a,e)}function a(t){x.enqueueEvents(t),x.processEventQueue(!1)}function u(t,e){O=t,I=e,O.attachEvent(\"onchange\",o)}function c(){O&&(O.detachEvent(\"onchange\",o),O=null,I=null)}function s(t,e){var n=T.updateValueIfChanged(t),r=!0===e.simulated&&L._allowSimulatedPassThrough;if(n||r)return t}function l(t,e){if(\"topChange\"===t)return e}function f(t,e,n){\"topFocus\"===t?(c(),u(e,n)):\"topBlur\"===t&&c()}function p(t,e){O=t,I=e,O.attachEvent(\"onpropertychange\",d)}function h(){O&&(O.detachEvent(\"onpropertychange\",d),O=null,I=null)}function d(t){\"value\"===t.propertyName&&s(I,t)&&o(t)}function v(t,e,n){\"topFocus\"===t?(h(),p(e,n)):\"topBlur\"===t&&h()}function g(t,e,n){if(\"topSelectionChange\"===t||\"topKeyUp\"===t||\"topKeyDown\"===t)return s(I,n)}function m(t){var e=t.nodeName;return e&&\"input\"===e.toLowerCase()&&(\"checkbox\"===t.type||\"radio\"===t.type)}function y(t,e,n){if(\"topClick\"===t)return s(e,n)}function _(t,e,n){if(\"topInput\"===t||\"topChange\"===t)return s(e,n)}function b(t,e){if(null!=t){var n=t._wrapperState||e._wrapperState;if(n&&n.controlled&&\"number\"===e.type){var r=\"\"+e.value;e.getAttribute(\"value\")!==r&&e.setAttribute(\"value\",r)}}}var x=n(22),w=n(23),C=n(6),k=n(4),E=n(12),M=n(14),T=n(173),S=n(94),N=n(95),A=n(175),P={change:{phasedRegistrationNames:{bubbled:\"onChange\",captured:\"onChangeCapture\"},dependencies:[\"topBlur\",\"topChange\",\"topClick\",\"topFocus\",\"topInput\",\"topKeyDown\",\"topKeyUp\",\"topSelectionChange\"]}},O=null,I=null,D=!1;C.canUseDOM&&(D=N(\"change\")&&(!document.documentMode||document.documentMode>8));var R=!1;C.canUseDOM&&(R=N(\"input\")&&(!document.documentMode||document.documentMode>9));var L={eventTypes:P,_allowSimulatedPassThrough:!0,_isInputEventSupported:R,extractEvents:function(t,e,n,o){var a,u,c=e?k.getNodeFromInstance(e):window;if(i(c)?D?a=l:u=f:A(c)?R?a=_:(a=g,u=v):m(c)&&(a=y),a){var s=a(t,e,n);if(s){return r(s,n,o)}}u&&u(t,c,e),\"topBlur\"===t&&b(e,c)}};t.exports=L},function(t,e,n){\"use strict\";var r=n(1),i=n(20),o=n(6),a=n(333),u=n(11),c=(n(0),{dangerouslyReplaceNodeWithMarkup:function(t,e){if(o.canUseDOM||r(\"56\"),e||r(\"57\"),\"HTML\"===t.nodeName&&r(\"58\"),\"string\"==typeof e){var n=a(e,u)[0];t.parentNode.replaceChild(n,t)}else i.replaceChildWithTree(t,e)}});t.exports=c},function(t,e,n){\"use strict\";var r=[\"ResponderEventPlugin\",\"SimpleEventPlugin\",\"TapEventPlugin\",\"EnterLeaveEventPlugin\",\"ChangeEventPlugin\",\"SelectEventPlugin\",\"BeforeInputEventPlugin\"];t.exports=r},function(t,e,n){\"use strict\";var r=n(23),i=n(4),o=n(54),a={mouseEnter:{registrationName:\"onMouseEnter\",dependencies:[\"topMouseOut\",\"topMouseOver\"]},mouseLeave:{registrationName:\"onMouseLeave\",dependencies:[\"topMouseOut\",\"topMouseOver\"]}},u={eventTypes:a,extractEvents:function(t,e,n,u){if(\"topMouseOver\"===t&&(n.relatedTarget||n.fromElement))return null;if(\"topMouseOut\"!==t&&\"topMouseOver\"!==t)return null;var c;if(u.window===u)c=u;else{var s=u.ownerDocument;c=s?s.defaultView||s.parentWindow:window}var l,f;if(\"topMouseOut\"===t){l=e;var p=n.relatedTarget||n.toElement;f=p?i.getClosestInstanceFromNode(p):null}else l=null,f=e;if(l===f)return null;var h=null==l?c:i.getNodeFromInstance(l),d=null==f?c:i.getNodeFromInstance(f),v=o.getPooled(a.mouseLeave,l,n,u);v.type=\"mouseleave\",v.target=h,v.relatedTarget=d;var g=o.getPooled(a.mouseEnter,f,n,u);return g.type=\"mouseenter\",g.target=d,g.relatedTarget=h,r.accumulateEnterLeaveDispatches(v,g,l,f),[v,g]}};t.exports=u},function(t,e,n){\"use strict\";var r={topAbort:null,topAnimationEnd:null,topAnimationIteration:null,topAnimationStart:null,topBlur:null,topCanPlay:null,topCanPlayThrough:null,topChange:null,topClick:null,topCompositionEnd:null,topCompositionStart:null,topCompositionUpdate:null,topContextMenu:null,topCopy:null,topCut:null,topDoubleClick:null,topDrag:null,topDragEnd:null,topDragEnter:null,topDragExit:null,topDragLeave:null,topDragOver:null,topDragStart:null,topDrop:null,topDurationChange:null,topEmptied:null,topEncrypted:null,topEnded:null,topError:null,topFocus:null,topInput:null,topInvalid:null,topKeyDown:null,topKeyPress:null,topKeyUp:null,topLoad:null,topLoadedData:null,topLoadedMetadata:null,topLoadStart:null,topMouseDown:null,topMouseMove:null,topMouseOut:null,topMouseOver:null,topMouseUp:null,topPaste:null,topPause:null,topPlay:null,topPlaying:null,topProgress:null,topRateChange:null,topReset:null,topScroll:null,topSeeked:null,topSeeking:null,topSelectionChange:null,topStalled:null,topSubmit:null,topSuspend:null,topTextInput:null,topTimeUpdate:null,topTouchCancel:null,topTouchEnd:null,topTouchMove:null,topTouchStart:null,topTransitionEnd:null,topVolumeChange:null,topWaiting:null,topWheel:null},i={topLevelTypes:r};t.exports=i},function(t,e,n){\"use strict\";function r(t){this._root=t,this._startText=this.getText(),this._fallbackText=null}var i=n(3),o=n(18),a=n(172);i(r.prototype,{destructor:function(){this._root=null,this._startText=null,this._fallbackText=null},getText:function(){return\"value\"in this._root?this._root.value:this._root[a()]},getData:function(){if(this._fallbackText)return this._fallbackText;var t,e,n=this._startText,r=n.length,i=this.getText(),o=i.length;for(t=0;t<r&&n[t]===i[t];t++);var a=r-t;for(e=1;e<=a&&n[r-e]===i[o-e];e++);var u=e>1?1-e:void 0;return this._fallbackText=i.slice(t,u),this._fallbackText}}),o.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";var r=n(21),i=r.injection.MUST_USE_PROPERTY,o=r.injection.HAS_BOOLEAN_VALUE,a=r.injection.HAS_NUMERIC_VALUE,u=r.injection.HAS_POSITIVE_NUMERIC_VALUE,c=r.injection.HAS_OVERLOADED_BOOLEAN_VALUE,s={isCustomAttribute:RegExp.prototype.test.bind(new RegExp(\"^(data|aria)-[\"+r.ATTRIBUTE_NAME_CHAR+\"]*$\")),Properties:{accept:0,acceptCharset:0,accessKey:0,action:0,allowFullScreen:o,allowTransparency:0,alt:0,as:0,async:o,autoComplete:0,autoPlay:o,capture:o,cellPadding:0,cellSpacing:0,charSet:0,challenge:0,checked:i|o,cite:0,classID:0,className:0,cols:u,colSpan:0,content:0,contentEditable:0,contextMenu:0,controls:o,controlsList:0,coords:0,crossOrigin:0,data:0,dateTime:0,default:o,defer:o,dir:0,disabled:o,download:c,draggable:0,encType:0,form:0,formAction:0,formEncType:0,formMethod:0,formNoValidate:o,formTarget:0,frameBorder:0,headers:0,height:0,hidden:o,high:0,href:0,hrefLang:0,htmlFor:0,httpEquiv:0,icon:0,id:0,inputMode:0,integrity:0,is:0,keyParams:0,keyType:0,kind:0,label:0,lang:0,list:0,loop:o,low:0,manifest:0,marginHeight:0,marginWidth:0,max:0,maxLength:0,media:0,mediaGroup:0,method:0,min:0,minLength:0,multiple:i|o,muted:i|o,name:0,nonce:0,noValidate:o,open:o,optimum:0,pattern:0,placeholder:0,playsInline:o,poster:0,preload:0,profile:0,radioGroup:0,readOnly:o,referrerPolicy:0,rel:0,required:o,reversed:o,role:0,rows:u,rowSpan:a,sandbox:0,scope:0,scoped:o,scrolling:0,seamless:o,selected:i|o,shape:0,size:u,sizes:0,span:u,spellCheck:0,src:0,srcDoc:0,srcLang:0,srcSet:0,start:a,step:0,style:0,summary:0,tabIndex:0,target:0,title:0,type:0,useMap:0,value:0,width:0,wmode:0,wrap:0,about:0,datatype:0,inlist:0,prefix:0,property:0,resource:0,typeof:0,vocab:0,autoCapitalize:0,autoCorrect:0,autoSave:0,color:0,itemProp:0,itemScope:o,itemType:0,itemID:0,itemRef:0,results:0,security:0,unselectable:0},DOMAttributeNames:{acceptCharset:\"accept-charset\",className:\"class\",htmlFor:\"for\",httpEquiv:\"http-equiv\"},DOMPropertyNames:{},DOMMutationMethods:{value:function(t,e){if(null==e)return t.removeAttribute(\"value\");\"number\"!==t.type||!1===t.hasAttribute(\"value\")?t.setAttribute(\"value\",\"\"+e):t.validity&&!t.validity.badInput&&t.ownerDocument.activeElement!==t&&t.setAttribute(\"value\",\"\"+e)}}};t.exports=s},function(t,e,n){\"use strict\";(function(e){function r(t,e,n,r){var i=void 0===t[n];null!=e&&i&&(t[n]=o(e,!0))}var i=n(24),o=n(174),a=(n(85),n(96)),u=n(177);n(2);void 0!==e&&e.env;var c={instantiateChildren:function(t,e,n,i){if(null==t)return null;var o={};return u(t,r,o),o},updateChildren:function(t,e,n,r,u,c,s,l,f){if(e||t){var p,h;for(p in e)if(e.hasOwnProperty(p)){h=t&&t[p];var d=h&&h._currentElement,v=e[p];if(null!=h&&a(d,v))i.receiveComponent(h,v,u,l),e[p]=h;else{h&&(r[p]=i.getHostNode(h),i.unmountComponent(h,!1));var g=o(v,!0);e[p]=g;var m=i.mountComponent(g,u,c,s,l,f);n.push(m)}}for(p in t)!t.hasOwnProperty(p)||e&&e.hasOwnProperty(p)||(h=t[p],r[p]=i.getHostNode(h),i.unmountComponent(h,!1))}},unmountChildren:function(t,e){for(var n in t)if(t.hasOwnProperty(n)){var r=t[n];i.unmountComponent(r,e)}}};t.exports=c}).call(e,n(156))},function(t,e,n){\"use strict\";var r=n(82),i=n(364),o={processChildrenUpdates:i.dangerouslyProcessChildrenUpdates,replaceNodeWithMarkup:r.dangerouslyReplaceNodeWithMarkup};t.exports=o},function(t,e,n){\"use strict\";function r(t){}function i(t){return!(!t.prototype||!t.prototype.isReactComponent)}function o(t){return!(!t.prototype||!t.prototype.isPureReactComponent)}var a=n(1),u=n(3),c=n(26),s=n(87),l=n(15),f=n(88),p=n(39),h=(n(9),n(168)),d=n(24),v=n(51),g=(n(0),n(81)),m=n(96),y=(n(2),{ImpureClass:0,PureClass:1,StatelessFunctional:2});r.prototype.render=function(){var t=p.get(this)._currentElement.type,e=t(this.props,this.context,this.updater);return e};var _=1,b={construct:function(t){this._currentElement=t,this._rootNodeID=0,this._compositeType=null,this._instance=null,this._hostParent=null,this._hostContainerInfo=null,this._updateBatchNumber=null,this._pendingElement=null,this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1,this._renderedNodeType=null,this._renderedComponent=null,this._context=null,this._mountOrder=0,this._topLevelWrapper=null,this._pendingCallbacks=null,this._calledComponentWillUnmount=!1},mountComponent:function(t,e,n,u){this._context=u,this._mountOrder=_++,this._hostParent=e,this._hostContainerInfo=n;var s,l=this._currentElement.props,f=this._processContext(u),h=this._currentElement.type,d=t.getUpdateQueue(),g=i(h),m=this._constructComponent(g,l,f,d);g||null!=m&&null!=m.render?o(h)?this._compositeType=y.PureClass:this._compositeType=y.ImpureClass:(s=m,null===m||!1===m||c.isValidElement(m)||a(\"105\",h.displayName||h.name||\"Component\"),m=new r(h),this._compositeType=y.StatelessFunctional);m.props=l,m.context=f,m.refs=v,m.updater=d,this._instance=m,p.set(m,this);var b=m.state;void 0===b&&(m.state=b=null),(\"object\"!=typeof b||Array.isArray(b))&&a(\"106\",this.getName()||\"ReactCompositeComponent\"),this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1;var x;return x=m.unstable_handleError?this.performInitialMountWithErrorHandling(s,e,n,t,u):this.performInitialMount(s,e,n,t,u),m.componentDidMount&&t.getReactMountReady().enqueue(m.componentDidMount,m),x},_constructComponent:function(t,e,n,r){return this._constructComponentWithoutOwner(t,e,n,r)},_constructComponentWithoutOwner:function(t,e,n,r){var i=this._currentElement.type;return t?new i(e,n,r):i(e,n,r)},performInitialMountWithErrorHandling:function(t,e,n,r,i){var o,a=r.checkpoint();try{o=this.performInitialMount(t,e,n,r,i)}catch(u){r.rollback(a),this._instance.unstable_handleError(u),this._pendingStateQueue&&(this._instance.state=this._processPendingState(this._instance.props,this._instance.context)),a=r.checkpoint(),this._renderedComponent.unmountComponent(!0),r.rollback(a),o=this.performInitialMount(t,e,n,r,i)}return o},performInitialMount:function(t,e,n,r,i){var o=this._instance,a=0;o.componentWillMount&&(o.componentWillMount(),this._pendingStateQueue&&(o.state=this._processPendingState(o.props,o.context))),void 0===t&&(t=this._renderValidatedComponent());var u=h.getType(t);this._renderedNodeType=u;var c=this._instantiateReactComponent(t,u!==h.EMPTY);this._renderedComponent=c;var s=d.mountComponent(c,r,e,n,this._processChildContext(i),a);return s},getHostNode:function(){return d.getHostNode(this._renderedComponent)},unmountComponent:function(t){if(this._renderedComponent){var e=this._instance;if(e.componentWillUnmount&&!e._calledComponentWillUnmount)if(e._calledComponentWillUnmount=!0,t){var n=this.getName()+\".componentWillUnmount()\";f.invokeGuardedCallback(n,e.componentWillUnmount.bind(e))}else e.componentWillUnmount();this._renderedComponent&&(d.unmountComponent(this._renderedComponent,t),this._renderedNodeType=null,this._renderedComponent=null,this._instance=null),this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1,this._pendingCallbacks=null,this._pendingElement=null,this._context=null,this._rootNodeID=0,this._topLevelWrapper=null,p.remove(e)}},_maskContext:function(t){var e=this._currentElement.type,n=e.contextTypes;if(!n)return v;var r={};for(var i in n)r[i]=t[i];return r},_processContext:function(t){var e=this._maskContext(t);return e},_processChildContext:function(t){var e,n=this._currentElement.type,r=this._instance;if(r.getChildContext&&(e=r.getChildContext()),e){\"object\"!=typeof n.childContextTypes&&a(\"107\",this.getName()||\"ReactCompositeComponent\");for(var i in e)i in n.childContextTypes||a(\"108\",this.getName()||\"ReactCompositeComponent\",i);return u({},t,e)}return t},_checkContextTypes:function(t,e,n){},receiveComponent:function(t,e,n){var r=this._currentElement,i=this._context;this._pendingElement=null,this.updateComponent(e,r,t,i,n)},performUpdateIfNecessary:function(t){null!=this._pendingElement?d.receiveComponent(this,this._pendingElement,t,this._context):null!==this._pendingStateQueue||this._pendingForceUpdate?this.updateComponent(t,this._currentElement,this._currentElement,this._context,this._context):this._updateBatchNumber=null},updateComponent:function(t,e,n,r,i){var o=this._instance;null==o&&a(\"136\",this.getName()||\"ReactCompositeComponent\");var u,c=!1;this._context===i?u=o.context:(u=this._processContext(i),c=!0);var s=e.props,l=n.props;e!==n&&(c=!0),c&&o.componentWillReceiveProps&&o.componentWillReceiveProps(l,u);var f=this._processPendingState(l,u),p=!0;this._pendingForceUpdate||(o.shouldComponentUpdate?p=o.shouldComponentUpdate(l,f,u):this._compositeType===y.PureClass&&(p=!g(s,l)||!g(o.state,f))),this._updateBatchNumber=null,p?(this._pendingForceUpdate=!1,this._performComponentUpdate(n,l,f,u,t,i)):(this._currentElement=n,this._context=i,o.props=l,o.state=f,o.context=u)},_processPendingState:function(t,e){var n=this._instance,r=this._pendingStateQueue,i=this._pendingReplaceState;if(this._pendingReplaceState=!1,this._pendingStateQueue=null,!r)return n.state;if(i&&1===r.length)return r[0];for(var o=u({},i?r[0]:n.state),a=i?1:0;a<r.length;a++){var c=r[a];u(o,\"function\"==typeof c?c.call(n,o,t,e):c)}return o},_performComponentUpdate:function(t,e,n,r,i,o){var a,u,c,s=this._instance,l=Boolean(s.componentDidUpdate);l&&(a=s.props,u=s.state,c=s.context),s.componentWillUpdate&&s.componentWillUpdate(e,n,r),this._currentElement=t,this._context=o,s.props=e,s.state=n,s.context=r,this._updateRenderedComponent(i,o),l&&i.getReactMountReady().enqueue(s.componentDidUpdate.bind(s,a,u,c),s)},_updateRenderedComponent:function(t,e){var n=this._renderedComponent,r=n._currentElement,i=this._renderValidatedComponent(),o=0;if(m(r,i))d.receiveComponent(n,i,t,this._processChildContext(e));else{var a=d.getHostNode(n);d.unmountComponent(n,!1);var u=h.getType(i);this._renderedNodeType=u;var c=this._instantiateReactComponent(i,u!==h.EMPTY);this._renderedComponent=c;var s=d.mountComponent(c,t,this._hostParent,this._hostContainerInfo,this._processChildContext(e),o);this._replaceNodeWithMarkup(a,s,n)}},_replaceNodeWithMarkup:function(t,e,n){s.replaceNodeWithMarkup(t,e,n)},_renderValidatedComponentWithoutOwnerOrContext:function(){var t=this._instance;return t.render()},_renderValidatedComponent:function(){var t;if(this._compositeType!==y.StatelessFunctional){l.current=this;try{t=this._renderValidatedComponentWithoutOwnerOrContext()}finally{l.current=null}}else t=this._renderValidatedComponentWithoutOwnerOrContext();return null===t||!1===t||c.isValidElement(t)||a(\"109\",this.getName()||\"ReactCompositeComponent\"),t},attachRef:function(t,e){var n=this.getPublicInstance();null==n&&a(\"110\");var r=e.getPublicInstance();(n.refs===v?n.refs={}:n.refs)[t]=r},detachRef:function(t){delete this.getPublicInstance().refs[t]},getName:function(){var t=this._currentElement.type,e=this._instance&&this._instance.constructor;return t.displayName||e&&e.displayName||t.name||e&&e.name||null},getPublicInstance:function(){var t=this._instance;return this._compositeType===y.StatelessFunctional?null:t},_instantiateReactComponent:null};t.exports=b},function(t,e,n){\"use strict\";var r=n(4),i=n(372),o=n(167),a=n(24),u=n(12),c=n(385),s=n(401),l=n(171),f=n(408);n(2);i.inject();var p={findDOMNode:s,render:o.render,unmountComponentAtNode:o.unmountComponentAtNode,version:c,unstable_batchedUpdates:u.batchedUpdates,unstable_renderSubtreeIntoContainer:f};\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&\"function\"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.inject&&__REACT_DEVTOOLS_GLOBAL_HOOK__.inject({ComponentTree:{getClosestInstanceFromNode:r.getClosestInstanceFromNode,getNodeFromInstance:function(t){return t._renderedComponent&&(t=l(t)),t?r.getNodeFromInstance(t):null}},Mount:o,Reconciler:a});t.exports=p},function(t,e,n){\"use strict\";function r(t){if(t){var e=t._currentElement._owner||null;if(e){var n=e.getName();if(n)return\" This DOM node was rendered by `\"+n+\"`.\"}}return\"\"}function i(t,e){e&&($[t._tag]&&(null!=e.children||null!=e.dangerouslySetInnerHTML)&&g(\"137\",t._tag,t._currentElement._owner?\" Check the render method of \"+t._currentElement._owner.getName()+\".\":\"\"),null!=e.dangerouslySetInnerHTML&&(null!=e.children&&g(\"60\"),\"object\"==typeof e.dangerouslySetInnerHTML&&z in e.dangerouslySetInnerHTML||g(\"61\")),null!=e.style&&\"object\"!=typeof e.style&&g(\"62\",r(t)))}function o(t,e,n,r){if(!(r instanceof D)){var i=t._hostContainerInfo,o=i._node&&i._node.nodeType===q,u=o?i._node:i._ownerDocument;B(e,u),r.getReactMountReady().enqueue(a,{inst:t,registrationName:e,listener:n})}}function a(){var t=this;k.putListener(t.inst,t.registrationName,t.listener)}function u(){var t=this;N.postMountWrapper(t)}function c(){var t=this;O.postMountWrapper(t)}function s(){var t=this;A.postMountWrapper(t)}function l(){L.track(this)}function f(){var t=this;t._rootNodeID||g(\"63\");var e=j(t);switch(e||g(\"64\"),t._tag){case\"iframe\":case\"object\":t._wrapperState.listeners=[M.trapBubbledEvent(\"topLoad\",\"load\",e)];break;case\"video\":case\"audio\":t._wrapperState.listeners=[];for(var n in Y)Y.hasOwnProperty(n)&&t._wrapperState.listeners.push(M.trapBubbledEvent(n,Y[n],e));break;case\"source\":t._wrapperState.listeners=[M.trapBubbledEvent(\"topError\",\"error\",e)];break;case\"img\":t._wrapperState.listeners=[M.trapBubbledEvent(\"topError\",\"error\",e),M.trapBubbledEvent(\"topLoad\",\"load\",e)];break;case\"form\":t._wrapperState.listeners=[M.trapBubbledEvent(\"topReset\",\"reset\",e),M.trapBubbledEvent(\"topSubmit\",\"submit\",e)];break;case\"input\":case\"select\":case\"textarea\":t._wrapperState.listeners=[M.trapBubbledEvent(\"topInvalid\",\"invalid\",e)]}}function p(){P.postUpdateWrapper(this)}function h(t){Z.call(Q,t)||(X.test(t)||g(\"65\",t),Q[t]=!0)}function d(t,e){return t.indexOf(\"-\")>=0||null!=e.is}function v(t){var e=t.type;h(e),this._currentElement=t,this._tag=e.toLowerCase(),this._namespaceURI=null,this._renderedChildren=null,this._previousStyle=null,this._previousStyleCopy=null,this._hostNode=null,this._hostParent=null,this._rootNodeID=0,this._domID=0,this._hostContainerInfo=null,this._wrapperState=null,this._topLevelWrapper=null,this._flags=0}var g=n(1),m=n(3),y=n(346),_=n(348),b=n(20),x=n(83),w=n(21),C=n(160),k=n(22),E=n(84),M=n(53),T=n(161),S=n(4),N=n(365),A=n(366),P=n(162),O=n(369),I=(n(9),n(378)),D=n(383),R=(n(11),n(56)),L=(n(0),n(95),n(81),n(173)),U=(n(97),n(2),T),F=k.deleteListener,j=S.getNodeFromInstance,B=M.listenTo,V=E.registrationNameModules,W={string:!0,number:!0},z=\"__html\",H={children:null,dangerouslySetInnerHTML:null,suppressContentEditableWarning:null},q=11,Y={topAbort:\"abort\",topCanPlay:\"canplay\",topCanPlayThrough:\"canplaythrough\",topDurationChange:\"durationchange\",topEmptied:\"emptied\",topEncrypted:\"encrypted\",topEnded:\"ended\",topError:\"error\",topLoadedData:\"loadeddata\",topLoadedMetadata:\"loadedmetadata\",topLoadStart:\"loadstart\",topPause:\"pause\",topPlay:\"play\",topPlaying:\"playing\",topProgress:\"progress\",topRateChange:\"ratechange\",topSeeked:\"seeked\",topSeeking:\"seeking\",topStalled:\"stalled\",topSuspend:\"suspend\",topTimeUpdate:\"timeupdate\",topVolumeChange:\"volumechange\",topWaiting:\"waiting\"},K={area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0},G={listing:!0,pre:!0,textarea:!0},$=m({menuitem:!0},K),X=/^[a-zA-Z][a-zA-Z:_\\.\\-\\d]*$/,Q={},Z={}.hasOwnProperty,J=1;v.displayName=\"ReactDOMComponent\",v.Mixin={mountComponent:function(t,e,n,r){this._rootNodeID=J++,this._domID=n._idCounter++,this._hostParent=e,this._hostContainerInfo=n;var o=this._currentElement.props;switch(this._tag){case\"audio\":case\"form\":case\"iframe\":case\"img\":case\"link\":case\"object\":case\"source\":case\"video\":this._wrapperState={listeners:null},t.getReactMountReady().enqueue(f,this);break;case\"input\":N.mountWrapper(this,o,e),o=N.getHostProps(this,o),t.getReactMountReady().enqueue(l,this),t.getReactMountReady().enqueue(f,this);break;case\"option\":A.mountWrapper(this,o,e),o=A.getHostProps(this,o);break;case\"select\":P.mountWrapper(this,o,e),o=P.getHostProps(this,o),t.getReactMountReady().enqueue(f,this);break;case\"textarea\":O.mountWrapper(this,o,e),o=O.getHostProps(this,o),t.getReactMountReady().enqueue(l,this),t.getReactMountReady().enqueue(f,this)}i(this,o);var a,p;null!=e?(a=e._namespaceURI,p=e._tag):n._tag&&(a=n._namespaceURI,p=n._tag),(null==a||a===x.svg&&\"foreignobject\"===p)&&(a=x.html),a===x.html&&(\"svg\"===this._tag?a=x.svg:\"math\"===this._tag&&(a=x.mathml)),this._namespaceURI=a;var h;if(t.useCreateElement){var d,v=n._ownerDocument;if(a===x.html)if(\"script\"===this._tag){var g=v.createElement(\"div\"),m=this._currentElement.type;g.innerHTML=\"<\"+m+\"></\"+m+\">\",d=g.removeChild(g.firstChild)}else d=o.is?v.createElement(this._currentElement.type,o.is):v.createElement(this._currentElement.type);else d=v.createElementNS(a,this._currentElement.type);S.precacheNode(this,d),this._flags|=U.hasCachedChildNodes,this._hostParent||C.setAttributeForRoot(d),this._updateDOMProperties(null,o,t);var _=b(d);this._createInitialChildren(t,o,r,_),h=_}else{var w=this._createOpenTagMarkupAndPutListeners(t,o),k=this._createContentMarkup(t,o,r);h=!k&&K[this._tag]?w+\"/>\":w+\">\"+k+\"</\"+this._currentElement.type+\">\"}switch(this._tag){case\"input\":t.getReactMountReady().enqueue(u,this),o.autoFocus&&t.getReactMountReady().enqueue(y.focusDOMComponent,this);break;case\"textarea\":t.getReactMountReady().enqueue(c,this),o.autoFocus&&t.getReactMountReady().enqueue(y.focusDOMComponent,this);break;case\"select\":case\"button\":o.autoFocus&&t.getReactMountReady().enqueue(y.focusDOMComponent,this);break;case\"option\":t.getReactMountReady().enqueue(s,this)}return h},_createOpenTagMarkupAndPutListeners:function(t,e){var n=\"<\"+this._currentElement.type;for(var r in e)if(e.hasOwnProperty(r)){var i=e[r];if(null!=i)if(V.hasOwnProperty(r))i&&o(this,r,i,t);else{\"style\"===r&&(i&&(i=this._previousStyleCopy=m({},e.style)),i=_.createMarkupForStyles(i,this));var a=null;null!=this._tag&&d(this._tag,e)?H.hasOwnProperty(r)||(a=C.createMarkupForCustomAttribute(r,i)):a=C.createMarkupForProperty(r,i),a&&(n+=\" \"+a)}}return t.renderToStaticMarkup?n:(this._hostParent||(n+=\" \"+C.createMarkupForRoot()),n+=\" \"+C.createMarkupForID(this._domID))},_createContentMarkup:function(t,e,n){var r=\"\",i=e.dangerouslySetInnerHTML;if(null!=i)null!=i.__html&&(r=i.__html);else{var o=W[typeof e.children]?e.children:null,a=null!=o?null:e.children;if(null!=o)r=R(o);else if(null!=a){var u=this.mountChildren(a,t,n);r=u.join(\"\")}}return G[this._tag]&&\"\\n\"===r.charAt(0)?\"\\n\"+r:r},_createInitialChildren:function(t,e,n,r){var i=e.dangerouslySetInnerHTML;if(null!=i)null!=i.__html&&b.queueHTML(r,i.__html);else{var o=W[typeof e.children]?e.children:null,a=null!=o?null:e.children;if(null!=o)\"\"!==o&&b.queueText(r,o);else if(null!=a)for(var u=this.mountChildren(a,t,n),c=0;c<u.length;c++)b.queueChild(r,u[c])}},receiveComponent:function(t,e,n){var r=this._currentElement;this._currentElement=t,this.updateComponent(e,r,t,n)},updateComponent:function(t,e,n,r){var o=e.props,a=this._currentElement.props;switch(this._tag){case\"input\":o=N.getHostProps(this,o),a=N.getHostProps(this,a);break;case\"option\":o=A.getHostProps(this,o),a=A.getHostProps(this,a);break;case\"select\":o=P.getHostProps(this,o),a=P.getHostProps(this,a);break;case\"textarea\":o=O.getHostProps(this,o),a=O.getHostProps(this,a)}switch(i(this,a),this._updateDOMProperties(o,a,t),this._updateDOMChildren(o,a,t,r),this._tag){case\"input\":N.updateWrapper(this),L.updateValueIfChanged(this);break;case\"textarea\":O.updateWrapper(this);break;case\"select\":t.getReactMountReady().enqueue(p,this)}},_updateDOMProperties:function(t,e,n){var r,i,a;for(r in t)if(!e.hasOwnProperty(r)&&t.hasOwnProperty(r)&&null!=t[r])if(\"style\"===r){var u=this._previousStyleCopy;for(i in u)u.hasOwnProperty(i)&&(a=a||{},a[i]=\"\");this._previousStyleCopy=null}else V.hasOwnProperty(r)?t[r]&&F(this,r):d(this._tag,t)?H.hasOwnProperty(r)||C.deleteValueForAttribute(j(this),r):(w.properties[r]||w.isCustomAttribute(r))&&C.deleteValueForProperty(j(this),r);for(r in e){var c=e[r],s=\"style\"===r?this._previousStyleCopy:null!=t?t[r]:void 0;if(e.hasOwnProperty(r)&&c!==s&&(null!=c||null!=s))if(\"style\"===r)if(c?c=this._previousStyleCopy=m({},c):this._previousStyleCopy=null,s){for(i in s)!s.hasOwnProperty(i)||c&&c.hasOwnProperty(i)||(a=a||{},a[i]=\"\");for(i in c)c.hasOwnProperty(i)&&s[i]!==c[i]&&(a=a||{},a[i]=c[i])}else a=c;else if(V.hasOwnProperty(r))c?o(this,r,c,n):s&&F(this,r);else if(d(this._tag,e))H.hasOwnProperty(r)||C.setValueForAttribute(j(this),r,c);else if(w.properties[r]||w.isCustomAttribute(r)){var l=j(this);null!=c?C.setValueForProperty(l,r,c):C.deleteValueForProperty(l,r)}}a&&_.setValueForStyles(j(this),a,this)},_updateDOMChildren:function(t,e,n,r){var i=W[typeof t.children]?t.children:null,o=W[typeof e.children]?e.children:null,a=t.dangerouslySetInnerHTML&&t.dangerouslySetInnerHTML.__html,u=e.dangerouslySetInnerHTML&&e.dangerouslySetInnerHTML.__html,c=null!=i?null:t.children,s=null!=o?null:e.children,l=null!=i||null!=a,f=null!=o||null!=u;null!=c&&null==s?this.updateChildren(null,n,r):l&&!f&&this.updateTextContent(\"\"),null!=o?i!==o&&this.updateTextContent(\"\"+o):null!=u?a!==u&&this.updateMarkup(\"\"+u):null!=s&&this.updateChildren(s,n,r)},getHostNode:function(){return j(this)},unmountComponent:function(t){switch(this._tag){case\"audio\":case\"form\":case\"iframe\":case\"img\":case\"link\":case\"object\":case\"source\":case\"video\":var e=this._wrapperState.listeners;if(e)for(var n=0;n<e.length;n++)e[n].remove();break;case\"input\":case\"textarea\":L.stopTracking(this);break;case\"html\":case\"head\":case\"body\":g(\"66\",this._tag)}this.unmountChildren(t),S.uncacheNode(this),k.deleteAllListeners(this),this._rootNodeID=0,this._domID=0,this._wrapperState=null},getPublicInstance:function(){return j(this)}},m(v.prototype,v.Mixin,I.Mixin),t.exports=v},function(t,e,n){\"use strict\";function r(t,e){var n={_topLevelWrapper:t,_idCounter:1,_ownerDocument:e?e.nodeType===i?e:e.ownerDocument:null,_node:e,_tag:e?e.nodeName.toLowerCase():null,_namespaceURI:e?e.namespaceURI:null};return n}var i=(n(97),9);t.exports=r},function(t,e,n){\"use strict\";var r=n(3),i=n(20),o=n(4),a=function(t){this._currentElement=null,this._hostNode=null,this._hostParent=null,this._hostContainerInfo=null,this._domID=0};r(a.prototype,{mountComponent:function(t,e,n,r){var a=n._idCounter++;this._domID=a,this._hostParent=e,this._hostContainerInfo=n;var u=\" react-empty: \"+this._domID+\" \";if(t.useCreateElement){var c=n._ownerDocument,s=c.createComment(u);return o.precacheNode(this,s),i(s)}return t.renderToStaticMarkup?\"\":\"\\x3c!--\"+u+\"--\\x3e\"},receiveComponent:function(){},getHostNode:function(){return o.getNodeFromInstance(this)},unmountComponent:function(){o.uncacheNode(this)}}),t.exports=a},function(t,e,n){\"use strict\";var r={useCreateElement:!0,useFiber:!1};t.exports=r},function(t,e,n){\"use strict\";var r=n(82),i=n(4),o={dangerouslyProcessChildrenUpdates:function(t,e){var n=i.getNodeFromInstance(t);r.processUpdates(n,e)}};t.exports=o},function(t,e,n){\"use strict\";function r(){this._rootNodeID&&p.updateWrapper(this)}function i(t){return\"checkbox\"===t.type||\"radio\"===t.type?null!=t.checked:null!=t.value}function o(t){var e=this._currentElement.props,n=s.executeOnChange(e,t);f.asap(r,this);var i=e.name;if(\"radio\"===e.type&&null!=i){for(var o=l.getNodeFromInstance(this),u=o;u.parentNode;)u=u.parentNode;for(var c=u.querySelectorAll(\"input[name=\"+JSON.stringify(\"\"+i)+'][type=\"radio\"]'),p=0;p<c.length;p++){var h=c[p];if(h!==o&&h.form===o.form){var d=l.getInstanceFromNode(h);d||a(\"90\"),f.asap(r,d)}}}return n}var a=n(1),u=n(3),c=n(160),s=n(86),l=n(4),f=n(12),p=(n(0),n(2),{getHostProps:function(t,e){var n=s.getValue(e),r=s.getChecked(e);return u({type:void 0,step:void 0,min:void 0,max:void 0},e,{defaultChecked:void 0,defaultValue:void 0,value:null!=n?n:t._wrapperState.initialValue,checked:null!=r?r:t._wrapperState.initialChecked,onChange:t._wrapperState.onChange})},mountWrapper:function(t,e){var n=e.defaultValue;t._wrapperState={initialChecked:null!=e.checked?e.checked:e.defaultChecked,initialValue:null!=e.value?e.value:n,listeners:null,onChange:o.bind(t),controlled:i(e)}},updateWrapper:function(t){var e=t._currentElement.props,n=e.checked;null!=n&&c.setValueForProperty(l.getNodeFromInstance(t),\"checked\",n||!1);var r=l.getNodeFromInstance(t),i=s.getValue(e);if(null!=i)if(0===i&&\"\"===r.value)r.value=\"0\";else if(\"number\"===e.type){var o=parseFloat(r.value,10)||0;(i!=o||i==o&&r.value!=i)&&(r.value=\"\"+i)}else r.value!==\"\"+i&&(r.value=\"\"+i);else null==e.value&&null!=e.defaultValue&&r.defaultValue!==\"\"+e.defaultValue&&(r.defaultValue=\"\"+e.defaultValue),null==e.checked&&null!=e.defaultChecked&&(r.defaultChecked=!!e.defaultChecked)},postMountWrapper:function(t){var e=t._currentElement.props,n=l.getNodeFromInstance(t);switch(e.type){case\"submit\":case\"reset\":break;case\"color\":case\"date\":case\"datetime\":case\"datetime-local\":case\"month\":case\"time\":case\"week\":n.value=\"\",n.value=n.defaultValue;break;default:n.value=n.value}var r=n.name;\"\"!==r&&(n.name=\"\"),n.defaultChecked=!n.defaultChecked,n.defaultChecked=!n.defaultChecked,\"\"!==r&&(n.name=r)}});t.exports=p},function(t,e,n){\"use strict\";function r(t){var e=\"\";return o.Children.forEach(t,function(t){null!=t&&(\"string\"==typeof t||\"number\"==typeof t?e+=t:c||(c=!0))}),e}var i=n(3),o=n(26),a=n(4),u=n(162),c=(n(2),!1),s={mountWrapper:function(t,e,n){var i=null;if(null!=n){var o=n;\"optgroup\"===o._tag&&(o=o._hostParent),null!=o&&\"select\"===o._tag&&(i=u.getSelectValueContext(o))}var a=null;if(null!=i){var c;if(c=null!=e.value?e.value+\"\":r(e.children),a=!1,Array.isArray(i)){for(var s=0;s<i.length;s++)if(\"\"+i[s]===c){a=!0;break}}else a=\"\"+i===c}t._wrapperState={selected:a}},postMountWrapper:function(t){var e=t._currentElement.props;if(null!=e.value){a.getNodeFromInstance(t).setAttribute(\"value\",e.value)}},getHostProps:function(t,e){var n=i({selected:void 0,children:void 0},e);null!=t._wrapperState.selected&&(n.selected=t._wrapperState.selected);var o=r(e.children);return o&&(n.children=o),n}};t.exports=s},function(t,e,n){\"use strict\";function r(t,e,n,r){return t===n&&e===r}function i(t){var e=document.selection,n=e.createRange(),r=n.text.length,i=n.duplicate();i.moveToElementText(t),i.setEndPoint(\"EndToStart\",n);var o=i.text.length;return{start:o,end:o+r}}function o(t){var e=window.getSelection&&window.getSelection();if(!e||0===e.rangeCount)return null;var n=e.anchorNode,i=e.anchorOffset,o=e.focusNode,a=e.focusOffset,u=e.getRangeAt(0);try{u.startContainer.nodeType,u.endContainer.nodeType}catch(t){return null}var c=r(e.anchorNode,e.anchorOffset,e.focusNode,e.focusOffset),s=c?0:u.toString().length,l=u.cloneRange();l.selectNodeContents(t),l.setEnd(u.startContainer,u.startOffset);var f=r(l.startContainer,l.startOffset,l.endContainer,l.endOffset),p=f?0:l.toString().length,h=p+s,d=document.createRange();d.setStart(n,i),d.setEnd(o,a);var v=d.collapsed;return{start:v?h:p,end:v?p:h}}function a(t,e){var n,r,i=document.selection.createRange().duplicate();void 0===e.end?(n=e.start,r=n):e.start>e.end?(n=e.end,r=e.start):(n=e.start,r=e.end),i.moveToElementText(t),i.moveStart(\"character\",n),i.setEndPoint(\"EndToStart\",i),i.moveEnd(\"character\",r-n),i.select()}function u(t,e){if(window.getSelection){var n=window.getSelection(),r=t[l()].length,i=Math.min(e.start,r),o=void 0===e.end?i:Math.min(e.end,r);if(!n.extend&&i>o){var a=o;o=i,i=a}var u=s(t,i),c=s(t,o);if(u&&c){var f=document.createRange();f.setStart(u.node,u.offset),n.removeAllRanges(),i>o?(n.addRange(f),n.extend(c.node,c.offset)):(f.setEnd(c.node,c.offset),n.addRange(f))}}}var c=n(6),s=n(405),l=n(172),f=c.canUseDOM&&\"selection\"in document&&!(\"getSelection\"in window),p={getOffsets:f?i:o,setOffsets:f?a:u};t.exports=p},function(t,e,n){\"use strict\";var r=n(1),i=n(3),o=n(82),a=n(20),u=n(4),c=n(56),s=(n(0),n(97),function(t){this._currentElement=t,this._stringText=\"\"+t,this._hostNode=null,this._hostParent=null,this._domID=0,this._mountIndex=0,this._closingComment=null,this._commentNodes=null});i(s.prototype,{mountComponent:function(t,e,n,r){var i=n._idCounter++,o=\" react-text: \"+i+\" \";if(this._domID=i,this._hostParent=e,t.useCreateElement){var s=n._ownerDocument,l=s.createComment(o),f=s.createComment(\" /react-text \"),p=a(s.createDocumentFragment());return a.queueChild(p,a(l)),this._stringText&&a.queueChild(p,a(s.createTextNode(this._stringText))),a.queueChild(p,a(f)),u.precacheNode(this,l),this._closingComment=f,p}var h=c(this._stringText);return t.renderToStaticMarkup?h:\"\\x3c!--\"+o+\"--\\x3e\"+h+\"\\x3c!-- /react-text --\\x3e\"},receiveComponent:function(t,e){if(t!==this._currentElement){this._currentElement=t;var n=\"\"+t;if(n!==this._stringText){this._stringText=n;var r=this.getHostNode();o.replaceDelimitedText(r[0],r[1],n)}}},getHostNode:function(){var t=this._commentNodes;if(t)return t;if(!this._closingComment)for(var e=u.getNodeFromInstance(this),n=e.nextSibling;;){if(null==n&&r(\"67\",this._domID),8===n.nodeType&&\" /react-text \"===n.nodeValue){this._closingComment=n;break}n=n.nextSibling}return t=[this._hostNode,this._closingComment],this._commentNodes=t,t},unmountComponent:function(){this._closingComment=null,this._commentNodes=null,u.uncacheNode(this)}}),t.exports=s},function(t,e,n){\"use strict\";function r(){this._rootNodeID&&l.updateWrapper(this)}function i(t){var e=this._currentElement.props,n=u.executeOnChange(e,t);return s.asap(r,this),n}var o=n(1),a=n(3),u=n(86),c=n(4),s=n(12),l=(n(0),n(2),{getHostProps:function(t,e){return null!=e.dangerouslySetInnerHTML&&o(\"91\"),a({},e,{value:void 0,defaultValue:void 0,children:\"\"+t._wrapperState.initialValue,onChange:t._wrapperState.onChange})},mountWrapper:function(t,e){var n=u.getValue(e),r=n;if(null==n){var a=e.defaultValue,c=e.children;null!=c&&(null!=a&&o(\"92\"),Array.isArray(c)&&(c.length<=1||o(\"93\"),c=c[0]),a=\"\"+c),null==a&&(a=\"\"),r=a}t._wrapperState={initialValue:\"\"+r,listeners:null,onChange:i.bind(t)}},updateWrapper:function(t){var e=t._currentElement.props,n=c.getNodeFromInstance(t),r=u.getValue(e);if(null!=r){var i=\"\"+r;i!==n.value&&(n.value=i),null==e.defaultValue&&(n.defaultValue=i)}null!=e.defaultValue&&(n.defaultValue=e.defaultValue)},postMountWrapper:function(t){var e=c.getNodeFromInstance(t),n=e.textContent;n===t._wrapperState.initialValue&&(e.value=n)}});t.exports=l},function(t,e,n){\"use strict\";function r(t,e){\"_hostNode\"in t||c(\"33\"),\"_hostNode\"in e||c(\"33\");for(var n=0,r=t;r;r=r._hostParent)n++;for(var i=0,o=e;o;o=o._hostParent)i++;for(;n-i>0;)t=t._hostParent,n--;for(;i-n>0;)e=e._hostParent,i--;for(var a=n;a--;){if(t===e)return t;t=t._hostParent,e=e._hostParent}return null}function i(t,e){\"_hostNode\"in t||c(\"35\"),\"_hostNode\"in e||c(\"35\");for(;e;){if(e===t)return!0;e=e._hostParent}return!1}function o(t){return\"_hostNode\"in t||c(\"36\"),t._hostParent}function a(t,e,n){for(var r=[];t;)r.push(t),t=t._hostParent;var i;for(i=r.length;i-- >0;)e(r[i],\"captured\",n);for(i=0;i<r.length;i++)e(r[i],\"bubbled\",n)}function u(t,e,n,i,o){for(var a=t&&e?r(t,e):null,u=[];t&&t!==a;)u.push(t),t=t._hostParent;for(var c=[];e&&e!==a;)c.push(e),e=e._hostParent;var s;for(s=0;s<u.length;s++)n(u[s],\"bubbled\",i);for(s=c.length;s-- >0;)n(c[s],\"captured\",o)}var c=n(1);n(0);t.exports={isAncestor:i,getLowestCommonAncestor:r,getParentInstance:o,traverseTwoPhase:a,traverseEnterLeave:u}},function(t,e,n){\"use strict\";function r(){this.reinitializeTransaction()}var i=n(3),o=n(12),a=n(55),u=n(11),c={initialize:u,close:function(){p.isBatchingUpdates=!1}},s={initialize:u,close:o.flushBatchedUpdates.bind(o)},l=[s,c];i(r.prototype,a,{getTransactionWrappers:function(){return l}});var f=new r,p={isBatchingUpdates:!1,batchedUpdates:function(t,e,n,r,i,o){var a=p.isBatchingUpdates;return p.isBatchingUpdates=!0,a?t(e,n,r,i,o):f.perform(t,null,e,n,r,i,o)}};t.exports=p},function(t,e,n){\"use strict\";function r(){C||(C=!0,y.EventEmitter.injectReactEventListener(m),y.EventPluginHub.injectEventPluginOrder(u),y.EventPluginUtils.injectComponentTree(p),y.EventPluginUtils.injectTreeTraversal(d),y.EventPluginHub.injectEventPluginsByName({SimpleEventPlugin:w,EnterLeaveEventPlugin:c,ChangeEventPlugin:a,SelectEventPlugin:x,BeforeInputEventPlugin:o}),y.HostComponent.injectGenericComponentClass(f),y.HostComponent.injectTextComponentClass(v),y.DOMProperty.injectDOMPropertyConfig(i),y.DOMProperty.injectDOMPropertyConfig(s),y.DOMProperty.injectDOMPropertyConfig(b),y.EmptyComponent.injectEmptyComponentFactory(function(t){return new h(t)}),y.Updates.injectReconcileTransaction(_),y.Updates.injectBatchingStrategy(g),y.Component.injectEnvironment(l))}var i=n(345),o=n(347),a=n(349),u=n(351),c=n(352),s=n(355),l=n(357),f=n(360),p=n(4),h=n(362),d=n(370),v=n(368),g=n(371),m=n(375),y=n(376),_=n(381),b=n(386),x=n(387),w=n(388),C=!1;t.exports={inject:r}},function(t,e,n){\"use strict\";var r=\"function\"==typeof Symbol&&Symbol.for&&Symbol.for(\"react.element\")||60103;t.exports=r},function(t,e,n){\"use strict\";function r(t){i.enqueueEvents(t),i.processEventQueue(!1)}var i=n(22),o={handleTopLevel:function(t,e,n,o){r(i.extractEvents(t,e,n,o))}};t.exports=o},function(t,e,n){\"use strict\";function r(t){for(;t._hostParent;)t=t._hostParent;var e=f.getNodeFromInstance(t),n=e.parentNode;return f.getClosestInstanceFromNode(n)}function i(t,e){this.topLevelType=t,this.nativeEvent=e,this.ancestors=[]}function o(t){var e=h(t.nativeEvent),n=f.getClosestInstanceFromNode(e),i=n;do{t.ancestors.push(i),i=i&&r(i)}while(i);for(var o=0;o<t.ancestors.length;o++)n=t.ancestors[o],v._handleTopLevel(t.topLevelType,n,t.nativeEvent,h(t.nativeEvent))}function a(t){t(d(window))}var u=n(3),c=n(153),s=n(6),l=n(18),f=n(4),p=n(12),h=n(94),d=n(335);u(i.prototype,{destructor:function(){this.topLevelType=null,this.nativeEvent=null,this.ancestors.length=0}}),l.addPoolingTo(i,l.twoArgumentPooler);var v={_enabled:!0,_handleTopLevel:null,WINDOW_HANDLE:s.canUseDOM?window:null,setHandleTopLevel:function(t){v._handleTopLevel=t},setEnabled:function(t){v._enabled=!!t},isEnabled:function(){return v._enabled},trapBubbledEvent:function(t,e,n){return n?c.listen(n,e,v.dispatchEvent.bind(null,t)):null},trapCapturedEvent:function(t,e,n){return n?c.capture(n,e,v.dispatchEvent.bind(null,t)):null},monitorScrollValue:function(t){var e=a.bind(null,t);c.listen(window,\"scroll\",e)},dispatchEvent:function(t,e){if(v._enabled){var n=i.getPooled(t,e);try{p.batchedUpdates(o,n)}finally{i.release(n)}}}};t.exports=v},function(t,e,n){\"use strict\";var r=n(21),i=n(22),o=n(52),a=n(87),u=n(163),c=n(53),s=n(165),l=n(12),f={Component:a.injection,DOMProperty:r.injection,EmptyComponent:u.injection,EventPluginHub:i.injection,EventPluginUtils:o.injection,EventEmitter:c.injection,HostComponent:s.injection,Updates:l.injection};t.exports=f},function(t,e,n){\"use strict\";var r=n(399),i=/\\/?>/,o=/^<\\!\\-\\-/,a={CHECKSUM_ATTR_NAME:\"data-react-checksum\",addChecksumToMarkup:function(t){var e=r(t);return o.test(t)?t:t.replace(i,\" \"+a.CHECKSUM_ATTR_NAME+'=\"'+e+'\"$&')},canReuseMarkup:function(t,e){var n=e.getAttribute(a.CHECKSUM_ATTR_NAME);return n=n&&parseInt(n,10),r(t)===n}};t.exports=a},function(t,e,n){\"use strict\";function r(t,e,n){return{type:\"INSERT_MARKUP\",content:t,fromIndex:null,fromNode:null,toIndex:n,afterNode:e}}function i(t,e,n){return{type:\"MOVE_EXISTING\",content:null,fromIndex:t._mountIndex,fromNode:p.getHostNode(t),toIndex:n,afterNode:e}}function o(t,e){return{type:\"REMOVE_NODE\",content:null,fromIndex:t._mountIndex,fromNode:e,toIndex:null,afterNode:null}}function a(t){return{type:\"SET_MARKUP\",content:t,fromIndex:null,fromNode:null,toIndex:null,afterNode:null}}function u(t){return{type:\"TEXT_CONTENT\",content:t,fromIndex:null,fromNode:null,toIndex:null,afterNode:null}}function c(t,e){return e&&(t=t||[],t.push(e)),t}function s(t,e){f.processChildrenUpdates(t,e)}var l=n(1),f=n(87),p=(n(39),n(9),n(15),n(24)),h=n(356),d=(n(11),n(402)),v=(n(0),{Mixin:{_reconcilerInstantiateChildren:function(t,e,n){return h.instantiateChildren(t,e,n)},_reconcilerUpdateChildren:function(t,e,n,r,i,o){var a,u=0;return a=d(e,u),h.updateChildren(t,a,n,r,i,this,this._hostContainerInfo,o,u),a},mountChildren:function(t,e,n){var r=this._reconcilerInstantiateChildren(t,e,n);this._renderedChildren=r;var i=[],o=0;for(var a in r)if(r.hasOwnProperty(a)){var u=r[a],c=0,s=p.mountComponent(u,e,this,this._hostContainerInfo,n,c);u._mountIndex=o++,i.push(s)}return i},updateTextContent:function(t){var e=this._renderedChildren;h.unmountChildren(e,!1);for(var n in e)e.hasOwnProperty(n)&&l(\"118\");s(this,[u(t)])},updateMarkup:function(t){var e=this._renderedChildren;h.unmountChildren(e,!1);for(var n in e)e.hasOwnProperty(n)&&l(\"118\");s(this,[a(t)])},updateChildren:function(t,e,n){this._updateChildren(t,e,n)},_updateChildren:function(t,e,n){var r=this._renderedChildren,i={},o=[],a=this._reconcilerUpdateChildren(r,t,o,i,e,n);if(a||r){var u,l=null,f=0,h=0,d=0,v=null;for(u in a)if(a.hasOwnProperty(u)){var g=r&&r[u],m=a[u];g===m?(l=c(l,this.moveChild(g,v,f,h)),h=Math.max(g._mountIndex,h),g._mountIndex=f):(g&&(h=Math.max(g._mountIndex,h)),l=c(l,this._mountChildAtIndex(m,o[d],v,f,e,n)),d++),f++,v=p.getHostNode(m)}for(u in i)i.hasOwnProperty(u)&&(l=c(l,this._unmountChild(r[u],i[u])));l&&s(this,l),this._renderedChildren=a}},unmountChildren:function(t){var e=this._renderedChildren;h.unmountChildren(e,t),this._renderedChildren=null},moveChild:function(t,e,n,r){if(t._mountIndex<r)return i(t,e,n)},createChild:function(t,e,n){return r(n,e,t._mountIndex)},removeChild:function(t,e){return o(t,e)},_mountChildAtIndex:function(t,e,n,r,i,o){return t._mountIndex=r,this.createChild(t,n,e)},_unmountChild:function(t,e){var n=this.removeChild(t,e);return t._mountIndex=null,n}}});t.exports=v},function(t,e,n){\"use strict\";function r(t){return!(!t||\"function\"!=typeof t.attachRef||\"function\"!=typeof t.detachRef)}var i=n(1),o=(n(0),{addComponentAsRefTo:function(t,e,n){r(n)||i(\"119\"),n.attachRef(e,t)},removeComponentAsRefFrom:function(t,e,n){r(n)||i(\"120\");var o=n.getPublicInstance();o&&o.refs[e]===t.getPublicInstance()&&n.detachRef(e)}});t.exports=o},function(t,e,n){\"use strict\";t.exports=\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\"},function(t,e,n){\"use strict\";function r(t){this.reinitializeTransaction(),this.renderToStaticMarkup=!1,this.reactMountReady=o.getPooled(null),this.useCreateElement=t}var i=n(3),o=n(159),a=n(18),u=n(53),c=n(166),s=(n(9),n(55)),l=n(89),f={initialize:c.getSelectionInformation,close:c.restoreSelection},p={initialize:function(){var t=u.isEnabled();return u.setEnabled(!1),t},close:function(t){u.setEnabled(t)}},h={initialize:function(){this.reactMountReady.reset()},close:function(){this.reactMountReady.notifyAll()}},d=[f,p,h],v={getTransactionWrappers:function(){return d},getReactMountReady:function(){return this.reactMountReady},getUpdateQueue:function(){return l},checkpoint:function(){return this.reactMountReady.checkpoint()},rollback:function(t){this.reactMountReady.rollback(t)},destructor:function(){o.release(this.reactMountReady),this.reactMountReady=null}};i(r.prototype,s,v),a.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){\"function\"==typeof t?t(e.getPublicInstance()):o.addComponentAsRefTo(e,t,n)}function i(t,e,n){\"function\"==typeof t?t(null):o.removeComponentAsRefFrom(e,t,n)}var o=n(379),a={};a.attachRefs=function(t,e){if(null!==e&&\"object\"==typeof e){var n=e.ref;null!=n&&r(n,t,e._owner)}},a.shouldUpdateRefs=function(t,e){var n=null,r=null;null!==t&&\"object\"==typeof t&&(n=t.ref,r=t._owner);var i=null,o=null;return null!==e&&\"object\"==typeof e&&(i=e.ref,o=e._owner),n!==i||\"string\"==typeof i&&o!==r},a.detachRefs=function(t,e){if(null!==e&&\"object\"==typeof e){var n=e.ref;null!=n&&i(n,t,e._owner)}},t.exports=a},function(t,e,n){\"use strict\";function r(t){this.reinitializeTransaction(),this.renderToStaticMarkup=t,this.useCreateElement=!1,this.updateQueue=new u(this)}var i=n(3),o=n(18),a=n(55),u=(n(9),n(384)),c=[],s={enqueue:function(){}},l={getTransactionWrappers:function(){return c},getReactMountReady:function(){return s},getUpdateQueue:function(){return this.updateQueue},destructor:function(){},checkpoint:function(){},rollback:function(){}};i(r.prototype,a,l),o.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";function r(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}var i=n(89),o=(n(2),function(){function t(e){r(this,t),this.transaction=e}return t.prototype.isMounted=function(t){return!1},t.prototype.enqueueCallback=function(t,e,n){this.transaction.isInTransaction()&&i.enqueueCallback(t,e,n)},t.prototype.enqueueForceUpdate=function(t){this.transaction.isInTransaction()&&i.enqueueForceUpdate(t)},t.prototype.enqueueReplaceState=function(t,e){this.transaction.isInTransaction()&&i.enqueueReplaceState(t,e)},t.prototype.enqueueSetState=function(t,e){this.transaction.isInTransaction()&&i.enqueueSetState(t,e)},t}());t.exports=o},function(t,e,n){\"use strict\";t.exports=\"15.6.2\"},function(t,e,n){\"use strict\";var r={xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\"},i={accentHeight:\"accent-height\",accumulate:0,additive:0,alignmentBaseline:\"alignment-baseline\",allowReorder:\"allowReorder\",alphabetic:0,amplitude:0,arabicForm:\"arabic-form\",ascent:0,attributeName:\"attributeName\",attributeType:\"attributeType\",autoReverse:\"autoReverse\",azimuth:0,baseFrequency:\"baseFrequency\",baseProfile:\"baseProfile\",baselineShift:\"baseline-shift\",bbox:0,begin:0,bias:0,by:0,calcMode:\"calcMode\",capHeight:\"cap-height\",clip:0,clipPath:\"clip-path\",clipRule:\"clip-rule\",clipPathUnits:\"clipPathUnits\",colorInterpolation:\"color-interpolation\",colorInterpolationFilters:\"color-interpolation-filters\",colorProfile:\"color-profile\",colorRendering:\"color-rendering\",contentScriptType:\"contentScriptType\",contentStyleType:\"contentStyleType\",cursor:0,cx:0,cy:0,d:0,decelerate:0,descent:0,diffuseConstant:\"diffuseConstant\",direction:0,display:0,divisor:0,dominantBaseline:\"dominant-baseline\",dur:0,dx:0,dy:0,edgeMode:\"edgeMode\",elevation:0,enableBackground:\"enable-background\",end:0,exponent:0,externalResourcesRequired:\"externalResourcesRequired\",fill:0,fillOpacity:\"fill-opacity\",fillRule:\"fill-rule\",filter:0,filterRes:\"filterRes\",filterUnits:\"filterUnits\",floodColor:\"flood-color\",floodOpacity:\"flood-opacity\",focusable:0,fontFamily:\"font-family\",fontSize:\"font-size\",fontSizeAdjust:\"font-size-adjust\",fontStretch:\"font-stretch\",fontStyle:\"font-style\",fontVariant:\"font-variant\",fontWeight:\"font-weight\",format:0,from:0,fx:0,fy:0,g1:0,g2:0,glyphName:\"glyph-name\",glyphOrientationHorizontal:\"glyph-orientation-horizontal\",glyphOrientationVertical:\"glyph-orientation-vertical\",glyphRef:\"glyphRef\",gradientTransform:\"gradientTransform\",gradientUnits:\"gradientUnits\",hanging:0,horizAdvX:\"horiz-adv-x\",horizOriginX:\"horiz-origin-x\",ideographic:0,imageRendering:\"image-rendering\",in:0,in2:0,intercept:0,k:0,k1:0,k2:0,k3:0,k4:0,kernelMatrix:\"kernelMatrix\",kernelUnitLength:\"kernelUnitLength\",kerning:0,keyPoints:\"keyPoints\",keySplines:\"keySplines\",keyTimes:\"keyTimes\",lengthAdjust:\"lengthAdjust\",letterSpacing:\"letter-spacing\",lightingColor:\"lighting-color\",limitingConeAngle:\"limitingConeAngle\",local:0,markerEnd:\"marker-end\",markerMid:\"marker-mid\",markerStart:\"marker-start\",markerHeight:\"markerHeight\",markerUnits:\"markerUnits\",markerWidth:\"markerWidth\",mask:0,maskContentUnits:\"maskContentUnits\",maskUnits:\"maskUnits\",mathematical:0,mode:0,numOctaves:\"numOctaves\",offset:0,opacity:0,operator:0,order:0,orient:0,orientation:0,origin:0,overflow:0,overlinePosition:\"overline-position\",overlineThickness:\"overline-thickness\",paintOrder:\"paint-order\",panose1:\"panose-1\",pathLength:\"pathLength\",patternContentUnits:\"patternContentUnits\",patternTransform:\"patternTransform\",patternUnits:\"patternUnits\",pointerEvents:\"pointer-events\",points:0,pointsAtX:\"pointsAtX\",pointsAtY:\"pointsAtY\",pointsAtZ:\"pointsAtZ\",preserveAlpha:\"preserveAlpha\",preserveAspectRatio:\"preserveAspectRatio\",primitiveUnits:\"primitiveUnits\",r:0,radius:0,refX:\"refX\",refY:\"refY\",renderingIntent:\"rendering-intent\",repeatCount:\"repeatCount\",repeatDur:\"repeatDur\",requiredExtensions:\"requiredExtensions\",requiredFeatures:\"requiredFeatures\",restart:0,result:0,rotate:0,rx:0,ry:0,scale:0,seed:0,shapeRendering:\"shape-rendering\",slope:0,spacing:0,specularConstant:\"specularConstant\",specularExponent:\"specularExponent\",speed:0,spreadMethod:\"spreadMethod\",startOffset:\"startOffset\",stdDeviation:\"stdDeviation\",stemh:0,stemv:0,stitchTiles:\"stitchTiles\",stopColor:\"stop-color\",stopOpacity:\"stop-opacity\",strikethroughPosition:\"strikethrough-position\",strikethroughThickness:\"strikethrough-thickness\",string:0,stroke:0,strokeDasharray:\"stroke-dasharray\",strokeDashoffset:\"stroke-dashoffset\",strokeLinecap:\"stroke-linecap\",strokeLinejoin:\"stroke-linejoin\",strokeMiterlimit:\"stroke-miterlimit\",strokeOpacity:\"stroke-opacity\",strokeWidth:\"stroke-width\",surfaceScale:\"surfaceScale\",systemLanguage:\"systemLanguage\",tableValues:\"tableValues\",targetX:\"targetX\",targetY:\"targetY\",textAnchor:\"text-anchor\",textDecoration:\"text-decoration\",textRendering:\"text-rendering\",textLength:\"textLength\",to:0,transform:0,u1:0,u2:0,underlinePosition:\"underline-position\",underlineThickness:\"underline-thickness\",unicode:0,unicodeBidi:\"unicode-bidi\",unicodeRange:\"unicode-range\",unitsPerEm:\"units-per-em\",vAlphabetic:\"v-alphabetic\",vHanging:\"v-hanging\",vIdeographic:\"v-ideographic\",vMathematical:\"v-mathematical\",values:0,vectorEffect:\"vector-effect\",version:0,vertAdvY:\"vert-adv-y\",vertOriginX:\"vert-origin-x\",vertOriginY:\"vert-origin-y\",viewBox:\"viewBox\",viewTarget:\"viewTarget\",visibility:0,widths:0,wordSpacing:\"word-spacing\",writingMode:\"writing-mode\",x:0,xHeight:\"x-height\",x1:0,x2:0,xChannelSelector:\"xChannelSelector\",xlinkActuate:\"xlink:actuate\",xlinkArcrole:\"xlink:arcrole\",xlinkHref:\"xlink:href\",xlinkRole:\"xlink:role\",xlinkShow:\"xlink:show\",xlinkTitle:\"xlink:title\",xlinkType:\"xlink:type\",xmlBase:\"xml:base\",xmlns:0,xmlnsXlink:\"xmlns:xlink\",xmlLang:\"xml:lang\",xmlSpace:\"xml:space\",y:0,y1:0,y2:0,yChannelSelector:\"yChannelSelector\",z:0,zoomAndPan:\"zoomAndPan\"},o={Properties:{},DOMAttributeNamespaces:{xlinkActuate:r.xlink,xlinkArcrole:r.xlink,xlinkHref:r.xlink,xlinkRole:r.xlink,xlinkShow:r.xlink,xlinkTitle:r.xlink,xlinkType:r.xlink,xmlBase:r.xml,xmlLang:r.xml,xmlSpace:r.xml},DOMAttributeNames:{}};Object.keys(i).forEach(function(t){o.Properties[t]=0,i[t]&&(o.DOMAttributeNames[t]=i[t])}),t.exports=o},function(t,e,n){\"use strict\";function r(t){if(\"selectionStart\"in t&&c.hasSelectionCapabilities(t))return{start:t.selectionStart,end:t.selectionEnd};if(window.getSelection){var e=window.getSelection();return{anchorNode:e.anchorNode,anchorOffset:e.anchorOffset,focusNode:e.focusNode,focusOffset:e.focusOffset}}if(document.selection){var n=document.selection.createRange();return{parentElement:n.parentElement(),text:n.text,top:n.boundingTop,left:n.boundingLeft}}}function i(t,e){if(y||null==v||v!==l())return null;var n=r(v);if(!m||!p(m,n)){m=n;var i=s.getPooled(d.select,g,t,e);return i.type=\"select\",i.target=v,o.accumulateTwoPhaseDispatches(i),i}return null}var o=n(23),a=n(6),u=n(4),c=n(166),s=n(14),l=n(155),f=n(175),p=n(81),h=a.canUseDOM&&\"documentMode\"in document&&document.documentMode<=11,d={select:{phasedRegistrationNames:{bubbled:\"onSelect\",captured:\"onSelectCapture\"},dependencies:[\"topBlur\",\"topContextMenu\",\"topFocus\",\"topKeyDown\",\"topKeyUp\",\"topMouseDown\",\"topMouseUp\",\"topSelectionChange\"]}},v=null,g=null,m=null,y=!1,_=!1,b={eventTypes:d,extractEvents:function(t,e,n,r){if(!_)return null;var o=e?u.getNodeFromInstance(e):window;switch(t){case\"topFocus\":(f(o)||\"true\"===o.contentEditable)&&(v=o,g=e,m=null);break;case\"topBlur\":v=null,g=null,m=null;break;case\"topMouseDown\":y=!0;break;case\"topContextMenu\":case\"topMouseUp\":return y=!1,i(n,r);case\"topSelectionChange\":if(h)break;case\"topKeyDown\":case\"topKeyUp\":return i(n,r)}return null},didPutListener:function(t,e,n){\"onSelect\"===e&&(_=!0)}};t.exports=b},function(t,e,n){\"use strict\";function r(t){return\".\"+t._rootNodeID}function i(t){return\"button\"===t||\"input\"===t||\"select\"===t||\"textarea\"===t}var o=n(1),a=n(153),u=n(23),c=n(4),s=n(389),l=n(390),f=n(14),p=n(393),h=n(395),d=n(54),v=n(392),g=n(396),m=n(397),y=n(25),_=n(398),b=n(11),x=n(92),w=(n(0),{}),C={};[\"abort\",\"animationEnd\",\"animationIteration\",\"animationStart\",\"blur\",\"canPlay\",\"canPlayThrough\",\"click\",\"contextMenu\",\"copy\",\"cut\",\"doubleClick\",\"drag\",\"dragEnd\",\"dragEnter\",\"dragExit\",\"dragLeave\",\"dragOver\",\"dragStart\",\"drop\",\"durationChange\",\"emptied\",\"encrypted\",\"ended\",\"error\",\"focus\",\"input\",\"invalid\",\"keyDown\",\"keyPress\",\"keyUp\",\"load\",\"loadedData\",\"loadedMetadata\",\"loadStart\",\"mouseDown\",\"mouseMove\",\"mouseOut\",\"mouseOver\",\"mouseUp\",\"paste\",\"pause\",\"play\",\"playing\",\"progress\",\"rateChange\",\"reset\",\"scroll\",\"seeked\",\"seeking\",\"stalled\",\"submit\",\"suspend\",\"timeUpdate\",\"touchCancel\",\"touchEnd\",\"touchMove\",\"touchStart\",\"transitionEnd\",\"volumeChange\",\"waiting\",\"wheel\"].forEach(function(t){var e=t[0].toUpperCase()+t.slice(1),n=\"on\"+e,r=\"top\"+e,i={phasedRegistrationNames:{bubbled:n,captured:n+\"Capture\"},dependencies:[r]};w[t]=i,C[r]=i});var k={},E={eventTypes:w,extractEvents:function(t,e,n,r){var i=C[t];if(!i)return null;var a;switch(t){case\"topAbort\":case\"topCanPlay\":case\"topCanPlayThrough\":case\"topDurationChange\":case\"topEmptied\":case\"topEncrypted\":case\"topEnded\":case\"topError\":case\"topInput\":case\"topInvalid\":case\"topLoad\":case\"topLoadedData\":case\"topLoadedMetadata\":case\"topLoadStart\":case\"topPause\":case\"topPlay\":case\"topPlaying\":case\"topProgress\":case\"topRateChange\":case\"topReset\":case\"topSeeked\":case\"topSeeking\":case\"topStalled\":case\"topSubmit\":case\"topSuspend\":case\"topTimeUpdate\":case\"topVolumeChange\":case\"topWaiting\":a=f;break;case\"topKeyPress\":if(0===x(n))return null;case\"topKeyDown\":case\"topKeyUp\":a=h;break;case\"topBlur\":case\"topFocus\":a=p;break;case\"topClick\":if(2===n.button)return null;case\"topDoubleClick\":case\"topMouseDown\":case\"topMouseMove\":case\"topMouseUp\":case\"topMouseOut\":case\"topMouseOver\":case\"topContextMenu\":a=d;break;case\"topDrag\":case\"topDragEnd\":case\"topDragEnter\":case\"topDragExit\":case\"topDragLeave\":case\"topDragOver\":case\"topDragStart\":case\"topDrop\":a=v;break;case\"topTouchCancel\":case\"topTouchEnd\":case\"topTouchMove\":case\"topTouchStart\":a=g;break;case\"topAnimationEnd\":case\"topAnimationIteration\":case\"topAnimationStart\":a=s;break;case\"topTransitionEnd\":a=m;break;case\"topScroll\":a=y;break;case\"topWheel\":a=_;break;case\"topCopy\":case\"topCut\":case\"topPaste\":a=l}a||o(\"86\",t);var c=a.getPooled(i,e,n,r);return u.accumulateTwoPhaseDispatches(c),c},didPutListener:function(t,e,n){if(\"onClick\"===e&&!i(t._tag)){var o=r(t),u=c.getNodeFromInstance(t);k[o]||(k[o]=a.listen(u,\"click\",b))}},willDeleteListener:function(t,e){if(\"onClick\"===e&&!i(t._tag)){var n=r(t);k[n].remove(),delete k[n]}}};t.exports=E},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={animationName:null,elapsedTime:null,pseudoElement:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={clipboardData:function(t){return\"clipboardData\"in t?t.clipboardData:window.clipboardData}};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={data:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(54),o={dataTransfer:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o={relatedTarget:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={data:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(92),a=n(403),u=n(93),c={key:a,location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:u,charCode:function(t){return\"keypress\"===t.type?o(t):0},keyCode:function(t){return\"keydown\"===t.type||\"keyup\"===t.type?t.keyCode:0},which:function(t){return\"keypress\"===t.type?o(t):\"keydown\"===t.type||\"keyup\"===t.type?t.keyCode:0}};i.augmentClass(r,c),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(93),a={touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:o};i.augmentClass(r,a),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={propertyName:null,elapsedTime:null,pseudoElement:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(54),o={deltaX:function(t){return\"deltaX\"in t?t.deltaX:\"wheelDeltaX\"in t?-t.wheelDeltaX:0},deltaY:function(t){return\"deltaY\"in t?t.deltaY:\"wheelDeltaY\"in t?-t.wheelDeltaY:\"wheelDelta\"in t?-t.wheelDelta:0},deltaZ:null,deltaMode:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e=1,n=0,r=0,o=t.length,a=-4&o;r<a;){for(var u=Math.min(r+4096,a);r<u;r+=4)n+=(e+=t.charCodeAt(r))+(e+=t.charCodeAt(r+1))+(e+=t.charCodeAt(r+2))+(e+=t.charCodeAt(r+3));e%=i,n%=i}for(;r<o;r++)n+=e+=t.charCodeAt(r);return e%=i,n%=i,e|n<<16}var i=65521;t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){if(null==e||\"boolean\"==typeof e||\"\"===e)return\"\";var i=isNaN(e);if(r||i||0===e||o.hasOwnProperty(t)&&o[t])return\"\"+e;if(\"string\"==typeof e){e=e.trim()}return e+\"px\"}var i=n(158),o=(n(2),i.isUnitlessNumber);t.exports=r},function(t,e,n){\"use strict\";function r(t){if(null==t)return null;if(1===t.nodeType)return t;var e=a.get(t);if(e)return e=u(e),e?o.getNodeFromInstance(e):null;\"function\"==typeof t.render?i(\"44\"):i(\"45\",Object.keys(t))}var i=n(1),o=(n(15),n(4)),a=n(39),u=n(171);n(0),n(2);t.exports=r},function(t,e,n){\"use strict\";(function(e){function r(t,e,n,r){if(t&&\"object\"==typeof t){var i=t,o=void 0===i[n];o&&null!=e&&(i[n]=e)}}function i(t,e){if(null==t)return t;var n={};return o(t,r,n),n}var o=(n(85),n(177));n(2);void 0!==e&&e.env,t.exports=i}).call(e,n(156))},function(t,e,n){\"use strict\";function r(t){if(t.key){var e=o[t.key]||t.key;if(\"Unidentified\"!==e)return e}if(\"keypress\"===t.type){var n=i(t);return 13===n?\"Enter\":String.fromCharCode(n)}return\"keydown\"===t.type||\"keyup\"===t.type?a[t.keyCode]||\"Unidentified\":\"\"}var i=n(92),o={Esc:\"Escape\",Spacebar:\" \",Left:\"ArrowLeft\",Up:\"ArrowUp\",Right:\"ArrowRight\",Down:\"ArrowDown\",Del:\"Delete\",Win:\"OS\",Menu:\"ContextMenu\",Apps:\"ContextMenu\",Scroll:\"ScrollLock\",MozPrintableKey:\"Unidentified\"},a={8:\"Backspace\",9:\"Tab\",12:\"Clear\",13:\"Enter\",16:\"Shift\",17:\"Control\",18:\"Alt\",19:\"Pause\",20:\"CapsLock\",27:\"Escape\",32:\" \",33:\"PageUp\",34:\"PageDown\",35:\"End\",36:\"Home\",37:\"ArrowLeft\",38:\"ArrowUp\",39:\"ArrowRight\",40:\"ArrowDown\",45:\"Insert\",46:\"Delete\",112:\"F1\",113:\"F2\",114:\"F3\",115:\"F4\",116:\"F5\",117:\"F6\",118:\"F7\",119:\"F8\",120:\"F9\",121:\"F10\",122:\"F11\",123:\"F12\",144:\"NumLock\",145:\"ScrollLock\",224:\"Meta\"};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t&&(i&&t[i]||t[o]);if(\"function\"==typeof e)return e}var i=\"function\"==typeof Symbol&&Symbol.iterator,o=\"@@iterator\";t.exports=r},function(t,e,n){\"use strict\";function r(t){for(;t&&t.firstChild;)t=t.firstChild;return t}function i(t){for(;t;){if(t.nextSibling)return t.nextSibling;t=t.parentNode}}function o(t,e){for(var n=r(t),o=0,a=0;n;){if(3===n.nodeType){if(a=o+n.textContent.length,o<=e&&a>=e)return{node:n,offset:e-o};o=a}n=r(i(n))}}t.exports=o},function(t,e,n){\"use strict\";function r(t,e){var n={};return n[t.toLowerCase()]=e.toLowerCase(),n[\"Webkit\"+t]=\"webkit\"+e,n[\"Moz\"+t]=\"moz\"+e,n[\"ms\"+t]=\"MS\"+e,n[\"O\"+t]=\"o\"+e.toLowerCase(),n}function i(t){if(u[t])return u[t];if(!a[t])return t;var e=a[t];for(var n in e)if(e.hasOwnProperty(n)&&n in c)return u[t]=e[n];return\"\"}var o=n(6),a={animationend:r(\"Animation\",\"AnimationEnd\"),animationiteration:r(\"Animation\",\"AnimationIteration\"),animationstart:r(\"Animation\",\"AnimationStart\"),transitionend:r(\"Transition\",\"TransitionEnd\")},u={},c={};o.canUseDOM&&(c=document.createElement(\"div\").style,\"AnimationEvent\"in window||(delete a.animationend.animation,delete a.animationiteration.animation,delete a.animationstart.animation),\"TransitionEvent\"in window||delete a.transitionend.transition),t.exports=i},function(t,e,n){\"use strict\";function r(t){return'\"'+i(t)+'\"'}var i=n(56);t.exports=r},function(t,e,n){\"use strict\";var r=n(167);t.exports=r.renderSubtreeIntoContainer},function(t,e,n){\"use strict\";function r(t,e){var n=l.extractSingleTouch(e);return n?n[t.page]:t.page in e?e[t.page]:e[t.client]+f[t.envScroll]}function i(t,e){var n=r(b.x,e),i=r(b.y,e);return Math.pow(Math.pow(n-t.x,2)+Math.pow(i-t.y,2),.5)}function o(t){return{tapMoveThreshold:g,ignoreMouseThreshold:m,eventTypes:C,extractEvents:function(e,n,o,a){if(!h(e)&&!d(e))return null;if(v(e))_=k();else if(t(_,k()))return null;var u=null,l=i(y,o);return d(e)&&l<g&&(u=s.getPooled(C.touchTap,n,o,a)),h(e)?(y.x=r(b.x,o),y.y=r(b.y,o)):d(e)&&(y.x=0,y.y=0),c.accumulateTwoPhaseDispatches(u),u}}}var a=n(353),u=n(52),c=n(23),s=n(25),l=n(410),f=n(90),p=n(340),h=(a.topLevelTypes,u.isStartish),d=u.isEndish,v=function(t){return[\"topTouchCancel\",\"topTouchEnd\",\"topTouchStart\",\"topTouchMove\"].indexOf(t)>=0},g=10,m=750,y={x:null,y:null},_=null,b={x:{page:\"pageX\",client:\"clientX\",envScroll:\"currentPageScrollLeft\"},y:{page:\"pageY\",client:\"clientY\",envScroll:\"currentPageScrollTop\"}},x=[\"topTouchStart\",\"topTouchCancel\",\"topTouchEnd\",\"topTouchMove\"],w=[\"topMouseDown\",\"topMouseMove\",\"topMouseUp\"].concat(x),C={touchTap:{phasedRegistrationNames:{bubbled:p({onTouchTap:null}),captured:p({onTouchTapCapture:null})},dependencies:w}},k=function(){return Date.now?Date.now:function(){return+new Date}}();t.exports=o},function(t,e){var n={extractSingleTouch:function(t){var e=t.touches,n=t.changedTouches,r=e&&e.length>0,i=n&&n.length>0;return!r&&i?n[0]:r?e[0]:t}};t.exports=n},function(t,e){t.exports=function(t,e){if(t&&e-t<750)return!0}},function(t,e,n){\"use strict\";function r(t){var e={\"=\":\"=0\",\":\":\"=2\"};return\"$\"+(\"\"+t).replace(/[=:]/g,function(t){return e[t]})}function i(t){var e=/(=0|=2)/g,n={\"=0\":\"=\",\"=2\":\":\"};return(\"\"+(\".\"===t[0]&&\"$\"===t[1]?t.substring(2):t.substring(1))).replace(e,function(t){return n[t]})}var o={escape:r,unescape:i};t.exports=o},function(t,e,n){\"use strict\";var r=n(40),i=(n(0),function(t){var e=this;if(e.instancePool.length){var n=e.instancePool.pop();return e.call(n,t),n}return new e(t)}),o=function(t,e){var n=this;if(n.instancePool.length){var r=n.instancePool.pop();return n.call(r,t,e),r}return new n(t,e)},a=function(t,e,n){var r=this;if(r.instancePool.length){var i=r.instancePool.pop();return r.call(i,t,e,n),i}return new r(t,e,n)},u=function(t,e,n,r){var i=this;if(i.instancePool.length){var o=i.instancePool.pop();return i.call(o,t,e,n,r),o}return new i(t,e,n,r)},c=function(t){var e=this;t instanceof e||r(\"25\"),t.destructor(),e.instancePool.length<e.poolSize&&e.instancePool.push(t)},s=i,l=function(t,e){var n=t;return n.instancePool=[],n.getPooled=e||s,n.poolSize||(n.poolSize=10),n.release=c,n},f={addPoolingTo:l,oneArgumentPooler:i,twoArgumentPooler:o,threeArgumentPooler:a,fourArgumentPooler:u};t.exports=f},function(t,e,n){\"use strict\";function r(t){return(\"\"+t).replace(b,\"$&/\")}function i(t,e){this.func=t,this.context=e,this.count=0}function o(t,e,n){var r=t.func,i=t.context;r.call(i,e,t.count++)}function a(t,e,n){if(null==t)return t;var r=i.getPooled(e,n);m(t,o,r),i.release(r)}function u(t,e,n,r){this.result=t,this.keyPrefix=e,this.func=n,this.context=r,this.count=0}function c(t,e,n){var i=t.result,o=t.keyPrefix,a=t.func,u=t.context,c=a.call(u,e,t.count++);Array.isArray(c)?s(c,i,n,g.thatReturnsArgument):null!=c&&(v.isValidElement(c)&&(c=v.cloneAndReplaceKey(c,o+(!c.key||e&&e.key===c.key?\"\":r(c.key)+\"/\")+n)),i.push(c))}function s(t,e,n,i,o){var a=\"\";null!=n&&(a=r(n)+\"/\");var s=u.getPooled(e,a,i,o);m(t,c,s),u.release(s)}function l(t,e,n){if(null==t)return t;var r=[];return s(t,r,null,e,n),r}function f(t,e,n){return null}function p(t,e){return m(t,f,null)}function h(t){var e=[];return s(t,e,null,g.thatReturnsArgument),e}var d=n(413),v=n(27),g=n(11),m=n(423),y=d.twoArgumentPooler,_=d.fourArgumentPooler,b=/\\/+/g;i.prototype.destructor=function(){this.func=null,this.context=null,this.count=0},d.addPoolingTo(i,y),u.prototype.destructor=function(){this.result=null,this.keyPrefix=null,this.func=null,this.context=null,this.count=0},d.addPoolingTo(u,_);var x={forEach:a,map:l,mapIntoWithKeyPrefixInternal:s,count:p,toArray:h};t.exports=x},function(t,e,n){\"use strict\";var r=n(27),i=r.createFactory,o={a:i(\"a\"),abbr:i(\"abbr\"),address:i(\"address\"),area:i(\"area\"),article:i(\"article\"),aside:i(\"aside\"),audio:i(\"audio\"),b:i(\"b\"),base:i(\"base\"),bdi:i(\"bdi\"),bdo:i(\"bdo\"),big:i(\"big\"),blockquote:i(\"blockquote\"),body:i(\"body\"),br:i(\"br\"),button:i(\"button\"),canvas:i(\"canvas\"),caption:i(\"caption\"),cite:i(\"cite\"),code:i(\"code\"),col:i(\"col\"),colgroup:i(\"colgroup\"),data:i(\"data\"),datalist:i(\"datalist\"),dd:i(\"dd\"),del:i(\"del\"),details:i(\"details\"),dfn:i(\"dfn\"),dialog:i(\"dialog\"),div:i(\"div\"),dl:i(\"dl\"),dt:i(\"dt\"),em:i(\"em\"),embed:i(\"embed\"),fieldset:i(\"fieldset\"),figcaption:i(\"figcaption\"),figure:i(\"figure\"),footer:i(\"footer\"),form:i(\"form\"),h1:i(\"h1\"),h2:i(\"h2\"),h3:i(\"h3\"),h4:i(\"h4\"),h5:i(\"h5\"),h6:i(\"h6\"),head:i(\"head\"),header:i(\"header\"),hgroup:i(\"hgroup\"),hr:i(\"hr\"),html:i(\"html\"),i:i(\"i\"),iframe:i(\"iframe\"),img:i(\"img\"),input:i(\"input\"),ins:i(\"ins\"),kbd:i(\"kbd\"),keygen:i(\"keygen\"),label:i(\"label\"),legend:i(\"legend\"),li:i(\"li\"),link:i(\"link\"),main:i(\"main\"),map:i(\"map\"),mark:i(\"mark\"),menu:i(\"menu\"),menuitem:i(\"menuitem\"),meta:i(\"meta\"),meter:i(\"meter\"),nav:i(\"nav\"),noscript:i(\"noscript\"),object:i(\"object\"),ol:i(\"ol\"),optgroup:i(\"optgroup\"),option:i(\"option\"),output:i(\"output\"),p:i(\"p\"),param:i(\"param\"),picture:i(\"picture\"),pre:i(\"pre\"),progress:i(\"progress\"),q:i(\"q\"),rp:i(\"rp\"),rt:i(\"rt\"),ruby:i(\"ruby\"),s:i(\"s\"),samp:i(\"samp\"),script:i(\"script\"),section:i(\"section\"),select:i(\"select\"),small:i(\"small\"),source:i(\"source\"),span:i(\"span\"),strong:i(\"strong\"),style:i(\"style\"),sub:i(\"sub\"),summary:i(\"summary\"),sup:i(\"sup\"),table:i(\"table\"),tbody:i(\"tbody\"),td:i(\"td\"),textarea:i(\"textarea\"),tfoot:i(\"tfoot\"),th:i(\"th\"),thead:i(\"thead\"),time:i(\"time\"),title:i(\"title\"),tr:i(\"tr\"),track:i(\"track\"),u:i(\"u\"),ul:i(\"ul\"),var:i(\"var\"),video:i(\"video\"),wbr:i(\"wbr\"),circle:i(\"circle\"),clipPath:i(\"clipPath\"),defs:i(\"defs\"),ellipse:i(\"ellipse\"),g:i(\"g\"),image:i(\"image\"),line:i(\"line\"),linearGradient:i(\"linearGradient\"),mask:i(\"mask\"),path:i(\"path\"),pattern:i(\"pattern\"),polygon:i(\"polygon\"),polyline:i(\"polyline\"),radialGradient:i(\"radialGradient\"),rect:i(\"rect\"),stop:i(\"stop\"),svg:i(\"svg\"),text:i(\"text\"),tspan:i(\"tspan\")};t.exports=o},function(t,e,n){\"use strict\";var r=n(27),i=r.isValidElement,o=n(157);t.exports=o(i)},function(t,e,n){\"use strict\";t.exports=\"15.6.2\"},function(t,e,n){\"use strict\";var r=n(178),i=r.Component,o=n(27),a=o.isValidElement,u=n(181),c=n(191);t.exports=c(i,a,u)},function(t,e,n){\"use strict\";function r(t){var e=t&&(i&&t[i]||t[o]);if(\"function\"==typeof e)return e}var i=\"function\"==typeof Symbol&&Symbol.iterator,o=\"@@iterator\";t.exports=r},function(t,e,n){\"use strict\";function r(){return i++}var i=1;t.exports=r},function(t,e,n){\"use strict\";var r=function(){};t.exports=r},function(t,e,n){\"use strict\";function r(t){return o.isValidElement(t)||i(\"143\"),t}var i=n(40),o=n(27);n(0);t.exports=r},function(t,e,n){\"use strict\";function r(t,e){return t&&\"object\"==typeof t&&null!=t.key?s.escape(t.key):e.toString(36)}function i(t,e,n,o){var p=typeof t;if(\"undefined\"!==p&&\"boolean\"!==p||(t=null),null===t||\"string\"===p||\"number\"===p||\"object\"===p&&t.$$typeof===u)return n(o,t,\"\"===e?l+r(t,0):e),1;var h,d,v=0,g=\"\"===e?l:e+f;if(Array.isArray(t))for(var m=0;m<t.length;m++)h=t[m],d=g+r(h,m),v+=i(h,d,n,o);else{var y=c(t);if(y){var _,b=y.call(t);if(y!==t.entries)for(var x=0;!(_=b.next()).done;)h=_.value,d=g+r(h,x++),v+=i(h,d,n,o);else for(;!(_=b.next()).done;){var w=_.value;w&&(h=w[1],d=g+s.escape(w[0])+f+r(h,0),v+=i(h,d,n,o))}}else if(\"object\"===p){var C=\"\",k=String(t);a(\"31\",\"[object Object]\"===k?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":k,C)}}return v}function o(t,e,n){return null==t?0:i(t,\"\",e,n)}var a=n(40),u=(n(15),n(180)),c=n(419),s=(n(0),n(412)),l=(n(2),\".\"),f=\":\";t.exports=o}]);</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<< 0 1\n",
      "temp/f0\n",
      "0.5389019644164152\n",
      "[0.9145106781848173, 1.1632932506480131]\n",
      "temp/f1\n",
      "0.5621465322654936\n",
      "[0.914515310033912, 1.2097777544970751]\n",
      "temp/f2\n",
      "0.5334273069753113\n",
      "[0.9033044170629023, 1.1635501968877202]\n",
      "temp/f3\n",
      "0.5435605361426943\n",
      "[0.8963107546605267, 1.190810317624862]\n",
      "temp/f4\n",
      "0.5475939133682264\n",
      "[0.9040473301087072, 1.1911404966277455]\n",
      "temp/f5\n",
      "0.5619723826933206\n",
      "[0.9223194272259232, 1.201625338160718]\n",
      "temp/f6\n",
      "0.5435735500970941\n",
      "[0.8964533453164971, 1.190693754877691]\n",
      "temp/f7\n",
      "0.5717164438795297\n",
      "[0.9268668636945057, 1.2165660240645537]\n",
      "temp/f8\n",
      "0.5607876532189279\n",
      "[0.9235741342547199, 1.1980011721831358]\n",
      "temp/f9\n",
      "0.5674332381743465\n",
      "[0.9059715260204375, 1.2288949503282556]\n",
      "temp/f10\n",
      "0.5396514690701294\n",
      "[0.9172820656762849, 1.1620208724639738]\n",
      "temp/f11\n",
      "0.5672545899575998\n",
      "[0.9075034855947288, 1.2270056943204708]\n",
      "temp/f12\n",
      "0.5433131271714081\n",
      "[0.8970685796772332, 1.189557674665583]\n",
      "temp/f13\n",
      "0.5652792757509364\n",
      "[0.9409207385408148, 1.1896378129610579]\n",
      "temp/f14\n",
      "0.5308291613999376\n",
      "[0.8947517841565401, 1.166906538643335]\n",
      "temp/f15\n",
      "0.5548053044568871\n",
      "[0.8959113896963672, 1.213699219217407]\n",
      "temp/f16\n",
      "0.5413579267438678\n",
      "[0.9084106938382832, 1.1743051596494525]\n",
      "temp/f17\n",
      "0.5368217917326409\n",
      "[0.9068318384120062, 1.1668117450532756]\n",
      "temp/f18\n",
      "0.5295424079943596\n",
      "[0.8957003725557668, 1.1633844434329523]\n",
      "temp/f19\n",
      "0.5592765783254289\n",
      "[0.9034990794563476, 1.2150540771945102]\n",
      "temp/f20\n",
      "0.539685343719841\n",
      "[0.9055997776789426, 1.1737709097607394]\n",
      "temp/f21\n",
      "0.5416231846114075\n",
      "[0.9224721575032965, 1.1607742117195183]\n",
      "temp/f22\n",
      "0.5510048216913211\n",
      "[0.8910059659791605, 1.2110036774034818]\n",
      "temp/f23\n",
      "0.537390687635633\n",
      "[0.902015063305354, 1.172766311965912]\n",
      "temp/f24\n",
      "0.553934328011424\n",
      "[0.9159977198916742, 1.1918709361311737]\n",
      "temp/f25\n",
      "0.5421141424484645\n",
      "[0.9040703056700252, 1.1801579792269037]\n",
      "temp/f26\n",
      "0.5151784343016597\n",
      "[0.86838640219578, 1.1619704664075392]\n",
      "temp/f27\n",
      "0.5427973996182438\n",
      "[0.9201361791175257, 1.1654586201189618]\n",
      "temp/f28\n",
      "0.5376787368808499\n",
      "[0.9083369415333192, 1.1670205322283804]\n",
      "temp/f29\n",
      "0.5681192923020204\n",
      "[0.9384337812028513, 1.1978048034011894]\n",
      "temp/f30\n",
      "0.562796725924233\n",
      "[0.9326843432182013, 1.1929091086302648]\n",
      "temp/f31\n",
      "0.5724598704859795\n",
      "[0.9383874556587045, 1.2065322853132543]\n",
      "temp/f32\n",
      "0.5240060233262269\n",
      "[0.885889771166665, 1.1621222754857887]\n",
      "temp/f33\n",
      "0.5548808745953603\n",
      "[0.9144038512225875, 1.195357897968133]\n",
      "temp/f34\n",
      "0.5486575290296484\n",
      "[0.9099104642403588, 1.187404593818938]\n",
      "temp/f35\n",
      "0.5418772716789603\n",
      "[0.8939796083580491, 1.1897749349998714]\n",
      "temp/f36\n",
      "0.5507314259844998\n",
      "[0.9138126396664128, 1.1876502123025867]\n",
      "temp/f37\n",
      "0.554623538836235\n",
      "[0.8954678511254884, 1.2137792265469816]\n",
      "temp/f38\n",
      "0.5635491482256763\n",
      "[0.9340857982792963, 1.1930124981720562]\n",
      "temp/f39\n",
      "0.5648941352491773\n",
      "[0.9141646432538252, 1.2156236272445293]\n",
      "temp/f40\n",
      "0.5565892896610086\n",
      "[0.8845625973982588, 1.2286159819237583]\n",
      "temp/f41\n",
      "0.5570465296523228\n",
      "[0.9253550952418241, 1.1887379640628215]\n",
      "temp/f42\n",
      "0.5620844695411195\n",
      "[0.9387123034152487, 1.1854566356669902]\n",
      "temp/f43\n",
      "0.5584817405730002\n",
      "[0.9264400556752777, 1.1905234254707227]\n",
      "temp/f44\n",
      "0.5201582097996973\n",
      "[0.8765933720173901, 1.1637230475820044]\n",
      "temp/f45\n",
      "0.5450014344485214\n",
      "[0.932937855301886, 1.1570650135951568]\n",
      "temp/f46\n",
      "0.5487543161487218\n",
      "[0.9205969921451078, 1.1769116401523358]\n",
      "temp/f47\n",
      "0.5538520042765452\n",
      "[0.9101918602346692, 1.1975121483184212]\n",
      "temp/f48\n",
      "0.5356054977436632\n",
      "[0.889551915277803, 1.1816590802095233]\n",
      "temp/f49\n",
      "0.5296776046685742\n",
      "[0.8765557757138136, 1.1827994336233347]\n",
      "temp/f50\n",
      "0.5472505143381934\n",
      "[0.9357423345261857, 1.158758694150201]\n",
      "temp/f51\n",
      "0.5775667712441445\n",
      "[0.9373177625507464, 1.2178157799375424]\n",
      "temp/f52\n",
      "0.5596303974737569\n",
      "[0.9390680472247839, 1.1801927477227299]\n",
      "temp/f53\n",
      "0.5353706063561026\n",
      "[0.9126390118422296, 1.1581022008699755]\n",
      "temp/f54\n",
      "0.5698919929181484\n",
      "[0.9221179495492872, 1.2176660362870095]\n",
      "temp/f55\n",
      "0.5602715110471169\n",
      "[0.9273943891852566, 1.193148632908977]\n",
      "temp/f56\n",
      "0.5802951494214508\n",
      "[0.9222572469245387, 1.2383330519183628]\n",
      "temp/f57\n",
      "0.5466960907876469\n",
      "[0.8883997542041777, 1.2049924273711161]\n",
      "temp/f58\n",
      "0.555920505905675\n",
      "[0.9086788958765551, 1.2031621159347947]\n",
      "temp/f59\n",
      "0.5399023338142138\n",
      "[0.9031568484339643, 1.1766478191944634]\n",
      "temp/f60\n",
      "0.5426472787244166\n",
      "[0.9191234565737978, 1.1661711008750355]\n",
      "temp/f61\n",
      "0.5647725839463973\n",
      "[0.9197015657018589, 1.2098436021909356]\n",
      "temp/f62\n",
      "0.5335203972783727\n",
      "[0.9011457249945788, 1.1658950695621666]\n",
      "temp/f63\n",
      "0.5370759266706565\n",
      "[0.8970810671932676, 1.1770707861480454]\n",
      "temp/f64\n",
      "0.5319226666766242\n",
      "[0.8823881684339817, 1.1814571649192667]\n",
      "temp/f65\n",
      "0.5555390097033374\n",
      "[0.8998514018937585, 1.2112266175129163]\n",
      "temp/f66\n",
      "0.5276468714717665\n",
      "[0.9042194984614436, 1.1510742444820894]\n",
      "temp/f67\n",
      "0.5431487770905705\n",
      "[0.9278582659184259, 1.158439288262715]\n",
      "temp/f68\n",
      "0.5726952798180593\n",
      "[0.9508246839076989, 1.1945658757284197]\n",
      "temp/f69\n",
      "0.5490365866138575\n",
      "[0.9146766959942798, 1.183396477233435]\n",
      "temp/f70\n",
      "0.5068210294150932\n",
      "[0.8740526800749678, 1.1395893787552185]\n",
      "temp/f71\n",
      "0.5515644331051376\n",
      "[0.9010027819205487, 1.2021260842897263]\n",
      "temp/f72\n",
      "0.5491103322287747\n",
      "[0.9105659611529536, 1.1876547033045957]\n",
      "temp/f73\n",
      "0.5390960806213552\n",
      "[0.9059776791405219, 1.1722144821021885]\n",
      "temp/f74\n",
      "0.5340749173243026\n",
      "[0.8911921241752395, 1.1769577104733655]\n",
      "temp/f75\n",
      "0.5318730924631667\n",
      "[0.8916269481345974, 1.172119236791736]\n",
      "temp/f76\n",
      "0.5549813992441145\n",
      "[0.9148837935794281, 1.195079004908801]\n",
      "temp/f77\n",
      "0.5422789904856112\n",
      "[0.8995853320603397, 1.1849726489108827]\n",
      "temp/f78\n",
      "0.5232316701908525\n",
      "[0.9166466348117035, 1.1298167055700015]\n",
      "temp/f79\n",
      "0.5384322521851407\n",
      "[0.9207520951737503, 1.156112409196531]\n",
      "temp/f80\n",
      "0.5590985532227267\n",
      "[0.9178624509226121, 1.2003346555228414]\n",
      "temp/f81\n",
      "0.5392402769681182\n",
      "[0.8957431366524123, 1.1827374172838239]\n",
      "temp/f82\n",
      "0.5402255774809094\n",
      "[0.9142255800777451, 1.1662255748840735]\n",
      "temp/f83\n",
      "0.5401544132281251\n",
      "[0.899109583035102, 1.181199243421148]\n",
      "temp/f84\n",
      "0.5139454274348564\n",
      "[0.8676437079833486, 1.1602471468863642]\n",
      "temp/f85\n",
      "0.5649272734511337\n",
      "[0.9305934405265865, 1.1992611063756808]\n",
      "temp/f86\n",
      "0.5473333190741407\n",
      "[0.9241881439383829, 1.1704784942098985]\n",
      "temp/f87\n",
      "0.5397014303660804\n",
      "[0.9065376024437003, 1.1728652582884604]\n",
      "temp/f88\n",
      "0.5520569744962041\n",
      "[0.9270158485763861, 1.177098100416022]\n",
      "temp/f89\n",
      "0.5231259503602007\n",
      "[0.8553496224052308, 1.1909022783151706]\n",
      "temp/f90\n",
      "0.5512299736966703\n",
      "[0.9029957296506226, 1.199464217742718]\n",
      "temp/f91\n",
      "0.543570240068426\n",
      "[0.924019696697153, 1.163120783439699]\n",
      "temp/f92\n",
      "0.5629383529234137\n",
      "[0.9397424003071031, 1.1861343055397242]\n",
      "temp/f93\n",
      "0.5553326294803025\n",
      "[0.8948899384703419, 1.215775320490263]\n",
      "temp/f94\n",
      "0.5569490325308148\n",
      "[0.9247689281184774, 1.1891291369431523]\n",
      "temp/f95\n",
      "0.541466359093968\n",
      "[0.9078360657588732, 1.1750966524290627]\n",
      "temp/f96\n",
      "0.5518556272056041\n",
      "[0.914200534897961, 1.189510719513247]\n",
      "temp/f97\n",
      "0.5435317853355823\n",
      "[0.9104662036636364, 1.1765973670075283]\n",
      "temp/f98\n",
      "0.5721243434557717\n",
      "[0.9455841429756068, 1.1986645439359367]\n",
      "temp/f99\n",
      "0.5625058715696624\n",
      "[0.9287109707050684, 1.1963007724342563]\n",
      "temp/f100\n",
      "0.532976868260461\n",
      "[0.8961543472847262, 1.1697993892361958]\n",
      "temp/f101\n",
      "0.5533472125487913\n",
      "[0.9153245836539754, 1.1913698414436071]\n",
      "temp/f102\n",
      "0.5612528092762872\n",
      "[0.9055402927706078, 1.2169653257819666]\n",
      "temp/f103\n",
      "0.5428417049480517\n",
      "[0.9118830772389442, 1.173800332657159]\n",
      "temp/f104\n",
      "0.5654274758897926\n",
      "[0.9481135289511896, 1.1827414228283957]\n",
      "temp/f105\n",
      "0.5288847434121035\n",
      "[0.8948336132724107, 1.162935873551796]\n",
      "temp/f106\n",
      "0.5558451885789385\n",
      "[0.9206209566747954, 1.1910694204830816]\n",
      "temp/f107\n",
      "0.5411874497720756\n",
      "[0.9201784610351319, 1.162196438509019]\n",
      "temp/f108\n",
      "0.5421560153917185\n",
      "[0.9210410996639841, 1.163270931119453]\n",
      "temp/f109\n",
      "0.5612256916496465\n",
      "[0.9492271153551114, 1.1732242679441818]\n",
      "temp/f110\n",
      "0.5372980964353911\n",
      "[0.8927323890115467, 1.1818638038592353]\n",
      "temp/f111\n",
      "0.5282021662247196\n",
      "[0.8924828806011846, 1.1639214518482546]\n",
      "temp/f112\n",
      "0.5312364024193084\n",
      "[0.8951267180868864, 1.1673460867517302]\n",
      "temp/f113\n",
      "0.5425131997743278\n",
      "[0.8920678101707086, 1.1929585893779469]\n",
      "temp/f114\n",
      "0.5330693802601509\n",
      "[0.9148120281540157, 1.1513267323662861]\n",
      "temp/f115\n",
      "0.5387098767928633\n",
      "[0.9036635664647431, 1.1737561871209834]\n",
      "temp/f116\n",
      "0.5378902451062122\n",
      "[0.9157200214176477, 1.1600604687947766]\n",
      "temp/f117\n",
      "0.5631716956612249\n",
      "[0.9289950205194696, 1.1973483708029802]\n",
      "temp/f118\n",
      "0.5298835889803506\n",
      "[0.8953578934395504, 1.1644092845211507]\n",
      "temp/f119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5570849281687961\n",
      "[0.9060719912504004, 1.2080978650871916]\n",
      "temp/f120\n",
      "0.568271250285046\n",
      "[0.9391377305232989, 1.1974047700467931]\n",
      "temp/f121\n",
      "0.5304894248607074\n",
      "[0.8838882230830398, 1.177090626638375]\n",
      "temp/f122\n",
      "0.5408633930746884\n",
      "[0.8875717035330688, 1.194155082616308]\n",
      "temp/f123\n",
      "0.5498519224230349\n",
      "[0.9090075701220549, 1.1906962747240148]\n",
      "temp/f124\n",
      "0.5619635304973577\n",
      "[0.9179979202373064, 1.2059291407574089]\n",
      "temp/f125\n",
      "0.5572481442285481\n",
      "[0.9268332591700493, 1.1876630292870467]\n",
      "temp/f126\n",
      "0.5616352408172207\n",
      "[0.9208404404328983, 1.2024300412015432]\n",
      "temp/f127\n",
      "0.5362343120279391\n",
      "[0.8874092775981742, 1.185059346457704]\n",
      "temp/f128\n",
      "0.5428340952161368\n",
      "[0.9229691088578091, 1.1626990815744644]\n",
      "temp/f129\n",
      "0.545558242078639\n",
      "[0.881024755185186, 1.210091728972092]\n",
      "temp/f130\n",
      "0.5306300959287763\n",
      "[0.9055017882680972, 1.1557584035894553]\n",
      "temp/f131\n",
      "0.5477792512553397\n",
      "[0.9363850269329272, 1.159173475577752]\n",
      "temp/f132\n",
      "0.5363189602292913\n",
      "[0.8967296248080094, 1.175908295650573]\n",
      "temp/f133\n",
      "0.5312512877806485\n",
      "[0.8855749250564096, 1.1769276505048873]\n",
      "temp/f134\n",
      "0.5412583834947904\n",
      "[0.9039710392708907, 1.17854572771869]\n",
      "temp/f135\n",
      "0.5298879987784988\n",
      "[0.9230850098114785, 1.1366909877455191]\n",
      "temp/f136\n",
      "0.5604233521880565\n",
      "[0.91602540252849, 1.204821301847623]\n",
      "temp/f137\n",
      "0.544358634908134\n",
      "[0.9160623318944358, 1.172654937921832]\n",
      "temp/f138\n",
      "0.5520388770183983\n",
      "[0.9169265858517026, 1.187151168185094]\n",
      "temp/f139\n",
      "0.5547582097632833\n",
      "[0.9114685971440476, 1.1980478223825188]\n",
      "temp/f140\n",
      "0.5305175488454721\n",
      "[0.905503665455374, 1.15553143223557]\n",
      "temp/f141\n",
      "0.5591835388948341\n",
      "[0.9128415199672412, 1.2055255578224269]\n",
      "temp/f142\n",
      "0.535926265990541\n",
      "[0.9098992521550118, 1.1619532798260703]\n",
      "temp/f143\n",
      "0.5187886297673757\n",
      "[0.8710039635591285, 1.166573295975623]\n",
      "temp/f144\n",
      "0.5362501364031217\n",
      "[0.8968790233756372, 1.1756212494306062]\n",
      "temp/f145\n",
      "0.5622709591168988\n",
      "[0.9327026359133868, 1.191839282320411]\n",
      "temp/f146\n",
      "0.5374825648826635\n",
      "[0.900497413741798, 1.174467716023529]\n",
      "temp/f147\n",
      "0.5160196559059315\n",
      "[0.8812151388549823, 1.1508241729568807]\n",
      "temp/f148\n",
      "0.5520936457668706\n",
      "[0.9396936583470176, 1.1644936331867235]\n",
      "temp/f149\n",
      "0.5164980436069833\n",
      "[0.8944437071217562, 1.1385523800922102]\n",
      "temp/f150\n",
      "0.527416608195158\n",
      "[0.9043995051152554, 1.1504337112750607]\n",
      "temp/f151\n",
      "0.5726175750025561\n",
      "[0.929019383116086, 1.216215766889026]\n",
      "temp/f152\n",
      "0.5373277722505663\n",
      "[0.8753803888427495, 1.199275155658383]\n",
      "temp/f153\n",
      "0.5608809885578436\n",
      "[0.9246792333632758, 1.1970827437524114]\n",
      "temp/f154\n",
      "0.5543904834236684\n",
      "[0.9014938522253356, 1.207287114622001]\n",
      "temp/f155\n",
      "0.5394905734418933\n",
      "[0.882406570055775, 1.1965745768280116]\n",
      "temp/f156\n",
      "0.543740804853649\n",
      "[0.9002414445564968, 1.187240165150801]\n",
      "temp/f157\n",
      "0.5492730763341335\n",
      "[0.9065948780864399, 1.191951274581827]\n",
      "temp/f158\n",
      "0.5404325489480952\n",
      "[0.9300054597225003, 1.1508596381736902]\n",
      "temp/f159\n",
      "0.5506095107193757\n",
      "[0.918244375685201, 1.1829746457535504]\n",
      "temp/f160\n",
      "0.5414733218634051\n",
      "[0.8913460488198273, 1.191600594906983]\n",
      "temp/f161\n",
      "0.5179948440067226\n",
      "[0.8810017732711163, 1.1549879147423288]\n",
      "temp/f162\n",
      "0.5300921930163558\n",
      "[0.887169531209854, 1.1730148548228576]\n",
      "temp/f163\n",
      "0.5407192091892213\n",
      "[0.9154294768664926, 1.1660089415119501]\n",
      "temp/f164\n",
      "0.5277905168345749\n",
      "[0.8925039474584735, 1.1630770862106763]\n",
      "temp/f165\n",
      "0.5271534694783422\n",
      "[0.913082526946765, 1.1412244120099193]\n",
      "temp/f166\n",
      "0.5607564566086878\n",
      "[0.9238474963532659, 1.1976654168641097]\n",
      "temp/f167\n",
      "0.5712884329251494\n",
      "[0.9225062848731765, 1.2200705809771222]\n",
      "temp/f168\n",
      "0.5519953039399071\n",
      "[0.9237215780192796, 1.1802690298605347]\n",
      "temp/f169\n",
      "0.5475787536995581\n",
      "[0.9061282765804626, 1.1890292308186536]\n",
      "temp/f170\n",
      "0.5419640993100232\n",
      "[0.9070454178090053, 1.1768827808110411]\n",
      "temp/f171\n",
      "0.5639533601528959\n",
      "[0.913563571071042, 1.2143431492347496]\n",
      "temp/f172\n",
      "0.5206841175210334\n",
      "[0.8798663612421979, 1.1615018737998688]\n",
      "temp/f173\n",
      "0.5521764703381028\n",
      "[0.9106637870174926, 1.1936891536587129]\n",
      "temp/f174\n",
      "0.5480422317817423\n",
      "[0.9291503561861088, 1.1669341073773758]\n",
      "temp/f175\n",
      "0.5283745353369369\n",
      "[0.8964316280610298, 1.160317442612844]\n",
      "temp/f176\n",
      "0.5233276770393619\n",
      "[0.8920897777976207, 1.1545655762811031]\n",
      "temp/f177\n",
      "0.5495672767767071\n",
      "[0.9106711076581113, 1.188463445895303]\n",
      "temp/f178\n",
      "0.5609233297861135\n",
      "[0.8953932696195246, 1.2264533899527024]\n",
      "temp/f179\n",
      "0.5500360040257523\n",
      "[0.8985928345664527, 1.2014791734850518]\n",
      "temp/f180\n",
      "0.5340775350881927\n",
      "[0.8988635329491427, 1.1692915372272426]\n",
      "temp/f181\n",
      "0.547009325014913\n",
      "[0.9178834660306769, 1.176135183999149]\n",
      "temp/f182\n",
      "0.5504449001879541\n",
      "[0.9097777711169996, 1.1911120292589086]\n",
      "temp/f183\n",
      "0.5465662056388881\n",
      "[0.9299526488079133, 1.163179762469863]\n",
      "temp/f184\n",
      "0.550048448740135\n",
      "[0.900512616452847, 1.199584281027423]\n",
      "temp/f185\n",
      "0.5294325842668297\n",
      "[0.8804329730363284, 1.178432195497331]\n",
      "temp/f186\n",
      "0.5431579349884947\n",
      "[0.91834117491555, 1.1679746950614394]\n",
      "temp/f187\n",
      "0.5466673517207865\n",
      "[0.9204042212252334, 1.1729304822163396]\n",
      "temp/f188\n",
      "0.5543490838159351\n",
      "[0.9196837034726412, 1.1890144641592288]\n",
      "temp/f189\n",
      "0.5408374647202674\n",
      "[0.8887557171497008, 1.1929192122908339]\n",
      "temp/f190\n",
      "0.5698333218854953\n",
      "[0.9345155876966379, 1.2051510560743526]\n",
      "temp/f191\n",
      "0.5381889987868399\n",
      "[0.9059209828968247, 1.1704570146768551]\n",
      "temp/f192\n",
      "0.5585158844457799\n",
      "[0.9196985703263162, 1.1973331985652436]\n",
      "temp/f193\n",
      "0.5676621310066432\n",
      "[0.9235679869407001, 1.2117562750725863]\n",
      "temp/f194\n",
      "0.539411445749989\n",
      "[0.9052670443958206, 1.1735558471041574]\n",
      "temp/f195\n",
      "0.5762576358551934\n",
      "[0.931549247203943, 1.2209660245064438]\n",
      "temp/f196\n",
      "0.5534769082581301\n",
      "[0.9074387890458818, 1.1995150274703783]\n",
      "temp/f197\n",
      "0.5638869889707768\n",
      "[0.9203240262890879, 1.2074499516524657]\n",
      "temp/f198\n",
      "0.5651408485761962\n",
      "[0.9221323831280003, 1.208149314024392]\n",
      "temp/f199\n",
      "0.536720045392737\n",
      "[0.9058952546675831, 1.1675448361178908]\n",
      "<<<<<<<< 0 1.5\n",
      "temp/f0\n",
      "1.0263604528208488\n",
      "[1.2060951270513036, 1.8466257785903937]\n",
      "temp/f1\n",
      "1.0558998027155462\n",
      "[1.2011281288548972, 1.9106714765761947]\n",
      "temp/f2\n",
      "1.0188809688526894\n",
      "[1.1932341832882791, 1.8445277544170997]\n",
      "temp/f3\n",
      "1.0352679332272612\n",
      "[1.180035086462037, 1.8905007799924851]\n",
      "temp/f4\n",
      "1.0422401395536676\n",
      "[1.1930394591820306, 1.8914408199253046]\n",
      "temp/f5\n",
      "1.05926877413495\n",
      "[1.213282220138457, 1.905255328131443]\n",
      "temp/f6\n",
      "1.0367284236536327\n",
      "[1.1821537750171711, 1.891303072290094]\n",
      "temp/f7\n",
      "1.0764785016539054\n",
      "[1.2133338770780724, 1.9396231262297383]\n",
      "temp/f8\n",
      "1.0536601560796024\n",
      "[1.21603204147724, 1.891288270681965]\n",
      "temp/f9\n",
      "1.0751650161324933\n",
      "[1.1992596802458457, 1.9510703520191408]\n",
      "temp/f10\n",
      "1.0288347703388403\n",
      "[1.2098434211443714, 1.847826119533309]\n",
      "temp/f11\n",
      "1.0705300928149932\n",
      "[1.192914843827408, 1.9481453418025785]\n",
      "temp/f12\n",
      "1.0401191429912626\n",
      "[1.1892727118194295, 1.8909655741630953]\n",
      "temp/f13\n",
      "1.060878314155756\n",
      "[1.2422480207617064, 1.8795086075498058]\n",
      "temp/f14\n",
      "1.0088283232930446\n",
      "[1.176731103387614, 1.8409255431984752]\n",
      "temp/f15\n",
      "1.0514064260887297\n",
      "[1.1819489399517276, 1.9208639122257318]\n",
      "temp/f16\n",
      "1.0269919239160448\n",
      "[1.193274702574853, 1.8607091452572364]\n",
      "temp/f17\n",
      "1.0260831582138945\n",
      "[1.195994773775684, 1.8561715426521048]\n",
      "temp/f18\n",
      "1.0210269435393389\n",
      "[1.18726402739864, 1.8547898596800376]\n",
      "temp/f19\n",
      "1.0587032713524147\n",
      "[1.1918795980032808, 1.9255269447015488]\n",
      "temp/f20\n",
      "1.0240217002016465\n",
      "[1.1890184615884725, 1.8590249388148203]\n",
      "temp/f21\n",
      "1.028834473976369\n",
      "[1.2127798515022463, 1.8448890964504918]\n",
      "temp/f22\n",
      "1.0438343301629351\n",
      "[1.1717061920077483, 1.9159624683181218]\n",
      "temp/f23\n",
      "1.0250389969048879\n",
      "[1.1855497740010814, 1.8645282198086943]\n",
      "temp/f24\n",
      "1.0464226515604405\n",
      "[1.2054136716629678, 1.887431631457913]\n",
      "temp/f25\n",
      "1.0313350151188834\n",
      "[1.194590674850381, 1.8680793553873856]\n",
      "temp/f26\n",
      "0.9969076974904442\n",
      "[1.1471194142442078, 1.8466959807366803]\n",
      "temp/f27\n",
      "1.0307493615375165\n",
      "[1.2103854662806883, 1.8511132567943447]\n",
      "temp/f28\n",
      "1.0277713440272673\n",
      "[1.2006919670137777, 1.8548507210407568]\n",
      "temp/f29\n",
      "1.0664505133810236\n",
      "[1.2351092240539379, 1.8977918027081093]\n",
      "temp/f30\n",
      "1.0578964426223423\n",
      "[1.227792032737395, 1.8880008525072898]\n",
      "temp/f31\n",
      "1.07618773446849\n",
      "[1.240930339773928, 1.911445129163052]\n",
      "temp/f32\n",
      "1.0059610841719095\n",
      "[1.1684919510009322, 1.8434302173428867]\n",
      "temp/f33\n",
      "1.0475212162074534\n",
      "[1.2043307576865785, 1.8907116747283286]\n",
      "temp/f34\n",
      "1.0424426359762222\n",
      "[1.19718274202651, 1.8877025299259345]\n",
      "temp/f35\n",
      "1.025546814455267\n",
      "[1.1782992227522298, 1.8727944061583042]\n",
      "temp/f36\n",
      "1.042018123493453\n",
      "[1.2046234646403513, 1.879412782346554]\n",
      "temp/f37\n",
      "1.047930487563707\n",
      "[1.1755333832870487, 1.920327591840365]\n",
      "temp/f38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0603489208118986\n",
      "[1.2237185812893823, 1.8969792603344147]\n",
      "temp/f39\n",
      "1.0593945172768626\n",
      "[1.2016098741400942, 1.9171791604136308]\n",
      "temp/f40\n",
      "1.0604234667054129\n",
      "[1.1723454513044917, 1.948501482106334]\n",
      "temp/f41\n",
      "1.050231815221843\n",
      "[1.21612806852617, 1.8843355619175162]\n",
      "temp/f42\n",
      "1.0612708327379936\n",
      "[1.2360728117922863, 1.886468853683701]\n",
      "temp/f43\n",
      "1.053954240476127\n",
      "[1.2209265327981644, 1.8869819481540895]\n",
      "temp/f44\n",
      "1.0071758885169757\n",
      "[1.1614956978796867, 1.8528560791542648]\n",
      "temp/f45\n",
      "1.032341916836903\n",
      "[1.2233354168558122, 1.8413484168179937]\n",
      "temp/f46\n",
      "1.0449222342912838\n",
      "[1.2183826259058221, 1.8714618426767455]\n",
      "temp/f47\n",
      "1.0459529882079448\n",
      "[1.1998359075828968, 1.8920700688329928]\n",
      "temp/f48\n",
      "1.0198750346843735\n",
      "[1.1719937407586674, 1.8677563286100796]\n",
      "temp/f49\n",
      "1.0165071961583747\n",
      "[1.1590313513175157, 1.8739830409992337]\n",
      "temp/f50\n",
      "1.0384839011527986\n",
      "[1.2346156501477814, 1.842352152157816]\n",
      "temp/f51\n",
      "1.0797492703850584\n",
      "[1.2354817276604386, 1.9240168131096782]\n",
      "temp/f52\n",
      "1.056690896023234\n",
      "[1.237614395900048, 1.8757673961464199]\n",
      "temp/f53\n",
      "1.021258080576747\n",
      "[1.2019822978086583, 1.8405338633448358]\n",
      "temp/f54\n",
      "1.0698519019174795\n",
      "[1.211495889150146, 1.928207914684813]\n",
      "temp/f55\n",
      "1.0474661055111263\n",
      "[1.2161875343524928, 1.8787446766697595]\n",
      "temp/f56\n",
      "1.0854563629357141\n",
      "[1.214171580966604, 1.9567411449048242]\n",
      "temp/f57\n",
      "1.0429548653464429\n",
      "[1.178281352649547, 1.9076283780433383]\n",
      "temp/f58\n",
      "1.055401157043185\n",
      "[1.2010205074455877, 1.909781806640782]\n",
      "temp/f59\n",
      "1.0298952037992233\n",
      "[1.1892553985478862, 1.8705350090505604]\n",
      "temp/f60\n",
      "1.0283719551208303\n",
      "[1.2098327381842744, 1.8469111720573863]\n",
      "temp/f61\n",
      "1.0675640383042908\n",
      "[1.213051731471852, 1.9220763451367298]\n",
      "temp/f62\n",
      "1.0173955726091384\n",
      "[1.1864064640164593, 1.8483846812018176]\n",
      "temp/f63\n",
      "1.0281224935488817\n",
      "[1.1825616629476252, 1.873683324150138]\n",
      "temp/f64\n",
      "1.0216030636721942\n",
      "[1.1646829058987642, 1.878523221445624]\n",
      "temp/f65\n",
      "1.0518773107699286\n",
      "[1.1828086226780508, 1.9209459988618065]\n",
      "temp/f66\n",
      "1.0159262783394971\n",
      "[1.1943045206298102, 1.8375480360491838]\n",
      "temp/f67\n",
      "1.0283164560489202\n",
      "[1.2195873235910921, 1.837045588506748]\n",
      "temp/f68\n",
      "1.0727380492453922\n",
      "[1.2498831356739422, 1.8955929628168422]\n",
      "temp/f69\n",
      "1.0422871077932316\n",
      "[1.2048099179934186, 1.8797642975930442]\n",
      "temp/f70\n",
      "0.9854767926528638\n",
      "[1.1525100347853134, 1.8184435505204142]\n",
      "temp/f71\n",
      "1.047282647155416\n",
      "[1.1925955681007243, 1.9019697262101074]\n",
      "temp/f72\n",
      "1.038881877403726\n",
      "[1.201932450772301, 1.875831304035151]\n",
      "temp/f73\n",
      "1.0234392669288443\n",
      "[1.1893380632560728, 1.8575404706016159]\n",
      "temp/f74\n",
      "1.0221100952193907\n",
      "[1.1772942515735412, 1.8669259388652402]\n",
      "temp/f75\n",
      "1.0159010745724664\n",
      "[1.1724437490834916, 1.8593584000614414]\n",
      "temp/f76\n",
      "1.0424881435645919\n",
      "[1.2015682974133133, 1.8834079897158702]\n",
      "temp/f77\n",
      "1.0337606644603072\n",
      "[1.186611315157212, 1.8809100137634027]\n",
      "temp/f78\n",
      "1.0045950648223558\n",
      "[1.211941474224836, 1.7972486554198754]\n",
      "temp/f79\n",
      "1.0254235289548639\n",
      "[1.2141093509773282, 1.8367377069323993]\n",
      "temp/f80\n",
      "1.055274961630064\n",
      "[1.2067670432968864, 1.9037828799632417]\n",
      "temp/f81\n",
      "1.0314742389862737\n",
      "[1.1847189829346407, 1.8782294950379066]\n",
      "temp/f82\n",
      "1.0284595238673548\n",
      "[1.2020192244041834, 1.8548998233305263]\n",
      "temp/f83\n",
      "1.0283526377524983\n",
      "[1.183616509304265, 1.8730887662007314]\n",
      "temp/f84\n",
      "0.9918542581704226\n",
      "[1.1394690958721638, 1.8442394204686812]\n",
      "temp/f85\n",
      "1.06587156161124\n",
      "[1.2269927122213844, 1.9047504110010955]\n",
      "temp/f86\n",
      "1.0424078806789172\n",
      "[1.2192014603070918, 1.8656143010507427]\n",
      "temp/f87\n",
      "1.0318973586743776\n",
      "[1.2012878351511755, 1.8625068821975794]\n",
      "temp/f88\n",
      "1.0449200850761131\n",
      "[1.2222677029630145, 1.8675724671892113]\n",
      "temp/f89\n",
      "1.012156455351441\n",
      "[1.135793878313132, 1.8885190323897496]\n",
      "temp/f90\n",
      "1.0394519200265286\n",
      "[1.1879135165175139, 1.8909903235355434]\n",
      "temp/f91\n",
      "1.030476590590757\n",
      "[1.2179937637033122, 1.8429594174782016]\n",
      "temp/f92\n",
      "1.0580776217672023\n",
      "[1.22996443262554, 1.8861908109088645]\n",
      "temp/f93\n",
      "1.050315098105526\n",
      "[1.1731662081334469, 1.9274639880776052]\n",
      "temp/f94\n",
      "1.047100298852118\n",
      "[1.213220883330849, 1.880979714373387]\n",
      "temp/f95\n",
      "1.031030357682008\n",
      "[1.2001305552083712, 1.8619301601556444]\n",
      "temp/f96\n",
      "1.0464032187264267\n",
      "[1.209579008199731, 1.8832274292531221]\n",
      "temp/f97\n",
      "1.033351395074754\n",
      "[1.1992174862103415, 1.8674853039391663]\n",
      "temp/f98\n",
      "1.0719837867260908\n",
      "[1.2461906334691029, 1.897776939983079]\n",
      "temp/f99\n",
      "1.0615455713469357\n",
      "[1.2256469261247598, 1.8974442165691119]\n",
      "temp/f100\n",
      "1.0145218256131368\n",
      "[1.1734540277568781, 1.8555896234693956]\n",
      "temp/f101\n",
      "1.0481308435650272\n",
      "[1.2088220266206644, 1.8874396605093895]\n",
      "temp/f102\n",
      "1.055765856745313\n",
      "[1.1885163306459108, 1.9230153828447152]\n",
      "temp/f103\n",
      "1.0304180380150978\n",
      "[1.199585425004197, 1.8612506510259985]\n",
      "temp/f104\n",
      "1.0618492967251991\n",
      "[1.2431762270208324, 1.8805223664295658]\n",
      "temp/f105\n",
      "1.0138645344075146\n",
      "[1.1821620463917553, 1.8455670224232736]\n",
      "temp/f106\n",
      "1.0542621716637086\n",
      "[1.2149710815320014, 1.8935532617954154]\n",
      "temp/f107\n",
      "1.0327357475475472\n",
      "[1.2169662640632115, 1.8485052310318826]\n",
      "temp/f108\n",
      "1.0388671487362304\n",
      "[1.2202266009529026, 1.857507696519558]\n",
      "temp/f109\n",
      "1.0503016151439213\n",
      "[1.2468598923533505, 1.8537433379344923]\n",
      "temp/f110\n",
      "1.0278646877562208\n",
      "[1.1783435458803717, 1.8773858296320696]\n",
      "temp/f111\n",
      "1.018337363309037\n",
      "[1.1845987352986311, 1.8520759913194424]\n",
      "temp/f112\n",
      "1.0151298428329572\n",
      "[1.1820622416631736, 1.8481974440027409]\n",
      "temp/f113\n",
      "1.0391740028558207\n",
      "[1.181317806324105, 1.8970301993875365]\n",
      "temp/f114\n",
      "1.0186706877887217\n",
      "[1.209699780131822, 1.8276415954456218]\n",
      "temp/f115\n",
      "1.0312969060948967\n",
      "[1.1967755588956552, 1.8658182532941379]\n",
      "temp/f116\n",
      "1.0283814338001447\n",
      "[1.2114432389180587, 1.8453196286822304]\n",
      "temp/f117\n",
      "1.0632918267119515\n",
      "[1.2290902872509337, 1.8974933661729694]\n",
      "temp/f118\n",
      "1.0144276868948392\n",
      "[1.1826688091879258, 1.8461865646017523]\n",
      "temp/f119\n",
      "1.048095270994732\n",
      "[1.188735986729748, 1.9074545552597157]\n",
      "temp/f120\n",
      "1.0691983741019682\n",
      "[1.2328637326507736, 1.9055330155531627]\n",
      "temp/f121\n",
      "1.012924676505649\n",
      "[1.1662663909000874, 1.8595829621112105]\n",
      "temp/f122\n",
      "1.0354082310935753\n",
      "[1.1717591755785564, 1.8990572866085944]\n",
      "temp/f123\n",
      "1.046470315952809\n",
      "[1.1973672988258754, 1.8955733330797424]\n",
      "temp/f124\n",
      "1.0610993730328269\n",
      "[1.2110015724424565, 1.9111971736231967]\n",
      "temp/f125\n",
      "1.0495185819006463\n",
      "[1.219323559181866, 1.8797136046194263]\n",
      "temp/f126\n",
      "1.053601476653633\n",
      "[1.207246568802965, 1.8999563845043008]\n",
      "temp/f127\n",
      "1.017761156728225\n",
      "[1.1655080006593466, 1.8700143127971032]\n",
      "temp/f128\n",
      "1.0274755979987726\n",
      "[1.2194976994877325, 1.8354534965098128]\n",
      "temp/f129\n",
      "1.0384132654275817\n",
      "[1.159290257955896, 1.9175362728992675]\n",
      "temp/f130\n",
      "1.0145538774947578\n",
      "[1.1942663460960998, 1.8348414088934157]\n",
      "temp/f131\n",
      "1.033362784874841\n",
      "[1.2324710934682053, 1.8342544762814765]\n",
      "temp/f132\n",
      "1.0241161048239458\n",
      "[1.184799257457796, 1.8634329521900954]\n",
      "temp/f133\n",
      "1.0250200354968606\n",
      "[1.1730602654860944, 1.876979805507627]\n",
      "temp/f134\n",
      "1.0320077221957853\n",
      "[1.1904434893131477, 1.8735719550784227]\n",
      "temp/f135\n",
      "1.011094432951709\n",
      "[1.2153301263525385, 1.8068587395508795]\n",
      "temp/f136\n",
      "1.058545103225963\n",
      "[1.2120577485811173, 1.9050324578708089]\n",
      "temp/f137\n",
      "1.0335985281895246\n",
      "[1.2077224374455664, 1.8594746189334828]\n",
      "temp/f138\n",
      "1.0504885839527363\n",
      "[1.2113463946699492, 1.889630773235523]\n",
      "temp/f139\n",
      "1.0456546567267346\n",
      "[1.2002313548880248, 1.8910779585654447]\n",
      "temp/f140\n",
      "1.0107357121794598\n",
      "[1.1885325472298314, 1.8329388771290882]\n",
      "temp/f141\n",
      "1.0611994165486736\n",
      "[1.2074479836966043, 1.9149508494007426]\n",
      "temp/f142\n",
      "1.0191319514937598\n",
      "[1.1956574739640817, 1.8426064290234376]\n",
      "temp/f143\n",
      "1.004229267911695\n",
      "[1.1530799495298836, 1.8553785862935064]\n",
      "temp/f144\n",
      "1.027677369132749\n",
      "[1.1826590888048667, 1.872695649460631]\n",
      "temp/f145\n",
      "1.059667024162819\n",
      "[1.2305418212054078, 1.88879222712023]\n",
      "temp/f146\n",
      "1.0176868242631352\n",
      "[1.179787872480823, 1.855585776045447]\n",
      "temp/f147\n",
      "0.9985722539111015\n",
      "[1.1637189015405338, 1.8334256062816692]\n",
      "temp/f148\n",
      "1.0363059860214525\n",
      "[1.234039359334266, 1.8385726127086388]\n",
      "temp/f149\n",
      "0.9894639815030528\n",
      "[1.175663125057618, 1.8032648379484877]\n",
      "temp/f150\n",
      "1.0100871941662464\n",
      "[1.1934606551764106, 1.826713733156082]\n",
      "temp/f151\n",
      "1.0772735876230288\n",
      "[1.222191536870659, 1.9323556383753984]\n",
      "temp/f152\n",
      "1.0309029598363364\n",
      "[1.158632836495262, 1.9031730831774107]\n",
      "temp/f153\n",
      "1.055827015520677\n",
      "[1.2143749738501706, 1.8972790571911835]\n",
      "temp/f154\n",
      "1.0487562761566116\n",
      "[1.1892137911983085, 1.9082987611149145]\n",
      "temp/f155\n",
      "1.0317966789547715\n",
      "[1.1630629487935058, 1.900530409116037]\n",
      "temp/f156\n",
      "1.0317041289449076\n",
      "[1.1833476190461694, 1.880060638843646]\n",
      "temp/f157\n",
      "1.0377183313205807\n",
      "[1.1870892655410448, 1.8883473971001166]\n",
      "temp/f158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0246023539483162\n",
      "[1.2260029044817642, 1.823201803414868]\n",
      "temp/f159\n",
      "1.041364625473446\n",
      "[1.2080451905475393, 1.8746840603993526]\n",
      "temp/f160\n",
      "1.0346712667192062\n",
      "[1.1792972507279582, 1.8900452827104541]\n",
      "temp/f161\n",
      "0.9991276944798319\n",
      "[1.1576091935366777, 1.840646195422986]\n",
      "temp/f162\n",
      "1.0248753784573281\n",
      "[1.177330667563621, 1.8724200893510352]\n",
      "temp/f163\n",
      "1.025696663611995\n",
      "[1.205384129729208, 1.8460091974947819]\n",
      "temp/f164\n",
      "1.0079300649880785\n",
      "[1.173561412346981, 1.8422987176291759]\n",
      "temp/f165\n",
      "1.005352462511959\n",
      "[1.1992906764827647, 1.811414248541153]\n",
      "temp/f166\n",
      "1.0633932665862367\n",
      "[1.2221496270916994, 1.904636906080774]\n",
      "temp/f167\n",
      "1.0739869539967732\n",
      "[1.2112288244919474, 1.936745083501599]\n",
      "temp/f168\n",
      "1.0430771982127922\n",
      "[1.2168469196928948, 1.8693074767326894]\n",
      "temp/f169\n",
      "1.0363793840719149\n",
      "[1.1867301800284453, 1.8860285881153842]\n",
      "temp/f170\n",
      "1.0281480611284688\n",
      "[1.190549138918575, 1.8657469833383624]\n",
      "temp/f171\n",
      "1.064267085062923\n",
      "[1.2045782434492256, 1.9239559266766202]\n",
      "temp/f172\n",
      "1.0047680688795086\n",
      "[1.165097981058185, 1.844438156700832]\n",
      "temp/f173\n",
      "1.0470228252354437\n",
      "[1.1988998770662844, 1.895145773404603]\n",
      "temp/f174\n",
      "1.0378807844202276\n",
      "[1.2243258309357878, 1.851435737904667]\n",
      "temp/f175\n",
      "1.0116909513010344\n",
      "[1.1819072266590436, 1.8414746759430252]\n",
      "temp/f176\n",
      "1.0078523220547209\n",
      "[1.1809027571966746, 1.8348018869127671]\n",
      "temp/f177\n",
      "1.040851192536151\n",
      "[1.1996862379853264, 1.8820161470869758]\n",
      "temp/f178\n",
      "1.0622231926466799\n",
      "[1.1810884597453053, 1.943357925548054]\n",
      "temp/f179\n",
      "1.0379145290179852\n",
      "[1.1793770346111088, 1.8964520234248616]\n",
      "temp/f180\n",
      "1.0173000196088045\n",
      "[1.1814590647249434, 1.853140974492665]\n",
      "temp/f181\n",
      "1.0368316352123141\n",
      "[1.2098671829244758, 1.8637960875001525]\n",
      "temp/f182\n",
      "1.0475436615049505\n",
      "[1.199593512183, 1.895493810826901]\n",
      "temp/f183\n",
      "1.0377171814441781\n",
      "[1.2240120784625415, 1.8514222844258146]\n",
      "temp/f184\n",
      "1.0465828985719474\n",
      "[1.1868200163991787, 1.9063457807447162]\n",
      "temp/f185\n",
      "1.0072268107222102\n",
      "[1.158421380735888, 1.8560322407085321]\n",
      "temp/f186\n",
      "1.034248326746361\n",
      "[1.21139257660552, 1.8571040768872016]\n",
      "temp/f187\n",
      "1.0375275060784512\n",
      "[1.2118713843910165, 1.8631836277658858]\n",
      "temp/f188\n",
      "1.0495138228098295\n",
      "[1.2147371071055797, 1.8842905385140793]\n",
      "temp/f189\n",
      "1.0304684660574197\n",
      "[1.1716999957426588, 1.8892369363721802]\n",
      "temp/f190\n",
      "1.0719288891141794\n",
      "[1.2349579597572609, 1.9088998184710977]\n",
      "temp/f191\n",
      "1.028138677750149\n",
      "[1.1971767167287592, 1.8591006387715387]\n",
      "temp/f192\n",
      "1.0495193103637295\n",
      "[1.2096679744032046, 1.889370646324254]\n",
      "temp/f193\n",
      "1.071746650315147\n",
      "[1.217890328173142, 1.925602972457152]\n",
      "temp/f194\n",
      "1.0293403015795082\n",
      "[1.1951934794729813, 1.863487123686035]\n",
      "temp/f195\n",
      "1.0823915481464084\n",
      "[1.226690439822433, 1.9380926564703835]\n",
      "temp/f196\n",
      "1.0513912569558923\n",
      "[1.1986213503932306, 1.904161163518554]\n",
      "temp/f197\n",
      "1.0667657990483246\n",
      "[1.2123858613099638, 1.921145736786685]\n",
      "temp/f198\n",
      "1.0677554826107027\n",
      "[1.2187776830484356, 1.91673328217297]\n",
      "temp/f199\n",
      "1.0241348576949763\n",
      "[1.1927004721334302, 1.855569243256522]\n",
      "<<<<<<<< 0.5 1\n",
      "temp/f0\n",
      "0.40584755951190254\n",
      "[0.7442731404707333, 1.0674219785530716]\n",
      "temp/f1\n",
      "0.42183536217704054\n",
      "[0.741640044061315, 1.102030680292766]\n",
      "temp/f2\n",
      "0.3997702164021978\n",
      "[0.7340366604909822, 1.0655037723134133]\n",
      "temp/f3\n",
      "0.4242823005930497\n",
      "[0.7419202955256, 1.1066443056604993]\n",
      "temp/f4\n",
      "0.4116047573999958\n",
      "[0.7352567397491612, 1.0879527750508304]\n",
      "temp/f5\n",
      "0.4245904775125561\n",
      "[0.756807434794746, 1.0923735202303662]\n",
      "temp/f6\n",
      "0.4100910086126738\n",
      "[0.7353422379707183, 1.0848397792546292]\n",
      "temp/f7\n",
      "0.4404918679394594\n",
      "[0.7666500549270202, 1.1143336809518984]\n",
      "temp/f8\n",
      "0.4194659376740142\n",
      "[0.7489734794858276, 1.0899583958622008]\n",
      "temp/f9\n",
      "0.432970506943385\n",
      "[0.7430117027354712, 1.1229293111512988]\n",
      "temp/f10\n",
      "0.40712483186100956\n",
      "[0.7463902683694197, 1.0678593953525994]\n",
      "temp/f11\n",
      "0.4438155827595144\n",
      "[0.7418559868614324, 1.1457751786575963]\n",
      "temp/f12\n",
      "0.4100589918897892\n",
      "[0.7340240044487537, 1.0860939793308246]\n",
      "temp/f13\n",
      "0.438861614494239\n",
      "[0.7744531054302091, 1.103270123558269]\n",
      "temp/f14\n",
      "0.39956723041068676\n",
      "[0.7278408442798279, 1.0712936165415456]\n",
      "temp/f15\n",
      "0.42548913641035135\n",
      "[0.7330037850118534, 1.1179744878088493]\n",
      "temp/f16\n",
      "0.41507873272346074\n",
      "[0.7513184222595357, 1.0788390431873858]\n",
      "temp/f17\n",
      "0.4089315111196219\n",
      "[0.7353283936987064, 1.0825346285405373]\n",
      "temp/f18\n",
      "0.39892237058037605\n",
      "[0.7278441618819891, 1.070000579278763]\n",
      "temp/f19\n",
      "0.4369635387883266\n",
      "[0.7459321376458535, 1.1279949399307996]\n",
      "temp/f20\n",
      "0.39221150343942146\n",
      "[0.7273348683484234, 1.0570881385304194]\n",
      "temp/f21\n",
      "0.4174643992116883\n",
      "[0.7569537352571933, 1.0779750631661833]\n",
      "temp/f22\n",
      "0.41470727184313416\n",
      "[0.7269149396017268, 1.1024996040845414]\n",
      "temp/f23\n",
      "0.40872312893653384\n",
      "[0.7347637733160539, 1.0826824845570138]\n",
      "temp/f24\n",
      "0.4255572863206134\n",
      "[0.7452387117646535, 1.1058758608765733]\n",
      "temp/f25\n",
      "0.40631802989869603\n",
      "[0.7283353458133216, 1.0843007139840704]\n",
      "temp/f26\n",
      "0.39788053205192186\n",
      "[0.709843986835157, 1.0859170772686866]\n",
      "temp/f27\n",
      "0.404160290110936\n",
      "[0.7410147867426893, 1.0673057934791828]\n",
      "temp/f28\n",
      "0.4091860365212203\n",
      "[0.7341960037747487, 1.0841760692676918]\n",
      "temp/f29\n",
      "0.42662867358474665\n",
      "[0.7567324047012478, 1.0965249424682455]\n",
      "temp/f30\n",
      "0.41311193219369946\n",
      "[0.7539815763069007, 1.0722422880804983]\n",
      "temp/f31\n",
      "0.44530435531636514\n",
      "[0.7625622514511512, 1.128046459181579]\n",
      "temp/f32\n",
      "0.3961035840967718\n",
      "[0.7204438301463276, 1.071763338047216]\n",
      "temp/f33\n",
      "0.4236365692745957\n",
      "[0.7419943651364904, 1.105278773412701]\n",
      "temp/f34\n",
      "0.41262724757105285\n",
      "[0.743187311643679, 1.0820671834984266]\n",
      "temp/f35\n",
      "0.41861758944203153\n",
      "[0.7323443659112218, 1.1048908129728412]\n",
      "temp/f36\n",
      "0.41479154709885624\n",
      "[0.7360876935634134, 1.093495400634299]\n",
      "temp/f37\n",
      "0.4125858254494704\n",
      "[0.726051304076709, 1.0991203468222317]\n",
      "temp/f38\n",
      "0.44216547021216046\n",
      "[0.7673034995208643, 1.1170274409034566]\n",
      "temp/f39\n",
      "0.410102895431403\n",
      "[0.7250949129281247, 1.0951108779346812]\n",
      "temp/f40\n",
      "0.42121908664768704\n",
      "[0.7162396145692349, 1.1261985587261392]\n",
      "temp/f41\n",
      "0.41520464988682426\n",
      "[0.743112501776261, 1.0872967979973875]\n",
      "temp/f42\n",
      "0.4220755600076399\n",
      "[0.7607778657121316, 1.0833732543031482]\n",
      "temp/f43\n",
      "0.4292069896875357\n",
      "[0.7548525877717932, 1.103561391603278]\n",
      "temp/f44\n",
      "0.4081218168419921\n",
      "[0.7236457133430777, 1.0925979203409064]\n",
      "temp/f45\n",
      "0.41601886319654957\n",
      "[0.7631433227181441, 1.068894403674955]\n",
      "temp/f46\n",
      "0.41441419847190275\n",
      "[0.7427204642069734, 1.0861079327368321]\n",
      "temp/f47\n",
      "0.419283434519125\n",
      "[0.742836275826482, 1.0957305932117678]\n",
      "temp/f48\n",
      "0.4007076708659052\n",
      "[0.7164439743319895, 1.084971367399821]\n",
      "temp/f49\n",
      "0.40612994603739483\n",
      "[0.722880910813741, 1.0893789812610486]\n",
      "temp/f50\n",
      "0.4099051991146965\n",
      "[0.7489010245829433, 1.0709093736464497]\n",
      "temp/f51\n",
      "0.43333290602613306\n",
      "[0.7522528872627811, 1.114412924789485]\n",
      "temp/f52\n",
      "0.4300273046086356\n",
      "[0.7697513796437575, 1.0903032295735136]\n",
      "temp/f53\n",
      "0.39870756474075864\n",
      "[0.7439449597805893, 1.0534701697009279]\n",
      "temp/f54\n",
      "0.43232968594464216\n",
      "[0.7490349156401079, 1.1156244562491764]\n",
      "temp/f55\n",
      "0.43351899881333855\n",
      "[0.7494559171877357, 1.1175820804389414]\n",
      "temp/f56\n",
      "0.44515030269544575\n",
      "[0.7482728936093069, 1.1420277117815845]\n",
      "temp/f57\n",
      "0.4045108129009024\n",
      "[0.7196620447676493, 1.0893595810341554]\n",
      "temp/f58\n",
      "0.41973547051948623\n",
      "[0.7283293263319781, 1.1111416147069944]\n",
      "temp/f59\n",
      "0.400612595136317\n",
      "[0.7308229871674891, 1.0704022031051448]\n",
      "temp/f60\n",
      "0.4067201777248861\n",
      "[0.7309859171547056, 1.0824544382950665]\n",
      "temp/f61\n",
      "0.4240107241137243\n",
      "[0.7403137749832687, 1.10770767324418]\n",
      "temp/f62\n",
      "0.39303501621269366\n",
      "[0.7297560823385336, 1.0563139500868537]\n",
      "temp/f63\n",
      "0.39980918979468827\n",
      "[0.7211338687020168, 1.0784845108873597]\n",
      "temp/f64\n",
      "0.39783257830494323\n",
      "[0.7210723006535521, 1.0745928559563342]\n",
      "temp/f65\n",
      "0.42342498688595054\n",
      "[0.7377854021852518, 1.1090645715866492]\n",
      "temp/f66\n",
      "0.4009894501100302\n",
      "[0.7358732709262903, 1.06610562929377]\n",
      "temp/f67\n",
      "0.40199474912941435\n",
      "[0.7492497820286715, 1.054739716230157]\n",
      "temp/f68\n",
      "0.43754208137677664\n",
      "[0.782343658918895, 1.0927405038346583]\n",
      "temp/f69\n",
      "0.4265868238499898\n",
      "[0.7497080082515868, 1.1034656394483928]\n",
      "temp/f70\n",
      "0.38040571110109433\n",
      "[0.7058339341872165, 1.054977488014972]\n",
      "temp/f71\n",
      "0.41114867951083367\n",
      "[0.7305623706930685, 1.0917349883285987]\n",
      "temp/f72\n",
      "0.4060212630937301\n",
      "[0.7302897938263011, 1.081752732361159]\n",
      "temp/f73\n",
      "0.3987685992757688\n",
      "[0.7267608517696977, 1.0707763467818399]\n",
      "temp/f74\n",
      "0.39569849349038544\n",
      "[0.7142698722371272, 1.0771271147436436]\n",
      "temp/f75\n",
      "0.4029435918694525\n",
      "[0.7275958625271496, 1.0782913212117553]\n",
      "temp/f76\n",
      "0.41902803495339747\n",
      "[0.7418016854848072, 1.0962543844219876]\n",
      "temp/f77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4181046397307008\n",
      "[0.7313665194643295, 1.104842759997072]\n",
      "temp/f78\n",
      "0.3852864845303473\n",
      "[0.7355813634530388, 1.0349916056076558]\n",
      "temp/f79\n",
      "0.4054254421195196\n",
      "[0.7414405467959816, 1.0694103374430575]\n",
      "temp/f80\n",
      "0.4323202613934929\n",
      "[0.7424680928350925, 1.1221724299518931]\n",
      "temp/f81\n",
      "0.40479909705994066\n",
      "[0.7196267630692742, 1.089971431050607]\n",
      "temp/f82\n",
      "0.4138558296885575\n",
      "[0.7482248422378391, 1.0794868171392757]\n",
      "temp/f83\n",
      "0.40232582621186663\n",
      "[0.7261024977765891, 1.0785491546471442]\n",
      "temp/f84\n",
      "0.3891530244182829\n",
      "[0.712936091168387, 1.0653699576681788]\n",
      "temp/f85\n",
      "0.4456757398975594\n",
      "[0.7736118486384379, 1.1177396311566807]\n",
      "temp/f86\n",
      "0.4275780962615815\n",
      "[0.7679312714963232, 1.0872249210268397]\n",
      "temp/f87\n",
      "0.4205534033012073\n",
      "[0.7431483364039341, 1.0979584701984804]\n",
      "temp/f88\n",
      "0.41892833046149824\n",
      "[0.7534034112683428, 1.0844532496546537]\n",
      "temp/f89\n",
      "0.40982256672334283\n",
      "[0.7137800423182208, 1.1058650911284649]\n",
      "temp/f90\n",
      "0.4257722740268589\n",
      "[0.7361681389452189, 1.1153764091084988]\n",
      "temp/f91\n",
      "0.4112909438538783\n",
      "[0.7506027357562403, 1.0719791519515163]\n",
      "temp/f92\n",
      "0.4177501779037208\n",
      "[0.7615615862034718, 1.0739387696039697]\n",
      "temp/f93\n",
      "0.43371177549640827\n",
      "[0.7294991021195824, 1.137924448873234]\n",
      "temp/f94\n",
      "0.4182844598738399\n",
      "[0.7482751028762021, 1.0882938168714775]\n",
      "temp/f95\n",
      "0.3994460992242125\n",
      "[0.7316700797914009, 1.067222118657024]\n",
      "temp/f96\n",
      "0.4193234029009889\n",
      "[0.7440983404329452, 1.0945484653690325]\n",
      "temp/f97\n",
      "0.4124546002975127\n",
      "[0.7434726343282131, 1.0814365662668122]\n",
      "temp/f98\n",
      "0.435251625344679\n",
      "[0.7683608067736349, 1.102142443915723]\n",
      "temp/f99\n",
      "0.43249564780107175\n",
      "[0.7687742342031259, 1.0962170613990176]\n",
      "temp/f100\n",
      "0.41975855322172617\n",
      "[0.7388502284680284, 1.1006668779754238]\n",
      "temp/f101\n",
      "0.42774091668580705\n",
      "[0.7493334186002157, 1.1061484147713982]\n",
      "temp/f102\n",
      "0.4408246869489577\n",
      "[0.7422643034016256, 1.1393850704962898]\n",
      "temp/f103\n",
      "0.41977788782528713\n",
      "[0.7459415252275282, 1.093614250423046]\n",
      "temp/f104\n",
      "0.4252752886462504\n",
      "[0.7650797306011473, 1.0854708466913534]\n",
      "temp/f105\n",
      "0.40130234328536196\n",
      "[0.7260071511945063, 1.0765975353762176]\n",
      "temp/f106\n",
      "0.4335221159636389\n",
      "[0.7452649146972885, 1.1217793172299892]\n",
      "temp/f107\n",
      "0.40843464696645393\n",
      "[0.7530190984465841, 1.0638501954863238]\n",
      "temp/f108\n",
      "0.41935629212783554\n",
      "[0.7670805113528542, 1.0716320729028168]\n",
      "temp/f109\n",
      "0.41646174784983137\n",
      "[0.7609242109246301, 1.0719992847750326]\n",
      "temp/f110\n",
      "0.40153825052207404\n",
      "[0.7222437947100522, 1.080832706334096]\n",
      "temp/f111\n",
      "0.3976722464055681\n",
      "[0.7220981675714867, 1.0732463252396494]\n",
      "temp/f112\n",
      "0.39570138318030357\n",
      "[0.7183183290350142, 1.0730844373255928]\n",
      "temp/f113\n",
      "0.4056451571238612\n",
      "[0.7171027651468915, 1.0941875491008308]\n",
      "temp/f114\n",
      "0.40141286059414105\n",
      "[0.7454365613246751, 1.057389159863607]\n",
      "temp/f115\n",
      "0.40938407509959196\n",
      "[0.7525732935714116, 1.0661948566277724]\n",
      "temp/f116\n",
      "0.4066938318478368\n",
      "[0.7526301304734985, 1.060757533222175]\n",
      "temp/f117\n",
      "0.43750642808768014\n",
      "[0.7600617020001859, 1.1149511541751744]\n",
      "temp/f118\n",
      "0.40184544981610615\n",
      "[0.7230390289847639, 1.0806518706474484]\n",
      "temp/f119\n",
      "0.4144657171198105\n",
      "[0.7238606103473867, 1.1050708238922342]\n",
      "temp/f120\n",
      "0.4358209170964572\n",
      "[0.7668950370408041, 1.1047467971521103]\n",
      "temp/f121\n",
      "0.4041143489360667\n",
      "[0.7185219324362262, 1.0897067654359072]\n",
      "temp/f122\n",
      "0.4306808003215834\n",
      "[0.7405403471628358, 1.120821253480331]\n",
      "temp/f123\n",
      "0.4115497923519037\n",
      "[0.7411460279082754, 1.0819535567955318]\n",
      "temp/f124\n",
      "0.43638849165721794\n",
      "[0.7576689940150437, 1.115107989299392]\n",
      "temp/f125\n",
      "0.4191956174902972\n",
      "[0.7653773241767944, 1.0730139108038]\n",
      "temp/f126\n",
      "0.4234008730516381\n",
      "[0.7398182839910331, 1.106983462112243]\n",
      "temp/f127\n",
      "0.3961089680211949\n",
      "[0.7118944954411277, 1.080323440601262]\n",
      "temp/f128\n",
      "0.4158117267625868\n",
      "[0.7444988726722017, 1.087124580852972]\n",
      "temp/f129\n",
      "0.4193216979765717\n",
      "[0.7234842997865896, 1.1151590961665538]\n",
      "temp/f130\n",
      "0.4127931160168862\n",
      "[0.7463550516763301, 1.0792311803574421]\n",
      "temp/f131\n",
      "0.40316761675318313\n",
      "[0.755772569358293, 1.0505626641480732]\n",
      "temp/f132\n",
      "0.4004894374576161\n",
      "[0.725626004045838, 1.0753528708693942]\n",
      "temp/f133\n",
      "0.4001772002694505\n",
      "[0.7203758266818664, 1.0799785738570344]\n",
      "temp/f134\n",
      "0.41507054740988847\n",
      "[0.7322881019849787, 1.0978529928347982]\n",
      "temp/f135\n",
      "0.399025943649449\n",
      "[0.7468489396154494, 1.0512029476834486]\n",
      "temp/f136\n",
      "0.4335402327947936\n",
      "[0.7517500218221503, 1.1153304437674367]\n",
      "temp/f137\n",
      "0.41543736960611244\n",
      "[0.7470173920797403, 1.0838573471324846]\n",
      "temp/f138\n",
      "0.41526933004138145\n",
      "[0.7332462796357738, 1.097292380446989]\n",
      "temp/f139\n",
      "0.42567120801156133\n",
      "[0.7375780302945878, 1.1137643857285349]\n",
      "temp/f140\n",
      "0.39112778435036377\n",
      "[0.7376392926273353, 1.0446162760733921]\n",
      "temp/f141\n",
      "0.4332852138345217\n",
      "[0.7439923915812523, 1.122578036087791]\n",
      "temp/f142\n",
      "0.41274052837307107\n",
      "[0.7396623029725756, 1.0858187537735664]\n",
      "temp/f143\n",
      "0.38947544397800604\n",
      "[0.6948817095861939, 1.0840691783698182]\n",
      "temp/f144\n",
      "0.4227370478785156\n",
      "[0.7436241042116332, 1.101849991545398]\n",
      "temp/f145\n",
      "0.4368634564914696\n",
      "[0.7726737634243467, 1.1010531495585925]\n",
      "temp/f146\n",
      "0.38608100264388256\n",
      "[0.7113568445901659, 1.0608051606975992]\n",
      "temp/f147\n",
      "0.38950525682027737\n",
      "[0.7169880899628511, 1.0620224236777036]\n",
      "temp/f148\n",
      "0.4227146661889086\n",
      "[0.7726660002269111, 1.072763332150906]\n",
      "temp/f149\n",
      "0.3896256614360366\n",
      "[0.7272188878038345, 1.0520324350682386]\n",
      "temp/f150\n",
      "0.40695667830593907\n",
      "[0.7435390737181267, 1.0703742828937515]\n",
      "temp/f151\n",
      "0.44047730264941165\n",
      "[0.7613833275586789, 1.1195712777401443]\n",
      "temp/f152\n",
      "0.41578355039961523\n",
      "[0.7228015041888507, 1.1087655966103798]\n",
      "temp/f153\n",
      "0.42227649322822314\n",
      "[0.745859263794183, 1.0986937226622633]\n",
      "temp/f154\n",
      "0.4290193989232275\n",
      "[0.7442794867229374, 1.1137593111235176]\n",
      "temp/f155\n",
      "0.41684401484778566\n",
      "[0.71936666000944, 1.1143213696861312]\n",
      "temp/f156\n",
      "0.4045296524638573\n",
      "[0.7092927547270846, 1.09976655020063]\n",
      "temp/f157\n",
      "0.39834637885472146\n",
      "[0.7180267206046343, 1.0786660371048085]\n",
      "temp/f158\n",
      "0.40598111395660674\n",
      "[0.7533136287221484, 1.058648599191065]\n",
      "temp/f159\n",
      "0.41691606904610856\n",
      "[0.7418532912559496, 1.0919788468362674]\n",
      "temp/f160\n",
      "0.41060876090603204\n",
      "[0.724056251400167, 1.097161270411897]\n",
      "temp/f161\n",
      "0.40078501017550006\n",
      "[0.7172304117088205, 1.0843396086421795]\n",
      "temp/f162\n",
      "0.41218032831866924\n",
      "[0.7230515023807333, 1.1013091542566051]\n",
      "temp/f163\n",
      "0.3973537860843783\n",
      "[0.7379991947565165, 1.05670837741224]\n",
      "temp/f164\n",
      "0.39752525238482783\n",
      "[0.7254203894155001, 1.0696301153541554]\n",
      "temp/f165\n",
      "0.39716989426188853\n",
      "[0.7404171958040149, 1.0539225927197622]\n",
      "temp/f166\n",
      "0.42859708594833645\n",
      "[0.754892704336816, 1.1023014675598568]\n",
      "temp/f167\n",
      "0.4372824202648029\n",
      "[0.7529669064110327, 1.1215979341185731]\n",
      "temp/f168\n",
      "0.41630418938742564\n",
      "[0.7413346928809754, 1.0912736858938759]\n",
      "temp/f169\n",
      "0.4245010529390817\n",
      "[0.7415606231107108, 1.1074414827674526]\n",
      "temp/f170\n",
      "0.4127648940981975\n",
      "[0.7459632068278512, 1.0795665813685438]\n",
      "temp/f171\n",
      "0.44944644710378556\n",
      "[0.7558604792753124, 1.1430324149322586]\n",
      "temp/f172\n",
      "0.3908502189674704\n",
      "[0.705049425413208, 1.0766510125217328]\n",
      "temp/f173\n",
      "0.40888018361393996\n",
      "[0.747809394497645, 1.0699509727302348]\n",
      "temp/f174\n",
      "0.4196214637013219\n",
      "[0.7661747362901682, 1.0730681911124755]\n",
      "temp/f175\n",
      "0.39003873378256826\n",
      "[0.7167789624631088, 1.0632985051020276]\n",
      "temp/f176\n",
      "0.38916973245066455\n",
      "[0.7291276408861473, 1.0492118240151818]\n",
      "temp/f177\n",
      "0.4045606882217747\n",
      "[0.7163686829347716, 1.0927526935087777]\n",
      "temp/f178\n",
      "0.42800616189013385\n",
      "[0.7246547630916218, 1.131357560688646]\n",
      "temp/f179\n",
      "0.4175793824585394\n",
      "[0.729743169822369, 1.1054155950947098]\n",
      "temp/f180\n",
      "0.39819516738232796\n",
      "[0.7371767729757467, 1.0592135617889091]\n",
      "temp/f181\n",
      "0.4142065644169771\n",
      "[0.7459533581849875, 1.0824597706489667]\n",
      "temp/f182\n",
      "0.41805286474311487\n",
      "[0.7297292295086537, 1.106376499977576]\n",
      "temp/f183\n",
      "0.4118529144697234\n",
      "[0.759262748859123, 1.0644430800803237]\n",
      "temp/f184\n",
      "0.43771224013041676\n",
      "[0.7432922758507555, 1.132132204410078]\n",
      "temp/f185\n",
      "0.39350411551033415\n",
      "[0.6979423991746547, 1.0890658318460136]\n",
      "temp/f186\n",
      "0.4146065748195118\n",
      "[0.7477616723357758, 1.0814514773032478]\n",
      "temp/f187\n",
      "0.4144844532413957\n",
      "[0.7539963855084337, 1.0749725209743577]\n",
      "temp/f188\n",
      "0.4072230744882551\n",
      "[0.7541975501172417, 1.0602485988592685]\n",
      "temp/f189\n",
      "0.40539521701118153\n",
      "[0.7209539725546201, 1.089836461467743]\n",
      "temp/f190\n",
      "0.43492040614228455\n",
      "[0.7539601194974707, 1.1158806927870983]\n",
      "temp/f191\n",
      "0.40473645699911986\n",
      "[0.731319751411265, 1.0781531625869747]\n",
      "temp/f192\n",
      "0.43571498880304704\n",
      "[0.7562809752760589, 1.1151490023300352]\n",
      "temp/f193\n",
      "0.43569306796952967\n",
      "[0.7560184692693123, 1.115367666669747]\n",
      "temp/f194\n",
      "0.40957632531800314\n",
      "[0.7404630513066961, 1.0786895993293102]\n",
      "temp/f195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.441741692525222\n",
      "[0.7613742949044703, 1.1221090901459736]\n",
      "temp/f196\n",
      "0.4110993723362154\n",
      "[0.7267140962337406, 1.0954846484386902]\n",
      "temp/f197\n",
      "0.42590802269637384\n",
      "[0.7515308381788095, 1.1002852072139382]\n",
      "temp/f198\n",
      "0.44582948021751456\n",
      "[0.7587313263980993, 1.1329276340369299]\n",
      "temp/f199\n",
      "0.4147335592741149\n",
      "[0.7402577317110669, 1.0892093868371628]\n",
      "<<<<<<<< 0.5 1.5\n",
      "temp/f0\n",
      "0.9739019275312764\n",
      "[1.1636708669220808, 1.7841329881404717]\n",
      "temp/f1\n",
      "0.9987185131740287\n",
      "[1.1555628408883352, 1.8418741854597223]\n",
      "temp/f2\n",
      "0.9643064962975596\n",
      "[1.1493534876991058, 1.7792595048960131]\n",
      "temp/f3\n",
      "0.9945027011349379\n",
      "[1.1455962975106269, 1.8434091047592487]\n",
      "temp/f4\n",
      "0.9846114799724205\n",
      "[1.1469187417785425, 1.8223042181662985]\n",
      "temp/f5\n",
      "1.0013188092022172\n",
      "[1.1738064991294492, 1.8288311192749847]\n",
      "temp/f6\n",
      "0.9805958446628317\n",
      "[1.1418965377478485, 1.8192951515778146]\n",
      "temp/f7\n",
      "1.025365716351726\n",
      "[1.1792878364489476, 1.8714435962545042]\n",
      "temp/f8\n",
      "0.9936737641973812\n",
      "[1.1687808552979282, 1.818566673096834]\n",
      "temp/f9\n",
      "1.0184849265681861\n",
      "[1.1590072218844463, 1.8779626312519255]\n",
      "temp/f10\n",
      "0.9769896471196462\n",
      "[1.164977873337772, 1.7890014209015204]\n",
      "temp/f11\n",
      "1.027294661231695\n",
      "[1.1520422384216895, 1.9025470840417007]\n",
      "temp/f12\n",
      "0.9845174057176957\n",
      "[1.1481790012631825, 1.820855810172209]\n",
      "temp/f13\n",
      "1.0161804180917153\n",
      "[1.202744942226566, 1.8296158939568647]\n",
      "temp/f14\n",
      "0.9576560483751372\n",
      "[1.1331100284623252, 1.782202068287949]\n",
      "temp/f15\n",
      "0.9993396417805775\n",
      "[1.139883405364545, 1.85879587819661]\n",
      "temp/f16\n",
      "0.9798277998403448\n",
      "[1.16254953964216, 1.7971060600385298]\n",
      "temp/f17\n",
      "0.9760854060648807\n",
      "[1.1496210133508582, 1.802549798778903]\n",
      "temp/f18\n",
      "0.9669999422267272\n",
      "[1.1417951130986992, 1.7922047713547553]\n",
      "temp/f19\n",
      "1.015506999618828\n",
      "[1.1562737874115026, 1.8747402118261531]\n",
      "temp/f20\n",
      "0.956315780169888\n",
      "[1.138376615869867, 1.7742549444699092]\n",
      "temp/f21\n",
      "0.9844215158939702\n",
      "[1.174229175688814, 1.7946138560991265]\n",
      "temp/f22\n",
      "0.9879847044350086\n",
      "[1.132435595722987, 1.8435338131470302]\n",
      "temp/f23\n",
      "0.9753645774963214\n",
      "[1.1451701805356658, 1.8055589744569769]\n",
      "temp/f24\n",
      "1.0002507566517806\n",
      "[1.1630085163278432, 1.8374929969757177]\n",
      "temp/f25\n",
      "0.9752896034283184\n",
      "[1.1454571809018095, 1.8051220259548273]\n",
      "temp/f26\n",
      "0.9546323129924256\n",
      "[1.107096025210026, 1.802168600774825]\n",
      "temp/f27\n",
      "0.9713764105078907\n",
      "[1.158401505100903, 1.7843513159148785]\n",
      "temp/f28\n",
      "0.9761014331750222\n",
      "[1.1499405876085331, 1.802262278741511]\n",
      "temp/f29\n",
      "1.008516347382141\n",
      "[1.1842332841527297, 1.8327994106115524]\n",
      "temp/f30\n",
      "0.9904494638293847\n",
      "[1.1795737754644096, 1.8013251521943598]\n",
      "temp/f31\n",
      "1.0320876927005047\n",
      "[1.1956062289707357, 1.8685691564302738]\n",
      "temp/f32\n",
      "0.9560278561458717\n",
      "[1.1270768150293449, 1.7849788972623986]\n",
      "temp/f33\n",
      "0.9973881706517692\n",
      "[1.158831005797936, 1.8359453355056021]\n",
      "temp/f34\n",
      "0.9852543238836701\n",
      "[1.1540459570738997, 1.8164626906934405]\n",
      "temp/f35\n",
      "0.9842780451449752\n",
      "[1.1393670711835515, 1.8291890191063986]\n",
      "temp/f36\n",
      "0.9877484199787169\n",
      "[1.1563770227302945, 1.819119817227139]\n",
      "temp/f37\n",
      "0.9854081027249707\n",
      "[1.1316240158451252, 1.839192189604816]\n",
      "temp/f38\n",
      "1.020923907954409\n",
      "[1.1855302039346614, 1.8563176119741567]\n",
      "temp/f39\n",
      "0.9893717662125694\n",
      "[1.1423665783044832, 1.8363769541206556]\n",
      "temp/f40\n",
      "1.0025203532541311\n",
      "[1.1233656065131015, 1.8816750999951608]\n",
      "temp/f41\n",
      "0.9902057643944646\n",
      "[1.1635380209148065, 1.8168735078741225]\n",
      "temp/f42\n",
      "1.0011354751800128\n",
      "[1.1862592138820185, 1.8160117364780066]\n",
      "temp/f43\n",
      "1.0064345228379976\n",
      "[1.1780339108093731, 1.834835134866622]\n",
      "temp/f44\n",
      "0.9700673556092415\n",
      "[1.1244538780258013, 1.8156808331926815]\n",
      "temp/f45\n",
      "0.9828047938537752\n",
      "[1.1817690869443525, 1.7838405007631977]\n",
      "temp/f46\n",
      "0.9891562284914053\n",
      "[1.1664727376306467, 1.8118397193521636]\n",
      "temp/f47\n",
      "0.9913326486775863\n",
      "[1.1580721627929695, 1.8245931345622028]\n",
      "temp/f48\n",
      "0.9665195510409756\n",
      "[1.1230456119782775, 1.8099934901036738]\n",
      "temp/f49\n",
      "0.9706587550649524\n",
      "[1.1243379218770577, 1.816979588252847]\n",
      "temp/f50\n",
      "0.9812942738359479\n",
      "[1.1764620130997203, 1.7861265345721753]\n",
      "temp/f51\n",
      "1.0199639669233989\n",
      "[1.181571482450398, 1.8583564513963997]\n",
      "temp/f52\n",
      "1.0088223643010865\n",
      "[1.1953532043848374, 1.8222915242173356]\n",
      "temp/f53\n",
      "0.9612694179683942\n",
      "[1.1584108370369899, 1.7641279988997984]\n",
      "temp/f54\n",
      "1.0141076381573428\n",
      "[1.1671118512468326, 1.8611034250678529]\n",
      "temp/f55\n",
      "1.0041179307415917\n",
      "[1.1643210054494837, 1.8439148560336998]\n",
      "temp/f56\n",
      "1.0327368428637622\n",
      "[1.1664796176074643, 1.89899406812006]\n",
      "temp/f57\n",
      "0.9790839058200548\n",
      "[1.1316856298453852, 1.8264821817947243]\n",
      "temp/f58\n",
      "0.9993345239505702\n",
      "[1.1462898474594299, 1.8523792004417103]\n",
      "temp/f59\n",
      "0.9700152238103618\n",
      "[1.142573117460982, 1.7974573301597416]\n",
      "temp/f60\n",
      "0.9750380436234508\n",
      "[1.15206503342444, 1.7980110538224614]\n",
      "temp/f61\n",
      "1.0084770678943054\n",
      "[1.1610588026650084, 1.8558953331236023]\n",
      "temp/f62\n",
      "0.9569914438285665\n",
      "[1.1425101105979907, 1.7714727770591423]\n",
      "temp/f63\n",
      "0.9689526258439484\n",
      "[1.1309854357727342, 1.8069198159151623]\n",
      "temp/f64\n",
      "0.9641545237128947\n",
      "[1.1252109153213432, 1.8030981321044461]\n",
      "temp/f65\n",
      "0.997996424550684\n",
      "[1.143792259451195, 1.852200589650173]\n",
      "temp/f66\n",
      "0.9673543414021992\n",
      "[1.151883759558573, 1.7828249232458253]\n",
      "temp/f67\n",
      "0.9682206807214859\n",
      "[1.165515014164481, 1.7709263472784906]\n",
      "temp/f68\n",
      "1.018258150012941\n",
      "[1.2079525840195422, 1.8285637160063402]\n",
      "temp/f69\n",
      "0.9989741848572925\n",
      "[1.1638035951924186, 1.8341447745221664]\n",
      "temp/f70\n",
      "0.934759902458578\n",
      "[1.103615206822994, 1.7659045980941617]\n",
      "temp/f71\n",
      "0.9859735262018424\n",
      "[1.145460179582519, 1.8264868728211656]\n",
      "temp/f72\n",
      "0.977130453022659\n",
      "[1.1485340975256972, 1.8057268085196208]\n",
      "temp/f73\n",
      "0.9643666097323111\n",
      "[1.1381702215802207, 1.7905629978844013]\n",
      "temp/f74\n",
      "0.9622318366940028\n",
      "[1.1252441740598893, 1.7992194993281163]\n",
      "temp/f75\n",
      "0.9659522836247596\n",
      "[1.133694756487288, 1.7982098107622313]\n",
      "temp/f76\n",
      "0.9891609129626036\n",
      "[1.1562452758809838, 1.8220765500442233]\n",
      "temp/f77\n",
      "0.9879702218629048\n",
      "[1.1403199510422533, 1.8356204926835562]\n",
      "temp/f78\n",
      "0.9459277174428807\n",
      "[1.1583743564119326, 1.7334810784738288]\n",
      "temp/f79\n",
      "0.9737911410330201\n",
      "[1.1644037610085807, 1.7831785210574593]\n",
      "temp/f80\n",
      "1.0101836553998278\n",
      "[1.1593927354196574, 1.8609745753799982]\n",
      "temp/f81\n",
      "0.9771768798067815\n",
      "[1.1339136380359462, 1.8204401215776165]\n",
      "temp/f82\n",
      "0.9798547485671579\n",
      "[1.1594886017114967, 1.8002208954228192]\n",
      "temp/f83\n",
      "0.9696109758988061\n",
      "[1.1370446749627756, 1.8021772768348365]\n",
      "temp/f84\n",
      "0.9414199165579019\n",
      "[1.101095794662052, 1.7817440384537517]\n",
      "temp/f85\n",
      "1.0249270720233026\n",
      "[1.1928668167099945, 1.8569873273366106]\n",
      "temp/f86\n",
      "1.0005514824165262\n",
      "[1.1883575014952157, 1.8127454633378366]\n",
      "temp/f87\n",
      "0.9909885669753644\n",
      "[1.1612819102409138, 1.820695223709815]\n",
      "temp/f88\n",
      "0.9930611180657047\n",
      "[1.177108174194171, 1.8090140619372386]\n",
      "temp/f89\n",
      "0.9730791361388416\n",
      "[1.1047681000553704, 1.8413901722223127]\n",
      "temp/f90\n",
      "0.9943692624394533\n",
      "[1.1458139558714306, 1.842924569007476]\n",
      "temp/f91\n",
      "0.9808581066957525\n",
      "[1.1742740158368077, 1.7874421975546972]\n",
      "temp/f92\n",
      "0.9930364161798318\n",
      "[1.1834922958539296, 1.802580536505734]\n",
      "temp/f93\n",
      "1.007788202337113\n",
      "[1.1273858228531628, 1.888190581821063]\n",
      "temp/f94\n",
      "0.9918066109414525\n",
      "[1.162503560499794, 1.821109661383111]\n",
      "temp/f95\n",
      "0.9689737932384386\n",
      "[1.1509606745700987, 1.7869869119067783]\n",
      "temp/f96\n",
      "0.9963285522555653\n",
      "[1.1665018536841587, 1.8261552508269716]\n",
      "temp/f97\n",
      "0.9832311195419255\n",
      "[1.1573753014532127, 1.8090869376306384]\n",
      "temp/f98\n",
      "1.017239861623262\n",
      "[1.1995881243884974, 1.8348915988580266]\n",
      "temp/f99\n",
      "1.012828948431168\n",
      "[1.1918589560860302, 1.8337989407763056]\n",
      "temp/f100\n",
      "0.9812638594377258\n",
      "[1.1390815642762249, 1.8234461545992264]\n",
      "temp/f101\n",
      "1.0026547149994243\n",
      "[1.1671649461038012, 1.8381444838950474]\n",
      "temp/f102\n",
      "1.018368048561653\n",
      "[1.1501602797674275, 1.8865758173558782]\n",
      "temp/f103\n",
      "0.9877456846771677\n",
      "[1.1602154590658287, 1.8152759102885068]\n",
      "temp/f104\n",
      "1.005627539034172\n",
      "[1.1949465937709542, 1.8163084842973896]\n",
      "temp/f105\n",
      "0.9638443032849034\n",
      "[1.1348684463375056, 1.792820160232301]\n",
      "temp/f106\n",
      "1.0130473215937794\n",
      "[1.1672221958535196, 1.8588724473340392]\n",
      "temp/f107\n",
      "0.9800521308973715\n",
      "[1.1763539221213362, 1.7837503396734067]\n",
      "temp/f108\n",
      "0.9907606375029133\n",
      "[1.187466181720246, 1.7940550932855805]\n",
      "temp/f109\n",
      "0.989359799148464\n",
      "[1.1928749693731848, 1.7858446289237428]\n",
      "temp/f110\n",
      "0.9685976418223127\n",
      "[1.1308418318207005, 1.8063534518239246]\n",
      "temp/f111\n",
      "0.9660242245756944\n",
      "[1.137675445917489, 1.7943730032338996]\n",
      "temp/f112\n",
      "0.9583997238767776\n",
      "[1.1287030572631178, 1.7880963904904374]\n",
      "temp/f113\n",
      "0.9810070554813263\n",
      "[1.1311364709310232, 1.8308776400316291]\n",
      "temp/f114\n",
      "0.9646853070315647\n",
      "[1.1654738475910653, 1.763896766472064]\n",
      "temp/f115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795197097993853\n",
      "[1.1694655272373546, 1.7895738923614157]\n",
      "temp/f116\n",
      "0.9766054977864868\n",
      "[1.1743369834981636, 1.7788740120748099]\n",
      "temp/f117\n",
      "1.017779182536984\n",
      "[1.1867332134070494, 1.8488251516669185]\n",
      "temp/f118\n",
      "0.9656144871082822\n",
      "[1.1344642679390677, 1.7967647062774967]\n",
      "temp/f119\n",
      "0.9873131693479861\n",
      "[1.1336990285189041, 1.8409273101770678]\n",
      "temp/f120\n",
      "1.016013844103501\n",
      "[1.1888256980859353, 1.8432019901210668]\n",
      "temp/f121\n",
      "0.9631738306347597\n",
      "[1.1186218893300761, 1.807725771939443]\n",
      "temp/f122\n",
      "1.0006723333431802\n",
      "[1.141321464317772, 1.8600232023685883]\n",
      "temp/f123\n",
      "0.9868097794220315\n",
      "[1.1541456042914628, 1.8194739545526002]\n",
      "temp/f124\n",
      "1.0146275651474261\n",
      "[1.1746816301580871, 1.8545735001367651]\n",
      "temp/f125\n",
      "0.9924903904674408\n",
      "[1.185095832477471, 1.7998849484574106]\n",
      "temp/f126\n",
      "0.9977536172025151\n",
      "[1.1575671925800028, 1.8379400418250271]\n",
      "temp/f127\n",
      "0.9592827284128542\n",
      "[1.1164950612687192, 1.8020703955569892]\n",
      "temp/f128\n",
      "0.9830342979031951\n",
      "[1.1682257065692414, 1.7978428892371485]\n",
      "temp/f129\n",
      "0.9903877923093006\n",
      "[1.1218643113530389, 1.8589112732655624]\n",
      "temp/f130\n",
      "0.9757758634926976\n",
      "[1.1574026586835446, 1.7941490683018504]\n",
      "temp/f131\n",
      "0.9711912028525606\n",
      "[1.182885816946341, 1.7594965887587801]\n",
      "temp/f132\n",
      "0.9664016799467355\n",
      "[1.1371178469102396, 1.7956855129832314]\n",
      "temp/f133\n",
      "0.968511291608368\n",
      "[1.1288431782839135, 1.8081794049328224]\n",
      "temp/f134\n",
      "0.9845040724490904\n",
      "[1.1431403491686511, 1.8258677957295297]\n",
      "temp/f135\n",
      "0.9597736022132349\n",
      "[1.1664801383759564, 1.7530670660505132]\n",
      "temp/f136\n",
      "1.0123928293661941\n",
      "[1.170491641228966, 1.8542940175034222]\n",
      "temp/f137\n",
      "0.9857081206611126\n",
      "[1.1657405969977832, 1.805675644324442]\n",
      "temp/f138\n",
      "0.9940595369114097\n",
      "[1.1546683643569016, 1.8334507094659176]\n",
      "temp/f139\n",
      "0.997472974606867\n",
      "[1.1523085224850118, 1.8426374267287222]\n",
      "temp/f140\n",
      "0.9505568664656208\n",
      "[1.1485835925734105, 1.7525301403578308]\n",
      "temp/f141\n",
      "1.0148405782391252\n",
      "[1.1639062964276856, 1.8657748600505648]\n",
      "temp/f142\n",
      "0.9755748764033152\n",
      "[1.1495980212549626, 1.8015517315516678]\n",
      "temp/f143\n",
      "0.9521602583237813\n",
      "[1.0977399578217422, 1.8065805588258201]\n",
      "temp/f144\n",
      "0.9922394997336996\n",
      "[1.150141960097155, 1.8343370393702443]\n",
      "temp/f145\n",
      "1.0159339552022808\n",
      "[1.1982017780644099, 1.833666132340152]\n",
      "temp/f146\n",
      "0.9489739385505476\n",
      "[1.1193972104724648, 1.7785506666286302]\n",
      "temp/f147\n",
      "0.9472878678752438\n",
      "[1.1192871457756985, 1.775288589974789]\n",
      "temp/f148\n",
      "0.9894326830235367\n",
      "[1.195973733686315, 1.7828916323607584]\n",
      "temp/f149\n",
      "0.9420441171536786\n",
      "[1.1320553862388245, 1.7520328480685328]\n",
      "temp/f150\n",
      "0.9678167589305475\n",
      "[1.1560894655275906, 1.7795440523335042]\n",
      "temp/f151\n",
      "1.0254488160416768\n",
      "[1.1831978966480954, 1.867699735435258]\n",
      "temp/f152\n",
      "0.98713857090074\n",
      "[1.122936322405467, 1.8513408193960128]\n",
      "temp/f153\n",
      "0.9994669855387611\n",
      "[1.1638188142012829, 1.8351151568762392]\n",
      "temp/f154\n",
      "1.0039334392785646\n",
      "[1.1535970816583339, 1.854269796898795]\n",
      "temp/f155\n",
      "0.9861252555752207\n",
      "[1.1201217097376122, 1.852128801412829]\n",
      "temp/f156\n",
      "0.9735477600011166\n",
      "[1.118851051142008, 1.828244468860225]\n",
      "temp/f157\n",
      "0.9684450871084055\n",
      "[1.127023248254309, 1.8098669259625018]\n",
      "temp/f158\n",
      "0.9707315182656963\n",
      "[1.1784793800176607, 1.7629836565137316]\n",
      "temp/f159\n",
      "0.9870531138530185\n",
      "[1.157933356353216, 1.8161728713528211]\n",
      "temp/f160\n",
      "0.9799877766630054\n",
      "[1.132119942456366, 1.8278556108696449]\n",
      "temp/f161\n",
      "0.9586279381405227\n",
      "[1.1149488679843735, 1.8023070082966717]\n",
      "temp/f162\n",
      "0.9797011673896938\n",
      "[1.1331767929116936, 1.8262255418676938]\n",
      "temp/f163\n",
      "0.964807200381811\n",
      "[1.155956575912478, 1.773657824851144]\n",
      "temp/f164\n",
      "0.9537327144616694\n",
      "[1.1261643922767537, 1.7813010366465851]\n",
      "temp/f165\n",
      "0.9537347963476054\n",
      "[1.153730557105841, 1.7537390355893698]\n",
      "temp/f166\n",
      "1.0096389787321058\n",
      "[1.179698060908291, 1.8395798965559202]\n",
      "temp/f167\n",
      "1.0219319843174357\n",
      "[1.1696805912113917, 1.8741833774234797]\n",
      "temp/f168\n",
      "0.9887841722711866\n",
      "[1.1645088095621383, 1.8130595349802348]\n",
      "temp/f169\n",
      "0.9945086201188422\n",
      "[1.1472532358215688, 1.8417640044161154]\n",
      "temp/f170\n",
      "0.9799358349858754\n",
      "[1.1545550384926728, 1.805316631479078]\n",
      "temp/f171\n",
      "1.0293626455290106\n",
      "[1.1687509426489417, 1.8899743484090792]\n",
      "temp/f172\n",
      "0.952945535122409\n",
      "[1.112401159889383, 1.7934899103554347]\n",
      "temp/f173\n",
      "0.9827250034368787\n",
      "[1.1611215508392423, 1.8043284560345152]\n",
      "temp/f174\n",
      "0.9900113473809958\n",
      "[1.188296114620929, 1.7917265801410625]\n",
      "temp/f175\n",
      "0.952801254717357\n",
      "[1.1297630731880195, 1.7758394362466945]\n",
      "temp/f176\n",
      "0.9531994777898068\n",
      "[1.1418752722589138, 1.7645236833206996]\n",
      "temp/f177\n",
      "0.977689456403429\n",
      "[1.1320450229200074, 1.8233338898868505]\n",
      "temp/f178\n",
      "1.0077068422906836\n",
      "[1.1325601027634864, 1.8828535818178804]\n",
      "temp/f179\n",
      "0.9857377479105403\n",
      "[1.1359617005618474, 1.8355137952592329]\n",
      "temp/f180\n",
      "0.9609485904478203\n",
      "[1.1423703206305562, 1.7795268602650844]\n",
      "temp/f181\n",
      "0.9837241617024584\n",
      "[1.1637618493416044, 1.803686474063312]\n",
      "temp/f182\n",
      "0.9957616588792221\n",
      "[1.1470034014489756, 1.8445199163094685]\n",
      "temp/f183\n",
      "0.9821125267786854\n",
      "[1.1827086528156034, 1.7815164007417672]\n",
      "temp/f184\n",
      "1.0119462967845376\n",
      "[1.1510292007415612, 1.8728633928275138]\n",
      "temp/f185\n",
      "0.9531305022997605\n",
      "[1.0991524794962289, 1.8071085251032921]\n",
      "temp/f186\n",
      "0.9853684073516543\n",
      "[1.1680391161594477, 1.8026976985438607]\n",
      "temp/f187\n",
      "0.9842245746171833\n",
      "[1.1703884242932028, 1.7980607249411635]\n",
      "temp/f188\n",
      "0.9826586146605808\n",
      "[1.1750808283312457, 1.7902364009899159]\n",
      "temp/f189\n",
      "0.9746964119026615\n",
      "[1.1262472855794126, 1.8231455382259105]\n",
      "temp/f190\n",
      "1.0185251822356745\n",
      "[1.1825948522757694, 1.854455512195579]\n",
      "temp/f191\n",
      "0.9739250027344271\n",
      "[1.1460191888569182, 1.8018308166119357]\n",
      "temp/f192\n",
      "1.0081539407989983\n",
      "[1.1719957719892493, 1.8443121096087476]\n",
      "temp/f193\n",
      "1.019958133755949\n",
      "[1.177270043449616, 1.8626462240622816]\n",
      "temp/f194\n",
      "0.9778772093427077\n",
      "[1.1543635464752742, 1.8013908722101413]\n",
      "temp/f195\n",
      "1.0283319301321499\n",
      "[1.184904760960604, 1.8717590993036957]\n",
      "temp/f196\n",
      "0.989796453016808\n",
      "[1.1448323020273465, 1.8347606040062694]\n",
      "temp/f197\n",
      "1.0101549633418179\n",
      "[1.1713627814364285, 1.848947145247207]\n",
      "temp/f198\n",
      "1.0295865613840383\n",
      "[1.1821110819251748, 1.8770620408429017]\n",
      "temp/f199\n",
      "0.9810716034980349\n",
      "[1.152896425932768, 1.8092467810633017]\n"
     ]
    }
   ],
   "source": [
    "nb_test = 2000\n",
    "metrics_dicts = []\n",
    "shap_dicts = []\n",
    "shap_var = []\n",
    "for m in models:\n",
    "    metrics_dicts.append(defaultdict(list))\n",
    "    shap_dicts.append(defaultdict(list))\n",
    "    shap_var.append(defaultdict(list))\n",
    "#means = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "#variances = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "means = [0, 0.5]\n",
    "variances = [1, 1.5]\n",
    "\n",
    "\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "def get_shap(model, df, samples):\n",
    "    x_train = df[inputs][:(samples * 2)]\n",
    "    explainer_shap = shap.DeepExplainer(model=model, data=x_train)\n",
    "    shap_values = explainer_shap.shap_values(X=x_train.values[:samples],ranked_outputs = True)\n",
    "    #shap.summary_plot(shap_values[0], x_train.values[:samples], feature_names = x_train.columns)\n",
    "    l = []\n",
    "    for f, feat in enumerate(inputs):\n",
    "        tot = 0\n",
    "        for i in shap_values[0]:\n",
    "            for j in i:\n",
    "                tot += np.abs(j[f])\n",
    "        l.append(tot/samples)\n",
    "    return l\n",
    "\n",
    "nshap = 200\n",
    "base_df = gen_data()\n",
    "def norm(a):\n",
    "    return a / np.sum(a)\n",
    "base_shap = norm(get_shap(model, df, nshap))\n",
    "#shap_var.append(base_shap)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# ok at this point we need to check the model on various variances and means\n",
    "for m in means:\n",
    "    for v in variances:\n",
    "        print(\"<<<<<<<<\", m,v)\n",
    "        #t0 = time.time()\n",
    "        perturbed_df = gen_data(mean =m, var = v, SIZE = nb_test)\n",
    "        y_test2 = perturbed_df[target]\n",
    "        x_test2 = perturbed_df[inputs]\n",
    "        #t1 = time.time()\n",
    "        #print(\"Time for gen_data = \", t1 - t0)\n",
    "        for idx, model_name in enumerate(model_names):\n",
    "            print(model_name)\n",
    "            #t0 = time.time()\n",
    "            if type(models[idx]) is list:\n",
    "                keras.backend.clear_session()\n",
    "                model = load_model(model_name)\n",
    "            else:\n",
    "                model = models[idx]\n",
    "            #t1 = time.time()\n",
    "            #print(\"Time to load model = \", t1 - t0)\n",
    "            \n",
    "            y_pred2 = model.predict(x_test2)\n",
    "            metrics_dicts[idx][str(m) + '_' + str(v)].append(mean_squared_error(y_test2, y_pred2))\n",
    "            pred_shap = get_shap(model, x_test2, nshap)\n",
    "            shap_dicts[idx][str(m) + '_' + str(v)].append(mean_absolute_error(base_shap, pred_shap))\n",
    "            shap_var[idx][str(m) + '_' + str(v)].append(pred_shap)\n",
    "            print(mean_absolute_error(base_shap, pred_shap))\n",
    "            print(pred_shap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times =  0\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8710.277034568626\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8791.238213151739\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8717.121951812105\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8711.635839315286\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8755.348512315819\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8831.419035905901\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8706.369718894002\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8830.443720415218\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8769.904544575926\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8836.757425752874\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8721.868399933071\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8809.088579325595\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8728.317625853604\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8783.989876927657\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8653.453392449708\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8775.949024220658\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8719.216579443826\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8694.302710566193\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8706.80855872607\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8778.836951506093\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8721.4918097891\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8696.848580515114\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8783.61173391089\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8727.042938622206\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8757.103156520454\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8721.259972503136\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8621.476946422154\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8730.107368026984\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8720.305532043192\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8823.792329404088\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8814.338365681724\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8820.854800522782\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8641.882993393938\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8779.409684329603\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8753.617294766333\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8681.894001665492\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8755.14648025867\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8788.61928625347\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8791.328632251187\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8828.718759442052\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8803.400924915322\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8780.333279238255\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8805.506121051028\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8794.250251242209\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8631.148071545105\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8726.50113075474\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8731.124585566205\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8756.864803574847\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8702.218681553415\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8683.240584877223\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8727.96195976801\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8844.568442427219\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8786.926450580266\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8706.185898430625\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8805.498907922978\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8742.272277491053\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8850.475820011077\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8754.975789568178\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8769.974800977925\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8724.578409716945\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8727.042918396959\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8817.084663422233\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8713.946954544972\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8739.787105426567\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8690.415833783307\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8792.55259078327\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8668.857796976883\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8704.799350434361\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8851.200302483328\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8751.68961390658\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8599.37702584216\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8768.62214001119\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8748.921718653353\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8713.692641883217\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8708.72755611662\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8680.032049005287\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8753.756686860386\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8717.162652775663\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8660.514710357693\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8711.921484440401\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8798.917235951605\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8733.093994798834\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8695.56841860176\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8717.623651830409\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8590.279059985918\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8781.583326201264\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8738.845232268799\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8714.12428987502\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8751.05117265661\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8671.374080674414\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8742.95167898919\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8717.766978691263\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8790.600599955691\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8772.809877289745\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8778.277281286582\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8733.501147762\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8777.609473600136\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8728.511088386043\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8826.10761468404\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8801.358977907126\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8676.330426987299\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8774.025170210214\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8783.55834064444\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8714.501357063753\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8791.176674728642\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8665.66703650705\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8772.895292779958\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8740.042843983563\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8691.1826334906\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8788.598585535246\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8728.53690510823\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8697.5112147013\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8692.211211792854\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8764.167713488947\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8672.637188622619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8719.418416819542\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8703.10053329106\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8795.322831953135\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8670.783569918287\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8777.885118794897\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8804.042525041572\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8685.01111824159\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8715.565503726388\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8755.597601104526\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8790.608389779998\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8777.3810521763\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8802.899501754044\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8703.930597165581\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8680.98252598507\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8735.831653164762\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8658.28310469446\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8724.723456599968\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8706.87003851252\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8700.967904134512\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8725.148898241856\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8665.047380243514\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8782.414705804276\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8706.603921445501\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8769.516011085616\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8775.665318632788\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8659.499336222021\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8789.588613541686\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8700.794831435585\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8661.998055244054\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8695.531720183295\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8798.248145175396\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8709.432543495192\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8634.834421790085\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8746.341100817204\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8592.688871650553\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8656.457368075484\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8833.169913900549\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8689.345353263012\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8779.54775240557\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8764.960151010007\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8703.787616017651\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8720.546689139424\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8753.628121851823\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8697.999339588812\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8755.021270949577\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8740.688778219333\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8612.215971078884\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8692.4707238612\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8722.72470540501\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8667.123295783684\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8669.09277989632\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8804.89737777018\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8813.588853872472\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8753.896732523488\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8733.578882755934\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8718.423673652753\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8788.594533217627\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8643.540076198227\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8773.681770673888\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8717.382795260715\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8667.327791259548\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8671.964285089072\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8774.10797660401\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8777.78232373429\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8764.099324936784\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8684.382838375695\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8737.967834847517\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8763.798764801408\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8755.932063907965\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8746.740996008775\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8683.60330062611\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8720.48690347567\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8741.025653921746\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8777.865239492156\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8727.908179369457\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8814.254099956968\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8709.0568188482\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8765.146028537478\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8804.123965785426\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8714.783759206766\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8857.21090779662\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8777.046608228731\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8815.709437041485\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8799.137088588559\n",
      "['a --> b', 'a --> c', 'b --> c']\n",
      "-9173.112705213785 -8693.128106700558\n"
     ]
    }
   ],
   "source": [
    "#the number of times to sample\n",
    "times = 1\n",
    "\n",
    "\n",
    "violations = np.zeros(len(models))\n",
    "violation_mean = np.zeros((len(models), times))\n",
    "violation_mean2 = np.zeros((len(models), times))\n",
    "mean = np.zeros((len(models), times))\n",
    "\n",
    "fold = 0\n",
    "\n",
    "from pycausal import prior as p\n",
    "def get_bic(df, prior):\n",
    "\n",
    "    tetrad.run(algoId = 'fges', dfs = df,  scoreId = 'sem-bic', dataType = 'continuous',\n",
    "               structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, priorKnowledge = prior,\n",
    "               completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "               penaltyDiscount = 200\n",
    "               )\n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC #/ len(df)\n",
    "import itertools\n",
    "def get_pairs(lst):\n",
    "    a = set()\n",
    "    for i in itertools.permutations(lst,2):\n",
    "        a.add(i)\n",
    "    return a\n",
    "\n",
    "full_conx = get_pairs(['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "forced_conx = set({('a','b'), ('b','f'),('b','c'),('b','d'),('d','f'),('e','d'),('f','g')})\n",
    "full_conx = get_pairs(['a', 'b', 'c'])\n",
    "forced_conx = set({('a','b'), ('a', 'c'), ('b', 'c')})\n",
    "restricted_conx = full_conx.difference(forced_conx)   \n",
    "prior = p.knowledge(requiredirect =  list(map(list, forced_conx)),\n",
    "                       forbiddirect = list(map(list, restricted_conx))\n",
    "                       )\n",
    "\n",
    "\n",
    "for t in range(times):\n",
    "    print(\"Times = \", t)\n",
    "    df_test = gen_data(SIZE = nb_test)\n",
    "    x_test = df_test[inputs].values\n",
    "    y_test = df_test[target].values\n",
    "    bic_orig = get_bic(df_test,prior)\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        if type(models[idx]) is list:\n",
    "            keras.backend.clear_session()\n",
    "            model = load_model(model_name)\n",
    "        else:\n",
    "            model = models[idx]\n",
    "        test_df = pd.DataFrame(x_test, columns = inputs)\n",
    "        test_targets = pd.DataFrame(model.predict(x_test), columns = target)\n",
    "        test_df = test_df.join(test_targets)\n",
    "       \n",
    "        mean[idx][t] = mean_squared_error(y_test, model.predict(x_test)) \n",
    "        bic_pred = get_bic(test_df,prior)\n",
    "        print(tetrad.getEdges())\n",
    "        print(bic_orig, bic_pred)\n",
    "        violation_mean[idx][t] = bic_pred\n",
    "        violation_mean2[idx][t] = bic_pred\n",
    "        #print(bic_orig - bic_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times =  0\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9239.510616993352 6936.330726005187 -1.3320458585334245\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9324.51609726656 6784.143739765889 -1.3744573309392079\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9209.990622228112 6959.075328912896 -1.3234503417376917\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9252.086567139602 6589.599081192228 -1.4040439263667102\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9294.985693829893 6662.4542065889755 -1.3951293931052342\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9343.88403247673 6729.630546786785 -1.3884690946278142\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9274.514248660384 6517.515960649138 -1.4230136611336586\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9373.555620034864 6296.893700136814 -1.4885999456892853\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9307.672467805332 6092.7651874528065 -1.5276598032980453\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9359.074596736591 6746.538495951794 -1.387240968439212\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9244.443695279939 6607.223021565626 -1.3991420699901553\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9352.579207250295 6425.079332261175 -1.4556363779494137\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9282.478762201057 6734.283084338767 -1.3783915297217557\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9342.146830375956 6686.92443085318 -1.3970767767722474\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9194.711702852135 6699.969553658992 -1.3723512665562358\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9307.534060886126 6943.513374387865 -1.3404646263400726\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9238.874866880697 6866.089785428669 -1.3455802582843575\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9250.033926617012 6803.573283696197 -1.3595846683658737\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9223.392511174276 6844.732453880874 -1.3475168786100225\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9320.04666929137 6520.80827935674 -1.4292778241612047\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9257.823947475237 6742.980461291801 -1.3729572554184222\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9228.580082358072 6613.59094081033 -1.395396262779346\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9292.500010733806 6699.216136095068 -1.3871025836390385\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9256.067134589473 6955.441323606583 -1.330766331558952\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9279.65438889923 6805.094845885239 -1.3636333657436464\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9249.954214326159 7013.053034373218 -1.3189625358583732\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9161.270795892455 6517.233481959048 -1.4056993387228813\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9270.018750432682 6502.8214722766415 -1.4255379437915345\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9237.019382211063 6392.342310700153 -1.4450132569948893\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9355.327754790029 6392.6634100697165 -1.4634475733625403\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9347.636814157495 7014.3764664750415 -1.3326397376636665\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9382.851052121237 6696.01980306605 -1.4012579604117823\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9187.26941388498 6783.293573489886 -1.3543965500461586\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9293.354630623215 7129.916938024767 -1.3034309812307288\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9295.498385102634 6279.809992730539 -1.4802196875165066\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9235.981979384938 6451.741384875337 -1.4315486980052596\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9287.376082789408 6604.872458971472 -1.4061401095147963\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9298.745856833633 6630.526832534043 -1.402414331725109\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9337.672577009647 6125.77187092266 -1.5243258766022596\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9364.697839694676 6648.039475100978 -1.4086405284999355\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9333.57517278373 6915.584645163934 -1.3496436891001973\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9308.966935213422 6566.558898828259 -1.4176324432077387\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9359.793590200514 6662.215846135109 -1.4049069868593835\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9299.12756951691 6813.27527076738 -1.3648542294210797\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9206.22789333102 6534.569402749051 -1.4088499679042388\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9265.030601814611 6536.215275585098 -1.4174916539885904\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9274.357367126544 6826.22496970697 -1.3586363485357948\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9291.244227336227 7130.963069424032 -1.3029438151453896\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9246.218556752705 7075.647615789563 -1.3067663991801166\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9196.279532095175 6995.606038699429 -1.3145793918670812\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9281.075074269313 6766.547419340008 -1.3716116209785707\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9379.34132733048 6546.1763236257775 -1.4327969281058834\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9344.70633270045 6846.719039095255 -1.3648444283081445\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9208.895373953896 6582.491582503179 -1.3989984276519123\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9362.33927971056 6806.376600675073 -1.3755247217413713\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9289.95064580645 6261.642180145357 -1.4836284761309682\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9410.739146434731 6481.635795581944 -1.4519080434678762\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9300.084323283114 6850.828865822851 -1.3575122814232032\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9336.659230561785 6787.983775084822 -1.3754687017420155\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9262.132137645014 6687.82381356901 -1.3849246624668787\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9271.408248906599 6882.098661057405 -1.3471774680257327\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9370.739597670774 6655.573156861279 -1.407953812063565\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9239.298309610067 6801.136264510129 -1.358493338506217\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9236.035492040883 6634.688977798125 -1.392082661741602\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9238.735578319112 6756.124128189894 -1.367460899625946\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9298.919300453057 6405.231673881652 -1.4517693931932043\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9172.10693585849 6930.724894658256 -1.3233979237767384\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9283.162804346364 6306.183323685572 -1.4720730952237737\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9356.381126251777 6035.735317172911 -1.5501642525030785\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9277.745164594697 6889.840406520153 -1.34658346451897\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9120.63754125586 6717.452990552557 -1.3577523436461925\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9306.3702710547 6823.903278635435 -1.363789885503137\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9284.180924883065 6888.160580022525 -1.34784617998158\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9254.0395830108 6513.917842015457 -1.4206564785513978\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9244.569919150425 6893.7011651959 -1.3410169222047674\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9216.889567328642 7061.079201767149 -1.3053089058995355\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9284.623466103296 6632.049898478311 -1.3999628483244078\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9253.85725374944 6450.95658229605 -1.4344938050188782\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9188.96864012879 6528.553456692905 -1.4075045415624954\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9224.470487548164 6807.890159104487 -1.3549675849590317\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9308.804222139497 6490.918216868584 -1.4341274856841975\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9290.722660986525 6757.835806309593 -1.3748073980004145\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9252.807465868715 6457.104276361879 -1.4329654702559669\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9254.172916824184 6572.634424940285 -1.4079853402021918\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9151.587709033804 6343.912827782015 -1.4425777840067546\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9352.107293480265 6286.964927337006 -1.4875392819220916\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9300.929230796428 6564.627791820268 -1.4168250700193052\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9234.674926241609 7015.2416104287495 -1.316373040169206\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9314.178664723895 6480.759065434884 -1.4372048969388553\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9171.35229076 6500.117678256333 -1.4109517311416166\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9278.602277528058 6822.184917163061 -1.3600631454866037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9257.19845789225 6863.848276810652 -1.34868926068303\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9325.570063734516 6436.662460086769 -1.4488207392513797\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9305.551334609623 6141.1460718934995 -1.5152792696462343\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9308.706198242464 6206.411115819344 -1.4998533008095079\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9259.766241566336 6957.548573115019 -1.3308949473019018\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9313.7141750185 6896.728334946719 -1.350453972186285\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9262.300217922726 6758.324194627817 -1.3705025019790138\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9372.283831412275 6702.651127660679 -1.3982950407092627\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9343.097384732206 6904.708618069904 -1.3531486846933611\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9185.174403221768 6465.78652248 -1.420581142183879\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9287.35743144132 6453.684435330102 -1.4390783318438278\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9323.450634565492 6510.974586399691 -1.431959303610335\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9242.203944969622 6703.3860457603705 -1.378736638749152\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9350.938745759191 6748.212027413178 -1.3856913072341221\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9175.209583573316 6376.1824221793895 -1.4389816627042509\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9316.09683842786 6424.187067395894 -1.4501596452116128\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9264.564665392712 7267.307787449767 -1.274827616547643\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9251.39093468526 6740.61473059224 -1.3724847516796763\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9312.340519208428 7075.405348037155 -1.316156468942354\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9268.516713336214 6745.868917068875 -1.3739544641735266\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9230.795341257093 6511.153481562828 -1.41768971771212\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9206.867665928989 6889.452885212099 -1.3363713809105386\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9255.354708398188 6582.349609003143 -1.4060867711643557\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9222.970883468675 7093.704976342808 -1.3001627378396585\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9266.81288958266 6878.808298810572 -1.3471538218596675\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9227.1285242161 7010.729155279867 -1.3161439159672905\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9343.699305442631 6990.821658437802 -1.336566681566672\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9226.10410798604 6872.391788826837 -1.3424880873331289\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9326.354405012775 6390.168145040948 -1.4594849765026037\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9359.31459914498 6170.404555631783 -1.5168072878791472\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9204.091307864988 6991.549345266895 -1.3164594646100767\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9248.510060517498 6766.227026878772 -1.3668636928347038\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9304.929471318821 6612.766920011244 -1.407115899270649\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9333.689118140484 7164.866491876285 -1.3027024479413911\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9316.16955435558 6738.040883729365 -1.3826228892216625\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9326.851580849368 6810.285799977544 -1.3695242541627435\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9246.829624733982 7020.075878450347 -1.317197959799714\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9234.765145334815 6340.88447639813 -1.456384386075509\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9251.15690400032 6694.3897713092865 -1.3819268402399851\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9213.559792076492 6303.2059489522635 -1.4617259640085212\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9259.960159023656 6727.011773740649 -1.376533960468234\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9245.07278382071 6941.860238271435 -1.3317860726799633\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9250.152923674315 6813.86989591259 -1.3575476293175437\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9257.816585379056 6535.622997628436 -1.4165163120238753\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9204.735710179024 6750.3549585024475 -1.3635928431563658\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9321.87762887868 6745.653903978025 -1.381908672097958\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9269.092874238833 6886.877716520724 -1.345906411551854\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9321.771337471178 6672.515029075292 -1.3970401410640259\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9293.95623363091 6835.052147286939 -1.3597491333434804\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9214.205891357404 7211.333921528653 -1.27773945730753\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9346.896269629637 6762.094507021294 -1.382248689355711\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9223.468889972079 6264.932965191739 -1.4722374431168066\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9200.245983713321 6971.934062520922 -1.3196117320115162\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9217.050467535562 6456.642312338099 -1.4275299794635605\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9321.928122506095 6982.249561795371 -1.3350895066129824\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9242.299914981248 6649.975440295756 -1.3898246689720404\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9161.537955688575 6692.851009826958 -1.368854310702106\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9270.398153046954 6825.115470483013 -1.3582771153307518\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9135.520748336972 6512.438285297046 -1.4027803947043902\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9209.951295045954 6931.829946581469 -1.3286464564220841\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9352.92863794927 6867.8387377523 -1.3618445329149191\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9254.071059619928 6249.642915823313 -1.4807359691206963\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9329.608359764294 6418.380216328688 -1.453576766304572\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9303.247240724033 6946.540209182996 -1.33926342619101\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9279.509268995782 6655.409312460208 -1.3942807772352563\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9288.404040796224 6176.107096189903 -1.5039253523512124\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9259.577233822405 6280.020958220884 -1.4744500528618656\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9250.426509330526 6920.582575604922 -1.336654307390004\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9280.309873149785 6878.583309756443 -1.3491600603261986\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9259.31170080003 6489.14513540881 -1.4268923729684313\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9179.000617941269 6534.831163364921 -1.4046270498004434\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9223.100601069884 6724.03495325532 -1.3716616087197295\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9255.284758983234 6527.177951897391 -1.4179611506214271\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9200.134369948231 6328.970548461905 -1.453654160578151\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9180.52249643923 6937.936842437222 -1.3232352361994422\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9336.311166409552 6670.22072234213 -1.3997004829446291\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9364.270790211265 6342.699731916789 -1.4763856379783795\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9311.53313737185 6735.776604498643 -1.3823993407312425\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9276.762815221678 6034.769277432311 -1.5372191361007224\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9249.153216521301 6349.098652404499 -1.4567663416315806\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9324.328050137246 6449.500149492659 -1.445744295528194\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9198.36491407509 6750.808117475892 -1.3625576011060336\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9285.270184520352 6627.331987685717 -1.401057047055039\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9263.684939101087 6650.844170956903 -1.3928585155481483\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9201.920467694297 6748.412618614395 -1.3635681437605491\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9189.298154333424 6811.667372263601 -1.3490526844794695\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9293.975606067545 6245.236817436221 -1.4881702452210426\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9368.775366606747 6641.916288996824 -1.4105530631464462\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9297.84598961147 6359.452181623388 -1.4620514038110106\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9223.691996532845 6499.846926878462 -1.4190629564506536\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9280.228968472427 6758.817000760248 -1.3730552206737605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9311.346673708684 6474.9464626304525 -1.4380577086541564\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9276.527788960564 6966.831346690191 -1.3315275377475106\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9292.058619091964 6460.865439085041 -1.4382064921023745\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9223.471580279798 6052.569991842479 -1.5238934192766034\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9252.768265463194 6833.705484845663 -1.3539899086933163\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9268.3462182777 7037.8590152492725 -1.3169269515339144\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9312.984555658319 6725.485742692027 -1.384730398957115\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9248.278523964054 6666.418580471401 -1.38729340384595\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9379.174591121018 6942.642085657339 -1.3509517666908484\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9264.619823343932 6710.42898640479 -1.3806300375302216\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9294.890777147846 6642.310260710496 -1.3993460727252474\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9360.819659441551 6490.846913020207 -1.4421568995356169\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9261.919064472419 7235.830473939308 -1.2800077472558686\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9392.20194620973 6527.701368543127 -1.4388222462918692\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9344.03499984791 6629.123154890946 -1.4095431298412235\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9321.558691014041 6914.441491147557 -1.3481289418600586\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9317.41856792619 6640.223662953239 -1.4031784230265323\n",
      "['a --- b', 'a --- c', 'b --- c']\n",
      "-9233.839643997144 7118.325015795657 -1.2971927558108307\n"
     ]
    }
   ],
   "source": [
    "#the number of times to sample\n",
    "times = 1\n",
    "\n",
    "\n",
    "violations = np.zeros(len(models))\n",
    "violation_mean = np.zeros((len(models), times))\n",
    "violation_mean2 = np.zeros((len(models), times))\n",
    "mean = np.zeros((len(models), times))\n",
    "\n",
    "fold = 0\n",
    "\n",
    "from pycausal import prior as p\n",
    "def get_bic(df, prior):\n",
    "\n",
    "    tetrad.run(algoId = 'gfci', dfs = df,  scoreId = 'sem-bic', dataType = 'continuous',\n",
    "        structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, priorKnowledge = prior,\n",
    "        completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "        penaltyDiscount = 200)\n",
    "\n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC #/ len(df)\n",
    "\n",
    "def get_bic2(df, prior):\n",
    "\n",
    "    tetrad.run(algoId = 'fges', dfs = df,  scoreId = 'sem-bic', dataType = 'continuous',\n",
    "               structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, \n",
    "               completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "              penalty = 0\n",
    "              )\n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC\n",
    "import itertools\n",
    "def get_pairs(lst):\n",
    "    a = set()\n",
    "    for i in itertools.permutations(lst,2):\n",
    "        a.add(i)\n",
    "    return a\n",
    "\n",
    "full_conx = get_pairs(['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "forced_conx = set({('a','b'), ('b','f'),('b','c'),('b','d'),('d','f'),('e','d'),('f','g')})\n",
    "full_conx = get_pairs(['a', 'b', 'c'])\n",
    "forced_conx = set({('a','b'), ('a', 'c'), ('b', 'c')})\n",
    "forced_conx = set({})\n",
    "restricted_conx = full_conx.difference(forced_conx)   \n",
    "prior = p.knowledge(requiredirect =  list(map(list, forced_conx)),\n",
    "                       forbiddirect = list(map(list, restricted_conx))\n",
    "                       )\n",
    "\n",
    "\n",
    "for t in range(times):\n",
    "    print(\"Times = \", t)\n",
    "    df_test = gen_data(SIZE = nb_test)\n",
    "    x_test = df_test[inputs].values\n",
    "    y_test = df_test[target].values\n",
    "    bic_orig = get_bic(df_test,prior)\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        if type(models[idx]) is list:\n",
    "            keras.backend.clear_session()\n",
    "            model = load_model(model_name)\n",
    "        else:\n",
    "            model = models[idx]\n",
    "        test_df = pd.DataFrame(x_test, columns = inputs)\n",
    "        test_targets = pd.DataFrame(model.predict(x_test), columns = target)\n",
    "        test_df = test_df.join(test_targets)\n",
    "       \n",
    "        mean[idx][t] = mean_squared_error(y_test, model.predict(x_test)) \n",
    "        bic_pred = get_bic(test_df,prior)\n",
    "        bic_pred2 =  get_bic2(test_df, prior)\n",
    "        print(tetrad.getEdges())\n",
    "        print(bic_pred, bic_pred2, bic_pred / bic_pred2)\n",
    "        violation_mean[idx][t] = bic_pred2\n",
    "        violation_mean2[idx][t] = bic_pred\n",
    "        #print(bic_orig - bic_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/f0\n",
      "Area under surface (rectangular approx) =  7.424379405347262\n",
      "Violations =  0.0\n",
      "Average_violations =  6936.330726005187\n",
      "MSE =  1.047491752947208\n",
      "0.1595857583831346\n",
      "temp/f1\n",
      "Area under surface (rectangular approx) =  7.327546223415439\n",
      "Violations =  0.0\n",
      "Average_violations =  6784.143739765889\n",
      "MSE =  1.0340632062526798\n",
      "0.16644268821239322\n",
      "temp/f2\n",
      "Area under surface (rectangular approx) =  7.471337291126748\n",
      "Violations =  0.0\n",
      "Average_violations =  6959.075328912896\n",
      "MSE =  1.0256533996797492\n",
      "0.15822212358446308\n",
      "temp/f3\n",
      "Area under surface (rectangular approx) =  7.318995626540395\n",
      "Violations =  0.0\n",
      "Average_violations =  6589.599081192228\n",
      "MSE =  1.0533667645371738\n",
      "0.16278568200559063\n",
      "temp/f4\n",
      "Area under surface (rectangular approx) =  7.40012186032943\n",
      "Violations =  0.0\n",
      "Average_violations =  6662.4542065889755\n",
      "MSE =  1.0591327487878688\n",
      "0.16507698883830094\n",
      "temp/f5\n",
      "Area under surface (rectangular approx) =  7.377541728204784\n",
      "Violations =  0.0\n",
      "Average_violations =  6729.630546786785\n",
      "MSE =  1.0308007964699342\n",
      "0.16678253741057908\n",
      "temp/f6\n",
      "Area under surface (rectangular approx) =  7.448902078580323\n",
      "Violations =  0.0\n",
      "Average_violations =  6517.515960649138\n",
      "MSE =  1.051431883092819\n",
      "0.16416015949604995\n",
      "temp/f7\n",
      "Area under surface (rectangular approx) =  7.434899006190271\n",
      "Violations =  0.0\n",
      "Average_violations =  6296.893700136814\n",
      "MSE =  1.044360722587362\n",
      "0.17271867698872223\n",
      "temp/f8\n",
      "Area under surface (rectangular approx) =  7.397245467860298\n",
      "Violations =  0.0\n",
      "Average_violations =  6092.7651874528065\n",
      "MSE =  1.0476873984306787\n",
      "0.16427923524823043\n",
      "temp/f9\n",
      "Area under surface (rectangular approx) =  7.352566967582452\n",
      "Violations =  0.0\n",
      "Average_violations =  6746.538495951794\n",
      "MSE =  1.046454807684187\n",
      "0.17342051105716844\n",
      "temp/f10\n",
      "Area under surface (rectangular approx) =  7.398388497687186\n",
      "Violations =  0.0\n",
      "Average_violations =  6607.223021565626\n",
      "MSE =  1.0347228249431286\n",
      "0.16077004857957028\n",
      "temp/f11\n",
      "Area under surface (rectangular approx) =  7.31192741493821\n",
      "Violations =  0.0\n",
      "Average_violations =  6425.079332261175\n",
      "MSE =  1.0343018118618783\n",
      "0.17147831973968317\n",
      "temp/f12\n",
      "Area under surface (rectangular approx) =  7.321580677141149\n",
      "Violations =  0.0\n",
      "Average_violations =  6734.283084338767\n",
      "MSE =  1.0534070581487553\n",
      "0.16558196231486602\n",
      "temp/f13\n",
      "Area under surface (rectangular approx) =  7.313900578492273\n",
      "Violations =  0.0\n",
      "Average_violations =  6686.92443085318\n",
      "MSE =  1.03635946120931\n",
      "0.16352841695245912\n",
      "temp/f14\n",
      "Area under surface (rectangular approx) =  7.395729264311021\n",
      "Violations =  0.0\n",
      "Average_violations =  6699.969553658992\n",
      "MSE =  1.0666906513819348\n",
      "0.15468995246720046\n",
      "temp/f15\n",
      "Area under surface (rectangular approx) =  7.251846205568965\n",
      "Violations =  0.0\n",
      "Average_violations =  6943.513374387865\n",
      "MSE =  1.0268710530344376\n",
      "0.16621537667896674\n",
      "temp/f16\n",
      "Area under surface (rectangular approx) =  7.33586941507526\n",
      "Violations =  0.0\n",
      "Average_violations =  6866.089785428669\n",
      "MSE =  1.035796424092143\n",
      "0.15845070926832894\n",
      "temp/f17\n",
      "Area under surface (rectangular approx) =  7.401462529928415\n",
      "Violations =  0.0\n",
      "Average_violations =  6803.573283696197\n",
      "MSE =  1.0441065151950293\n",
      "0.16026695498906668\n",
      "temp/f18\n",
      "Area under surface (rectangular approx) =  7.418190967005405\n",
      "Violations =  0.0\n",
      "Average_violations =  6844.732453880874\n",
      "MSE =  1.0482507872773448\n",
      "0.16136275763097416\n",
      "temp/f19\n",
      "Area under surface (rectangular approx) =  7.304273201424442\n",
      "Violations =  0.0\n",
      "Average_violations =  6520.80827935674\n",
      "MSE =  1.0306574949687244\n",
      "0.16776279845800884\n",
      "temp/f20\n",
      "Area under surface (rectangular approx) =  7.5891660778873336\n",
      "Violations =  0.0\n",
      "Average_violations =  6742.980461291801\n",
      "MSE =  1.0282112558889664\n",
      "0.15995919251291346\n",
      "temp/f21\n",
      "Area under surface (rectangular approx) =  7.3500260314697\n",
      "Violations =  0.0\n",
      "Average_violations =  6613.59094081033\n",
      "MSE =  1.0572265229197126\n",
      "0.1587072725389807\n",
      "temp/f22\n",
      "Area under surface (rectangular approx) =  7.4031080033323065\n",
      "Violations =  0.0\n",
      "Average_violations =  6699.216136095068\n",
      "MSE =  1.026549158856944\n",
      "0.16579806452844267\n",
      "temp/f23\n",
      "Area under surface (rectangular approx) =  7.384288701071741\n",
      "Violations =  0.0\n",
      "Average_violations =  6955.441323606583\n",
      "MSE =  1.0352896951939887\n",
      "0.16032175114754763\n",
      "temp/f24\n",
      "Area under surface (rectangular approx) =  7.312754966703189\n",
      "Violations =  0.0\n",
      "Average_violations =  6805.094845885239\n",
      "MSE =  1.0323096958517122\n",
      "0.16366499805943027\n",
      "temp/f25\n",
      "Area under surface (rectangular approx) =  7.268005018904265\n",
      "Violations =  0.0\n",
      "Average_violations =  7013.053034373218\n",
      "MSE =  1.0348064206141463\n",
      "0.16113823028567428\n",
      "temp/f26\n",
      "Area under surface (rectangular approx) =  7.459992058269597\n",
      "Violations =  0.0\n",
      "Average_violations =  6517.233481959048\n",
      "MSE =  1.061365030693008\n",
      "0.1555438248965857\n",
      "temp/f27\n",
      "Area under surface (rectangular approx) =  7.680807602366659\n",
      "Violations =  0.0\n",
      "Average_violations =  6502.8214722766415\n",
      "MSE =  1.050603185237665\n",
      "0.1603795207367326\n",
      "temp/f28\n",
      "Area under surface (rectangular approx) =  7.555240254198192\n",
      "Violations =  0.0\n",
      "Average_violations =  6392.342310700153\n",
      "MSE =  1.0407822389461316\n",
      "0.16019156323277267\n",
      "temp/f29\n",
      "Area under surface (rectangular approx) =  7.457737829869437\n",
      "Violations =  0.0\n",
      "Average_violations =  6392.6634100697165\n",
      "MSE =  1.0497071567508534\n",
      "0.16796556838467674\n",
      "temp/f30\n",
      "Area under surface (rectangular approx) =  7.385127282426373\n",
      "Violations =  0.0\n",
      "Average_violations =  7014.3764664750415\n",
      "MSE =  1.0461981735765449\n",
      "0.16627170745435355\n",
      "temp/f31\n",
      "Area under surface (rectangular approx) =  7.217567275981255\n",
      "Violations =  0.0\n",
      "Average_violations =  6696.01980306605\n",
      "MSE =  1.015702849480072\n",
      "0.16951913982953754\n",
      "temp/f32\n",
      "Area under surface (rectangular approx) =  7.581281827546553\n",
      "Violations =  0.0\n",
      "Average_violations =  6783.293573489886\n",
      "MSE =  1.0373206412424452\n",
      "0.15631741511808825\n",
      "temp/f33\n",
      "Area under surface (rectangular approx) =  7.371819528627492\n",
      "Violations =  0.0\n",
      "Average_violations =  7129.916938024767\n",
      "MSE =  1.0362938938006618\n",
      "0.16367915226136837\n",
      "temp/f34\n",
      "Area under surface (rectangular approx) =  7.455604486088708\n",
      "Violations =  0.0\n",
      "Average_violations =  6279.809992730539\n",
      "MSE =  1.0353103096882446\n",
      "0.16483681345463602\n",
      "temp/f35\n",
      "Area under surface (rectangular approx) =  7.339546475465578\n",
      "Violations =  0.0\n",
      "Average_violations =  6451.741384875337\n",
      "MSE =  1.0515971321025\n",
      "0.1582496289836318\n",
      "temp/f36\n",
      "Area under surface (rectangular approx) =  7.347066601216479\n",
      "Violations =  0.0\n",
      "Average_violations =  6604.872458971472\n",
      "MSE =  1.0482784051339626\n",
      "0.1629673619225887\n",
      "temp/f37\n",
      "Area under surface (rectangular approx) =  7.387600709099926\n",
      "Violations =  0.0\n",
      "Average_violations =  6630.526832534043\n",
      "MSE =  1.0378040467008058\n",
      "0.16647056564191365\n",
      "temp/f38\n",
      "Area under surface (rectangular approx) =  7.300349731372142\n",
      "Violations =  0.0\n",
      "Average_violations =  6125.77187092266\n",
      "MSE =  1.0366816177540692\n",
      "0.16609120006878333\n",
      "temp/f39\n",
      "Area under surface (rectangular approx) =  7.450950545221902\n",
      "Violations =  0.0\n",
      "Average_violations =  6648.039475100978\n",
      "MSE =  1.0489171411304048\n",
      "0.16868618755811632\n",
      "temp/f40\n",
      "Area under surface (rectangular approx) =  7.2984855713623205\n",
      "Violations =  0.0\n",
      "Average_violations =  6915.584645163934\n",
      "MSE =  1.0306788432386562\n",
      "0.17193530929540354\n",
      "temp/f41\n",
      "Area under surface (rectangular approx) =  7.367954107592608\n",
      "Violations =  0.0\n",
      "Average_violations =  6566.558898828259\n",
      "MSE =  1.0321376287368706\n",
      "0.16491025830130815\n",
      "temp/f42\n",
      "Area under surface (rectangular approx) =  7.447453573333607\n",
      "Violations =  0.0\n",
      "Average_violations =  6662.215846135109\n",
      "MSE =  1.0340573763631442\n",
      "0.1673068275801367\n",
      "temp/f43\n",
      "Area under surface (rectangular approx) =  7.2917060493951595\n",
      "Violations =  0.0\n",
      "Average_violations =  6813.27527076738\n",
      "MSE =  1.0464598728759087\n",
      "0.1647871211174062\n",
      "temp/f44\n",
      "Area under surface (rectangular approx) =  7.314804958961863\n",
      "Violations =  0.0\n",
      "Average_violations =  6534.569402749051\n",
      "MSE =  1.0700109630195378\n",
      "0.15793528007673618\n",
      "temp/f45\n",
      "Area under surface (rectangular approx) =  7.389132113808518\n",
      "Violations =  0.0\n",
      "Average_violations =  6536.215275585098\n",
      "MSE =  1.0281300255597297\n",
      "0.15898972443260795\n",
      "temp/f46\n",
      "Area under surface (rectangular approx) =  7.429743916136781\n",
      "Violations =  0.0\n",
      "Average_violations =  6826.22496970697\n",
      "MSE =  1.0351896019264406\n",
      "0.16438046833144776\n",
      "temp/f47\n",
      "Area under surface (rectangular approx) =  7.297527347362799\n",
      "Violations =  0.0\n",
      "Average_violations =  7130.963069424032\n",
      "MSE =  1.041967746860227\n",
      "0.1632694362697188\n",
      "temp/f48\n",
      "Area under surface (rectangular approx) =  7.364451496851879\n",
      "Violations =  0.0\n",
      "Average_violations =  7075.647615789563\n",
      "MSE =  1.0283639452724274\n",
      "0.15975834058030886\n",
      "temp/f49\n",
      "Area under surface (rectangular approx) =  7.3828384552829\n",
      "Violations =  0.0\n",
      "Average_violations =  6995.606038699429\n",
      "MSE =  1.0445960911542966\n",
      "0.15964407346437265\n",
      "temp/f50\n",
      "Area under surface (rectangular approx) =  7.520070148250108\n",
      "Violations =  0.0\n",
      "Average_violations =  6766.547419340008\n",
      "MSE =  1.0319742208612401\n",
      "0.16141991459049004\n",
      "temp/f51\n",
      "Area under surface (rectangular approx) =  7.428529030578575\n",
      "Violations =  0.0\n",
      "Average_violations =  6546.1763236257775\n",
      "MSE =  1.0335212614224594\n",
      "0.17102922700672474\n",
      "temp/f52\n",
      "Area under surface (rectangular approx) =  7.312949964914514\n",
      "Violations =  0.0\n",
      "Average_violations =  6846.719039095255\n",
      "MSE =  1.0564424709000368\n",
      "0.16531965041520066\n",
      "temp/f53\n",
      "Area under surface (rectangular approx) =  7.487478871558898\n",
      "Violations =  0.0\n",
      "Average_violations =  6582.491582503179\n",
      "MSE =  1.0547506095747174\n",
      "0.15814558856087538\n",
      "temp/f54\n",
      "Area under surface (rectangular approx) =  7.28406326190937\n",
      "Violations =  0.0\n",
      "Average_violations =  6806.376600675073\n",
      "MSE =  1.048267627350704\n",
      "0.1696359662528957\n",
      "temp/f55\n",
      "Area under surface (rectangular approx) =  7.290802153487504\n",
      "Violations =  0.0\n",
      "Average_violations =  6261.642180145357\n",
      "MSE =  1.0539594598106619\n",
      "0.1607018258868214\n",
      "temp/f56\n",
      "Area under surface (rectangular approx) =  7.217132940171526\n",
      "Violations =  0.0\n",
      "Average_violations =  6481.635795581944\n",
      "MSE =  1.0514247834559125\n",
      "0.17320692042251604\n",
      "temp/f57\n",
      "Area under surface (rectangular approx) =  7.393435276222496\n",
      "Violations =  0.0\n",
      "Average_violations =  6850.828865822851\n",
      "MSE =  1.0432904893280668\n",
      "0.1666733778534201\n",
      "temp/f58\n",
      "Area under surface (rectangular approx) =  7.453421881642038\n",
      "Violations =  0.0\n",
      "Average_violations =  6787.983775084822\n",
      "MSE =  1.0429791371967487\n",
      "0.16846176881872854\n",
      "temp/f59\n",
      "Area under surface (rectangular approx) =  7.52862085884621\n",
      "Violations =  0.0\n",
      "Average_violations =  6687.82381356901\n",
      "MSE =  1.051133718935636\n",
      "0.16269269969546354\n",
      "temp/f60\n",
      "Area under surface (rectangular approx) =  7.344314250821109\n",
      "Violations =  0.0\n",
      "Average_violations =  6882.098661057405\n",
      "MSE =  1.0507240274615806\n",
      "0.15953451536819419\n",
      "temp/f61\n",
      "Area under surface (rectangular approx) =  7.392379384401926\n",
      "Violations =  0.0\n",
      "Average_violations =  6655.573156861279\n",
      "MSE =  1.0347500648463308\n",
      "0.1713843459484033\n",
      "temp/f62\n",
      "Area under surface (rectangular approx) =  7.41249919885738\n",
      "Violations =  0.0\n",
      "Average_violations =  6801.136264510129\n",
      "MSE =  1.0518645770504322\n",
      "0.1586934561057659\n",
      "temp/f63\n",
      "Area under surface (rectangular approx) =  7.650756289899565\n",
      "Violations =  0.0\n",
      "Average_violations =  6634.688977798125\n",
      "MSE =  1.057959689640282\n",
      "0.1631147786699637\n",
      "temp/f64\n",
      "Area under surface (rectangular approx) =  7.448700152882955\n",
      "Violations =  0.0\n",
      "Average_violations =  6756.124128189894\n",
      "MSE =  1.0416377310714964\n",
      "0.16205149470021984\n",
      "temp/f65\n",
      "Area under surface (rectangular approx) =  7.489598750672412\n",
      "Violations =  0.0\n",
      "Average_violations =  6405.231673881652\n",
      "MSE =  1.022199573080941\n",
      "0.1669601044998989\n",
      "temp/f66\n",
      "Area under surface (rectangular approx) =  7.37067588207678\n",
      "Violations =  0.0\n",
      "Average_violations =  6930.724894658256\n",
      "MSE =  1.062839196313967\n",
      "0.15926438884348515\n",
      "temp/f67\n",
      "Area under surface (rectangular approx) =  7.597853502725849\n",
      "Violations =  0.0\n",
      "Average_violations =  6306.183323685572\n",
      "MSE =  1.0624817720573896\n",
      "0.15916272228209252\n",
      "temp/f68\n",
      "Area under surface (rectangular approx) =  7.558682913595327\n",
      "Violations =  0.0\n",
      "Average_violations =  6035.735317172911\n",
      "MSE =  1.041443942317847\n",
      "0.16748076850276275\n",
      "temp/f69\n",
      "Area under surface (rectangular approx) =  7.314002467968384\n",
      "Violations =  0.0\n",
      "Average_violations =  6889.840406520153\n",
      "MSE =  1.0326754505136988\n",
      "0.16294586004197342\n",
      "temp/f70\n",
      "Area under surface (rectangular approx) =  7.615462592479543\n",
      "Violations =  0.0\n",
      "Average_violations =  6717.452990552557\n",
      "MSE =  1.0439216096468384\n",
      "0.15437538881077448\n",
      "temp/f71\n",
      "Area under surface (rectangular approx) =  7.404061905928113\n",
      "Violations =  0.0\n",
      "Average_violations =  6823.903278635435\n",
      "MSE =  1.0516958385271198\n",
      "0.16596902206454112\n",
      "temp/f72\n",
      "Area under surface (rectangular approx) =  7.320471077740521\n",
      "Violations =  0.0\n",
      "Average_violations =  6888.160580022525\n",
      "MSE =  1.044604667306959\n",
      "0.16254240681161383\n",
      "temp/f73\n",
      "Area under surface (rectangular approx) =  7.515641012947841\n",
      "Violations =  0.0\n",
      "Average_violations =  6513.917842015457\n",
      "MSE =  1.0507059674727575\n",
      "0.15975447085667083\n",
      "temp/f74\n",
      "Area under surface (rectangular approx) =  7.557929071422786\n",
      "Violations =  0.0\n",
      "Average_violations =  6893.7011651959\n",
      "MSE =  1.0406440516434885\n",
      "0.16105954563074235\n",
      "temp/f75\n",
      "Area under surface (rectangular approx) =  7.350595896467958\n",
      "Violations =  0.0\n",
      "Average_violations =  7061.079201767149\n",
      "MSE =  1.0325171090537029\n",
      "0.1583654281361908\n",
      "temp/f76\n",
      "Area under surface (rectangular approx) =  7.359839286767873\n",
      "Violations =  0.0\n",
      "Average_violations =  6632.049898478311\n",
      "MSE =  1.0300998522980718\n",
      "0.16140518548993252\n",
      "temp/f77\n",
      "Area under surface (rectangular approx) =  7.476946219201565\n",
      "Violations =  0.0\n",
      "Average_violations =  6450.95658229605\n",
      "MSE =  1.0394575326516091\n",
      "0.1623580070897772\n",
      "temp/f78\n",
      "Area under surface (rectangular approx) =  7.58182137814097\n",
      "Violations =  0.0\n",
      "Average_violations =  6528.553456692905\n",
      "MSE =  1.0610612201738385\n",
      "0.15492598825913748\n",
      "temp/f79\n",
      "Area under surface (rectangular approx) =  7.307607244996375\n",
      "Violations =  0.0\n",
      "Average_violations =  6807.890159104487\n",
      "MSE =  1.0581147973863365\n",
      "0.15921665137398333\n",
      "temp/f80\n",
      "Area under surface (rectangular approx) =  7.278241481717148\n",
      "Violations =  0.0\n",
      "Average_violations =  6490.918216868584\n",
      "MSE =  1.051448976634746\n",
      "0.16626123868718568\n",
      "temp/f81\n",
      "Area under surface (rectangular approx) =  7.457676611787798\n",
      "Violations =  0.0\n",
      "Average_violations =  6757.835806309593\n",
      "MSE =  1.0347447548352635\n",
      "0.16368932298608885\n",
      "temp/f82\n",
      "Area under surface (rectangular approx) =  7.533224615657011\n",
      "Violations =  0.0\n",
      "Average_violations =  6457.104276361879\n",
      "MSE =  1.0507536990548925\n",
      "0.1596793798392571\n",
      "temp/f83\n",
      "Area under surface (rectangular approx) =  7.3942606750617195\n",
      "Violations =  0.0\n",
      "Average_violations =  6572.634424940285\n",
      "MSE =  1.0434296030463528\n",
      "0.16141696208853173\n",
      "temp/f84\n",
      "Area under surface (rectangular approx) =  7.701456388238036\n",
      "Violations =  0.0\n",
      "Average_violations =  6343.912827782015\n",
      "MSE =  1.0661990328379305\n",
      "0.15457717929998002\n",
      "temp/f85\n",
      "Area under surface (rectangular approx) =  7.262109705698695\n",
      "Violations =  0.0\n",
      "Average_violations =  6286.964927337006\n",
      "MSE =  1.0389671518176737\n",
      "0.1668059820268756\n",
      "temp/f86\n",
      "Area under surface (rectangular approx) =  7.380558215414626\n",
      "Violations =  0.0\n",
      "Average_violations =  6564.627791820268\n",
      "MSE =  1.0420257228257364\n",
      "0.16251911685943524\n",
      "temp/f87\n",
      "Area under surface (rectangular approx) =  7.325390349698358\n",
      "Violations =  0.0\n",
      "Average_violations =  7015.2416104287495\n",
      "MSE =  1.0442396256336117\n",
      "0.16089547116143327\n",
      "temp/f88\n",
      "Area under surface (rectangular approx) =  7.430251462554948\n",
      "Violations =  0.0\n",
      "Average_violations =  6480.759065434884\n",
      "MSE =  1.054977689609136\n",
      "0.1629755505495378\n",
      "temp/f89\n",
      "Area under surface (rectangular approx) =  7.451273235704747\n",
      "Violations =  0.0\n",
      "Average_violations =  6500.117678256333\n",
      "MSE =  1.0504902462369297\n",
      "0.16035192916826962\n",
      "temp/f90\n",
      "Area under surface (rectangular approx) =  7.276339574333688\n",
      "Violations =  0.0\n",
      "Average_violations =  6822.184917163061\n",
      "MSE =  1.0363441543669716\n",
      "0.16088500999722702\n",
      "temp/f91\n",
      "Area under surface (rectangular approx) =  7.447315930171582\n",
      "Violations =  0.0\n",
      "Average_violations =  6863.848276810652\n",
      "MSE =  1.030712803048551\n",
      "0.15928932851211514\n",
      "temp/f92\n",
      "Area under surface (rectangular approx) =  7.629075601342884\n",
      "Violations =  0.0\n",
      "Average_violations =  6436.662460086769\n",
      "MSE =  1.046358120120796\n",
      "0.16595708985278393\n",
      "temp/f93\n",
      "Area under surface (rectangular approx) =  7.428289710442648\n",
      "Violations =  0.0\n",
      "Average_violations =  6141.1460718934995\n",
      "MSE =  1.0658701316293844\n",
      "0.16678840565884342\n",
      "temp/f94\n",
      "Area under surface (rectangular approx) =  7.480862716281695\n",
      "Violations =  0.0\n",
      "Average_violations =  6206.411115819344\n",
      "MSE =  1.0609416364687212\n",
      "0.16364894879984984\n",
      "temp/f95\n",
      "Area under surface (rectangular approx) =  7.501681924087384\n",
      "Violations =  0.0\n",
      "Average_violations =  6957.548573115019\n",
      "MSE =  1.0296992111161336\n",
      "0.1616426991839101\n",
      "temp/f96\n",
      "Area under surface (rectangular approx) =  7.328738010390216\n",
      "Violations =  0.0\n",
      "Average_violations =  6896.728334946719\n",
      "MSE =  1.026683744173622\n",
      "0.16455556051960746\n",
      "temp/f97\n",
      "Area under surface (rectangular approx) =  7.412030572129719\n",
      "Violations =  0.0\n",
      "Average_violations =  6758.324194627817\n",
      "MSE =  1.0331341810063444\n",
      "0.161886290044407\n",
      "temp/f98\n",
      "Area under surface (rectangular approx) =  7.389063618481069\n",
      "Violations =  0.0\n",
      "Average_violations =  6702.651127660679\n",
      "MSE =  1.0347092388143526\n",
      "0.16746938732675412\n",
      "temp/f99\n",
      "Area under surface (rectangular approx) =  7.238808922718874\n",
      "Violations =  0.0\n",
      "Average_violations =  6904.708618069904\n",
      "MSE =  1.0306038889646838\n",
      "0.16687112788459535\n",
      "temp/f100\n",
      "Area under surface (rectangular approx) =  7.387831245117702\n",
      "Violations =  0.0\n",
      "Average_violations =  6465.78652248\n",
      "MSE =  1.040910502950696\n",
      "0.15666209140194542\n",
      "temp/f101\n",
      "Area under surface (rectangular approx) =  7.325154873494116\n",
      "Violations =  0.0\n",
      "Average_violations =  6453.684435330102\n",
      "MSE =  1.0466101166037158\n",
      "0.163957703481858\n",
      "temp/f102\n",
      "Area under surface (rectangular approx) =  7.255798400057717\n",
      "Violations =  0.0\n",
      "Average_violations =  6510.974586399691\n",
      "MSE =  1.0438254337934918\n",
      "0.16626040755122748\n",
      "temp/f103\n",
      "Area under surface (rectangular approx) =  7.328776824600126\n",
      "Violations =  0.0\n",
      "Average_violations =  6703.3860457603705\n",
      "MSE =  1.0563780595745293\n",
      "0.15960171388006858\n",
      "temp/f104\n",
      "Area under surface (rectangular approx) =  7.423279997746649\n",
      "Violations =  0.0\n",
      "Average_violations =  6748.212027413178\n",
      "MSE =  1.0342162905658348\n",
      "0.16658117702087938\n",
      "temp/f105\n",
      "Area under surface (rectangular approx) =  7.4423377312599115\n",
      "Violations =  0.0\n",
      "Average_violations =  6376.1824221793895\n",
      "MSE =  1.044890048774789\n",
      "0.1577139510023331\n",
      "temp/f106\n",
      "Area under surface (rectangular approx) =  7.357818506214437\n",
      "Violations =  0.0\n",
      "Average_violations =  6424.187067395894\n",
      "MSE =  1.0454778621848235\n",
      "0.1664715816391395\n",
      "temp/f107\n",
      "Area under surface (rectangular approx) =  7.369964196674122\n",
      "Violations =  0.0\n",
      "Average_violations =  7267.307787449767\n",
      "MSE =  1.0410395729613067\n",
      "0.16143210998458657\n",
      "temp/f108\n",
      "Area under surface (rectangular approx) =  7.42052450504319\n",
      "Violations =  0.0\n",
      "Average_violations =  6740.61473059224\n",
      "MSE =  1.0362288665990047\n",
      "0.1624443538600532\n",
      "temp/f109\n",
      "Area under surface (rectangular approx) =  7.4212800240088\n",
      "Violations =  0.0\n",
      "Average_violations =  7075.405348037155\n",
      "MSE =  1.043899220023927\n",
      "0.1614376518668999\n",
      "temp/f110\n",
      "Area under surface (rectangular approx) =  7.496082863209704\n",
      "Violations =  0.0\n",
      "Average_violations =  6745.868917068875\n",
      "MSE =  1.0482217070258597\n",
      "0.16215251704643366\n",
      "temp/f111\n",
      "Area under surface (rectangular approx) =  7.4201879094837\n",
      "Violations =  0.0\n",
      "Average_violations =  6511.153481562828\n",
      "MSE =  1.0681508845220178\n",
      "0.16077948989611324\n",
      "temp/f112\n",
      "Area under surface (rectangular approx) =  7.474675226951816\n",
      "Violations =  0.0\n",
      "Average_violations =  6889.452885212099\n",
      "MSE =  1.046962359461706\n",
      "0.15799384520695087\n",
      "temp/f113\n",
      "Area under surface (rectangular approx) =  7.40549913448133\n",
      "Violations =  0.0\n",
      "Average_violations =  6582.349609003143\n",
      "MSE =  1.0532582470290899\n",
      "0.16655799188282208\n",
      "temp/f114\n",
      "Area under surface (rectangular approx) =  7.510252798915369\n",
      "Violations =  0.0\n",
      "Average_violations =  7093.704976342808\n",
      "MSE =  1.023018329411016\n",
      "0.1568986936390346\n",
      "temp/f115\n",
      "Area under surface (rectangular approx) =  7.3591803153457\n",
      "Violations =  0.0\n",
      "Average_violations =  6878.808298810572\n",
      "MSE =  1.0463560984203428\n",
      "0.16184331347561623\n",
      "temp/f116\n",
      "Area under surface (rectangular approx) =  7.375018264656257\n",
      "Violations =  0.0\n",
      "Average_violations =  7010.729155279867\n",
      "MSE =  1.033669850808214\n",
      "0.16054197805631515\n",
      "temp/f117\n",
      "Area under surface (rectangular approx) =  7.221652118218586\n",
      "Violations =  0.0\n",
      "Average_violations =  6990.821658437802\n",
      "MSE =  1.0310001393347183\n",
      "0.1664738368835804\n",
      "temp/f118\n",
      "Area under surface (rectangular approx) =  7.418643565854451\n",
      "Violations =  0.0\n",
      "Average_violations =  6872.391788826837\n",
      "MSE =  1.0349916773550998\n",
      "0.157829973506018\n",
      "temp/f119\n",
      "Area under surface (rectangular approx) =  7.407916630865502\n",
      "Violations =  0.0\n",
      "Average_violations =  6390.168145040948\n",
      "MSE =  1.0413097747284195\n",
      "0.1651210908812382\n",
      "temp/f120\n",
      "Area under surface (rectangular approx) =  7.473783099093856\n",
      "Violations =  0.0\n",
      "Average_violations =  6170.404555631783\n",
      "MSE =  1.0422896821697194\n",
      "0.16830770032825373\n",
      "temp/f121\n",
      "Area under surface (rectangular approx) =  7.428271339744969\n",
      "Violations =  0.0\n",
      "Average_violations =  6991.549345266895\n",
      "MSE =  1.0293330886839942\n",
      "0.15669316510499806\n",
      "temp/f122\n",
      "Area under surface (rectangular approx) =  7.40543387023699\n",
      "Violations =  0.0\n",
      "Average_violations =  6766.227026878772\n",
      "MSE =  1.039416467274334\n",
      "0.16334444631626144\n",
      "temp/f123\n",
      "Area under surface (rectangular approx) =  7.442807202099448\n",
      "Violations =  0.0\n",
      "Average_violations =  6612.766920011244\n",
      "MSE =  1.0346236080443234\n",
      "0.16673366930798791\n",
      "temp/f124\n",
      "Area under surface (rectangular approx) =  7.368133367576087\n",
      "Violations =  0.0\n",
      "Average_violations =  7164.866491876285\n",
      "MSE =  1.0333888069651616\n",
      "0.16677103696910012\n",
      "temp/f125\n",
      "Area under surface (rectangular approx) =  7.349058284898424\n",
      "Violations =  0.0\n",
      "Average_violations =  6738.040883729365\n",
      "MSE =  1.0506966595008167\n",
      "0.16338081951898112\n",
      "temp/f126\n",
      "Area under surface (rectangular approx) =  7.47582200913119\n",
      "Violations =  0.0\n",
      "Average_violations =  6810.285799977544\n",
      "MSE =  1.0352493462479064\n",
      "0.16454900330935415\n",
      "temp/f127\n",
      "Area under surface (rectangular approx) =  7.462238096772429\n",
      "Violations =  0.0\n",
      "Average_violations =  7020.075878450347\n",
      "MSE =  1.0354307355267418\n",
      "0.1589047500076447\n",
      "temp/f128\n",
      "Area under surface (rectangular approx) =  7.433540362301101\n",
      "Violations =  0.0\n",
      "Average_violations =  6340.88447639813\n",
      "MSE =  1.069266168364209\n",
      "0.15724860397069138\n",
      "temp/f129\n",
      "Area under surface (rectangular approx) =  7.391904534957202\n",
      "Violations =  0.0\n",
      "Average_violations =  6694.3897713092865\n",
      "MSE =  1.0407220349619575\n",
      "0.16507241618932922\n",
      "temp/f130\n",
      "Area under surface (rectangular approx) =  7.4595118512771545\n",
      "Violations =  0.0\n",
      "Average_violations =  6303.2059489522635\n",
      "MSE =  1.0508127455861562\n",
      "0.15633583448877297\n",
      "temp/f131\n",
      "Area under surface (rectangular approx) =  7.465712077945611\n",
      "Violations =  0.0\n",
      "Average_violations =  6727.011773740649\n",
      "MSE =  1.0414399105638785\n",
      "0.15896523628824355\n",
      "temp/f132\n",
      "Area under surface (rectangular approx) =  7.51423696437379\n",
      "Violations =  0.0\n",
      "Average_violations =  6941.860238271435\n",
      "MSE =  1.0328931958159797\n",
      "0.16024691132741276\n",
      "temp/f133\n",
      "Area under surface (rectangular approx) =  7.437212094004661\n",
      "Violations =  0.0\n",
      "Average_violations =  6813.86989591259\n",
      "MSE =  1.0395919737838646\n",
      "0.16318836029759434\n",
      "temp/f134\n",
      "Area under surface (rectangular approx) =  7.367491150928512\n",
      "Violations =  0.0\n",
      "Average_violations =  6535.622997628436\n",
      "MSE =  1.0347028908630722\n",
      "0.16201917198491692\n",
      "temp/f135\n",
      "Area under surface (rectangular approx) =  7.415773626983863\n",
      "Violations =  0.0\n",
      "Average_violations =  6750.3549585024475\n",
      "MSE =  1.0584269527449515\n",
      "0.15478336167789564\n",
      "temp/f136\n",
      "Area under surface (rectangular approx) =  7.266621332112761\n",
      "Violations =  0.0\n",
      "Average_violations =  6745.653903978025\n",
      "MSE =  1.0245666551412083\n",
      "0.16629500090443333\n",
      "temp/f137\n",
      "Area under surface (rectangular approx) =  7.318671820969925\n",
      "Violations =  0.0\n",
      "Average_violations =  6886.877716520724\n",
      "MSE =  1.0493449331000815\n",
      "0.1606963386398324\n",
      "temp/f138\n",
      "Area under surface (rectangular approx) =  7.489160159335448\n",
      "Violations =  0.0\n",
      "Average_violations =  6672.515029075292\n",
      "MSE =  1.054202575825545\n",
      "0.16740450203191953\n",
      "temp/f139\n",
      "Area under surface (rectangular approx) =  7.236085554148519\n",
      "Violations =  0.0\n",
      "Average_violations =  6835.052147286939\n",
      "MSE =  1.030629550721349\n",
      "0.16254255111461663\n",
      "temp/f140\n",
      "Area under surface (rectangular approx) =  7.577729420962991\n",
      "Violations =  0.0\n",
      "Average_violations =  7211.333921528653\n",
      "MSE =  1.0440120299511677\n",
      "0.15611238209545564\n",
      "temp/f141\n",
      "Area under surface (rectangular approx) =  7.309016640655067\n",
      "Violations =  0.0\n",
      "Average_violations =  6762.094507021294\n",
      "MSE =  1.0467400368238144\n",
      "0.16875370747647503\n",
      "temp/f142\n",
      "Area under surface (rectangular approx) =  7.530822949734695\n",
      "Violations =  0.0\n",
      "Average_violations =  6264.932965191739\n",
      "MSE =  1.0645065980102528\n",
      "0.15694077290466346\n",
      "temp/f143\n",
      "Area under surface (rectangular approx) =  7.540614475269168\n",
      "Violations =  0.0\n",
      "Average_violations =  6971.934062520922\n",
      "MSE =  1.0431608360148594\n",
      "0.15921807064118038\n",
      "temp/f144\n",
      "Area under surface (rectangular approx) =  7.361566537899759\n",
      "Violations =  0.0\n",
      "Average_violations =  6456.642312338099\n",
      "MSE =  1.0478615347292017\n",
      "0.16161489848627647\n",
      "temp/f145\n",
      "Area under surface (rectangular approx) =  7.2595113448053965\n",
      "Violations =  0.0\n",
      "Average_violations =  6982.249561795371\n",
      "MSE =  1.0284734639181956\n",
      "0.16517444378345242\n",
      "temp/f146\n",
      "Area under surface (rectangular approx) =  7.561366617713299\n",
      "Violations =  0.0\n",
      "Average_violations =  6649.975440295756\n",
      "MSE =  1.0480622595172715\n",
      "0.15911203010443836\n",
      "temp/f147\n",
      "Area under surface (rectangular approx) =  7.507592009263454\n",
      "Violations =  0.0\n",
      "Average_violations =  6692.851009826958\n",
      "MSE =  1.0669779810974838\n",
      "0.1561138744746268\n",
      "temp/f148\n",
      "Area under surface (rectangular approx) =  7.392226861609219\n",
      "Violations =  0.0\n",
      "Average_violations =  6825.115470483013\n",
      "MSE =  1.0317055582756616\n",
      "0.15704877159392847\n",
      "temp/f149\n",
      "Area under surface (rectangular approx) =  7.545357020595502\n",
      "Violations =  0.0\n",
      "Average_violations =  6512.438285297046\n",
      "MSE =  1.050294098856606\n",
      "0.15081664536116599\n",
      "temp/f150\n",
      "Area under surface (rectangular approx) =  7.349596307026863\n",
      "Violations =  0.0\n",
      "Average_violations =  6931.829946581469\n",
      "MSE =  1.044133810515718\n",
      "0.1552215143806383\n",
      "temp/f151\n",
      "Area under surface (rectangular approx) =  7.299465210240474\n",
      "Violations =  0.0\n",
      "Average_violations =  6867.8387377523\n",
      "MSE =  1.0378572781553932\n",
      "0.17134834637650878\n",
      "temp/f152\n",
      "Area under surface (rectangular approx) =  7.353344585688712\n",
      "Violations =  0.0\n",
      "Average_violations =  6249.642915823313\n",
      "MSE =  1.0456435961302593\n",
      "0.16438556073254323\n",
      "temp/f153\n",
      "Area under surface (rectangular approx) =  7.473336005967034\n",
      "Violations =  0.0\n",
      "Average_violations =  6418.380216328688\n",
      "MSE =  1.0472988671471468\n",
      "0.1663000673211423\n",
      "temp/f154\n",
      "Area under surface (rectangular approx) =  7.31907932934649\n",
      "Violations =  0.0\n",
      "Average_violations =  6946.540209182996\n",
      "MSE =  1.0325239386549356\n",
      "0.16494689705854254\n",
      "temp/f155\n",
      "Area under surface (rectangular approx) =  7.290955927506868\n",
      "Violations =  0.0\n",
      "Average_violations =  6655.409312460208\n",
      "MSE =  1.0411538287494162\n",
      "0.1636294612682648\n",
      "temp/f156\n",
      "Area under surface (rectangular approx) =  7.491043902750448\n",
      "Violations =  0.0\n",
      "Average_violations =  6176.107096189903\n",
      "MSE =  1.030299403838032\n",
      "0.16261179411022175\n",
      "temp/f157\n",
      "Area under surface (rectangular approx) =  7.787345937160758\n",
      "Violations =  0.0\n",
      "Average_violations =  6280.020958220884\n",
      "MSE =  1.0657676997184076\n",
      "0.1643592600349334\n",
      "temp/f158\n",
      "Area under surface (rectangular approx) =  7.406199350416561\n",
      "Violations =  0.0\n",
      "Average_violations =  6920.582575604922\n",
      "MSE =  1.045233242404421\n",
      "0.15665823183515368\n",
      "temp/f159\n",
      "Area under surface (rectangular approx) =  7.4462665645984\n",
      "Violations =  0.0\n",
      "Average_violations =  6878.583309756443\n",
      "MSE =  1.0415502987670957\n",
      "0.16210674851485585\n",
      "temp/f160\n",
      "Area under surface (rectangular approx) =  7.448256404526226\n",
      "Violations =  0.0\n",
      "Average_violations =  6489.14513540881\n",
      "MSE =  1.0470171615368005\n",
      "0.1633044328368755\n",
      "temp/f161\n",
      "Area under surface (rectangular approx) =  7.419338182826717\n",
      "Violations =  0.0\n",
      "Average_violations =  6534.831163364921\n",
      "MSE =  1.063150479625907\n",
      "0.1559427822253938\n",
      "temp/f162\n",
      "Area under surface (rectangular approx) =  7.358621915082887\n",
      "Violations =  0.0\n",
      "Average_violations =  6724.03495325532\n",
      "MSE =  1.0448695622378137\n",
      "0.16196331465382835\n",
      "temp/f163\n",
      "Area under surface (rectangular approx) =  7.490674329617493\n",
      "Violations =  0.0\n",
      "Average_violations =  6527.177951897391\n",
      "MSE =  1.0504428441781142\n",
      "0.1596762354276416\n",
      "temp/f164\n",
      "Area under surface (rectangular approx) =  7.559712040574562\n",
      "Violations =  0.0\n",
      "Average_violations =  6328.970548461905\n",
      "MSE =  1.0355340063190528\n",
      "0.15529176420419719\n",
      "temp/f165\n",
      "Area under surface (rectangular approx) =  7.422397163821287\n",
      "Violations =  0.0\n",
      "Average_violations =  6937.936842437222\n",
      "MSE =  1.0404928550799364\n",
      "0.15324510671974564\n",
      "temp/f166\n",
      "Area under surface (rectangular approx) =  7.347360248475158\n",
      "Violations =  0.0\n",
      "Average_violations =  6670.22072234213\n",
      "MSE =  1.0391783901040441\n",
      "0.1685057108453159\n",
      "temp/f167\n",
      "Area under surface (rectangular approx) =  7.298497678641487\n",
      "Violations =  0.0\n",
      "Average_violations =  6342.699731916789\n",
      "MSE =  1.0383673331250356\n",
      "0.17153290166942983\n",
      "temp/f168\n",
      "Area under surface (rectangular approx) =  7.4509542175187224\n",
      "Violations =  0.0\n",
      "Average_violations =  6735.776604498643\n",
      "MSE =  1.0408607759199713\n",
      "0.16235541373684195\n",
      "temp/f169\n",
      "Area under surface (rectangular approx) =  7.358583796645215\n",
      "Violations =  0.0\n",
      "Average_violations =  6034.769277432311\n",
      "MSE =  1.0473445575004252\n",
      "0.16213726221541544\n",
      "temp/f170\n",
      "Area under surface (rectangular approx) =  7.514670305013041\n",
      "Violations =  0.0\n",
      "Average_violations =  6349.098652404499\n",
      "MSE =  1.0402433875260382\n",
      "0.16005377412849253\n",
      "temp/f171\n",
      "Area under surface (rectangular approx) =  7.248977787708794\n",
      "Violations =  0.0\n",
      "Average_violations =  6449.500149492659\n",
      "MSE =  1.0233448679118498\n",
      "0.16761385776893561\n",
      "temp/f172\n",
      "Area under surface (rectangular approx) =  7.430137326803882\n",
      "Violations =  0.0\n",
      "Average_violations =  6750.808117475892\n",
      "MSE =  1.0423030724112163\n",
      "0.15783180476261505\n",
      "temp/f173\n",
      "Area under surface (rectangular approx) =  7.5285044347547245\n",
      "Violations =  0.0\n",
      "Average_violations =  6627.331987685717\n",
      "MSE =  1.0453333592818574\n",
      "0.1660503042996216\n",
      "temp/f174\n",
      "Area under surface (rectangular approx) =  7.271828919271549\n",
      "Violations =  0.0\n",
      "Average_violations =  6650.844170956903\n",
      "MSE =  1.0398830562248418\n",
      "0.16024019935685763\n",
      "temp/f175\n",
      "Area under surface (rectangular approx) =  7.460892085452537\n",
      "Violations =  0.0\n",
      "Average_violations =  6748.412618614395\n",
      "MSE =  1.0553145535425483\n",
      "0.15797937769092288\n",
      "temp/f176\n",
      "Area under surface (rectangular approx) =  7.498991401990004\n",
      "Violations =  0.0\n",
      "Average_violations =  6811.667372263601\n",
      "MSE =  1.0482823635668141\n",
      "0.15799865428309146\n",
      "temp/f177\n",
      "Area under surface (rectangular approx) =  7.713283238978509\n",
      "Violations =  0.0\n",
      "Average_violations =  6245.236817436221\n",
      "MSE =  1.0397371518492855\n",
      "0.1646633293663172\n",
      "temp/f178\n",
      "Area under surface (rectangular approx) =  7.413019083537275\n",
      "Violations =  0.0\n",
      "Average_violations =  6641.916288996824\n",
      "MSE =  1.035979077264929\n",
      "0.17035644704483693\n",
      "temp/f179\n",
      "Area under surface (rectangular approx) =  7.416103957209712\n",
      "Violations =  0.0\n",
      "Average_violations =  6359.452181623388\n",
      "MSE =  1.0367113565254025\n",
      "0.1618421130293855\n",
      "temp/f180\n",
      "Area under surface (rectangular approx) =  7.499704379487801\n",
      "Violations =  0.0\n",
      "Average_violations =  6499.846926878462\n",
      "MSE =  1.0363199859173087\n",
      "0.158446267483794\n",
      "temp/f181\n",
      "Area under surface (rectangular approx) =  7.468789387710666\n",
      "Violations =  0.0\n",
      "Average_violations =  6758.817000760248\n",
      "MSE =  1.053793369395032\n",
      "0.16105731827835545\n",
      "temp/f182\n",
      "Area under surface (rectangular approx) =  7.459977606295746\n",
      "Violations =  0.0\n",
      "Average_violations =  6474.9464626304525\n",
      "MSE =  1.0407302997272325\n",
      "0.1669236488441083\n",
      "temp/f183\n",
      "Area under surface (rectangular approx) =  7.397063122057496\n",
      "Violations =  0.0\n",
      "Average_violations =  6966.831346690191\n",
      "MSE =  1.0330645049430374\n",
      "0.16129250507169426\n",
      "temp/f184\n",
      "Area under surface (rectangular approx) =  7.278844630111412\n",
      "Violations =  0.0\n",
      "Average_violations =  6460.865439085041\n",
      "MSE =  1.0347432657020479\n",
      "0.16501704680577203\n",
      "temp/f185\n",
      "Area under surface (rectangular approx) =  7.59145072027361\n",
      "Violations =  0.0\n",
      "Average_violations =  6052.569991842479\n",
      "MSE =  1.0726164546276518\n",
      "0.15647001361104965\n",
      "temp/f186\n",
      "Area under surface (rectangular approx) =  7.347659394421417\n",
      "Violations =  0.0\n",
      "Average_violations =  6833.705484845663\n",
      "MSE =  1.0332110558395138\n",
      "0.161302737779002\n",
      "temp/f187\n",
      "Area under surface (rectangular approx) =  7.4395227864865525\n",
      "Violations =  0.0\n",
      "Average_violations =  7037.8590152492725\n",
      "MSE =  1.048249958502392\n",
      "0.16156854605360224\n",
      "temp/f188\n",
      "Area under surface (rectangular approx) =  7.416606993355983\n",
      "Violations =  0.0\n",
      "Average_violations =  6725.485742692027\n",
      "MSE =  1.0476888534841782\n",
      "0.16579454265808696\n",
      "temp/f189\n",
      "Area under surface (rectangular approx) =  7.5390246891131465\n",
      "Violations =  0.0\n",
      "Average_violations =  6666.418580471401\n",
      "MSE =  1.033479276533258\n",
      "0.16299617335921662\n",
      "temp/f190\n",
      "Area under surface (rectangular approx) =  7.2952001762474\n",
      "Violations =  0.0\n",
      "Average_violations =  6942.642085657339\n",
      "MSE =  1.050909696486737\n",
      "0.16902511526060995\n",
      "temp/f191\n",
      "Area under surface (rectangular approx) =  7.478622832468268\n",
      "Violations =  0.0\n",
      "Average_violations =  6710.42898640479\n",
      "MSE =  1.0420033704190355\n",
      "0.16142682057207408\n",
      "temp/f192\n",
      "Area under surface (rectangular approx) =  7.258501832158381\n",
      "Violations =  0.0\n",
      "Average_violations =  6642.310260710496\n",
      "MSE =  1.055362125518136\n",
      "0.16197620293632872\n",
      "temp/f193\n",
      "Area under surface (rectangular approx) =  7.330676762873596\n",
      "Violations =  0.0\n",
      "Average_violations =  6490.846913020207\n",
      "MSE =  1.042542197920613\n",
      "0.17080546046056405\n",
      "temp/f194\n",
      "Area under surface (rectangular approx) =  7.444147666936929\n",
      "Violations =  0.0\n",
      "Average_violations =  7235.830473939308\n",
      "MSE =  1.0279833723208496\n",
      "0.16089181534390995\n",
      "temp/f195\n",
      "Area under surface (rectangular approx) =  7.356878726324176\n",
      "Violations =  0.0\n",
      "Average_violations =  6527.701368543127\n",
      "MSE =  1.0350239127370542\n",
      "0.1723549656983435\n",
      "temp/f196\n",
      "Area under surface (rectangular approx) =  7.435209341070481\n",
      "Violations =  0.0\n",
      "Average_violations =  6629.123154890946\n",
      "MSE =  1.049928729864267\n",
      "0.16815034077495333\n",
      "temp/f197\n",
      "Area under surface (rectangular approx) =  7.39018719506725\n",
      "Violations =  0.0\n",
      "Average_violations =  6914.441491147557\n",
      "MSE =  1.0238342747532745\n",
      "0.17118904794190215\n",
      "temp/f198\n",
      "Area under surface (rectangular approx) =  7.185454588152923\n",
      "Violations =  0.0\n",
      "Average_violations =  6640.223662953239\n",
      "MSE =  1.0368726805731967\n",
      "0.16871122902607183\n",
      "temp/f199\n",
      "Area under surface (rectangular approx) =  7.306045390959392\n",
      "Violations =  0.0\n",
      "Average_violations =  7118.325015795657\n",
      "MSE =  1.0371430840593647\n",
      "0.1591540344065576\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MSE = []\n",
    "SHAP = []\n",
    "SHAP_VAR = []\n",
    "VIO = []\n",
    "AUS = []\n",
    "for i, m in enumerate(models):\n",
    "    print(model_names[i])\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    \n",
    "    rectangular_approx = 0\n",
    "    for k, v in metrics_dicts[i].items():\n",
    "        x.append(float(k.split('_')[0]))\n",
    "        y.append(float(k.split('_')[-1]))\n",
    "        z.append(np.mean(v))\n",
    "        rectangular_approx += np.mean(v)\n",
    "        \n",
    "\n",
    "    print(\"Area under surface (rectangular approx) = \", rectangular_approx)\n",
    "    print(\"Violations = \", violations[i])\n",
    "    print(\"Average_violations = \", np.mean(violation_mean[i]))\n",
    "    print(\"MSE = \", np.mean(mean[i]))   \n",
    "    MSE.append(np.mean(mean[i]))\n",
    "    VIO.append(np.mean(violation_mean[i]))\n",
    "\n",
    "    AUS.append(rectangular_approx)\n",
    "    total_shap = []\n",
    "    for k, v in shap_dicts[i].items():\n",
    "        total_shap.append(np.mean(v))\n",
    "    SHAP.append(np.sum(total_shap))\n",
    "\n",
    "    var_l = []\n",
    "    for k,v in shap_var[i].items():\n",
    "        var_l.append(v)\n",
    "    print(np.sum(np.var(var_l, axis = 0)))\n",
    "    \n",
    "    SHAP_VAR.append(np.sum(np.var(var_l, axis = 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEKCAYAAADXdbjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmcVdWV77+rqgBBRYspDiWTAh0ghKFE0klowTjbajt0SExHY2yNbfKeSZsX8+knUbrtTPqSNs3rhCYm5oVIoqLyjEZMRG3zgkIhGlFRBAoKHAALJxCouuv9cc4tLrfucO49wz3n3PX9fM6n6p5x7zPs31577b22qCqGYRiG4YeGWifAMAzDSD4mJoZhGIZvTEwMwzAM35iYGIZhGL4xMTEMwzB8Y2JiGIZh+MbExDAMw/CNiYlhGIbhGxMTwzAMwzdNtU5AVAwZMkRHjhxZ62QYhmEkira2th2qOrTcfnUjJiNHjmTVqlW1ToZhGEaiEJF2L/tZM5dhGIbhGxMTwzAMwzcmJoZhGIZvTEwMwzAM35iYGIZhGL4xMTEMwzB8Y2JiGCmmrb2T+cvX09beWeukGCmnbsaZGEa90dbeySULV7CvK0PfpgYWXTGDaSOaa50sI6WYZWKkEquRw4oNO9nXlSGjsL8rw4oNO2udJCPFmGVipA6rkTvMGD2Yvk0N7O/K0KepgRmjB9c6SUaKMTExUkehGnk9ism0Ec0sumIGKzbsZMbowXV5D4zoMDExUofVyA8wbUSziYgRCSYmRlna2jsTVbu1GrlhRI+JiVGSpPofrEZuGNFivbmMkliPIMMwvGBiUgGNjY1MnjyZiRMncvHFF7N79+5aJyl0lv7gG2y9/cu8u/I+Mru2cts1f8OUKVN49dVXSx53xx13MGbMGMaMGcMdd9xRcJ+77rqLCRMm0NDQYHPNGEbCMTGpgP79+7NmzRqef/55+vbty49//GPf5+zu7g4gZeHw+uuv89Kzq/h/T69m3v/8BucM3Mqciy/gmWee4fjjjy963FtvvcVNN93EU089xdNPP81NN91EZ2fv8R4TJ05kyZIlzJw5M8xseMLGpRiGP0xMquSTn/wk69evB+CXv/wl06dPZ/LkyVx11VU9AnH11VfT2trKhAkT+Na3vtVz7MiRI5k3bx6f+MQnuOuuu7jtttsYP348kyZNYs6cOYBTIJ9//vlMmjSJGTNm8NxzzwFw4403cvnll3PyySczevRobrvttoLp+93vfsfUqVP56Ec/yimnnFLynO+//z6XX345J554IlOmTOH+++8H4LTTTuPNN9/ki+fNYscTi7jrjp+wcOFCZs2aVfLePPzww5x66qkMGjSI5uZmTj31VH73u9/12u/DH/4w48aN83zPwyLrF7p12TouWbjCBMUwqsAc8FXQ1dXFQw89xBlnnMGLL77Ir3/9a/74xz/Sp08f/uEf/oFFixbx+c9/nptvvplBgwbR3d3NKaecwnPPPcekSZMAOOSQQ3jyyScBOOaYY9i4cSP9+vVj165dAHzrW99iypQp3HfffTz66KN8/vOfZ82aNQC89NJLLF++nHfffZdx48Zx9dVX06dPn570bd++nb//+7/niSeeYNSoUbz11lslz3nzzTcze/Zsbr/9dnbt2sX06dP51Kc+xdKlSznnnHN6rquqHHbYYVx33XUAnHXWWSxcuJBjjjnmoPuzdetWjjvuuJ7fLS0tbN26NYxHEQg2LsUw/GNiUgF79uxh8uTJgGOZfPGLX2TBggW0tbVx4okn9uwzbNgwAH7zm9+wYMECurq6eO2113jhhRd6xOTTn/50z3knTZrEJZdcwvnnn8/5558PwJNPPsk999wDwOzZs9m5cydvv/02AGeffTb9+vWjX79+DBs2jDfeeIOWlpae861YsYKZM2cyatQoAAYNGlTynMuWLWPp0qXccsstAHzwwQds3ryZ/v37l7wfDz74YMH1qtprnYiUPFctsXEptSVpXc+NwpiYVEDWZ5KLqnLppZfy7W9/+6D1Gzdu5JZbbmHlypU0Nzdz2WWX8cEHH/RsP/TQQ3v+/+1vf8sTTzzB0qVL+ed//mfWrl1bskDu169fz7rGxka6urp6palQ4V3snKrKPffc06vJadOmTb32L8RTTz3FVVddBcC8efNoaWnhscce69ne0dHBySef7OlctcDGpdSOpHY9N3pjPhOfnHLKKdx99928+eabgOOXaG9v55133uHQQw/liCOO4I033uChhx4qeHwmk2HLli3MmjWL733ve+zatYv33nuPmTNnsmjRIgAee+wxhgwZwsCBAz2l6WMf+xiPP/44Gzdu7EkTUPScp59+Oj/60Y96xOaZZ56p6B6cdNJJrFmzhjVr1nDuuedy+umns2zZMjo7O+ns7GTZsmWcfvrpFZ0zaqaNaOaaWSdYQRYx1vU8PZhl4pPx48fzL//yL5x22mlkMhn69OnD/PnzmTFjBlOmTGHChAmMHj2aj3/84wWP7+7u5nOf+xxvv/02qspXv/pVjjzySG688Ua+8IUvMGnSJAYMGFC0e20hhg4dyoIFC7jgggvIZDIMGzaMRx55pOg5b7jhBq699lomTZqEqjJy5EgeeOCBstcp5jMZNGgQN9xwQ0/T39y5c3ua2q644gq+9KUv0drayr333stXvvIVtm/fztlnn83kyZN5+OGHPefTSD7WxJgepFDTRxppbW1VG8sQPkG3f1t7evqxZxxvRKRNVVvL7WeWiREYQbd/10t7ehoL00ryZKFv0oGJiREYQXexrYcuu2kUzDTmySiPOeCNwMi2fzcKgbR/B32+OJJGB3SlebLoA+nALBMjMILuYlvLLrtRNT2l0QFdSZ7MikkPJiZGoATd/l2L9vQoC7g0jnGpJE/10JRZL5iYGKmnUisj6gIujQ5or3lKo2VWr5iYGKmmGivDCrjoSKNlVq+YmBipphorwwq4aEmjZVaPmJgYqaZaK8MKOMOoDBMTI9XE1cpI40BFo74JfZyJiJwhIutEZL2IXF9g+0wRWS0iXSJyUc76WSKyJmf5QETOd7eNEpGnROQVEfm1iPQNOx9GcolbEEebjMtII6GKiYg0AvOBM4HxwGdEZHzebpuBy4Bf5a5U1eWqOllVJwOzgd3AMnfzd4EfqOoYoBP4YmiZMIyASeNARcMI2zKZDqxX1Q2qug9YDJyXu4OqblLV54BMifNcBDykqrvFmahjNnC3u+0O4Pzgk24Y4VAPI/uN+iNsn8mxwJac3x3ASVWcZw7wv9z/BwO7VDU7I1SHex3DSARx9eMYhh/CFpNCc7VWFPNeRI4GPgJkJ7rwfE4RuRK4EmD48OGVXNYwQsV6ixlpI+xmrg7guJzfLcC2Cs/xt8C9qrrf/b0DOFJEskJY9JyqukBVW1W1dejQoRVe1jDqFwu+aFRK2JbJSmCMiIwCtuI0V322wnN8Bvhm9oeqqogsx/GjLAYuBe4PJrmGEV+i6k5swReNagjVMnH9Gl/GaaJ6EfiNqq4VkXkici6AiJwoIh3AxcBPRGRt9ngRGYlj2Tyed+pvAF8TkfU4PpSfhpkPw6g1UXYntt5mRjWEPmhRVR8EHsxbNzfn/5U4TVWFjt1EAee6qm7A6SlmGHVBlMEnLTaZUQ02At4wEkCUBbz1NjOqQVQr6lyVWFpbW3XVqlW1ToZhVI2FYDFqgYi0qWpruf3MMjGMhFCP3YlNQJODiYlhGLHEepUli9ADPRqGcTC1HMORpPEj1qssWZhlYhgRklvbbmps4KJpLVw4tSWSGnfSavrWqyxZmGViGBGSW9ve15Xhzqc29xo3Epb1kLSafrZX2ddOGxd74TPMMjGMSMnWtvfuz6A4QeVyx42EaT2UqunH1dFdj50OkoqJSQKI64duVE62tr1kdQd3rdpCd0YPKtjDHJxYbPxI0pq/jHhiYhJz7ENPD7mVgpv/5iNcMLWlV8Eetp+gUE0/ytH1RnoxMYk59qGng2KVgvxnWYvR5+boNoLAxCTmpP1Dr5cmvEoqBVH7CSx8ihEEJiYxJ80fej014cW9UmCObsMvJiYJIK0fehya8KKyjNJcKTAMMDExaoif2noQIhC1ZZTWSoFhgIlJWeqlTb8WVFtbD0oE4mAZVYO9k0YcMTEpQT216deKamrrQYlAXP0YpcTC3kkjrpiYlCCpNde0E5QIxM2P0dbeyT2rO7i7rYOu7sJiYe+kEVdMTEoQ15prvROkCMTFj5G1OLJhVqCwWNg7acQVE5MSxK3mahwgLiIQFFmLIyskAgXFwt5JI66YmJQhbYVWnAnKsZxEB3WuxdHYIFzcehwXFAlNb++kEUdMTGJC3ArAqNMTlGM5qQ7qoCyOuL1HpUhSWsMgbfk3MYkBcSsAa5GeoBzLcXJQV1pY+LU4avUeVVMoxu2dj5o05t/EJAbEqQCsVXqCcixH6aCOWxfeYpNfhVn7rTafcXvnoyaN+TcxiQFx66FTi/SUmmuj0tp9FA7qcoVoLQr2/OfWPKCvp4LeT3NLtYViWO9YUpqO4vbNB4GJSQyIWw+dWqUnv5mn2lpvFA7qcoVotQW7H/Kfm5eC3q8FVW2hGMY7lqSmo7h980FgYhIT4tZDJw7puWd1R8+4Cz9NAYVqq35rsOUK0WoK9iDIfW7rXn+XBhFQLVrQ+02Xn0LRyztWyXMqlZc4Wixx+MaCxMSkRsTx5Y4Tbe2d3N3W0TPuorFBqmoKKFRbBXzXYL0UovmFRZTNGm3tncx7YC0ZVRoahLnnTCiYxiCaW8IqFCu1NIrlJUkWS5IxMakB9nKXZ8WGnXR1ZwBnAN/FrccF1rsLCMRKqLQQvXBqC+r+jbIZTlA6d+8ruF8llkXUFaBKraZieUmjszuOmJjUAHu5y5Nfy7xgaktVhVmx2mrUVkJu5eHCqS2hXg8qszi8NjdFXQGqxmoqlJc0OrvjiIlJDbCXuzz5tUyormmqWG01SudnkJWHct2Rc7cFmcdaVICCykMand1xxMSkBtjL7Y3cWub85eurLswK1VajdH4GVXkoZR0U2xZUHmtVAQoqD2lzdscRE5MaYS93ZSTZmguq8lDKOsjdtq8rww9//zLXfmpsYO+YVYCMcpiYGIkg6YVZEJWHUoKa3ZYVlCdf2cHKTW8F6tuwCpBRClHV8nulgNbWVl21alWtk2EYvijnM/nh71/myVd2oECjwNdOG8c1s06oSXqMdCAibaraWm6/hggScoaIrBOR9SJyfYHtM0VktYh0ichFeduGi8gyEXlRRF4QkZHu+p+LyEYRWeMuk8POh2HEgWkjmrlm1glFx7Vc+6mx9OvTQKMUng8lSLJ+mluXreOShStoa+8M7Vpe0jJ/+fqapqHeCbWZS0QagfnAqUAHsFJElqrqCzm7bQYuA64rcIpfADer6iMichiQydn2dVW9O5yUG1FhNdsDlLsXXu5VlM2BcenibuO24kHYPpPpwHpV3QAgIouB84AeMVHVTe62XKFARMYDTar6iLvfeyGn1YiYIOcwSboglbsXldyrqHwbUXWKKPd84yJq9U7YYnIssCXndwdwksdjxwK7RGQJMAr4PXC9qna7228WkbnAH9z1ewNKc10TZcEcRCEQZa00zHtT7l7EscCMwgry8nyT3NMvTYQtJlJgnVePfxPwSWAKTlPYr3Gaw34KfBN4HegLLAC+AczrdXGRK4ErAYYPH15ZyuuQqJsLgigEoipkw7435e5FrQrMcgIathXk5fkmvadfWghbTDqA43J+twDbKjj2mZwmsvuAGcBPVfU1d5+9IvIzCvtbUNUFOGJDa2trfXRbK0OpwiHq2m8QhUBUhWzY96bcvahFgRkHX4TX52vdlmtP1WIiIqcC/0NVTy2x20pgjIiMArYCc4DPerzESqBZRIaq6nZgNrDKvfbRqvqaiAhwPvB8tfmoJ8oVDrWaFMtPIRBVIRvFvSl3L6IuMIOaAiCfSpoLzepIDmXFRERmAz8GjgHuA/4Vp5eVADeXOlZVu0Tky8DDQCNwu6quFZF5wCpVXSoiJwL3As3AX4vITao6QVW7ReQ64A+uaLQB/+meepGIDHXTsAb4UsU5r0Nya9d792dYsrrjoI8z++Hes7qjYPtkXImikK23Qq3QFADNA/oyf/l6X/mvxtoxqyMZeLFMbsXxO/wJOBNYAdygqv/m5QKq+iDwYN66uTn/r8Rp/ip07CPApALrZ3u5di2JYw+jGaMH09TojJJW4K5VW7igQDj0Jas72NeV4Z7VHdbNMod6KtTypwA4edww5j2w1neTVxw7EhjB4GXQoqrqY6q6V1XvA7Z7FZJ6JU6DuXKZNqKZi6a19Fgd3Rntmd8jS7H5P9KIDXQrTrZZr1GgX58GhhzeL5D3Ive81vMqXXixTI4UkQtyfkvub1VdEnyyYsSzi+Heq5z/+x4GQ8Y6y9CxMGQcDB0HzaOg8cCtjHPt68KpLSxZ3RG7XkNREwfncpwpNAVAqfem2vPaPU8PZWNzub2liqGqenmwSQqHqmNz/f5GePIHVV93qw7hsJbxHHHcxBwhGgeHDqn6nH4JYqR1HPCTzvnL13PrsnVkNJoYVmkgKe+FESxeY3P5CvQoIh9S1TeqPkGEBBLo8YO3Ycd62LEOtq+DHS87f996NZhEAjQdcrDoZP8OOh6a+gZ3nYTj17LIHp+taZtlYhiF8SomFXcNFpEjgAtxuvh+GGeUe31wyBHQMs1ZvJDJwNtbDojOjpcP/L/nrcLHdH0Arz/nLF45/OiDxSf7/2EfAklSvyzv+G1KrMfmFrMsoqMe77UnMRGR/sC5OAIyFTgcZ3zHE+ElLQU0NEDzCGcZU2o4Tg5734Odr8B2V3h2rHP/X1f8mHdfc5aNj3tMV5Pj7xky5mDrZ/AJ0Ke/t3PUmCB8O3HpnRVFwVOpJVePhWFQ1Ks/zss4k0XATGAZ8O/AozjBGx8LN2l1Sr/D4JgpzuIFVZ578UV+eOf/ZYR2MLZhG+cc8y6Hv7sR3n+z8DGZLnhzrbN45dChboeDsQcL0cBja2L9pMWy8FLwBFGwV2LJ1WthGBRx7oATJl4sk4lAJ/Ai8JI7mNBCk8QFEf7rjb481jWRjE6kUeCtcWWcyfv3wM71btPbKwdbP5muwse8v91Z2p/0nraDrJ+sEI2FvodWlscixMWy8EO5gqfagj1fgHItucYGYduuPbS1d1oU3hColx6R+ZQVE1X9qIj8BU4T1+9F5E3gcBE5SlVfDz2FRlkqfnn79IejPuIsXlCF997s3fFgx8tO81oxdqxzlpce8Had/s151o/bBfuI4U6TYRXEvbmm3LOrpmAvJkDZ6AZ3t3Vw59Obiw5KrdfCMCiSGknCL558Jqr6EjAXmCsircBngKdFpENV/zLMBBrlCb3JRwQO/5CzjJrp7ZiuvfDWht7is+Nlp5NBIfZ0wpYVzuKVQcf3HvczZCwcMjCWzTX54lbu2VVTsBcToGkjmntGtnuNwts8oG/PAMVa37ukUW+RJLz4TFpVtadPrfv/KjdulseSxQib2DX5NPWDYR92Fq+8v6N3r7cdLzs94orx1qvO8vJDvTZNA15qxIkKB/AzoN/Awj3fmkdCQ2OvcwRJMXHLfXaVik0hSglQJVF4gdiJcVKox6ZCL5bJf7pT5t4JLM5OuavOABWP3YcMwwOHDnGWkR/3tn/3fujc5IrOupwecC/DviITc+59B7auchavHDmi97ifIWNhwKCCuxdrWqvWP1JpRaGUAFUiTkEXiHFvcgySemwq9OIzmSIi43DCx98tIvs4ICztYSfQMIrS2Mdx8A8ZA5zTszq3UG5qEC5uPe5AQMvdb+V0OsjpgNC5qfh1drU7y/pHPCXrw9qPvnoMG5Yfy1GtH+PYEybB0HHMGNkcuH+kGKUEyKs4BVkgxrHJMUzS0tuwErz6TNYBNwE3ichHcYTlURF5XVU9ViMNIxpyC+XujHLMkf0PfMwDBsHwk5zFC5luR2jye71tfxn2vl3wkAGyl4/IRj7CRlj9JKx21hdsdssysIW/O2wUh/c5lJe7j6G9oYVPHD0WVGnbvKsmhVKQBWI9NvvEruk5ZCoaAS8iDcAw4EPAocD2MBJlFKaemgn8EGgTQ0MjDD7eWcad0WtzfoyvT08fzrLVL3Ncdwfjml7j2o8qR+3b4gjQzvXFr/NOBwPf6eDzDRyI5b3YmYl6mrsc1Kjc2Pfgnm/ZbteDT3D8VQFRrECs9F2cMXowTQ3C/m6lsUHqotmn3vA6Av6TOD24srMaLga+qqqFq2ZG4NRbM4EfwmpiKFSA5gvXhVNbuHBqS89+R3m5djVhd7r3wRt/dhavHHbUAdHJFaLDj6po4GnV76IIoKkN8VPveOnNtQXYjCMgNyUlsGPaqMdmgnKUqh0H3cRQyjleSLgqunaJsDtFA1Lufc+xdHoEKKcDAkXGFL/3urNs9BgFSRryrB9nEOqqVxoqfhezXZIV6O629zeNeLFMPuHF0S4iP1LVrwSQJqMA9dg7pBRRW2qlxDzMtvGiVla/w+CYyc6SQ1t7J5/+yZ/oyjiC0gD84+njuObk4+Gdbb17vW1fVzzsjmZg+4vOksNVwFW5LWmPc6AJbsCQHtHJFaIZowbZ+5tyvPTm8tpjK5WO+Lj4Keqxd0gporbUainmlYjVig07yeRMKyGCEzpl8y6mjTgWjjgWjvc46/X+PbDz1d4dD0qF3dm9A9p3QPsfD84DJTofDB7Tu9v1kLGOYBqJoeIQ9PVE3PwU9dY7pBRhFe7FKg9Bi3nQlZTs+ZoH9KVvk9MMJSKIwJ1Pb+autg4umub4czxfr09/OGqis3ghL+zOmxv/zPoX2hjFNo6WIr4fcKJk73yl+PZjW2HAYGcM0oBBzv8DhuSsG+ysP+RI88fUEBOTEpifwj9hWXZhWGrlKg9BiXnQlZT88809ZwKdu/exddceFj+9mYzCvq4Mv3pqM79ZuYV5503ksycN952PXuSF3bnr/fXcusbp6dYg8I+FZrM8KOxO7vgfN+zOsPFwyEDH1/PmC06UhK49ha/f0AT9Bx0sMIVEJ7tuwGDoc0jw96FOCVJMUlclMD+FP8K27IK21KKqPAR9nfzzde7exzWzTqCtvZMlqzvYuz/T45Lvyihz73+ecUcdHnrFqHlAX1zXDRl1fveimrA7+3Y7zWm7dzrL++7f/HVvvuSue4uinRL6HlZedA7NEZ9Djqw66Gja8do1eCgwAmcek11Fdvu3wFIVE8xP4Y8oCucgLZ+oKg9BX6fY+bLv75LVHSx+ejPdPQW7RmJld+7eh9sZmAb3t18Oft4eratMtzPl9vs7CotOz7odjmX0/k7Y/37hc0lDcetHGmDbM57D7qQNL12DrwD+FXgVGCUiV6rq0vz9VPXnwSev9pifonrCLpyDtnyiqjwEfZ1ysbimjWhmwjFHMPf+58mo0jciK3vG6MH06xPc86/6eTc0uoV+70K9R5ym5T2H/XsOCE4p62fHeti9wrF+tNs51mPYHfoMKBx0dNBoJ1RQwvBimVwLTFDV7SIyGlgE9BITw8gn7MI5DMvHS+WhWmuoUERgP1Ryvs+eNJxxRx0eaVj5oJ9/GIEni4pTn/5wRAsc0eLc551l8pDJOF2st605uNfbjpcdq6gQ+3fDa2ucxSsDW3pPtz1knGMpFeh8EGVvVC9isk9VtwOo6gYRCS5Wg5F6wrTsauHT8jPzYZhOdy/nCyqsfG4BBZQsrIJ8/pXMFukFL+Lk+T43NDiRBMadUTDsTkE+eKdw0NEyYXd4pwM2LPd0iYnahwe753DJo2eH3hvVi5i0iMhtxX6r6n8LPlmGUZ5a+LSqrR2H7XSPKh0HRWRubABVujIaSdf57PP2MlukF7xURkL1+x0yEFqmOYsXMhlHSHrG/OQI0O6dBQ/pJ/u5oen/8PO9Z4buJ/MiJl/P+90WRkIMoxqi9mlVaw1F5XQvRVt7J9t27aGpQejOaFXpyC9cwXGwVzKlsB/xnzbC22yRXq7rpTISqx6dDQ1w5HBnGfOpsru3tXdyxcLHIku7qBbpMlfuQJFDgL9W1buCTVI4tLa26qpVFUyIZBhFCMpnEmU68i2Kigcw5p1nf1eGRtcyyQpTOQshqKa+ovHKQrpuXKJgVEMQaReRNlVtLbdfpSHoG4HTcCIInw78F5AIMTGMoKjWGgraiqo0zErPHC/dGY7NnePFA7mFUm5tPntuL4VVUE1GlTZvrtiws2eszb79lV837j06owx4Wgqv40xmAp8FzgaexonDNUpVd4eYNiMCklzr8kOY+Y7jPfXTXFOoZp87kt1rHoNsMqqkkGwe0LdnyGKGIoMnE0qcQj55GWfSgROC/j+Ar6vquyKy0YQk+cTpRYySMPMd13vqp7NCEBZFVmCzoV6iFNrO3ftoEHrCugQxeDIuxCnkkxfL5B6cSbE+DXSLyP0UjU1gJIk4vYhREma+43xPq23y8GtR1Fpgmwf0pUEEIhywGRVx6iDgJQT9fxeRa4FZOL6S7wMDReRvgQdV9b2Q02iERJxexKhoa+9k6649NDU20N0dfL7TeE/9dsGupcC2tXcy74G1ZFRpaBDmnjMhNuIeBHEK+eTJZ6JOl69HgUdFpA9wJjAH+N/AkPCSZ4RJnF7EKPjVU5uZe//zTu+jRmHO9OFcUEWPplKk5Z4WGl1fbV78+muqcfZnyRUyQVPVxJUlLh0EKo4arKr7ccKpLBWR/uX2F5EzcIJANgILVfU7edtnAj8EJgFzVPXunG3DgYXAcThNa2ep6iYRGYUzjfAgYDXwd6qavrckAmr9IkblrG5r72Tu/c/3zEDY1a0cU2GPJq9Uck/j6KyPS8yzIAZIptFSjCteHPB/prSPZFKJYxuB+cCpQAewUkSWquoLObttBi4Dritwil8AN6vqIyJyGE5nDIDvAj9Q1cUi8mPgizgdBIyY4KWQjLItPX8GwoYGqXnBUmtfQjFqFfOsXDqgsgGS2eumwVJMAl4sk3PcvwL8FjirgvNPxwlbvwFARBYD5wE9YqKqm9xtmdwDRWQ80KSqj7j7veeuF2A2TldlgDuAGzExiQ1eC8ko29KzNdR9XRkaRJjRTJhHAAARYElEQVR33sSaFyxh579aqycutfmDYnHlDZCsJE21tr7rhYrmgBeRvRXMCQ9wLLAl53cHcJLHY8cCu0RkCTAK+D1wPdAM7FLV7CTUHe51jJjgtZCMstCKYw01zPz7sXricq/y0wGV+0yM6Ah72t5Csy967VbcBHwSmILTFPZrnOawQuHvC55TRK4ErgQYPjyEaUqNgngtJIMotCqpfefWUPOPq4XvIsxC26/VE5fafH46apGmOPq14ogXn8nUnJ/9836jqqtLHN6B4zzP0gJs85i2DuCZnCay+4AZwO3AkSLS5FonRc+pqguABeDE5vJ4XcMnlRSSfgqtoMLBzz1nAvMeWFsT30U1+fdSuMWlqcoPcYiBFle/VhzxYpncilPzF+B14Ja87bNLHLsSGOP2vtqK0534syX2zz+2WUSGuvOpzAZWqaqKyHLgIpweXZcC93s8pxERUdRsgwrD/tDzr8V2oGE+Xgu3uDRVQXWFe1zmjYnzINS40eBhn28Al6jqLFWdhePwfg94HqdAL4prOXwZeBh4EfiNqq4VkXkici6AiJzohmy5GPiJiKx1j+3G6eH1B7dHmQD/mZOmr4nIemAw8NNKMm2kg2ztu1GoKhx89rgzJx5d1XlqQaHCrRjTRjRzzawTai4klyxcwa3L1nHJwhW0tXd6Oq6SfAZxXDGqfcfqES+WyY+BT0HPmJBvA18BJuM0IZUTlAeBB/PWzc35fyVOU1WhYx+hQNdjt+lruoe0Gymm2tp3oeOyU9rWuhZfjiibr4JoZqqmZu913pVC6Qv6/sTJwos7ZeczEZFnVfWj7v/zge2qeqP7e42qTg49lQFg85n4xxyRwVNtE1DYzyFof1Q1c4+UmnelVPpq+Z6m8RsJcj6Txhxn9ym4vaMqON5IAfXiiIyyMKj2nibJH9W5e1/Fc494mXelVPpq1ROtXr6RYngRgzuBx0VkB7AHZ0IsROQE4O0Q02bEiHpwREZdGAR9T4MUwiCnJ66kcPd63WqnLQ6zolAP30gpvAxavFlE/gAcDSzTA+1iDTi+E6MOSENX03JEXRgEeU/jEk/Lr4/B6/GVXieKikI9fCOl8Bo1eEWBdS8HnxwjrtSDIzLowqBcTTjIexqkEOamO3dGRa/4bWbyenwl14miolAP30gpzOdheCYuo6LDIsjCoJLxIEHc06CEMK3t/lFZDWn/RkphYmLUDV7azIMqDKJuMgtKCIOcojdOtfN6txqiwMTEqAuirnHXov08CCFM+hS9pfB6f+IohknAxMRILJV89Em1FKLGb7rjGla/kvPHVQzjjomJkUgq/ejDsBS8ONiTWBD5SXdcw+p7pd679/rBxMRIJJV+9EFbCkmpwfqtyVd6fKn77DctURT09d691w8mJkYiqeajL1fjjnOzWTX4FbwgR+gHIb5RFPRJbZ6MAyYmRiKptaWRhBpsruDt3Z9hyeqOiu6TX8H0G/Axn6gK+qQ2T9YaExMjUoJ0oAb50de62SwMZoweTFOjM++9Anet2sIFBYImljq+WsEsFPAxCPG1gj6+mJgYkRFnP0MYzWa1ZtqIZi6a1sKdT21Gge6MVmQR+BFMvwEfjeRhYmJERpz9DEmwNKrhwqktLFndUbVFUK1g+g34aCQPExMjMuLuZ0hjYVcrkUyrOBvFKTs5VlqwybGioZxPxEYXG0ayCHJyLMPwhBefSBpr//WCVQSMUpiYGIEVEnH2iRj+iHPnCSMemJjUOUEWEnH3iRjVYxWFA5iFVhgTkzonyELCnK7pxSoKDmahFcfEpM4JupColU/EaovhEkVFIYhnaPO81w4TkwpJW6GVBmvCaovREGZFIYhnaPO81xYTkwpIa6GV9B5WVltMPkE8Q5vnvbaYmFRAPRdacbbIrLbojzg82yCeoc3zXltMTCqgXgutuFtkVlusnrg82yCeob0HtcXEpALq9WVNgkWW9tpiWNZDnJ5tEM8wre9BHKzHcpiYVEhaX9ZS1ItFFtcPNkzroV6ebZKJi/VYDhMToyz1YJHF+YMN03qoh2ebdOJkPZbCxMTwRNotsjh/sGFbD2l/tkknKdajiYlhEO8P1qyH+iYpz99C0Bt1S76PJK4+E8OoJRaC3jBKUMxHYiJiGNXRUOsEGMmnrb2T+cvX09beWeukeKaQj8SIB0l8n4wILBMROQP4N6ARWKiq38nbPhP4ITAJmKOqd+ds6wb+7P7crKrnuut/DvwV8La77TJVXRNmPozCxLkXVCni7COpZ5L6Phkhi4mINALzgVOBDmCliCxV1RdydtsMXAZcV+AUe1R1cpHTfz1XeIzaEOdeUKVIilOz3kjq+2SEb5lMB9ar6gYAEVkMnAf0iImqbnK3ZUJOixECSa7h5/pIzPkeD5L8PtU7YYvJscCWnN8dwEkVHH+IiKwCuoDvqOp9OdtuFpG5wB+A61V1b/7BInIlcCXA8OHDK0274YE01PDT3rSSJKFMw/tUr4QtJlJgXSV9kYer6jYRGQ08KiJ/VtVXgW8CrwN9gQXAN4B5vS6kusDdTmtra330ga4BSe8FlaSmlUqFIYlCmfT3qV4JuzdXB3Bczu8WYJvXg1V1m/t3A/AYMMX9/Zo67AV+htOcZsSAJPbEyTatNAqxblrJCsOty9ZxycIVnu6x9VozoiJsy2QlMEZERgFbgTnAZ70cKCLNwG5V3SsiQ4CPA99ztx2tqq+JiADnA8+HknqjIpJYC4bkNK1UY0GZD8KIilDFRFW7ROTLwMM4XYNvV9W1IjIPWKWqS0XkROBeoBn4axG5SVUnAB8GfuI65htwfCZZx/0iERmK04y2BvhSmPkwvJGk5qJ8ktC0UkwYSjV9JUUojeRj4VSMwMhaJtnCLimWSZIoFAImidagkRwsnIoROVYLDp98CyrJ1qCRLkxMjEBJQnNRmjCfiBEXTEwMI8GYNWjEBRMTw0g4Zg0accCiBhuGYRi+MTExDMMwfGNiYhiGYfjGxMQwDMPwjYmJYRixJIlx3uoZ681lGEbssJH9ycMsE8MwYodFO04eJiaGYcSOpEwLYBzAmrkMw4gdNrI/eZiYGIYRS2xkf7KwZi7DMAzDNyYmhmEYhm9MTAzDMAzfmJgYhmEYvjExMQzDMHxjYmIYhmH4xsTEMAzD8I2JiWEYhuEbExPDMAzDNyYmhmEYhm9MTAzDMAzfmJgYhmEYvjExMQzDMHxjYmIYhmH4xsTEMAzD8I2JiVGXtLV3Mn/5etraO2udFMNIBTY5llF3tLV3csnCFezrytC3qYFFV8ywSZgMwydmmRh1x4oNO9nXlSGjsL8rw4oNO2udJMNIPCYmRt0xY/Rg+jY10CjQp6mBGaMH1zpJhpF4rJnLqDumjWhm0RUzWLFhJzNGD7YmLsMIgNAtExE5Q0TWich6Ebm+wPaZIrJaRLpE5KK8bd0issZdluasHyUiT4nIKyLyaxHpG3Y+jHQxbUQz18w6wYTEMAIiVDERkUZgPnAmMB74jIiMz9ttM3AZ8KsCp9ijqpPd5dyc9d8FfqCqY4BO4IuBJ94wDMPwTNiWyXRgvapuUNV9wGLgvNwdVHWTqj4HZLycUEQEmA3c7a66Azg/uCQbhmEYlRK2mBwLbMn53eGu88ohIrJKRFaISFYwBgO7VLWrynMahmEYARO2A14KrNMKjh+uqttEZDTwqIj8GXjH6zlF5ErgSoDhw4dXcFnDMAyjEsK2TDqA43J+twDbvB6sqtvcvxuAx4ApwA7gSBHJCmHRc6rqAlVtVdXWoUOHVp56wzAMwxNhi8lKYIzb+6ovMAdYWuYYAESkWUT6uf8PAT4OvKCqCiwHsj2/LgXuDzzlhmEYhmfEKZtDvIDIWcAPgUbgdlW9WUTmAatUdamInAjcCzQDHwCvq+oEEflL4Cc4jvkG4Ieq+lP3nKNxnPmDgGeAz6nq3jLp2A60F9g0BMfaSTppyEca8gDpyIflIT7UOh8jVLVs007oYhJ3RGSVqrbWOh1+SUM+0pAHSEc+LA/xISn5sHAqhmEYhm9MTAzDMAzfmJjAglonICDSkI805AHSkQ/LQ3xIRD7q3mdiGIZh+McsE8MwDMM3qRUTETlSRO4WkZdE5EUR+ZiIDBKRR9xow4+ISLO7r4jIbW5k4+dEZGrOeS51939FRC6NQR6+7/5+TkTuFZEjc/b/ppuHdSJyes76kpGbo85DzrbrRETdcUSxfQ6l8iEiX3Hv7VoR+V7O/ol4FiIy2Q1XtMYNXTTd3TeWz0JExsmBSOJrROQdEbk2Sd92iTwk6tvuhaqmcsEJAHmF+39f4Ejge8D17rrrge+6/58FPIQT/mUG8JS7fhCwwf3b7P7fXOM8nAY0ueu+m5OH8cCzQD9gFPAqztieRvf/0e45ngXG1zIP7v/HAQ/jjP0ZEufnUOJZzAJ+D/Rz1w9L2rMAlgFn5tz/x+L+LHLy0wi8DoxI2rddJA+J+rbzl1RaJiIyEJgJ/BRAVfep6i6ciMV3uLvlRhs+D/iFOqzACddyNHA68IiqvqWqncAjwBm1zIOqLtMDQS5X4ISTyeZhsaruVdWNwHqcqM1lIzdHnQd38w+A/8HBcdVi9xzK5ONq4DvqDphV1Tdz8pGUZ6HAQHe3IzgQmiiWzyKPU4BXVbWdBH3befTkIUnfdiFSKSY4Sr0d+JmIPCMiC0XkUOBDqvoagPt3mLt/sejGfqMe+6FYHnK5HKfWBQnKg4icC2xV1Wfz9o9jHqD4sxgLfFKcidoeFyeaAyXSG7tnAVwLfF9EtgC3AN90949jHvKZA9zp/p+kbzuX3DzkEvdvuxdpFZMmYCrwH6o6BXgfx/QtRrHoxn6jHvuhZB5E5J+ALmBRdlWBc8QxDzcC/wTMLbB/HPMAxZ9FE04TyQzg68BvRESIZz6K5eFq4KuqehzwVVzLhXjmoQdxYv2dC9xVbtcC62KRj2J5SMi33Yu0ikkH0KGqT7m/78b5kN5wTVzcv2/m7F8ourGvqMc+KZYHXGfhOcAl6jaqlkhrHPMwCnhWRDa56VktIkeVSGst8wDF89EBLHGbUJ7GiSM3pER64/gsLgWWuOvuwmk6ye4ftzzkciawWlXfcH8n6dvOkp+HJH3bvamVsybsBfgvYJz7/43A990l10n3Pff/sznYSfe0HnDSbcSpfTa7/w+qcR7OAF4AhubtO4GDnXQbcBx0Te7/ozjgpJtQyzzkbd/EAQd8LJ9DiWfxJWCeu24sTpODJOlZAC8CJ7vrTgHa4v4s3HQsBr6Q8ztR33aRPCTq2+6Vn1pdOIIHNRlYBTwH3Oe+MIOBPwCvuH8HufsKzlz1rwJ/BlpzznM5jsNrfe6Dr2Ee1ruF1hp3+XHO/v/k5mEdbg8dd/1ZwMvutn+qdR7ytm/igJjE8jmUeBZ9gV8CzwOrgdlJexbAJ4A2tyB6CpiWgGcxANgJHJGzLmnfdqE8JOrbzl9sBLxhGIbhm7T6TAzDMIwIMTExDMMwfGNiYhiGYfjGxMQwDMPwjYmJYRiG4RsTE8OIABHpdiPEPisiq0XkL931I0Xk+Zz9povIE24k2JfcsCcDapdyw/BGU60TYBh1wh5VnQzghhD/NvBXuTuIyIdwRqHPUdU/uaFZLgQOB3ZHnF7DqAgTE8OInoFAZ4H11wB3qOqfANQZBHZ3lAkzjGoxMTGMaOgvImuAQ4CjgdkF9pnIgTDqhpEoTEwMIxpym7k+BvxCRCbWOE2GERjmgDeMiHGbsYYAQ/M2rQWmRZ8iw/CPiYlhRIyI/AVO1NedeZv+HbhURE7K2fdzbnh+w4g11sxlGNGQ9ZmAE8n2UlXtdjpsOajqGyIyB7hFRIbhzI/yBAfmGzGM2GJRgw3DMAzfWDOXYRiG4RsTE8MwDMM3JiaGYRiGb0xMDMMwDN+YmBiGYRi+MTExDMMwfGNiYhiGYfjGxMQwDMPwzf8HyAeASqFKrqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmcVNW1qL/V3YCgQRoBFZkViaLI0AIqEpQITomGxAQlgqhx9sZ4vTfmGmdNvLmaJ159GiQajIoiTjwVgRgnNCA0IgqKItjQKILS4AAI3b3eH+cUXd1UVdd0pqr1/X4bunadYe1TVWvtvdbae4uqYhiGYRjpUhK0AIZhGEa0MMNhGIZhZIQZDsMwDCMjzHAYhmEYGWGGwzAMw8gIMxyGYRhGRpjhMAzDMDLCDIdhGIaREWY4DMMwjIwoC1oAL+jQoYP26NEjaDEMwzAiRWVl5Req2rG54wrScPTo0YNFixYFLYZhGEakEJGqdI4zV5VhGIaREWY4DMMwjIwww2EYhmFkhBkOwzAMIyPMcBiGYRgZYYbDMAzDyAgzHIaRJpVVNdzz8koqq2qCFsUwAqUg53EYRr6prKph3JT57Kitp2VZCY+cP5RB3cuDFsswAsFGHIaRBvNXfcmO2nrqFXbW1jN/1ZdBi2QYgWGGwzDSYGivfWhZVkKpQIuyEob22idokQwjMMxVZRhpMKh7OY+cP5T5q75kaK99zE1lFDVmOIzdqKyqMQWZgEHdy+15GAZmOIwmWBDYMIzmsBiH0QgLAhuG0RxmOIxGWBDYMIzm8MxwiEgfEVkSV74SkStE5H9E5AMRWSoiT4tIu7hzficiK0VkhYiMjqs/0a1bKSJXeyVzU0pLS+nfvz+HHXYYZ5xxBlu3bvXr1oFx+9WXUDfjKvpveZNbR7TnvNOOY8CAAXz88ccpz5s6dSq9e/emd+/eTJ06NeEx1157Lf369aN///6MGjWKTz/91IsmhBabQGgUCqKq3t9EpBRYBwwB+gD/VNVaEflvAFX9rYgcCkwDBgOdgX8AB7uX+BA4AagGFgJnquryZPerqKjQfGzktNdee/HNN98AMG7cOAYNGsSVV16Z0zXr6uooLS3NWTYvWL9+PUOGDKGqytnL5bbbbmPbtm3ceOONKc/btGkTFRUVLFq0CBFh0KBBVFZWUl7eODby1Vdf0bZtWwDuuusuli9fzn333edNY0KGxY6MKCAilapa0dxxfrmqRgIfq2qVqs5R1Vq3fj7Qxf37NOAxVf1OVVcDK3GMyGBgpaquUtUdwGPusb5y7LHHsnLlSgAefvhhBg8eTP/+/bnwwgupq6sD4OKLL6aiooK+ffty/fXX7zq3R48e3HTTTQwbNownnniCu+66i0MPPZR+/foxduxYwFG+p59+Ov369WPo0KEsXboUgBtuuIFzzz2XESNG0KtXL+66666E8r344osMHDiQI444gpEjR6a85rfffsu5557LkUceyYABA3j22WcBGDVqFBs2bKB///7ceOON3HnnnUyZMoXjjjsu5bOZPXs2J5xwAu3bt6e8vJwTTjiBF198cbfjYkYjJoOINP/gCwSLHRmFhF9ZVWNxRhNNORd43P37ABxDEqParQNY26R+SL4FTEVtbS2zZs3ixBNP5P333+fxxx/njTfeoEWLFlxyySU88sgjjB8/nltvvZX27dtTV1fHyJEjWbp0Kf369QNgjz32YN68eQB07tyZ1atX06pVKzZv3gzA9ddfz4ABA3jmmWf45z//yfjx41myZAkAH3zwAS+//DJff/01ffr04eKLL6ZFixa75Nu4cSO/+tWveO211+jZsyebNm1Kec1bb72V448/ngceeIDNmzczePBgfvjDHzJz5kxOPfXUXfdVVfbaay+uuuoqAE4++WSmTJlC586dGz2fdevW0bVr112vu3Tpwrp16xI+y2uuuYaHHnqIvffem5dffjnnzyYqxGJHO2vrLXZkRB7PRxwi0hL4MfBEk/prgFrgkVhVgtM1RX3T+1wgIotEZNHGjRtzE9pl27Zt9O/fn4qKCrp168Z5553HSy+9RGVlJUceeST9+/fnpZdeYtWqVQBMnz6dgQMHMmDAAJYtW8by5Q3etF/84he7/u7Xrx/jxo3j4YcfpqzMsd3z5s3j7LPPBuD444/nyy+/ZMuWLQCccsoptGrVig4dOtCpUyc+//zzRnLOnz+f4cOH07NnTwDat2+f8ppz5szhtttuo3///owYMYLt27ezZs2aZp/HCy+8sJvRAMfANCXZaOLWW29l7dq1jBs3jrvvvrvZexYKsQmEV47qY24qI/L4MeI4CVisqru0nYhMAE4FRmqD1qkGusad1wWIRU+T1e9CVScDk8GJceRD8NatW+/qfcfdhwkTJvDHP/6xUf3q1au5/fbbWbhwIeXl5Zxzzjls37591/t77rnnrr+ff/55XnvtNWbOnMnNN9/MsmXLUirfVq1a7aorLS2ltra20XGqmlBRJ7umqvLkk0/Sp0+fRu998sknux2fiAULFnDhhRcCcNNNN9GlSxdeeeWVXe9XV1czYsSIlNc466yzOOWUU5qNnxQSNoHQKBT8iHGcSZybSkROBH4L/FhV49OUZgJjRaSViPQEegNv4QTDe4tIT3f0MtY9NhBGjhzJjBkz2LBhA+DEEaqqqvjqq6/Yc8892Xvvvfn888+ZNWtWwvPr6+tZu3Ytxx13HH/605/YvHkz33zzDcOHD+eRR5zB1yuvvEKHDh0axQRScdRRR/Hqq6+yevXqXTIBSa85evRo/vd//3eXYXn77bczegZDhgxhyZIlLFmyhB//+MeMHj2aOXPmUFNTQ01NDXPmzGH06NG7nffRRx/t+nvmzJl8//vfz+i+hmGEA09HHCLSBicb6sK46ruBVsBct5c8X1UvUtVlIjIdWI7jwrpUVevc61wGzAZKgQdUdZmXcqfi0EMP5ZZbbmHUqFHU19fTokUL7rnnHoYOHcqAAQPo27cvvXr14phjjkl4fl1dHb/85S/ZsmULqspvfvMb2rVrxw033MDEiRPp168fbdq0SZrSmoiOHTsyefJkxowZQ319PZ06dWLu3LlJr3nttddyxRVX0K9fP1SVHj168NxzzzV7n2Qxjvbt23Pttddy5JFHAnDdddftcpedf/75XHTRRVRUVHD11VezYsUKSkpK6N69e9FkVBlGoeFLOq7f5Csd1/APWx/LMIIn3XRcW6vKCByb42AY0cKWHDECx+Y4GEa0MMNhBI6tj2UY0cJcVUbg2CZJhhEtzHAYoSDXOQ5BBdctqG8UI2Y4jMgTVHDdgvpGsWIxDiPyJAqu+7GEuQX1jWLFRhxG5Gm6gGB5m5a+jARs4UKjWDHDYUSepsH1RCMBLwyHBfWNYsUMh1EQNA2u+zUSsIULjWLEDEeEsAye9LCRgGF4ixmOiGAZPJlhIwHD8A7LqooIlsFjGEZYMMMREYJYlsOPlNZiwZ6lUUiYqyoi+O23N9dY/rBnaRQaNuKIEIO6l3PpcQf5onS8do0VUw/c3IxGoWEjDiMhXk5uK7YeuE0UNAoNMxxGQrx0jfk1QS8sWHqwUWiY4TCS4lVKazH2wC092CgkzHAYvmM98Pxjk0MNPzHDYQSC9cDzR7HFjIzgsawqw4g4lrVl+I0ZDiNyFFMqbzrYnu2G33jmqhKRPsDjcVW9gOuAh9z6HsAnwM9VtUZEBJgEnAxsBc5R1cXutSYAv3evc4uqTvVKbiNYkvnqY/XlbVpy03PLIuuWySQWke6xFjMy/MYzw6GqK4D+ACJSCqwDngauBl5S1dtE5Gr39W+Bk4DebhkC3AsMEZH2wPVABaBApYjMVFXrbhYYyXz18fUlItSrRjKVN5NYRKZxC4sZGX7il6tqJPCxqlYBpwGxEcNU4HT379OAh9RhPtBORPYHRgNzVXWTayzmAif6JLfhI8l89fH19fVKiUgk3TKZxCIsbmGEGb+yqsYC09y/91XVzwBU9TMR6eTWHwCsjTun2q1LVm8EhFepn8nmdzStv+7UvtRs3RE5t0x8O0pLS1i3eRuVVTUJ21CMc12M6CCq6u0NRFoCnwJ9VfVzEdmsqu3i3q9R1XIReR74o6rOc+tfAv4TOB5opaq3uPXXAltV9Y4m97kAuACgW7dug6qqqjxtV7GSjgslF8PSXIwjasaiKZVVNTy1uJonFq2ltl5TuqEKpc1GdBCRSlWtaO44P0YcJwGLVfVz9/XnIrK/O9rYH9jg1lcDXePO64JjcKqBEU3qX2l6E1WdDEwGqKio8NYaFhFNlVdzy4XkOqcgma++UHz4sWdYW998nKZQ2mwUHn7EOM6kwU0FMBOY4P49AXg2rn68OAwFtrgurdnAKBEpF5FyYJRbZ3hMzAjcMWcF46bMp7KqptnUT/PNN4+lzxpRx9MRh4i0AU4ALoyrvg2YLiLnAWuAM9z6F3BScVfipONOBFDVTSJyM7DQPe4mVd3kpdyGQyIjcOlxB6VM/czGN1+oLplk7bL0WSPqeB7jCIKKigpdtGhR0GJEntiII2YE0nU7ZTpXoRCXyyjUdhmFTZhiHEbAZNujb65nnKpHne59Ml1iPSqjk2JbOt4oLsxwFDheBavz1aPOxLUVpV68pdMahYwZjgInVc83l957rj3q+CVExgzsggBjBnZJeY0o9eKjEseIygjOCBdmOAqcZD3fXHvvufSo4+9dryBAqxYljBnYxbN7ZksuitXLdNp8KPwojeCMcGGGo8BJ1vPNtfeeS486/t7gLECWjgx+9+K9UKxhUvhRGsF5hY24ssMMRxGQqOebj957tj3q2L1jSquE9Ocz+DkpLt+KNWwKv9jjMDbiyh4zHEVKkD74+HuXt2kZ2nWn8q1Y8xVvypdcUYnDeIWNuLLHDEeEyXWY7UXvPZM9JML+I823Ys1XvCmfckXhc/CKYh9x5YIZjogSxmH2owvWcN2z71FXr7RqEQ6ZciWfijWf8aZiVvj5othHXLlghiOihG2YXVlVw3XPvketG/HesTN4mcKIV/EmIzvMAGeHGY6IkquyyXc2yfxVX1Ift3xNSYkUjAL0OvPGer5G1DDDEVFyUTZeuLniM6VKRLjptMMKYukQr1yCTdufTs83m2cWledsRAszHPGowv8dChs/gK5DYNiV0HsUlPi1w25mZDvM9sLNlYkhC2N8JhlePKts2u/FOWZUjGwxwxGPKnzj7iu1dgFM+0XDe9/rDMN+AwN+CS3bBCNfnvDKp56uIQtbfCYVqTKh/FiuJXafdZu3ZfzMmkv/jYrxNsKHGY54Skrgt6uhvh5WvADz/g+sc5dn//pTmPUfTolx9L/B0Eug7f7ByJslQfvUszVcXmxJ2xyJnpVfy7XE36estISyEqGuXtN+ZqnuEyXjbYQPMxyJKCmBQ051SoxP34Z5d8LyZxrq3rzLKTEOPd0ZlXTu75+sWeJVNkk6Cjobw5VIWQO+uMaaPiu/lmuJv09dXT1jB3ejc7vWaT+zVPexTC4jF8xwpEvnAfDzqQ2vv/oM5v/fxoZj+TONDcsBFY4h6XNyaOMk+SQTBZ2p4WqqrJ9aXM2Ti6vTule+e9d+LdfS9D7NrR6cyX2CHnUa0cYMR7a03R9G3ewUgB1b4e2HHffW1586desWwePjGs7ZsxMceyUMHA8t9/RfZo/x0v3RVIkqpH2vfPeu01W6+ZjZ76VytzkMRrbY1rFeUV8PH82G1/8M1W8lP27opXDUpbD3Af7J5hHZbjWbyfVjShTI6F5+ZxD5HXyOWoZU1OQtFtLdOtYMh598thTemATvzUh+zCE/ctxbBwzyT6484qdCCLPyueflldwxZwX1CqUCV47qw6XHHeTJvaKWIRU1eYsJ23M8jOzfD372V6cAfL0e5t8Lb9zZcMz7/88pu87p7xiSQ34EJaX+ypsh2SryXDKewqpw/Aw+Ry1DKmryGrtjhiNIvrcfnHCjUwB2boMljzpxki1rnbrPlsATExrOabOPMzFx0DnQai/fRU5Gql5kKsOQae8zzKOMePwMPufTSPnxfC2jK/qY4QgTLVrDkec5BZwJiR/NdQzJmjeduq1fwpxrnBJj8IVw9GXQrpv/Mrsk60U2ZxgynQyXjXEKCr9GRPkyUn65kCyjK/qY4QgzInDwKKfE+HyZEydZ+nhD3Vt/cUqMPqc47q2uR/omarJeZHOGIZPeZ7bGKV3CaHz8lMlPF1KY3YxG83hqOESkHTAFOAxna+lzgW3AfcAeQC1wiaq+JSICTAJOBrYC56jqYvc6E4Dfu5e9RVWnUqzs2xfGTHYKwDcbYcF9zqhE65y6Fc87Zdc5h8Oxv3EmKHoUJ0nWi2xqGMrbtOSel1c2Wtwv3d7n0F77UFYi7KxTSuNW382HwgtjwDZdmSqrajjz/oYMs2m/yk72MLmQwmjEjQa8HnFMAl5U1Z+JSEugDTAduFFVZ4nIycCfgBHASUBvtwwB7gWGiEh74HqgAsf4VIrITFWt8Vj2aLBXRxh5rVMAdm6Hd6Y5hmRzlVP3+bsw41wcuw3s0c4ZkVScC3u0zZsoiXqR8YahvE1Lbnpu2W6KMKPepwig7v8O+VB4fvW2M1GI6cr0lDsREpy5LU8trs5p3shTi6sJMtcyjEbcaIxnhkNE2gLDgXMAVHUHsENEFIhpq70Bd7YcpwEPqZMfPF9E2onI/jhGZa6qbnKvOxc4EZjmleyRpsUeUDHRKeDEST7+p2NIPnndqdu+Gf5xvVNiHHk+HH05lPfIu0gxw3DPyytzUs7zV31JbV09irMER+z8fPjM/ehtZ6oQ05WpqZLPVenHZuQ/tbg6EKVtWVfhx8sRRy9gI/CgiBwBVAK/Bq4AZovI7UAJcLR7/AHA2rjzq926ZPWNEJELgAsAunULLkgcOkTgoJFOibHhAydO8s6jDXULpzglRu/Rzqik+1F5EyVX5Zzq/Fx95vkO2CYaWWSqENOV6acDuzBj0Vp21iktSoWfDuyStdxhUNphcpkZifFsAqCIVADzgWNUdYGITAK+whllvKqqT4rIz4ELVPWHIvI88EdVneee/xLwn8DxQCtVvcWtvxbYqqp3JLt3aCcAhpVvv4S3JsO8P0PdjsTHdOrrGJK+P4HS7Psb6bpqkh2XiasnKD95spGFlzPr89VWr2f/ZyKHxTj8J/CZ4yKyHzBfVXu4r48FrgaGAe1UVd2A+BZVbSsifwFeUdVp7vErcNxUI4ARqnqhW9/ouESY4ciR2u9g6XTHvbXp48THtPyeE3CvOA9at8vr7fPh4w7ST55q1ngUFGIUZDS8IfCZ46q6XkTWikgfVV0BjASW47iwfgC8gjOa+Mg9ZSZwmYg8hhMc36Kqn4nIbOAPIhL7Bo8CfueV3AZQ1goGnu0UcOIkq1911t1a/apTt+NreOkmp8QYNBGO+Tdo3yun2+fDXRKky8VLl5ofREFGI1i8zqq6HHjEzahaBUwEngUmiUgZsB03LgG8gJOKuxInHXcigKpuEpGbgYXucTfFAuWGT4hArxFOifHFR06c5O2/N9RVPuiUGAf90I2THAMiafdk8+HjzvQa+exlezHBzUYBRpiwRQ6N/LB1E7x1v+Peqt2W8JCVegD31v6I2SXDmHr+sJSzvpvWZaM4M4mnZLOft5+LOYYxPdWMWeERuKvKKDLatIcRv3UKQO0OeO9JJ+D+xYcAHCTruKPFfdzBffAg0GJP1h12ERcvOoQvatvsNrcDHJfTivVfJ5z/0RzpulwydWvlshthNoQh06kpmUxOzOW5mHEKJ2Y4Coh8/8hyul5ZS+h/plOAyk82MemvD3C+PMvwkqXOMTu/5YC37+CtUsCd0L581mnws+uo/HafXYqpRJy9thVvFGembq2mivzJxdW7JuHle0RQWVXDus3bKCstoa4uuXx+K9h0jFmuI6WwjrQMMxwFQ75/ZPm+3qAe7fn1+ecxf9Xp7BlTbl9+zMbZ/0PHDxsS5A5d/yzc/SyDgA9K4TUO5y91P2ZBSV9USag4/dhpL/4eTQ2NkP5uhJkQ/xmUlQhjB3dLuH1stp9VLs8tHWOb60gpjCMtw8EMR4GQ7x9ZttdLpYx2cx3tcyAdz7qPyqo/Mn/VlxxzQBn918+AeXc6WVvA8NJ3GV767q5TtrftxR6b/h0O+DmUtcybgUvl1kp0j3hDA85s63xPWIv/DOrqlc7tWieUMZvPKpfnFvuMrzu1LzVbdyQ1PF5O+DSCxQxHgZDvH1k218tWGTVS2gdfBcOvcq63egObFjzGsPV/p/VmJ06yx1er4NlLnQIcIS25WE/lQR3N17Xf86RX2lQxP7W4ms7tWjdSmNlmUaUytM19BrFzy9u0zPizyqVjkO5nnGt2mRfZaUZ+sKyqAiLoGIcv26VW/cvJ3PpodvJj+v8Sjvk1dDw4L7eMn01dWloCqtTWa9Y99fhMseaUcKoZ9PHnNtf7T9WmTGaI+7klruE/llVVhOR74lam1/PFtdD9qMbrZ21azYY5t9Ppg4cb6pY87JR4TrnDmeUet6puusT3fNdt3sZjb63JS089nV5/ss+g6bk1W3dkpMCz7c2b+8gAMxxGHgnEtdC+J53G3gPc47zevgUWPQD/uKHxcc//u1NiVJwLo26Flm3Suk1MgVdW1fBUXDyj6f4iyUhkJHJRwvlQ4Nl0NMx9ZIC5qoqWKOXH5yRr3U545TZ4/fbUx3UdAmPuh/LuacuTbH+RZOckcg3l0rYofYbxRFXudIh62wJf5DBIcjEcUf/g0yFK+fGeyPreUzBjYupjWu4FZ06DnsOTficy9fcXw3erOaL03cuUpunTZ1R0TZg+HWYsxpEFhfyljidK+fHpypqRUj5sjFNirH8Xpo+HTasa6nZ8A1N/BMAgt9zy8jlw7vUM6tEeyNxdFNbFAwt1X3O/iW/bjjrl0QVreDKgzbC8xgxHHIX8pY4nSgHOdGTN2eDvdzj829sNr7/9Ep77Nbz//xod9vuSv8Hf/rbr9aABZzNtwtW8uXZ7ZEcRfneWovTdy5RY277b6exS6dVKB2EgpeEQkT2A76nqxib1nYCvVHW7l8L5TSF/qeOJUoAzHVnzbvD33Ad+4WRlVVbVMH7KG/xKn+KKsicbH/f23xnw9t8ZAPAqcMAg+OlfoX3P7O/tM353lqL03cuUWNueXFzNjMrqlEvERJ2UMQ4RmQy8qKpPNakfBwxT1Ys9li8rLMZRXOS6a11zn3nC95fPhOlnp75waUs463E48PhMmuMr+drxz343jYnq88hLcFxElqvqoUneW6aqfXOQ0TMsqyqaxP/YILPVZrP9oebNVfP5cnjiHPhiRerjRt0KQy+BkpLM7+ER+VjB1i93V1QVclTIV3A81Wyp8HzzjcjTKCMlwexsSG1Isg08Z7OkekI59j0ULnur4fXWTc68kWVPNb7AnGucEuOIM+GkP8EebTOWPV/kGrT3y91VLMkrUaA5w7FBRAar6lvxlSJyJLAxyTmGkTFNlQ80BBe9XLY8UVwr3WU+UsrRpj2c8aBTAOrr4I07G2+1C/DONKfE2O9w+NnfoEP6s8CD7oX7FRssluSVKNCc4fgPYLqI/A2odOsqgPHAWA/lMoqMeOUTWw+qrl49XbYcdg/WAkmNQ06Kq6QUjv13p8RYMQumNfkZrX8X7h4UVyFw1nQ4eFTCy/q9qVQiUgW882nUiiV5JQqkNByq+paIDAEuAc5xq5cBQ1R1g8eyGUVEIgWezrLl6Ww7m869Y8fd8/LKpMYh74qrz0lww5aG1xs/dCYmfv5e3EEKj57R+LyR1zuLOJaUJly590mPRmepSOTuyvueLgWckRU1mp3HoaqfA9f7IIsRUfLVq2yqfOL/TqQwkvW2EymrdGVMZRw8V1wdD4aL32h4vW0zzPpPWPp44+NeutEpwK9ad2Jzi5OYtvMH1Ja1QfFudJYpuYzQkn1eYZ1EWWw0N4/jXRxX825vAaqq/TyRyogMfgUsEymMRIoJdleckNz9lOg+qYyDV4oroaJs3Q7GTHYKOHGSf90Nc6/bdV7LbRu4pmQq17Sa6lS8A71bnML9O09iU1mHZkdnXpLtCM2C4OGnuRHHqb5IYUSWIAOWyRRT07pMZfS7V5u2oiwpdVxUx/y6oe6zd5wdE+OytyaWPM/EVs87Lx4EDvkx7x90PuOe2eqrMs52hGZB8PDTXIyjqmmdiHQAvtRCXB3RyBg/Apap3BaJFFOiujAHVXNSlPsf0Th76+v1MP9eJ4MrxvszOeT9mXxQCpTC0vperFtwMXQ93/P5JOka4VR7uoft8zKanwA4FLgN2ATcDPwd6IAzh2O8qr6Y8uIi7YApwGE4Lq9zVfVfInI5cBlQCzyvqv/pHv874DygDvg3VZ3t1p8ITAJKgSmqeluq+9oEQH/x0gVSWVXDmfc3zGye9qvCm9mcj9nbSdu3cxu8/TA7Xv0zLb/9NPHJbTrAsN/AoHOg1V7ZNyRLwpAZZjjka+b4IuC/gL2BycBJqjpfRL4PTFPVAc0IMRV4XVWniEhLoA0wALgGOEVVvxORTqq6QUQOBaYBg4HOwD+A2N6fHwInANXAQuBMVV2e7L5mOAqHa55+l0cWrNn1etyQbtz6k8MDlMgbct2XIx1XV2VVDfM//oJRLZfS+8P7Yc2/kl90yMVw9GWwd5dMm5Ixth1teMjXzPEyVZ3jXvAmVZ0PoKofSDNbcIpIW2A4bhqvqu4AdojIxcBtqvqdWx9L6z0NeMytXy0iK3GMCMBKVV3lXvcx99ikhsMoHJp2awrVP5pLXCVdV1fDPXrDsJ82vLH+PXhjErw7vaFuwb1OifH9U51RSZdmdUrGmGsqejRnOOrj/t7W5L3mfsO9cGaXPygiR+BMIPw1zijiWBG5FdgOXKWqC4EDgPlx51e7dQBrm9QPaXozEbkAuACgW7duzYhmRIWfDuzCjEVr2VmntCgVfjrQ+x5w1MhZ8e53GPz0fqcAfLMBFtwHr/+ZXT/zD55zisvGvfrwdcXl9Bp+lhO0zwGbnxE9mnNV1QHf4qTftga2xt4C9lDVFinOrcAxBMeo6gIRmQR8BfwE+CeOETkSeBzHyNwN/EtVH3bP/ytFKyLYAAAWOUlEQVTwAk48ZbSqnu/Wnw0MVtXLk93bXFWFRZjjE2HB02e0c7uzLMq8P8PmNYmPaV0Ow37D2/uO4c2139lnFVEC3zpWRPYD5qtqD/f1scDVOAHu21T1Fbf+Y2AocD6Aqv7RrZ8N3OBe7gZVHe3W/y7+uESY4TAMb/ivp9/l0QVV/KBkKReXzWRoyftJj93w/fF0Gn1VWvu4G+EgXcPhWS6eqq4H1opIH7dqJE5c4hngeFfIg4GWwBfATGCsiLQSkZ5Ab+AtnGB4bxHp6QbYx7rHGkboqayq4Z6XV1JZVRO0KHlB3H9frT+CsTuu5Zoj5jnLplwynw/2PaXRsZ0+eAgm9YMb9nbKo2NhzYIgxDbyjNdbx14OPOIq/FXARBzX1wMi8h6wA5jgzglZJiLTcYxLLXCpqtYBiMhlwGyc0coDqrrMY7kNjyg0t1Oq9hTiDOgxA7vwRGXDumFjYjGnTofw7cn38P0pZ7Oztp5OZd/w5MD36PzuvVC/0znmw1lOidGpLxx7JRx6OpTaLtZRwjNXVZCYqyqcFJoiba49hZpm2pyxTPhe7XfOmluv/xlqVie+cKu9YdgVcOR5sMfeHrbASEa+0nENI28U2lISzbWnUNNMU6UOJ32vrBUMHO8UAFVY9QrM+z+w+lWn7rstjRZwBKDiPDj68kjt414MmOEwfKM5RRo1N1Zz7bE00xSIwIHHOSXGxhXwxl2w5OGGukV/dUqMg05w5pN0P9q5hhEI5qoyEuKVEs/L7nohImrGLlJs3QRvTXZGJbXbEx/T8RDHkBw2BkqTzg4w0iTwdNwgMcORG0Eo8VTxAFPOBgC1O+DdJxxD8uVHiY9psScc+xs48nxnbkkahPH7FZRMFuMwsiaIWEQyt0+8ESsrEc6o6MqYgV1C8wOPImFUlGlR1hIGjHMKOHGST153Au6rXnbqdn4L/7zFKTEGTnCWot/nwN0uGcaRbhhlaooZDmM3cgnqZquUksUD4o3Yjjrl0QVreHJxdSh/TFEglVKKnEERgZ7DnRLji5VsnHM7HT+c1lC3eKpTYhx4PAy7EnoMC2XCRhhlaooZDmM3sg3q5tpTSpSREzNi3+2sR3FWTgrrjykKxCul73bWc+c/PuSKHzqLUIe9l5sWHQ5i+v5Xcce7P6JeoVy+4ZqOb/CTrU9QWuuumPTxP50CXAqc1LIz99X+iBdKjg1F5lsUsvHMcBgJyWa1Vi96SjEj9uTiamZUVlNXF94fUyrC0psvb9OSejesqcDrH33Bwk82MWZgl9D3ctMlpnh31NZTo3vxHxtG8/sWJznGsMte8N6TTpxk4wcA9JJP+VOLv/An/uLsmFjW2gm4D/4VtGmfV9nS+R5EIRvPDIeRN7zqKcWM2E8Hdsl84lkICJPPumbrDoTGS1vvrK1HCPcuiZkQU7x3/uND5n30xe6j1CPGOgWcOEnVm44hWTnXqavdBq/8wSkx+v/SmZzYoXfWcmXyPfB7++JMMcNh5A2ve0rJfkxhUsyJCJPPemivfSgrFXbWNZgOKRHGDOzCmBSGOWoM6l7OFT88mIWfbEptDEWgxzFOibFplTOfpPLBhrolDzeeX9LzB86opNeItOeThOl7kCtmOIy8EkRPKSw/yGSjnnyNxPIxqhrUvZxD92/LO9VbdtX13b8tg7qXF8xCjDGy7si07wU/utMpANs2w6IHYN6dzux2cGa7x2a8x84ZdiX0+4WT/ZWAKMQu0sXmcRiRJx97dudLhmSjnlyVfj5HVY8uWMN/Pf3urtd/+Mnh9Nnve3nZ2z1e3kIZvexGXS0se9pxb21Ist5qSQtnRDLkItizwUCE/bnYPA6jaPAjmNjcD765UU+uI7F8jqrOGuLskDnrvc846bD9OWtIN655+l121Dobfu6oreepxdVZXz/srsOcKS2Dfmc4Jcaa+Y4h+fBF53X9TnjtT06JccRZDDrm1ww67vv+yusBZjiMgsBLF1k6itBrN0S+r3/WkG67DAjkd2/3sLgOfaXbUDjr8YbXNZ/Am3fDwvsb6t551Ckxug9zZrkfODJy626Z4TCMZmg0CTGJIvQjMcDL6+dzb/dC8uVnTXkPOOV2pwBs/8oJtr/+Z9i+2amrmueUGO26O+6tI86EFnv4LnImWIzDCD1B+4UTxQTie+tBksuzaXpuPp9z0J9Z6Kmvg+XPOu6t9UsTHyMlTsB9yEWwV0dfxLIYRwFTTD9KP/3lyZ5r/NyHEve1n3ixonCqc+ev+hIgp+cc9nkIgVNS6qzoe9iYhrq1bzmZWyued15rPbx+u1NiHP5zZz7Jvn39lbcJZjgiRsEHHpvgl7881XMd2msfWrUIxvXSnILP9tkkOhcKZNmRqNJ1MJwZFwPZvBb+dQ8suLeh7t3pTonR7WjHvdX7BF/jJGY4IkaxBR798peneq5BLgHx1OLqXet0NZUrl2eT6Nxi+26FnnZd4aTbnALw3ddQOdVxb239wqlb8yY8+mbDOW27wPhncprhng5mOCJGsQUe/VLa6ezmF8TckCcWrd2V4VRa2liuXJ5NsnOL6bsVOVp9D46+zCngxEk+eM4JuH+2xKn7qhrmXgdnTkt+nTxgwfEIUiwxDr/bGfRzbXr/+M2tBDhzSDf+8JPDfZXBiBjr33P2HWnROqvTLThewBRD4DGIWE6QzzVRe5uOgmIpsl4q92L4bhU0+x3my23McBihpNj87Ynae+lxB+3mTiq25AgjnJR4eXERaSciM0TkAxF5X0SOinvvKhFREengvhYRuUtEVorIUhEZGHfsBBH5yC0TvJTZCAex3napUBT+9mTtHdS9nEuPOyhlJpVh+I3XI45JwIuq+jMRaQm0ARCRrsAJwJq4Y08CertlCHAvMERE2gPXAxU4qfSVIjJTVQtrKc8mFLuvOQqb2eSTdNtbbMkRRjjxLDguIm2Bd4Be2uQmIjIDuBl4FqhQ1S9E5C/AK6o6zT1mBTAiVlT1Qre+0XGJiHpw3NwRRiqKvVNheEcYguO9gI3AgyJyBFAJ/BoYCaxT1Xek8YSVA4C1ca+r3bpk9Y0QkQuACwC6dQvHchDZUmz+/SgQr6yBQBV3NgFsMzZGPvHScJQBA4HLVXWBiEwCbgCGA6MSHJ9o2qOmqG9coToZmAzOiCNLmUOBuSPCRfwIsKxEQITauuiMBm0Ea+QbL4Pj1UC1qi5wX8/AMSQ9gXdE5BOgC7BYRPZzj+8ad34X4NMU9QVLzN995ag+9iMPAY1GgHXKzjwGpyurarjn5ZWe7r5nAXUj33g24lDV9SKyVkT6qOoKHBfVYlUdGTvGNR6xGMdM4DIReQwnOL5FVT8TkdnAH0Qkpj1HAb/zSu6wYPn04SF+BFjqjjjq6nIfDfo1ErARrJFvvM6quhx4xM2oWgVMTHHsC8DJwEpga+xYVd0kIjcDC93jblLVTd6JbBiNaZrxBPmJcfgVyyq2DDXDe2zJEaOgiFIQOAx7pRtGPGHIqjIMX4laENhGAkZUMcNhFAz5dv34MXqxWFZhEKWRbj4ww2EUDOkGgdP5kUdt9GIERz6+K1EzPGY4jIIhHddPuj9ym4RppEuu35UodlI8XeTQMLwi2fyHposCNiXdOQ3FtsiikT25fleiOM/GRhxG5Milh5auO8sC10a65PpdieI8GzMcRuTIxTWQyY/cAtdGuuTyXYliJ8UMhxE5cu2hmUEwwhaMjtp30gyHETmi2EMLI2FTnn4RxWB02DDDYUSSqPXQ4gmDwi5m5WkZc7ljhsMoavxW4mFR2MWsPKMYjA4bZjiMoiUIJR4WhV3MytNcnbljhsOIHPkaJQShxMOisItdeebD1RkGl2NQmOEwIkU+RwlBKPEwKewox4mCJiwux6Aww2FEinyOEoJS4qawo0WikUVYXI5BYYbDiBT5HiWYEs+NQnfXJBtZhMXlGBRmOIxIESZXjxdESREXg7sm2cii0L+HzWGGw4gcXo4SglTcUVPExeCuSTWyKObRqhkOw3AJWnFHTREXg7um2EcWyTDDYRguQSvuqCniYlGqxTyySIYZDsNwCVpxR1ERm1ItTkRVg5Yh71RUVOiiRYuCFsOIIFEKThtGvhGRSlWtaO44G3EYRhzWgzaM5vF061gRaSciM0TkAxF5X0SOEpH/cV8vFZGnRaRd3PG/E5GVIrJCREbH1Z/o1q0Ukau9lNkwjOiTbGthIz94PeKYBLyoqj8TkZZAG2Au8DtVrRWR/wZ+B/xWRA4FxgJ9gc7AP0TkYPc69wAnANXAQhGZqarLPZbdMIwIEnR2XDHg2YhDRNoCw4G/AqjqDlXdrKpzVLXWPWw+0MX9+zTgMVX9TlVXAyuBwW5ZqaqrVHUH8Jh7rGEYxm4kyo4z8ouXrqpewEbgQRF5W0SmiMieTY45F5jl/n0AsDbuvWq3Lll9I0TkAhFZJCKLNm7cmK82GIYRMWLZcaVCJNKao4iXhqMMGAjcq6oDgG+BXfEJEbkGqAUeiVUluIamqG9coTpZVStUtaJjx465ym4YRkSJpTVfOaqPuak8wssYRzVQraoL3NczcA2HiEwATgVGakM+cDXQNe78LsCn7t/J6o2QYGmsRpiw7Dhv8cxwqOp6EVkrIn1UdQUwElguIicCvwV+oKpb406ZCTwqIn/GCY73Bt7CGXH0FpGewDqcAPpZXsltZI4FI81wGsWF11lVlwOPuBlVq4CJwEKgFTBXRADmq+pFqrpMRKYDy3FcWJeqah2AiFwGzAZKgQdUdZnHchsZEPRSHUFjhtMoNjw1HKq6BGg6C/GgFMffCtyaoP4F4IX8Smfki6CX6giaYjecRvFhM8eNnIniGkv5pNgNp1F82FpVhpEHLMZhFAK2VpVh+Ihl8RQnxdphMMNhGIaRBcWcFOHpIoeG4Te2uJ3hF8W8tImNOIyCoZh7gIb/FHNShBkOo2CwtFjDT4o5m9AMh1EwFHMP0AiGYk2KMMNhFAzF3AM0DD8xw2EUFMXaAzQMP7GsKsOIKJZBZgSFjTgMI4JYBpkRJDbiMIwIUsxzCIzgMcNhGBHEtkc1gsRcVYYRQSyDzAgSMxyGEVEsg8wICnNVGYZhFAh+ZdrZiMMwDKMA8DPTzkYchmEYBYCfmXZmOAwjQ4KeeBf0/Y1w4memnbmqDCMDgp54F/T9jfDiZ6adGQ7DyICgl24P+v5GuPEr085cVYaRAUFPvAv6/oYBIKrq3cVF2gFTgMMABc4FVgCPAz2AT4Cfq2qNiAgwCTgZ2Aqco6qL3etMAH7vXvYWVZ2a6r4VFRW6aNGivLfHMMBxFwU58S7o+xuFi4hUqmpFs8d5bDimAq+r6hQRaQm0Af4L2KSqt4nI1UC5qv5WRE4GLscxHEOASao6RETaA4uAChzjUwkMUtWkkUEzHIZhGJmTruHwzFUlIm2B4cBfAVR1h6puBk4DYiOGqcDp7t+nAQ+pw3ygnYjsD4wG5qrqJtdYzAVO9EpuwzAMIzVexjh6ARuBB0XkbRGZIiJ7Avuq6mcA7v+d3OMPANbGnV/t1iWrb4SIXCAii0Rk0caNG/PfGsMwDAPw1nCUAQOBe1V1APAtcHWK4yVBnaaob1yhOllVK1S1omPHjtnIaxiGYaSBl4ajGqhW1QXu6xk4huRz1wWF+/+GuOO7xp3fBfg0Rb1hGIYRAJ4ZDlVdD6wVkT5u1UhgOTATmODWTQCedf+eCYwXh6HAFteVNRsYJSLlIlIOjHLrDMMwjADwegLg5cAjbkbVKmAijrGaLiLnAWuAM9xjX8DJqFqJk447EUBVN4nIzcBC97ibVHWTx3IbhmEYSfA0HTcoRGQjUBW0HEnoAHwRtBB5phDbBIXZrkJsExRmu4JoU3dVbTZIXJCGI8yIyKJ08qSjRCG2CQqzXYXYJijMdoW5TbbkiGEYhpERZjgMwzCMjDDD4T+TgxbAAwqxTVCY7SrENkFhtiu0bbIYh2EYhpERNuIwDMMwMsIMR54QkQdEZIOIvJfkfRGRu0RkpYgsFZGBbn1/EfmXiCxz63/hr+TJyaFN3UWkUkSWuO26yF/JU5Ntu+Lebysi60Tkbn8kbp5c2iQide5ntUREZvondfPk2K5uIjJHRN4XkeUi0sMvuVORw+/quLjPaYmIbBeR0xNdw3NU1UoeCs5KwAOB95K8fzIwC2ftraHAArf+YKC3+3dn4DOgXdDtybFNLYFW7t974ey70jno9uTarrj3JwGPAncH3ZZ8tAn4Jmj5PWrXK8AJ7t97AW2Cbk8+vn/uMe2BTUG1yUYceUJVX8P5IJORcNl4Vf1QVT9yr/EpztpdoVilMYc27VDV79xjWhGykW227QIQkUHAvsAc7yVNn1zaFGaybZeIHAqUqepc9zrfqOpWH0Ruljx9Vj8DZgXVplD9oAucZpeHF5HBOL31j32UKxeStklEuorIUvf9/3aNYlRI2C4RKQHuAP4jEKlyI9X3bw9xtiSYH5jrI3uStetgYLOIPCXOtg7/IyKlgUiYOelsJTEWmOabRE0ww+EfKZeHd3sUfwcmqmq9b1LlRtI2qepaVe0HHARMEJF9fZUsN5K16xLgBVVdm+D9sJPq+9dNnRnKZwF3isiB/omVM8naVQYcC1wFHImzP9A5/omVE+noisMJcLFXMxz+kXR5eHF2S3we+L07NI0KzS557440luH8iKNCsnYdBVwmIp8At+Os5nyb/+JlRdLPKjYaVNVVOHGBAX4LlwOptmN4W1VXqWot8AxOXCEKNPe7+jnwtKru9FWqOMxw+EfCZePFWTn4aRyf5hPBipgxydrURURaA4izFP4xwIogBc2QhO1S1XGq2k1Ve+D0ZB9S1VSbk4WJZJ9VuYi0AhCRDjif1fIgBc2QZNsxLATKRSQWLzye6LQrWZtinEmAbirwfln1okFEpgEjgA4iUg1cD7QAUNX7SLJsPE7vYTiwj4ic49ado6pLfBM+CTm06RDgDhGJ7eB4u6q+66/0ycmhXaElx8/qLyJSj9ORvE1VQ6Ngs22XqtaJyFXASyIiQCVwv+8NSEAu3z83pbgr8KqfMjfFZo4bhmEYGWGuKsMwDCMjzHAYhmEYGWGGwzAMw8gIMxyGYRhGRpjhMAzDMDLCDIdh5AkRURH5e9zrMhHZKCLPua/3FZHnROQdd7XWF9z6HiKyrcnKp+ODaodhNIfN4zCM/PEtcJiItFbVbcAJwLq4928C5qrqJAAR6Rf33seq2t8/UQ0je2zEYRj5ZRZwivt30xm+++MsJwGAqi71US7DyBtmOAwjvzwGjBWRPYB+wIK49+4B/ioiL4vINSLSOe69A5u4qqK0tpdRZJiryjDyiKoudZeFOBNn6Yj492aLSC/gROAk4G0ROcx921xVRmSwEYdh5J+ZOKvn7rYQnapuUtVHVfVsnIX4hvstnGHkihkOw8g/DwA3NV3YUUSOF5E27t/fAw4E1gQgn2HkhLmqDCPPqGo1zr7kTRkE3C0itTidtimqutB1bR0oIvErIj+gqnd5LqxhZIGtjmsYhmFkhLmqDMMwjIwww2EYhmFkhBkOwzAMIyPMcBiGYRgZYYbDMAzDyAgzHIZhGEZGmOEwDMMwMsIMh2EYhpER/x/zFoXdYHeuEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.4431019480510043"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.polynomial.polynomial import polyfit  \n",
    "from scipy.stats import pearsonr\n",
    "from pylab import text\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(VIO,SHAP_VAR, 1)\n",
    "#ax.plot(VIO,AUS, '.')\n",
    "\n",
    "ax.plot(VIO,SHAP_VAR, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(VIO,SHAP_VAR)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(VIO, b + m * np.array(VIO), '-')\n",
    "ax.set_xlabel(\"BIC\")\n",
    "ax.set_ylabel(\"SHAP_VAR\")\n",
    "fig.savefig('Ex4VIOVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(MSE,SHAP_VAR, 1)\n",
    "#ax.plot(VIO,AUS, '.')\n",
    "\n",
    "ax.plot(MSE,SHAP_VAR, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(MSE,SHAP_VAR)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(MSE, b + m * np.array(MSE), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"SHAP_VAR\")\n",
    "fig.savefig('Ex4VIOVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(VIO,SHAP, 1)\n",
    "#ax.plot(VIO,AUS, '.')\n",
    "\n",
    "ax.plot(VIO,SHAP, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(VIO,SHAP)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(VIO, b + m * np.array(VIO), '-')\n",
    "ax.set_xlabel(\"BIC\")\n",
    "ax.set_ylabel(\"SHAP\")\n",
    "fig.savefig('Ex4VIOVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(MSE,SHAP, 1)\n",
    "ax.plot(MSE,SHAP, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(MSE,SHAP)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(MSE, b + m * np.array(MSE), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"SHAP\")\n",
    "fig.savefig('Ex4VIOVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "METRIC = (SHAP/np.max(SHAP)) + np.array(MSE)\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(METRIC,AUS, 1)\n",
    "ax.plot(METRIC,AUS, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(METRIC,AUS)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(METRIC, b + m * np.array(METRIC), '-')\n",
    "    #cax = ax.scatter(VIO,AUS)\n",
    "ax.set_xlabel(\"Proposed metric\")\n",
    "ax.set_ylabel(\"SHAP\")\n",
    "fig.savefig('Ex4ProposedVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(VIO,AUS, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(VIO,AUS)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(VIO,AUS, '.')\n",
    "plt.plot(VIO, b + m * np.array(VIO), '-')\n",
    "    #cax = ax.scatter(VIO,AUS)\n",
    "ax.set_xlabel(\"BIC\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(MSE,VIO, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(MSE,VIO)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(MSE,VIO, '.')\n",
    "plt.plot(MSE, b + m * np.array(MSE), '-')\n",
    "    #cax = ax.scatter(VIO,AUS)\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"BIC\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(MSE,AUS, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(MSE,AUS)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(MSE,AUS, '.')\n",
    "plt.plot(MSE, b + m * np.array(MSE), '-')\n",
    "    #cax = ax.scatter(VIO,AUS)\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "MSE = np.array(MSE)\n",
    "\n",
    "x = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "for split in range(10, len(AUS), 5):\n",
    "    #print(\"******\", split, \"*******\")\n",
    "    sorted_aus = [AUS for _,AUS in sorted(zip(VIO,AUS))]\n",
    "    sorted_mse = [MSE for _,MSE in sorted(zip(VIO,MSE))]\n",
    "\n",
    "    low = []\n",
    "    high = []\n",
    "    low = sorted_aus[:split]\n",
    "    high = sorted_aus[split:]\n",
    "\n",
    "    x.append(split)\n",
    "    \n",
    "    \n",
    "    #print(\"Low Violations = \", np.mean(low), \"for\", len(low))\n",
    "    #print(\"High Violations = \", np.mean(high), \"for\", len(high))\n",
    "    y1.append(np.mean(low))\n",
    "    sorted_aus_by_mse = [AUS for _,AUS in sorted(zip(MSE,AUS))]\n",
    "    low = sorted_aus_by_mse[:split]\n",
    "    high = sorted_aus_by_mse[split:]\n",
    "    #print(\"Low AUS by MSE = \", np.mean(low), \"for\", len(low))\n",
    "    #print(\"High AUS by MSE = \", np.mean(high), \"for\", len(high))\n",
    "    y2.append(np.mean(low))\n",
    "    sorted_aus = [AUS for _,AUS in sorted(zip(METRIC,AUS))]\n",
    "    sorted_mse = [MSE for _,MSE in sorted(zip(METRIC,MSE))]\n",
    "\n",
    "    low = []\n",
    "    high = []\n",
    "    low = sorted_aus[:split]\n",
    "    high = sorted_aus[split:]\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Low Metric = \", np.mean(low), \"for\", len(low))\n",
    "    #print(\"High Metric = \", np.mean(high), \"for\", len(high))\n",
    "    y3.append(np.mean(low))\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x,y1, '-', label = 'BIC')\n",
    "ax.plot(x,y2, '-', label = 'MSE')\n",
    "ax.plot(x,y3, '-', label = 'METRIC')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "plt.show()  \n",
    "pearsonr(METRIC,AUS)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP VAR Best by BIC =  0.16290749070042948\n",
      "SHAP VAR Best by MSE =  0.16363649208471778\n",
      "SHAP VAR Best by MET =  0.1655828407883969\n",
      "SHAP VAR Random =  0.16324172148758379\n",
      "SHAP Best by BIC =  2.996254319239635\n",
      "SHAP Best by MSE =  3.007954838411785\n",
      "SHAP Best by MET =  3.0365643572803998\n",
      "SHAP Random =  2.990940747465363\n",
      "AUS Best by BIC =  7.474756046806317\n",
      "AUS Best by MSE =  7.370754963830701\n",
      "AUS Best by MET =  7.399144082060601\n",
      "AUS Random =  7.395594365027405\n"
     ]
    }
   ],
   "source": [
    "def norm(a):\n",
    "    return (a - np.min(a)) / a.ptp()\n",
    "METRIC = norm(np.array(VIO)) + norm(np.array(MSE))\n",
    "n_low = 30\n",
    "\n",
    "sorted_aus = [SHAP_VAR for _,SHAP_VAR in sorted(zip(VIO,SHAP_VAR))]\n",
    "print(\"SHAP VAR Best by BIC = \", np.mean(sorted_aus[:n_low]))\n",
    "\n",
    "sorted_aus = [SHAP_VAR for _,SHAP_VAR in sorted(zip(MSE,SHAP_VAR))]\n",
    "print(\"SHAP VAR Best by MSE = \", np.mean(sorted_aus[:n_low]))\n",
    "\n",
    "\n",
    "sorted_aus = [SHAP_VAR for _,SHAP_VAR in sorted(zip(METRIC,SHAP_VAR))]\n",
    "print(\"SHAP VAR Best by MET = \", np.mean(sorted_aus[:n_low]))\n",
    "print(\"SHAP VAR Random = \", np.mean(SHAP_VAR[:n_low]))\n",
    "\n",
    "sorted_aus = [SHAP for _,SHAP in sorted(zip(VIO,SHAP))]\n",
    "print(\"SHAP Best by BIC = \", np.mean(sorted_aus[:n_low]))\n",
    "\n",
    "sorted_aus = [SHAP for _,SHAP in sorted(zip(MSE,SHAP))]\n",
    "print(\"SHAP Best by MSE = \", np.mean(sorted_aus[:n_low]))\n",
    "\n",
    "\n",
    "sorted_aus = [SHAP for _,SHAP in sorted(zip(METRIC,SHAP))]\n",
    "print(\"SHAP Best by MET = \", np.mean(sorted_aus[:n_low]))\n",
    "print(\"SHAP Random = \", np.mean(SHAP[:n_low]))\n",
    "\n",
    "sorted_aus = [AUS for _,AUS in sorted(zip(VIO,AUS))]\n",
    "print(\"AUS Best by BIC = \", np.mean(sorted_aus[:n_low]))\n",
    "\n",
    "sorted_aus = [AUS for _,AUS in sorted(zip(MSE,AUS))]\n",
    "print(\"AUS Best by MSE = \", np.mean(sorted_aus[:n_low]))\n",
    "\n",
    "\n",
    "sorted_aus = [AUS for _,AUS in sorted(zip(METRIC,AUS))]\n",
    "print(\"AUS Best by MET = \", np.mean(sorted_aus[:n_low]))\n",
    "print(\"AUS Random = \", np.mean(AUS[:n_low]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_comparison(x1, x2, y,  bins = 10):\n",
    "    sorted_y_by_x1 = [y for _,y in sorted(zip(x1,y))]\n",
    "    sorted_y_by_x2 = [y for _,y in sorted(zip(x2,y))]\n",
    "    total_len = len(sorted_y_by_x1)\n",
    "    X = []\n",
    "    Y1 = []\n",
    "    Y2 = []\n",
    "    for i in range(1, bins + 1):\n",
    "        X.append(i / bins)\n",
    "        Y1.append(np.mean(sorted_y_by_x1[int((i - 1)*(total_len/bins)):int(i*(total_len/bins))]))\n",
    "        Y2.append(np.mean(sorted_y_by_x2[int((i - 1)*(total_len/bins)):int(i*(total_len/bins))]))\n",
    "       \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ind = np.arange(bins)    # the x locations for the groups\n",
    "    width = 0.35         # the width of the bars\n",
    "    p1 = ax.bar(ind, Y1, width, color='r',)\n",
    "\n",
    "    p2 = ax.bar(ind + width, Y2, width,\n",
    "                color='y' )\n",
    "\n",
    "    #ax.set_title('Scores by group and gender')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(X)\n",
    "\n",
    "    #ax.legend((p1[0], p2[0]), ('Men', 'Women'))\n",
    "    #ax.yaxis.set_units(inch)\n",
    "    ax.autoscale_view()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def normalize(a):\n",
    "    return (a - np.min(a)) / (np.max(a) - np.min(a))\n",
    "plot_comparison(METRIC, MSE, normalize(AUS))\n",
    "plot_comparison(METRIC, MSE, normalize(SHAP))\n",
    "plot_comparison(METRIC, MSE, normalize(SHAP_VAR))\n",
    "#plot_comparison(MSE, normalize(AUS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def heat_plot(x,y,z, xlab = 'Mean', ylab = 'Variance', zlab= 'Mean Generalization Error (MSE)', file = 'heat.pdf', clim_low = 0, clim_high = 1):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    cax = ax.scatter(x, y, c=z, s=70, edgecolor='black', cmap = 'hot')\n",
    "    cax.set_clim(clim_low, clim_high)\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    #plt.colorbar(cax)\n",
    "    cbar = plt.colorbar(cax)\n",
    "    cbar.set_label(zlab)\n",
    "    plt.show()\n",
    "    fig.savefig(file, bbox = 'tight')\n",
    "    \n",
    "heat_plot(normalize(VIO), normalize(MSE), normalize(AUS), xlab = 'Proposed Metric', ylab = 'MSE', file = 'METRICvsMSE_Generalization.pdf')\n",
    "\n",
    "heat_plot(normalize(METRIC), normalize(SHAP), normalize(AUS), xlab = 'Proposed Metric', ylab = 'SHAP Var', )\n",
    "heat_plot(normalize(VIO), normalize(MSE), normalize(SHAP), xlab = 'Proposed Metric', ylab = 'MSE', zlab = 'SHAP (feature attribution) Error' ,file = 'METRICvsMSE_SHAP.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
