{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256]] ['temp/abalone0', 'temp/abalone1', 'temp/abalone2', 'temp/abalone3', 'temp/abalone4', 'temp/abalone5', 'temp/abalone6', 'temp/abalone7', 'temp/abalone8', 'temp/abalone9', 'temp/abalone10', 'temp/abalone11', 'temp/abalone12', 'temp/abalone13', 'temp/abalone14', 'temp/abalone15', 'temp/abalone16', 'temp/abalone17', 'temp/abalone18', 'temp/abalone19', 'temp/abalone20', 'temp/abalone21', 'temp/abalone22', 'temp/abalone23', 'temp/abalone24', 'temp/abalone25', 'temp/abalone26', 'temp/abalone27', 'temp/abalone28', 'temp/abalone29', 'temp/abalone30', 'temp/abalone31', 'temp/abalone32', 'temp/abalone33', 'temp/abalone34', 'temp/abalone35', 'temp/abalone36', 'temp/abalone37', 'temp/abalone38', 'temp/abalone39', 'temp/abalone40', 'temp/abalone41', 'temp/abalone42', 'temp/abalone43', 'temp/abalone44', 'temp/abalone45', 'temp/abalone46', 'temp/abalone47', 'temp/abalone48', 'temp/abalone49', 'temp/abalone50', 'temp/abalone51', 'temp/abalone52', 'temp/abalone53', 'temp/abalone54', 'temp/abalone55', 'temp/abalone56', 'temp/abalone57', 'temp/abalone58', 'temp/abalone59', 'temp/abalone60', 'temp/abalone61', 'temp/abalone62', 'temp/abalone63', 'temp/abalone64', 'temp/abalone65', 'temp/abalone66', 'temp/abalone67', 'temp/abalone68', 'temp/abalone69', 'temp/abalone70', 'temp/abalone71', 'temp/abalone72', 'temp/abalone73', 'temp/abalone74', 'temp/abalone75', 'temp/abalone76', 'temp/abalone77', 'temp/abalone78', 'temp/abalone79', 'temp/abalone80', 'temp/abalone81', 'temp/abalone82', 'temp/abalone83', 'temp/abalone84', 'temp/abalone85', 'temp/abalone86', 'temp/abalone87', 'temp/abalone88', 'temp/abalone89', 'temp/abalone90', 'temp/abalone91', 'temp/abalone92', 'temp/abalone93', 'temp/abalone94', 'temp/abalone95', 'temp/abalone96', 'temp/abalone97', 'temp/abalone98', 'temp/abalone99']\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"188pt\" viewBox=\"0.00 0.00 272.94 188.00\" width=\"273pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-184 268.9429,-184 268.9429,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- Length -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>Length</title>\n",
       "<ellipse cx=\"35.7468\" cy=\"-162\" fill=\"none\" rx=\"35.9954\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"35.7468\" y=\"-158.3\">Length</text>\n",
       "</g>\n",
       "<!-- Rings -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>Rings</title>\n",
       "<ellipse cx=\"115.7468\" cy=\"-90\" fill=\"none\" rx=\"31.3957\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"115.7468\" y=\"-86.3\">Rings</text>\n",
       "</g>\n",
       "<!-- Length&#45;&gt;Rings -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>Length-&gt;Rings</title>\n",
       "<path d=\"M61.2203,-139.0739C73.5209,-128.0033 87.9423,-115.0241 98.8634,-105.1951\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"58.593,-136.7296 53.5014,-146.0209 63.2758,-141.9327 58.593,-136.7296\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Sex -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>Sex</title>\n",
       "<ellipse cx=\"144.7468\" cy=\"-18\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144.7468\" y=\"-14.3\">Sex</text>\n",
       "</g>\n",
       "<!-- Length&#45;&gt;Sex -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>Length-&gt;Sex</title>\n",
       "<path d=\"M44.0123,-134.5357C50.5894,-115.6681 61.1265,-90.7417 75.7468,-72 89.2199,-54.729 109.3678,-39.8019 124.4184,-30.0465\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"40.6826,-133.4568 40.849,-144.0504 47.3252,-135.6652 40.6826,-133.4568\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Rings&#45;&gt;Sex -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>Rings-&gt;Sex</title>\n",
       "<path d=\"M122.9154,-72.2022C127.4105,-61.0419 133.1813,-46.7143 137.6607,-35.593\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Height -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>Height</title>\n",
       "<ellipse cx=\"123.7468\" cy=\"-162\" fill=\"none\" rx=\"34.394\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.7468\" y=\"-158.3\">Height</text>\n",
       "</g>\n",
       "<!-- Height&#45;&gt;Rings -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>Height-&gt;Rings</title>\n",
       "<path d=\"M120.6195,-133.8545C119.6701,-125.3097 118.6517,-116.1442 117.7927,-108.4133\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"117.1451,-134.2791 121.7281,-143.8314 124.1023,-133.506 117.1451,-134.2791\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Height&#45;&gt;Sex -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>Height-&gt;Sex</title>\n",
       "<path d=\"M142.5506,-136.6372C147.8985,-127.995 153.0106,-117.9845 155.7468,-108 162.4867,-83.4059 156.2914,-53.8981 150.8331,-35.5442\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"139.5608,-134.8134 136.9818,-145.0896 145.4062,-138.6646 139.5608,-134.8134\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Diameter -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>Diameter</title>\n",
       "<ellipse cx=\"220.7468\" cy=\"-162\" fill=\"none\" rx=\"44.393\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"220.7468\" y=\"-158.3\">Diameter</text>\n",
       "</g>\n",
       "<!-- Diameter&#45;&gt;Rings -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>Diameter-&gt;Rings</title>\n",
       "<path d=\"M189.3117,-140.4445C172.0354,-128.5979 151.1108,-114.2496 136.0016,-103.889\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"187.7367,-143.6083 197.9634,-146.3771 191.6955,-137.8352 187.7367,-143.6083\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Diameter&#45;&gt;Sex -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>Diameter-&gt;Sex</title>\n",
       "<path d=\"M206.5663,-135.1316C191.1568,-105.9346 166.9907,-60.1462 153.9048,-35.3519\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"203.6647,-137.1326 211.4277,-144.3428 209.8554,-133.8652 203.6647,-137.1326\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, \\\n",
    "                        Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "import keras.optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from pycausal import search as s\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from collections import defaultdict\n",
    "from numpy.polynomial.polynomial import polyfit  \n",
    "from scipy.stats import pearsonr\n",
    "from pylab import text\n",
    "from pycausal import prior as p\n",
    "import itertools\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# select your GPU Here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" #Comment this line out if you want all GPUS (2 hehe)\n",
    "\n",
    "# python full-display web browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "def examine_graph_continuous(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df,  scoreId = 'sem-bic', dataType = 'continuous',\n",
    "               structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, priorKnowledge = prior,\n",
    "               completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "               )\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def examine_graph_mixed(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 5,\n",
    "           structurePrior = 1.0, maxDegree = -1, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def examine_graph_discrete(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'bdeu', priorKnowledge = prior, dataType = 'discrete',\n",
    "               structurePrior = 1.0, samplePrior = 1.0, maxDegree = 3, faithfulnessAssumed = True, verbose = True)\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def normalize(a):\n",
    "    return (a - np.min(a)) / (np.max(a) - np.min(a))\n",
    "\n",
    "def make_categorical(df, complete_df, categoricals):   \n",
    "    retval = None\n",
    "    for key in df.columns:\n",
    "        if retval is not None:\n",
    "            if key in categoricals:\n",
    "                retval = np.concatenate((retval, to_categorical(df[key], len(complete_df[key].unique()))), axis = 1)\n",
    "            else:\n",
    "                retval = np.concatenate((retval, df[key].values[...,np.newaxis]), axis = 1)\n",
    "        else:\n",
    "            if key in categoricals:\n",
    "                retval = to_categorical(df[key], len(complete_df[key].unique()))\n",
    "            else:\n",
    "                retval = df[key]\n",
    "    return retval\n",
    "\n",
    "def get_model(dense, dropouts, inputs):\n",
    "    # dense is an ordered list of the number of dense neurons like [1024, 2048, 1024]\n",
    "    # dropouts is an ordered list of the dropout masks like [0.2, 0.3, 0.4]\n",
    "    inputs = keras.Input(shape = (inputs,))\n",
    "    x = keras.layers.Dense(dense[0], activation = 'relu')(inputs)\n",
    "    x = keras.layers.Dropout(dropouts[0])(x, training=True)\n",
    "    for den, drop in zip(dense[1:], dropouts[1:]):\n",
    "        x = keras.layers.Dense(den, activation = 'relu')(x)\n",
    "        x = keras.layers.Dropout(drop)(x, training=True)\n",
    "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_bic(df, prior, penalty = 2):\n",
    "\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 4,\n",
    "           structurePrior = 1.0, maxDegree = 3, faithfulnessAssumed = True, verbose = True)\n",
    "    \n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC\n",
    "\n",
    "num_models = 100     \n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '5000M')\n",
    "tetrad = s.tetradrunner()\n",
    "\n",
    "inputs = [\"Sex\", \"Length\", \"Diameter\"]\n",
    "target =  [\"Height\"]\n",
    "\n",
    "inputs = [\"Sex\", \"Length\", \"Diameter\", \"Height\"]\n",
    "target =  [\"Rings\"]\n",
    "categoricals = ['Sex'] \n",
    "\n",
    "\n",
    "df = pd.read_csv('~/Desktop/Kaggle/abalone.data', names = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Rings\"], usecols = [0, 1, 2, 3, 8])\n",
    "label_encoder_list = []\n",
    "#one_hot = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "for i,col in enumerate(['Sex']):\n",
    "    label_encoder_list.append(LabelEncoder())\n",
    "    df[col] = label_encoder_list[i].fit_transform(df[col].values)\n",
    "tempForbid = p.ForbiddenWithin(['Diameter', 'Height', 'Length'])\n",
    "temporal = [['Sex', 'Rings'], tempForbid]\n",
    "prior = p.knowledge(requiredirect= [('Sex', 'Height'),('Sex', 'Diameter'), ('Sex', 'Length')],\n",
    "                   addtemporal = temporal\n",
    "                   )\n",
    "\n",
    "g = examine_graph_mixed(df[inputs + target], prior = prior)\n",
    "dot_str = pc.tetradGraphToDot(g)\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "svg_str = graphs[0].create_svg()\n",
    "\n",
    "known_conx = set({})\n",
    "for i in tetrad.getEdges():\n",
    "    if ' --> ' in i:\n",
    "        known_conx.add((i.split(' --> ')[0], i.split(' --> ')[1]))\n",
    "\n",
    "\n",
    "prior = p.knowledge(requiredirect =  list(map(list, known_conx)),)\n",
    "\n",
    "n_holdout = 1000\n",
    "df['Rings'] = normalize(df['Rings'])\n",
    "\n",
    "\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "\n",
    "original_df = df.copy()\n",
    "randomize = False\n",
    "if randomize:\n",
    "    layers = [256, 512, 1024, 2048, 4096]\n",
    "    for i in range(num_models):\n",
    "        network = []\n",
    "        for j in range(3):\n",
    "            network.append(layers[random.randint(0,len(layers) -1)])\n",
    "        models.append(network)\n",
    "        model_names.append('temp/random' + str(i))\n",
    "    print(models, model_names)    \n",
    "else:\n",
    "    model_layers = [512,256]\n",
    "    for i in range(num_models):\n",
    "        models.append(model_layers)\n",
    "        model_names.append('temp/abalone' + str(i))\n",
    "\n",
    "print(models, model_names)\n",
    "SVG(svg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Occupation  Marital_Status  Purchase\n",
       "0       0    0          10               0      8370\n",
       "1       0    0          10               0     15200\n",
       "2       0    0          10               0      1422\n",
       "3       0    0          10               0      1057\n",
       "4       1    6          16               0      7969"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"332pt\" viewBox=\"0.00 0.00 256.86 332.00\" width=\"257pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-328 252.8598,-328 252.8598,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- Age -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>Age</title>\n",
       "<ellipse cx=\"135.6136\" cy=\"-306\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.6136\" y=\"-302.3\">Age</text>\n",
       "</g>\n",
       "<!-- Marital_Status -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>Marital_Status</title>\n",
       "<ellipse cx=\"77.6136\" cy=\"-162\" fill=\"none\" rx=\"63.0888\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.6136\" y=\"-158.3\">Marital_Status</text>\n",
       "</g>\n",
       "<!-- Age&#45;&gt;Marital_Status -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>Age-&gt;Marital_Status</title>\n",
       "<path d=\"M124.6827,-278.8614C113.0602,-250.0054 95.0006,-205.1679 84.9667,-180.256\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"121.5189,-280.3746 128.5016,-288.3428 128.012,-277.7593 121.5189,-280.3746\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Occupation -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>Occupation</title>\n",
       "<ellipse cx=\"102.6136\" cy=\"-90\" fill=\"none\" rx=\"51.1914\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"102.6136\" y=\"-86.3\">Occupation</text>\n",
       "</g>\n",
       "<!-- Age&#45;&gt;Occupation -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>Age-&gt;Occupation</title>\n",
       "<path d=\"M106.9772,-288.5322C75.3258,-267.3552 26.1121,-228.4147 5.6136,-180 -.6247,-165.2662 -2.4944,-157.7935 5.6136,-144 17.9201,-123.0639 41.6105,-109.6554 62.4975,-101.4362\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"105.1126,-291.4947 115.4003,-294.0272 108.9373,-285.6319 105.1126,-291.4947\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Purchase -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>Purchase</title>\n",
       "<ellipse cx=\"206.6136\" cy=\"-18\" fill=\"none\" rx=\"42.4939\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.6136\" y=\"-14.3\">Purchase</text>\n",
       "</g>\n",
       "<!-- Age&#45;&gt;Purchase -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>Age-&gt;Purchase</title>\n",
       "<path d=\"M167.1131,-290.7725C181.9982,-281.7502 198.2963,-268.7754 206.6136,-252 242.7953,-179.024 222.3017,-76.8208 211.7153,-35.9361\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.0831,-287.9001 158.1116,-295.8781 168.5366,-293.9889 165.0831,-287.9001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Gender -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>Gender</title>\n",
       "<ellipse cx=\"161.6136\" cy=\"-234\" fill=\"none\" rx=\"36.2938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.6136\" y=\"-230.3\">Gender</text>\n",
       "</g>\n",
       "<!-- Age&#45;&gt;Gender -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>Age-&gt;Gender</title>\n",
       "<path d=\"M145.5285,-278.5431C148.7603,-269.5938 152.2619,-259.8968 155.1704,-251.8425\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"142.1451,-277.6079 142.0405,-288.2022 148.729,-279.9855 142.1451,-277.6079\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Marital_Status&#45;&gt;Occupation -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>Marital_Status-&gt;Occupation</title>\n",
       "<path d=\"M83.9221,-143.8314C87.7409,-132.8334 92.591,-118.865 96.3936,-107.9134\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Occupation&#45;&gt;Purchase -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>Occupation-&gt;Purchase</title>\n",
       "<path d=\"M125.9532,-73.8418C143.4405,-61.7352 167.2166,-45.2748 184.4206,-33.3644\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Gender&#45;&gt;Marital_Status -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>Gender-&gt;Marital_Status</title>\n",
       "<path d=\"M143.3868,-218.3771C129.8762,-206.7966 111.4719,-191.0214 97.567,-179.1029\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Gender&#45;&gt;Occupation -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>Gender-&gt;Occupation</title>\n",
       "<path d=\"M162.201,-215.9208C162.1407,-197.1305 160.1283,-167.2713 149.6136,-144 143.2678,-129.9555 132.0424,-116.8472 122.1533,-107.0632\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Gender&#45;&gt;Purchase -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>Gender-&gt;Purchase</title>\n",
       "<path d=\"M165.3728,-215.9555C173.8434,-175.2967 194.343,-76.8988 202.8333,-36.1451\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def examine_graph_mixed(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 5,\n",
    "           structurePrior = 1.0, maxDegree = -1, faithfulnessAssumed = True, verbose = True,\n",
    "              penalty = 200)\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "\n",
    "df = pd.read_csv('~/Desktop/Kaggle/BlackFriday.csv')\n",
    "df.head()\n",
    "df =df[['Gender', 'Age', 'Occupation', 'Marital_Status', 'Purchase']]\n",
    "\n",
    "for i,col in enumerate(['Gender', 'Age']):\n",
    "    label_encoder_list.append(LabelEncoder())\n",
    "    df[col] = label_encoder_list[i].fit_transform(df[col].values)\n",
    "tempForbid = p.ForbiddenWithin(['Age', 'Gender'])\n",
    "temporal = [tempForbid, ['Occupation', 'Marital_Status'], ['Purchase']]\n",
    "prior = p.knowledge(addtemporal = temporal\n",
    "                   )\n",
    "\n",
    "g = examine_graph_mixed(df, prior = None)\n",
    "dot_str = pc.tetradGraphToDot(g)\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "svg_str = graphs[0].create_svg()\n",
    "\n",
    "SVG(svg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Diameter\n",
      "MSE =  0.08194892634863833\n",
      "BIC =  0.07715322661912069\n",
      "COMB =  0.07282090664841236\n",
      "1 1 Diameter\n",
      "MSE =  0.09523481511324645\n",
      "BIC =  0.09408688411422605\n",
      "COMB =  0.09406886297065234\n",
      "2 0 Length\n"
     ]
    }
   ],
   "source": [
    "bestMSE = []\n",
    "bestBIC = []\n",
    "bestCOMBO = []\n",
    "\n",
    "for t in range(100):\n",
    "    # let's split our df into two by race.  Let's see what happens if we \n",
    "    df = original_df.copy()\n",
    "\n",
    "    #df_test = df[df['Height'] < 0.13].copy()\n",
    "\n",
    "    '''\n",
    "    Good ones\n",
    "    #df_test = df.nsmallest(n_holdout, 'Height').copy()\n",
    "    #df_test = df.nlargest(n_holdout, 'Height').copy()\n",
    "    df_test = df.nsmallest(n_holdout, 'Length').copy()\n",
    "    df_test = df.nlargest(n_holdout, 'Length').copy()\n",
    "    df_test = df[df['Sex'] == 0].copy()\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    bad ones\n",
    "    df_test = df[df['Sex'] == 1][:n_holdout].copy()\n",
    "    df_test = df[df['Sex'] == 2].copy()\n",
    "    df_test = df[df['Sex'] == 1].copy()\n",
    "    '''\n",
    "    #df_test = df.nsmallest(n_holdout, 'Length').copy()\n",
    "\n",
    "    holdout = 800\n",
    "        #df_test = df[df['charges'] > 0.54].copy()\n",
    "    continuous = [\"Length\",  \"Diameter\", \"Height\", \"Rings\"]\n",
    "    \n",
    "    small = random.randint(0,1)\n",
    "    cont = random.randint(0, len(continuous) - 1)\n",
    "    if small == 0:\n",
    "        df_test = df.nsmallest(holdout, continuous[cont])\n",
    "    else:\n",
    "        df_test = df.nlargest(holdout, continuous[cont])\n",
    "    \n",
    "    print(t, small, continuous[cont])\n",
    "\n",
    "    '''\n",
    "    end_idx = len(df) - holdout\n",
    "    cont = random.randint(0, len(continuous) - 1)\n",
    "    start_idx = random.randint(0, end_idx)\n",
    "    print(t, \"Doing range:\",start_idx, start_idx + holdout, \"and \", continuous[cont])\n",
    "    df_test = df.nlargest(len(df) - start_idx, continuous[cont]).nsmallest(holdout, continuous[cont])\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    df.drop(df_test.index, inplace = True)\n",
    "    df_test.reset_index(inplace = True)\n",
    "    df.sample(frac= 1).reset_index(inplace = True) # this will shuffle and reset index\n",
    "\n",
    "    x_test = df_test[inputs]\n",
    "    y_test = df_test[target]\n",
    "\n",
    "    causal_split = 0.2\n",
    "    val_split = 0.2\n",
    "    train_split = 1 - (causal_split + val_split)\n",
    "\n",
    "    x_causal = df[inputs][-int(causal_split * len(df)) :]\n",
    "    y_causal = df[target][-int(causal_split * len(df)) :]\n",
    "\n",
    "    x_val = df[inputs][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "    y_val = df[target][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "\n",
    "    x_train = df[inputs][:int(train_split * len(df))]\n",
    "    y_train = df[target][:int(train_split * len(df))]\n",
    "    len(x_causal), len(y_causal), len(x_val), len(y_val), len(x_train), len(y_train)\n",
    "\n",
    "\n",
    "\n",
    "    x_test_NN = make_categorical(x_test, original_df, categoricals)\n",
    "    x_causal_NN = make_categorical(x_causal, original_df, categoricals)\n",
    "    x_val_NN = make_categorical(x_val, original_df, categoricals)\n",
    "    x_train_NN = make_categorical(x_train, original_df, categoricals)\n",
    "\n",
    "    verbosity = 0\n",
    "\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        #print(model_name)\n",
    "\n",
    "        if type(models[idx]) is list:\n",
    "            #clear session\n",
    "            keras.backend.clear_session() \n",
    "            #get model according to specification\n",
    "            model = get_model(models[idx], [0.2] * len(models), np.shape(x_train_NN)[1])\n",
    "            callbacks = [ModelCheckpoint(model_name, verbose= verbosity, monitor='val_loss',save_best_only=True), \n",
    "                         EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose= verbosity, mode='auto')]\n",
    "            model.compile(optimizer = optimizers.SGD(lr = 0.0001, momentum = 0.9, ), loss='mean_squared_error', metrics = ['mse'])\n",
    "            #print(len(X), len(y))\n",
    "            model.fit(x_train_NN, y_train, epochs = 20, validation_data = (x_val_NN, y_val), callbacks = callbacks, batch_size = 32, verbose = verbosity)\n",
    "        else:\n",
    "            models[idx].fit(X,y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    generalization = []\n",
    "    metrics = []\n",
    "    proposed = []\n",
    "    x_causal.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        #print(model_name)\n",
    "        if type(models[idx]) is list:\n",
    "            keras.backend.clear_session()\n",
    "            model = load_model(model_name)\n",
    "        else:\n",
    "            model = models[idx]\n",
    "\n",
    "        y_pred = model.predict(x_test_NN)\n",
    "        generalization.append(mean_absolute_error(y_pred, y_test))\n",
    "\n",
    "        #### CHECK FOR CAUSAL METRIC HERE\n",
    "        y_causal_pred = model.predict(x_causal_NN)\n",
    "        causal_targets = pd.DataFrame(y_causal_pred, columns = target)\n",
    "        causal_targets.reset_index(drop=True, inplace = True)\n",
    "        causal_df = x_causal.join(causal_targets)\n",
    "\n",
    "\n",
    "\n",
    "        metrics.append(mean_absolute_error(y_causal_pred, y_causal))\n",
    "        #print(x_causal.head)\n",
    "        bic_pred = get_bic(causal_df, prior)\n",
    "        #print(bic_pred, tetrad.getEdges())\n",
    "\n",
    "        found_conx = set({})\n",
    "        for i in tetrad.getEdges():\n",
    "            if ' --> ' in i:\n",
    "                found_conx.add((i.split(' --> ')[0], i.split(' --> ')[1]))\n",
    "        found_conx\n",
    "\n",
    "        if found_conx == known_conx:\n",
    "            proposed.append(bic_pred)\n",
    "        else:\n",
    "            print(\"******Found an error\")\n",
    "            # for now just remove bad model.  Will need to add it to distance metric.\n",
    "            metrics = metrics[:-1]\n",
    "            generalization = generalization[:-1]\n",
    "    total = normalize(metrics) + normalize(proposed)\n",
    "    nbest = 10\n",
    "    final = pd.DataFrame(np.stack((metrics, proposed, total, generalization), axis = 1), columns = ['metrics', 'proposed', 'combined', 'generalization'])\n",
    "    print(\"MSE = \", np.mean(final.nsmallest(nbest, 'metrics')['generalization']))\n",
    "    print(\"BIC = \", np.mean(final.nsmallest(nbest, 'proposed')['generalization']))\n",
    "    print(\"COMB = \",np.mean(final.nsmallest(nbest, 'combined')['generalization']))\n",
    "    bestMSE.append(final.nsmallest(nbest, 'metrics')['generalization'])\n",
    "    bestBIC.append(final.nsmallest(nbest, 'proposed')['generalization'])\n",
    "    bestCOMBO.append(final.nsmallest(nbest, 'combined')['generalization'])\n",
    "    \n",
    "\n",
    "np.mean(bestMSE), np.mean(bestBIC), np.mean(bestCOMBO), np.std(bestMSE), np.std(bestCOMBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestMSE = [0.009634, 0.005965, 0.006659, 0.008800, 0.006828, 0.005964, 0.008231, 0.008416, 0.007061, 0.007471]\n",
    "np.mean(bestMSE), np.mean(bestBIC), np.mean(bestCOMBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test) + len(x_train) + len(x_val) + len(x_causal), len(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(proposed,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(proposed,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(proposed,generalization, '.')\n",
    "plt.plot(proposed, b + m * np.array(proposed), '-')\n",
    "ax.set_xlabel(\"BIC\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(metrics,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(metrics,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(metrics,generalization, '.')\n",
    "plt.plot(metrics, b + m * np.array(metrics), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "total = normalize(metrics) + normalize(proposed)\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(total,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(total,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(total,generalization, '.')\n",
    "plt.plot(total, b + m * np.array(total), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest = 5\n",
    "final = pd.DataFrame(np.stack((metrics, proposed, total, generalization), axis = 1), columns = ['metrics', 'proposed', 'combined', 'generalization'])\n",
    "print(\"MSE = \", np.sum(final.nsmallest(nbest, 'metrics')['generalization']))\n",
    "print(\"BIC = \", np.sum(final.nsmallest(nbest, 'proposed')['generalization']))\n",
    "print(\"COMB = \",np.sum(final.nsmallest(nbest, 'combined')['generalization']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
