{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, \\\n",
    "                        Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "import keras.optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, mean_absolute_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from pycausal import search as s\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from collections import defaultdict\n",
    "from numpy.polynomial.polynomial import polyfit  \n",
    "from scipy.stats import pearsonr\n",
    "from pylab import text\n",
    "from pycausal import prior as p\n",
    "import itertools\n",
    "\n",
    "# select your GPU Here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" #Comment this line out if you want all GPUS (2 hehe)\n",
    "\n",
    "# python full-display web browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def gen_data(mean = 0, var = 1, SIZE = 20000):\n",
    "    a = np.random.normal(mean, var, SIZE)\n",
    "    b = a + np.random.normal(mean, var, SIZE)\n",
    "    c =  a + b + np.random.normal(mean, var, SIZE)\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c})\n",
    "\n",
    "def get_model(dense, dropouts, inputs):\n",
    "    # dense is an ordered list of the number of dense neurons like [1024, 2048, 1024]\n",
    "    # dropouts is an ordered list of the dropout masks like [0.2, 0.3, 0.4]\n",
    "    inputs = keras.Input(shape = (inputs,))\n",
    "    x = keras.layers.Dense(dense[0], activation = 'relu')(inputs)\n",
    "    #x = keras.layers.Dropout(dropouts[0])(x, training=True)\n",
    "    for den, drop in zip(dense[1:], dropouts[1:]):\n",
    "        x = keras.layers.Dense(den, activation = 'relu')(x)\n",
    "        #x = keras.layers.Dropout(drop)(x, training=True)\n",
    "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_bic(df, prior, penalty = 2):\n",
    "\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 4,\n",
    "           structurePrior = 1.0, maxDegree = 3, faithfulnessAssumed = True, verbose = True)\n",
    "    \n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC #/ len(df)\n",
    "\n",
    "def make_categorical(df, complete_df, categoricals):   \n",
    "    retval = None\n",
    "    for key in df.columns:\n",
    "        if retval is not None:\n",
    "            if key in categoricals:\n",
    "                retval = np.concatenate((retval, to_categorical(df[key], len(complete_df[key].unique()))), axis = 1)\n",
    "            else:\n",
    "                retval = np.concatenate((retval, df[key].values[...,np.newaxis]), axis = 1)\n",
    "        else:\n",
    "            if key in categoricals:\n",
    "                retval = to_categorical(df[key], len(complete_df[key].unique()))\n",
    "            else:\n",
    "                retval = df[key]\n",
    "    return retval\n",
    "num_models = 100       \n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '21000M')\n",
    "tetrad = s.tetradrunner()\n",
    "\n",
    "inputs = ['gender', 'race', 'lunch', 'test_preparation_course', 'education', 'reading_score', 'writing_score']\n",
    "#inputs = ['gender', 'race', 'lunch', 'test_preparation_course', 'education']#, 'math_score', 'writing_score']\n",
    "target = ['math_score']\n",
    "categoricals = ['gender', 'race', 'education', 'lunch', 'test_preparation_course'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  race  education  lunch  test_preparation_course  math_score  \\\n",
       "0       0     1          1      1                        1        0.72   \n",
       "1       0     2          4      1                        0        0.69   \n",
       "2       0     1          3      1                        1        0.90   \n",
       "3       1     0          0      0                        1        0.47   \n",
       "4       1     2          4      1                        1        0.76   \n",
       "\n",
       "   reading_score  writing_score  \n",
       "0       0.662651       0.711111  \n",
       "1       0.879518       0.866667  \n",
       "2       0.939759       0.922222  \n",
       "3       0.481928       0.377778  \n",
       "4       0.734940       0.722222  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "df = pd.read_csv('~/Desktop/Kaggle/students-performance-in-exams/StudentsPerformance.csv')\n",
    "# Prior knowledge knows that the test prep comes before the outcome.\n",
    "df = df.rename(index=str, columns={\"reading score\": \"reading_score\", \"writing score\": \"writing_score\",  \"math score\": \"math_score\",\n",
    "                              \"test preparation course\": \"test_preparation_course\", \"parental level of education\": \"education\", \"race/ethnicity\" : \"race\"\n",
    "                             })\n",
    "#return a list of encoders and an updated dataframe\n",
    "label_encoder_list = []\n",
    "#one_hot = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "for i,col in enumerate(categoricals):\n",
    "    label_encoder_list.append(LabelEncoder())\n",
    "    df[col] = label_encoder_list[i].fit_transform(df[col].values)\n",
    "def normalize(a):\n",
    "    return (a - np.min(a)) / (np.max(a) - np.min(a))\n",
    "df['math_score'] = normalize(df['math_score'])\n",
    "df['writing_score'] = normalize(df['writing_score'])\n",
    "df['reading_score'] = normalize(df['reading_score'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256]] ['temp/school0', 'temp/school1', 'temp/school2', 'temp/school3', 'temp/school4', 'temp/school5', 'temp/school6', 'temp/school7', 'temp/school8', 'temp/school9', 'temp/school10', 'temp/school11', 'temp/school12', 'temp/school13', 'temp/school14', 'temp/school15', 'temp/school16', 'temp/school17', 'temp/school18', 'temp/school19', 'temp/school20', 'temp/school21', 'temp/school22', 'temp/school23', 'temp/school24', 'temp/school25', 'temp/school26', 'temp/school27', 'temp/school28', 'temp/school29', 'temp/school30', 'temp/school31', 'temp/school32', 'temp/school33', 'temp/school34', 'temp/school35', 'temp/school36', 'temp/school37', 'temp/school38', 'temp/school39', 'temp/school40', 'temp/school41', 'temp/school42', 'temp/school43', 'temp/school44', 'temp/school45', 'temp/school46', 'temp/school47', 'temp/school48', 'temp/school49', 'temp/school50', 'temp/school51', 'temp/school52', 'temp/school53', 'temp/school54', 'temp/school55', 'temp/school56', 'temp/school57', 'temp/school58', 'temp/school59', 'temp/school60', 'temp/school61', 'temp/school62', 'temp/school63', 'temp/school64', 'temp/school65', 'temp/school66', 'temp/school67', 'temp/school68', 'temp/school69', 'temp/school70', 'temp/school71', 'temp/school72', 'temp/school73', 'temp/school74', 'temp/school75', 'temp/school76', 'temp/school77', 'temp/school78', 'temp/school79', 'temp/school80', 'temp/school81', 'temp/school82', 'temp/school83', 'temp/school84', 'temp/school85', 'temp/school86', 'temp/school87', 'temp/school88', 'temp/school89', 'temp/school90', 'temp/school91', 'temp/school92', 'temp/school93', 'temp/school94', 'temp/school95', 'temp/school96', 'temp/school97', 'temp/school98', 'temp/school99']\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"260pt\" viewBox=\"0.00 0.00 276.17 260.00\" width=\"276pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-256 272.1679,-256 272.1679,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- gender -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>gender</title>\n",
       "<ellipse cx=\"64.9743\" cy=\"-234\" fill=\"none\" rx=\"34.394\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.9743\" y=\"-230.3\">gender</text>\n",
       "</g>\n",
       "<!-- writing_score -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>writing_score</title>\n",
       "<ellipse cx=\"133.9743\" cy=\"-18\" fill=\"none\" rx=\"59.2899\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.9743\" y=\"-14.3\">writing_score</text>\n",
       "</g>\n",
       "<!-- gender&#45;&gt;writing_score -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>gender-&gt;writing_score</title>\n",
       "<path d=\"M41.6095,-220.4601C27.8609,-211.0577 11.6979,-197.1524 3.9743,-180 -2.5951,-165.4108 1.2158,-159.7604 3.9743,-144 9.8399,-110.4869 7.5606,-97.596 29.9743,-72 44.249,-55.6986 64.6472,-43.6145 83.6029,-35.0601\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"85.23,-38.171 93.0505,-31.0233 82.4796,-31.734 85.23,-38.171\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- reading_score -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>reading_score</title>\n",
       "<ellipse cx=\"194.9743\" cy=\"-162\" fill=\"none\" rx=\"59.5901\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.9743\" y=\"-158.3\">reading_score</text>\n",
       "</g>\n",
       "<!-- gender&#45;&gt;reading_score -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>gender-&gt;reading_score</title>\n",
       "<path d=\"M88.8183,-220.7941C108.0168,-210.1611 135.3526,-195.0213 157.4765,-182.768\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"159.2372,-185.7939 166.2893,-177.8871 155.8457,-179.6703 159.2372,-185.7939\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- math_score -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>math_score</title>\n",
       "<ellipse cx=\"64.9743\" cy=\"-162\" fill=\"none\" rx=\"51.9908\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.9743\" y=\"-158.3\">math_score</text>\n",
       "</g>\n",
       "<!-- gender&#45;&gt;math_score -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>gender-&gt;math_score</title>\n",
       "<path d=\"M64.9743,-215.8314C64.9743,-208.131 64.9743,-198.9743 64.9743,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"68.4744,-190.4132 64.9743,-180.4133 61.4744,-190.4133 68.4744,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- test_preparation_course -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>test_preparation_course</title>\n",
       "<ellipse cx=\"133.9743\" cy=\"-90\" fill=\"none\" rx=\"94.7833\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.9743\" y=\"-86.3\">test_preparation_course</text>\n",
       "</g>\n",
       "<!-- reading_score&#45;&gt;test_preparation_course -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>reading_score-&gt;test_preparation_course</title>\n",
       "<path d=\"M173.4127,-136.5502C165.3747,-127.0628 156.4283,-116.5031 149.0909,-107.8425\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"170.761,-138.8348 179.8956,-144.2022 176.1019,-134.3099 170.761,-138.8348\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- lunch -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>lunch</title>\n",
       "<ellipse cx=\"194.9743\" cy=\"-234\" fill=\"none\" rx=\"30.5947\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.9743\" y=\"-230.3\">lunch</text>\n",
       "</g>\n",
       "<!-- lunch&#45;&gt;writing_score -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>lunch-&gt;writing_score</title>\n",
       "<path d=\"M218.8914,-222.5782C234.885,-213.4998 254.6465,-199.1447 263.9743,-180 270.9823,-165.6164 266.7328,-159.7604 263.9743,-144 258.1087,-110.4869 260.388,-97.596 237.9743,-72 223.6996,-55.6986 203.3014,-43.6145 184.3457,-35.0601\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"185.469,-31.734 174.8981,-31.0233 182.7186,-38.171 185.469,-31.734\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- lunch&#45;&gt;reading_score -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>lunch-&gt;reading_score</title>\n",
       "<path d=\"M194.9743,-215.8314C194.9743,-208.131 194.9743,-198.9743 194.9743,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"198.4744,-190.4132 194.9743,-180.4133 191.4744,-190.4133 198.4744,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- lunch&#45;&gt;math_score -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>lunch-&gt;math_score</title>\n",
       "<path d=\"M172.6265,-221.6228C153.1437,-210.8323 124.5076,-194.9723 101.667,-182.3221\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"103.3561,-179.2567 92.9125,-177.4734 99.9646,-185.3803 103.3561,-179.2567\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- math_score&#45;&gt;test_preparation_course -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>math_score-&gt;test_preparation_course</title>\n",
       "<path d=\"M88.802,-137.1363C98.0629,-127.4727 108.4619,-116.6217 116.9458,-107.7689\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"86.0694,-134.9292 81.6773,-144.5708 91.1233,-139.7726 86.0694,-134.9292\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- test_preparation_course&#45;&gt;writing_score -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>test_preparation_course-&gt;writing_score</title>\n",
       "<path d=\"M133.9743,-71.8314C133.9743,-64.131 133.9743,-54.9743 133.9743,-46.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"137.4744,-46.4132 133.9743,-36.4133 130.4744,-46.4133 137.4744,-46.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "from IPython.display import SVG\n",
    "def examine_graph_continuous(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df,  scoreId = 'sem-bic', dataType = 'continuous',\n",
    "               structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, priorKnowledge = prior,\n",
    "               completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "               )\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def examine_graph_mixed(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 5,\n",
    "           structurePrior = 1.0, maxDegree = -1, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def examine_graph_discrete(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'bdeu', priorKnowledge = prior, dataType = 'discrete',\n",
    "               structurePrior = 1.0, samplePrior = 1.0, maxDegree = 3, faithfulnessAssumed = True, verbose = True)\n",
    "    return tetrad.getTetradGraph()\n",
    "    \n",
    "    \n",
    "\n",
    "tempForbid = p.ForbiddenWithin(['reading_score', 'writing_score', 'math_score'])\n",
    "temporal = [[ 'race', 'lunch', 'test_preparation_course', 'gender', 'education'], tempForbid]\n",
    "prior = p.knowledge( addtemporal = temporal)\n",
    "\n",
    "g = examine_graph_mixed(df[inputs + target], prior = prior)\n",
    "dot_str = pc.tetradGraphToDot(g)\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "svg_str = graphs[0].create_svg()\n",
    "\n",
    "known_conx = set({})\n",
    "for i in tetrad.getEdges():\n",
    "    if ' --> ' in i:\n",
    "        known_conx.add((i.split(' --> ')[0], i.split(' --> ')[1]))\n",
    "known_conx\n",
    "\n",
    "prior = p.knowledge(requiredirect =  list(map(list, known_conx)),)\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "\n",
    "\n",
    "randomize = False\n",
    "if randomize:\n",
    "    layers = [256, 512, 1024, 2048, 4096]\n",
    "    for i in range(num_models):\n",
    "        network = []\n",
    "        for j in range(3):\n",
    "            network.append(layers[random.randint(0,len(layers) -1)])\n",
    "        models.append(network)\n",
    "        model_names.append('temp/random' + str(i))\n",
    "    print(models, model_names)    \n",
    "else:\n",
    "    model_layers = [512,256]\n",
    "    for i in range(num_models):\n",
    "        models.append(model_layers)\n",
    "        model_names.append('temp/school' + str(i))\n",
    "\n",
    "print(models, model_names)\n",
    "\n",
    "SVG(svg_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Doing range: 512 712 and  math_score\n",
      "MSE =  0.6342100299060344\n",
      "BIC =  0.7944383990406988\n",
      "COMB =  0.7253553108215332\n",
      "1 Doing range: 461 661 and  writing_score\n",
      "MSE =  0.7856717961549758\n",
      "BIC =  0.9759001307725905\n",
      "COMB =  0.8923502720713615\n",
      "2 Doing range: 700 900 and  writing_score\n",
      "MSE =  0.9936210300564766\n",
      "BIC =  1.1329740822911265\n",
      "COMB =  1.0131272371292115\n",
      "3 Doing range: 766 966 and  math_score\n",
      "MSE =  1.7151555272459984\n",
      "BIC =  1.7309568705558775\n",
      "COMB =  1.6053211613893508\n",
      "4 Doing range: 419 619 and  reading_score\n",
      "MSE =  0.6932276688218117\n",
      "BIC =  0.8950238796889781\n",
      "COMB =  0.7285467846691608\n",
      "5 Doing range: 678 878 and  math_score\n",
      "MSE =  1.128899722790718\n",
      "BIC =  1.243970945584774\n",
      "COMB =  1.1295229789972305\n",
      "6 Doing range: 83 283 and  math_score\n",
      "MSE =  1.0879861301779745\n",
      "BIC =  1.1144861718833448\n",
      "COMB =  1.0764633140444755\n",
      "7 Doing range: 112 312 and  reading_score\n",
      "MSE =  0.9774165574073791\n",
      "BIC =  1.0190946541249752\n",
      "COMB =  0.9993323969364166\n",
      "8 Doing range: 305 505 and  math_score\n",
      "MSE =  0.5787837378740311\n",
      "BIC =  0.7755267191171646\n",
      "COMB =  0.6778305001735688\n",
      "9 Doing range: 347 547 and  writing_score\n",
      "MSE =  0.7696974080562591\n",
      "BIC =  0.8785308717608451\n",
      "COMB =  0.8065774155616761\n",
      "10 Doing range: 215 415 and  math_score\n",
      "MSE =  0.7160959284722805\n",
      "BIC =  0.9154759732127191\n",
      "COMB =  0.8307669337272645\n",
      "11 Doing range: 141 341 and  math_score\n",
      "MSE =  0.915219113111496\n",
      "BIC =  1.0045992979645728\n",
      "COMB =  0.9344602143406867\n",
      "12 Doing range: 528 728 and  reading_score\n",
      "MSE =  0.8141858001351356\n",
      "BIC =  0.9570883014678957\n",
      "COMB =  0.8567914398789406\n",
      "13 Doing range: 631 831 and  writing_score\n",
      "MSE =  0.9243747049748897\n",
      "BIC =  1.0964570438265802\n",
      "COMB =  0.9551389667212964\n",
      "14 Doing range: 26 226 and  writing_score\n",
      "MSE =  1.2283408904254438\n",
      "BIC =  1.1593244541168213\n",
      "COMB =  1.215692944663763\n",
      "15 Doing range: 519 719 and  writing_score\n",
      "MSE =  0.8290287752568721\n",
      "BIC =  1.0404489984631538\n",
      "COMB =  0.8827170434117317\n",
      "16 Doing range: 94 294 and  reading_score\n",
      "MSE =  0.964843290889263\n",
      "BIC =  1.0727838932693006\n",
      "COMB =  0.9895619162499905\n",
      "17 Doing range: 143 343 and  math_score\n",
      "MSE =  0.9137998270392418\n",
      "BIC =  0.9673648086488247\n",
      "COMB =  0.9490080360472202\n",
      "18 Doing range: 291 491 and  math_score\n",
      "MSE =  0.6220619961857796\n",
      "BIC =  0.7976784854352474\n",
      "COMB =  0.6525661697566509\n",
      "19 Doing range: 125 325 and  math_score\n",
      "MSE =  0.9666536287605765\n",
      "BIC =  1.0278864822506903\n",
      "COMB =  0.9771279062092305\n",
      "20 Doing range: 38 238 and  math_score\n",
      "MSE =  1.4322252935945987\n",
      "BIC =  1.3243349672138691\n",
      "COMB =  1.3007055554628373\n",
      "21 Doing range: 196 396 and  writing_score\n",
      "MSE =  0.819998832809925\n",
      "BIC =  0.9862204310774804\n",
      "COMB =  0.8567371677160264\n",
      "22 Doing range: 50 250 and  writing_score\n",
      "MSE =  1.0608160723268985\n",
      "BIC =  1.1055824984371663\n",
      "COMB =  1.059214903306961\n",
      "23 Doing range: 646 846 and  math_score\n",
      "MSE =  1.0346175176322463\n",
      "BIC =  1.1869147275567058\n",
      "COMB =  1.0525702675879003\n",
      "24 Doing range: 247 447 and  math_score\n",
      "MSE =  0.6569623942434789\n",
      "BIC =  0.819253266119957\n",
      "COMB =  0.7394050991654396\n",
      "25 Doing range: 265 465 and  math_score\n",
      "MSE =  0.673237392538786\n",
      "BIC =  0.836946939098835\n",
      "COMB =  0.7814447943806648\n",
      "26 Doing range: 417 617 and  math_score\n",
      "MSE =  0.5314862608730793\n",
      "BIC =  0.7318217096149922\n",
      "COMB =  0.5912983734309674\n",
      "27 Doing range: 763 963 and  math_score\n",
      "MSE =  1.6213971947848795\n",
      "BIC =  1.749326343232393\n",
      "COMB =  1.6057088021934034\n",
      "28 Doing range: 315 515 and  math_score\n",
      "MSE =  0.5780206900894641\n",
      "BIC =  0.7981253790676593\n",
      "COMB =  0.6481476202011108\n",
      "29 Doing range: 509 709 and  reading_score\n",
      "MSE =  0.7668382633149625\n",
      "BIC =  0.9218390451550483\n",
      "COMB =  0.8068584487557412\n",
      "30 Doing range: 697 897 and  math_score\n",
      "MSE =  1.2368114942491055\n",
      "BIC =  1.292293742364645\n",
      "COMB =  1.2142198555231094\n",
      "31 Doing range: 644 844 and  reading_score\n",
      "MSE =  0.9916000629007817\n",
      "BIC =  1.1089622632324696\n",
      "COMB =  1.0102366778671743\n",
      "32 Doing range: 521 721 and  math_score\n",
      "MSE =  0.6679538274824618\n",
      "BIC =  0.7575709409356117\n",
      "COMB =  0.6919235164880752\n",
      "33 Doing range: 269 469 and  math_score\n",
      "MSE =  0.617018988275528\n",
      "BIC =  0.7836471207380296\n",
      "COMB =  0.6624697010457516\n",
      "34 Doing range: 626 826 and  writing_score\n",
      "MSE =  0.959678796863556\n",
      "BIC =  1.0403755843400955\n",
      "COMB =  0.9755681128084658\n",
      "35 Doing range: 349 549 and  reading_score\n",
      "MSE =  0.6757797272741793\n",
      "BIC =  0.8325484892010688\n",
      "COMB =  0.7576478433728218\n",
      "36 Doing range: 394 594 and  writing_score\n",
      "MSE =  0.8402752867877483\n",
      "BIC =  0.9593604932129385\n",
      "COMB =  0.8750166745841503\n",
      "37 Doing range: 69 269 and  reading_score\n",
      "MSE =  1.048643234372139\n",
      "BIC =  1.0861068658590316\n",
      "COMB =  1.0531267680823801\n",
      "38 Doing range: 713 913 and  writing_score\n",
      "MSE =  1.0115448513507843\n",
      "BIC =  1.2345762846052646\n",
      "COMB =  1.0897561232149602\n",
      "39 Doing range: 396 596 and  writing_score\n",
      "MSE =  0.8114066046714783\n",
      "BIC =  0.971885249698162\n",
      "COMB =  0.8489752826690673\n",
      "40 Doing range: 423 623 and  reading_score\n",
      "MSE =  0.7308605370521547\n",
      "BIC =  0.8676118275940419\n",
      "COMB =  0.7842519049823284\n",
      "41 Doing range: 174 374 and  reading_score\n",
      "MSE =  0.8551794120848178\n",
      "BIC =  0.9425275030553341\n",
      "COMB =  0.8845754909455776\n",
      "42 Doing range: 660 860 and  writing_score\n",
      "MSE =  0.9429341898202896\n",
      "BIC =  1.0650434099555017\n",
      "COMB =  0.9849266230583191\n",
      "43 Doing range: 8 208 and  writing_score\n",
      "MSE =  1.391235778582096\n",
      "BIC =  1.3507863480746747\n",
      "COMB =  1.2681826837778092\n",
      "44 Doing range: 222 422 and  reading_score\n",
      "MSE =  0.855799534344673\n",
      "BIC =  0.9762669590830804\n",
      "COMB =  0.9121879455983638\n",
      "45 Doing range: 591 791 and  reading_score\n",
      "MSE =  0.8363370412230491\n",
      "BIC =  1.01305213047266\n",
      "COMB =  0.89035122975111\n",
      "46 Doing range: 444 644 and  math_score\n",
      "MSE =  0.5769614070057868\n",
      "BIC =  0.6782267216563225\n",
      "COMB =  0.6014278378605842\n",
      "47 Doing range: 770 970 and  reading_score\n",
      "MSE =  1.4103814887344837\n",
      "BIC =  1.591323699390888\n",
      "COMB =  1.4173235773801804\n",
      "48 Doing range: 665 865 and  writing_score\n",
      "MSE =  0.9370501507401466\n",
      "BIC =  1.0470617543339729\n",
      "COMB =  0.9811573950946331\n",
      "49 Doing range: 443 643 and  reading_score\n",
      "MSE =  0.7360914521992207\n",
      "BIC =  0.8757130227148532\n",
      "COMB =  0.8062202895641326\n",
      "50 Doing range: 316 516 and  math_score\n",
      "MSE =  0.5857289249539376\n",
      "BIC =  0.739528754156828\n",
      "COMB =  0.6178525049567223\n",
      "51 Doing range: 144 344 and  math_score\n"
     ]
    },
    {
     "ename": "JavaException",
     "evalue": "GC overhead limit exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0aaf8e8ed290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_causal_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m#print(x_causal.head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mbic_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcausal_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;31m#print(bic_pred, tetrad.getEdges())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-02c2282eeaf3>\u001b[0m in \u001b[0;36mget_bic\u001b[0;34m(df, prior, penalty)\u001b[0m\n\u001b[1;32m     77\u001b[0m     tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n\u001b[1;32m     78\u001b[0m            \u001b[0mpriorKnowledge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumCategoriesToDiscretize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m            structurePrior = 1.0, maxDegree = 3, faithfulnessAssumed = True, verbose = True)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mBIC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtetrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTetradGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAllAttributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pycausal/search.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, algoId, dfs, testId, scoreId, priorKnowledge, dataType, numCategoriesToDiscretize, **parameters)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mtetradData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadDiscreteData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mtetradData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadMixedData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumCategoriesToDiscretize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pycausal/pycausal.py\u001b[0m in \u001b[0;36mloadMixedData\u001b[0;34m(self, df, numCategoriesToDiscretize)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisc_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mcat_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjavabridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJClassWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.Integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                     \u001b[0mmixedDataBox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/javabridge/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mmsig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"(%s)V\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No matching constructor found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/javabridge/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnaame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/javabridge/jutil.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(jobject)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_javabridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJB_Object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toString'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'()Ljava/lang/String;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/javabridge/jutil.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(o, method_name, sig, *args)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0mret_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m')'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0mnice_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nice_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnice_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_occurred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/javabridge/jutil.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_occurred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mJavaException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJavaException\u001b[0m: GC overhead limit exceeded"
     ]
    }
   ],
   "source": [
    "\n",
    "bestMSE = []\n",
    "bestBIC = []\n",
    "bestCOMBO = []\n",
    "original_df = df.copy()\n",
    "for t in range(100):\n",
    "    # let's split our df into two by race.  Let's see what happens if we \n",
    "    df = original_df.copy()\n",
    "    \n",
    "    holdout = 200\n",
    "        #df_test = df[df['charges'] > 0.54].copy()\n",
    "    continuous = [\"reading_score\",  \"writing_score\", \"math_score\"]\n",
    "    #continuous = [\"math_score\"]\n",
    "    \n",
    "    \n",
    "    end_idx = len(df) - holdout\n",
    "    cont = random.randint(0, len(continuous) - 1)\n",
    "    start_idx = random.randint(0, end_idx)\n",
    "    print(t, \"Doing range:\",start_idx, start_idx + holdout, \"and \", continuous[cont])\n",
    "    df_test = df.nlargest(len(df) - start_idx, continuous[cont]).nsmallest(holdout, continuous[cont])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    small = random.randint(0,1)\n",
    "    cont = random.randint(0, len(continuous) - 1)\n",
    "    if small == 0:\n",
    "        df_test = df.nsmallest(holdout, continuous[cont])\n",
    "    else:\n",
    "        df_test = df.nlargest(holdout, continuous[cont])\n",
    "    print(t, small, continuous[cont])\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    df.drop(df_test.index, inplace = True)\n",
    "    df_test.reset_index(inplace = True)\n",
    "    df.sample(frac= 1).reset_index(inplace = True) # this will shuffle and reset index\n",
    "\n",
    "    x_test = df_test[inputs]\n",
    "    y_test = df_test[target]\n",
    "\n",
    "    causal_split = 0.2\n",
    "    val_split = 0.2\n",
    "    train_split = 1 - (causal_split + val_split)\n",
    "\n",
    "    x_causal = df[inputs][-int(causal_split * len(df)) :]\n",
    "    y_causal = df[target][-int(causal_split * len(df)) :]\n",
    "\n",
    "    x_val = df[inputs][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "    y_val = df[target][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "\n",
    "    x_train = df[inputs][:int(train_split * len(df))]\n",
    "    y_train = df[target][:int(train_split * len(df))]\n",
    "\n",
    "    x_test_NN = make_categorical(x_test, original_df, categoricals)\n",
    "    x_causal_NN = make_categorical(x_causal, original_df, categoricals)\n",
    "    x_val_NN = make_categorical(x_val, original_df, categoricals)\n",
    "    x_train_NN = make_categorical(x_train, original_df, categoricals)\n",
    "    verbosity = 0\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        if type(models[idx]) is list:\n",
    "            #clear session\n",
    "            keras.backend.clear_session() \n",
    "            #get model according to specification\n",
    "            model = get_model(models[idx], [0.2] * len(models), np.shape(x_train_NN)[1])\n",
    "            callbacks = [ModelCheckpoint(model_name, verbose= verbosity, monitor='val_loss',save_best_only=True), \n",
    "                         EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose= verbosity, mode='auto')]\n",
    "            model.compile(optimizer = optimizers.SGD(lr = 0.0001, momentum = 0.9, ), loss='mean_squared_error', metrics = ['mse'])\n",
    "            #print(len(X), len(y))\n",
    "            model.fit(x_train_NN, y_train, epochs = 20, validation_data = (x_val_NN, y_val), callbacks = callbacks, batch_size = 32, verbose = verbosity)\n",
    "        else:\n",
    "            models[idx].fit(X,y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    generalization = []\n",
    "    metrics = []\n",
    "    proposed = []\n",
    "    x_causal.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        #print(model_name)\n",
    "        if type(models[idx]) is list:\n",
    "            keras.backend.clear_session()\n",
    "            model = load_model(model_name)\n",
    "        else:\n",
    "            model = models[idx]\n",
    "\n",
    "        y_pred = model.predict(x_test_NN)\n",
    "        generalization.append(mean_absolute_error(y_pred, y_test))\n",
    "\n",
    "        #### CHECK FOR CAUSAL METRIC HERE\n",
    "        y_causal_pred = model.predict(x_causal_NN)\n",
    "        causal_targets = pd.DataFrame(y_causal_pred, columns = target)\n",
    "        causal_targets.reset_index(drop=True, inplace = True)\n",
    "        causal_df = x_causal.join(causal_targets)\n",
    "\n",
    "\n",
    "\n",
    "        metrics.append(mean_absolute_error(y_causal_pred, y_causal))\n",
    "        #print(x_causal.head)\n",
    "        bic_pred = get_bic(causal_df, prior)\n",
    "        #print(bic_pred, tetrad.getEdges())\n",
    "\n",
    "        found_conx = set({})\n",
    "        for i in tetrad.getEdges():\n",
    "            if ' --> ' in i:\n",
    "                found_conx.add((i.split(' --> ')[0], i.split(' --> ')[1]))\n",
    "        found_conx\n",
    "\n",
    "        if found_conx == known_conx:\n",
    "            proposed.append(bic_pred)\n",
    "        else:\n",
    "            print(\"******Found an error\")\n",
    "            # for now just remove bad model.  Will need to add it to distance metric.\n",
    "            metrics = metrics[:-1]\n",
    "            generalization = generalization[:-1]\n",
    "    nbest = 10\n",
    "    total = normalize(metrics) + normalize(proposed)\n",
    "    final = pd.DataFrame(np.stack((metrics, proposed, total, generalization), axis = 1), columns = ['metrics', 'proposed', 'combined', 'generalization'])\n",
    "    print(\"MSE = \", np.sum(final.nsmallest(nbest, 'metrics')['generalization']))\n",
    "    print(\"BIC = \", np.sum(final.nsmallest(nbest, 'proposed')['generalization']))\n",
    "    print(\"COMB = \",np.sum(final.nsmallest(nbest, 'combined')['generalization']))\n",
    "    bestMSE.append(final.nsmallest(nbest, 'metrics')['generalization'])\n",
    "    bestBIC.append(final.nsmallest(nbest, 'proposed')['generalization'])\n",
    "    bestCOMBO.append(final.nsmallest(nbest, 'combined')['generalization'])\n",
    "np.mean(bestMSE), np.mean(bestCOMBO), np.std(bestMSE), np.std(bestCOMBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_improvement(df1, df2):\n",
    "    ret = []\n",
    "    for i, j in zip(df1,df2):\n",
    "        ret.append(np.sum(j.values - i.values))\n",
    "    return ret\n",
    "\n",
    "improvement = get_average_improvement(bestMSE, bestCOMBO)\n",
    "np.mean(bestMSE), np.mean(bestCOMBO), np.std(bestMSE), np.std(bestCOMBO), np.mean(improvement), np.std(improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(proposed,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(proposed,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(proposed,generalization, '.')\n",
    "plt.plot(proposed, b + m * np.array(proposed), '-')\n",
    "ax.set_xlabel(\"BIC\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(metrics,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(metrics,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(metrics,generalization, '.')\n",
    "plt.plot(metrics, b + m * np.array(metrics), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "total = normalize(metrics) + normalize(proposed)\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(total,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(total,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(total,generalization, '.')\n",
    "plt.plot(total, b + m * np.array(total), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest = 10\n",
    "final = pd.DataFrame(np.stack((metrics, proposed, total, generalization), axis = 1), columns = ['metrics', 'proposed', 'combined', 'generalization'])\n",
    "print(\"MSE = \", np.sum(final.nsmallest(nbest, 'metrics')['generalization']))\n",
    "print(\"BIC = \", np.sum(final.nsmallest(nbest, 'proposed')['generalization']))\n",
    "print(\"COMB = \",np.sum(final.nsmallest(nbest, 'combined')['generalization']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
