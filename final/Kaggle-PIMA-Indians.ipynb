{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, \\\n",
    "                        Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "import keras.optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, mean_squared_error, mean_absolute_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from pycausal import search as s\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from collections import defaultdict\n",
    "from numpy.polynomial.polynomial import polyfit  \n",
    "from scipy.stats import pearsonr\n",
    "from pylab import text\n",
    "from pycausal import prior as p\n",
    "import itertools\n",
    "\n",
    "# select your GPU Here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" #Comment this line out if you want all GPUS (2 hehe)\n",
    "\n",
    "# python full-display web browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def gen_data(mean = 0, var = 1, SIZE = 20000):\n",
    "    a = np.random.normal(mean, var, SIZE)\n",
    "    b = a + np.random.normal(mean, var, SIZE)\n",
    "    c =  a + b + np.random.normal(mean, var, SIZE)\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c})\n",
    "\n",
    "def make_categorical(df, complete_df, categoricals):   \n",
    "    retval = None\n",
    "    for key in df.columns:\n",
    "        if retval is not None:\n",
    "            if key in categoricals:\n",
    "                retval = np.concatenate((retval, to_categorical(df[key], len(complete_df[key].unique()))), axis = 1)\n",
    "            else:\n",
    "                retval = np.concatenate((retval, df[key].values[...,np.newaxis]), axis = 1)\n",
    "        else:\n",
    "            if key in categoricals:\n",
    "                retval = to_categorical(df[key], len(complete_df[key].unique()))\n",
    "            else:\n",
    "                retval = np.expand_dims(df[key], axis = 1)\n",
    "    return retval\n",
    "num_models = 100\n",
    "           \n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '5000M')\n",
    "tetrad = s.tetradrunner()\n",
    "\n",
    "inputs = ['Glucose', 'Insulin', 'BMI', 'Age', 'BloodPressure']\n",
    "target = ['DiabetesPedigreeFunction']\n",
    "categoricals = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "df = pd.read_csv('~/Desktop/Kaggle/diabetes.csv')\n",
    "# Prior knowledge knows that the test prep comes before the outcome.\n",
    "df.head()\n",
    "\n",
    "def normalize(a):\n",
    "    return (a - np.min(a)) / (np.max(a) - np.min(a))\n",
    "\n",
    "df['Pregnancies'] = normalize(df['Pregnancies'])\n",
    "df['Glucose'] = normalize(df['Glucose'])\n",
    "df['BloodPressure'] = normalize(df['BloodPressure'])\n",
    "df['SkinThickness'] = normalize(df['SkinThickness'])\n",
    "df['Insulin'] = normalize(df['Insulin'])\n",
    "df['BMI'] = normalize(df['BMI'])\n",
    "df['DiabetesPedigreeFunction'] = normalize(df['DiabetesPedigreeFunction'])\n",
    "df['Age'] = normalize(df['Age'])\n",
    "df.drop(columns = ['Outcome', 'SkinThickness', 'Pregnancies'], inplace = True)\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "original_df = df.copy()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256], [512, 256]] ['temp/pima0', 'temp/pima1', 'temp/pima2', 'temp/pima3', 'temp/pima4', 'temp/pima5', 'temp/pima6', 'temp/pima7', 'temp/pima8', 'temp/pima9', 'temp/pima10', 'temp/pima11', 'temp/pima12', 'temp/pima13', 'temp/pima14', 'temp/pima15', 'temp/pima16', 'temp/pima17', 'temp/pima18', 'temp/pima19', 'temp/pima20', 'temp/pima21', 'temp/pima22', 'temp/pima23', 'temp/pima24', 'temp/pima25', 'temp/pima26', 'temp/pima27', 'temp/pima28', 'temp/pima29', 'temp/pima30', 'temp/pima31', 'temp/pima32', 'temp/pima33', 'temp/pima34', 'temp/pima35', 'temp/pima36', 'temp/pima37', 'temp/pima38', 'temp/pima39', 'temp/pima40', 'temp/pima41', 'temp/pima42', 'temp/pima43', 'temp/pima44', 'temp/pima45', 'temp/pima46', 'temp/pima47', 'temp/pima48', 'temp/pima49', 'temp/pima50', 'temp/pima51', 'temp/pima52', 'temp/pima53', 'temp/pima54', 'temp/pima55', 'temp/pima56', 'temp/pima57', 'temp/pima58', 'temp/pima59', 'temp/pima60', 'temp/pima61', 'temp/pima62', 'temp/pima63', 'temp/pima64', 'temp/pima65', 'temp/pima66', 'temp/pima67', 'temp/pima68', 'temp/pima69', 'temp/pima70', 'temp/pima71', 'temp/pima72', 'temp/pima73', 'temp/pima74', 'temp/pima75', 'temp/pima76', 'temp/pima77', 'temp/pima78', 'temp/pima79', 'temp/pima80', 'temp/pima81', 'temp/pima82', 'temp/pima83', 'temp/pima84', 'temp/pima85', 'temp/pima86', 'temp/pima87', 'temp/pima88', 'temp/pima89', 'temp/pima90', 'temp/pima91', 'temp/pima92', 'temp/pima93', 'temp/pima94', 'temp/pima95', 'temp/pima96', 'temp/pima97', 'temp/pima98', 'temp/pima99']\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"188pt\" viewBox=\"0.00 0.00 453.09 188.00\" width=\"453pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-184 449.0854,-184 449.0854,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- Age -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>Age</title>\n",
       "<ellipse cx=\"157.7445\" cy=\"-162\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157.7445\" y=\"-158.3\">Age</text>\n",
       "</g>\n",
       "<!-- BloodPressure -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>BloodPressure</title>\n",
       "<ellipse cx=\"61.7445\" cy=\"-90\" fill=\"none\" rx=\"61.99\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"61.7445\" y=\"-86.3\">BloodPressure</text>\n",
       "</g>\n",
       "<!-- Age&#45;&gt;BloodPressure -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>Age-&gt;BloodPressure</title>\n",
       "<path d=\"M139.6877,-148.4574C123.9365,-136.644 101.0231,-119.4589 84.1141,-106.7772\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Glucose -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>Glucose</title>\n",
       "<ellipse cx=\"180.7445\" cy=\"-90\" fill=\"none\" rx=\"39.7935\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.7445\" y=\"-86.3\">Glucose</text>\n",
       "</g>\n",
       "<!-- Age&#45;&gt;Glucose -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>Age-&gt;Glucose</title>\n",
       "<path d=\"M163.4299,-144.2022C166.9684,-133.1252 171.5036,-118.928 175.0448,-107.8425\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- BMI -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>BMI</title>\n",
       "<ellipse cx=\"61.7445\" cy=\"-162\" fill=\"none\" rx=\"27.8951\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"61.7445\" y=\"-158.3\">BMI</text>\n",
       "</g>\n",
       "<!-- BMI&#45;&gt;BloodPressure -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>BMI-&gt;BloodPressure</title>\n",
       "<path d=\"M61.7445,-143.8314C61.7445,-133 61.7445,-119.2876 61.7445,-108.4133\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- DiabetesPedigreeFunction -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>DiabetesPedigreeFunction</title>\n",
       "<ellipse cx=\"341.7445\" cy=\"-90\" fill=\"none\" rx=\"103.1819\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.7445\" y=\"-86.3\">DiabetesPedigreeFunction</text>\n",
       "</g>\n",
       "<!-- Insulin -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>Insulin</title>\n",
       "<ellipse cx=\"260.7445\" cy=\"-18\" fill=\"none\" rx=\"35.194\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.7445\" y=\"-14.3\">Insulin</text>\n",
       "</g>\n",
       "<!-- DiabetesPedigreeFunction&#45;&gt;Insulin -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>DiabetesPedigreeFunction-&gt;Insulin</title>\n",
       "<path d=\"M314.2118,-65.5264C302.344,-54.9773 288.8154,-42.9519 278.3359,-33.6368\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"311.9226,-68.1745 321.722,-72.2022 316.5732,-62.9426 311.9226,-68.1745\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- Glucose&#45;&gt;Insulin -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>Glucose-&gt;Insulin</title>\n",
       "<path d=\"M198.8978,-73.6621C212.1746,-61.7129 230.0837,-45.5947 243.2129,-33.7784\" fill=\"none\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "from IPython.display import SVG\n",
    "def examine_graph_continuous(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df,  scoreId = 'sem-bic', dataType = 'continuous',\n",
    "               structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, priorKnowledge = prior,\n",
    "               completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "               )\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def examine_graph_mixed(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 9, \n",
    "           structurePrior = 1.0, maxDegree = -1, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def examine_graph_discrete(df, prior = None):\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'bdeu', priorKnowledge = prior, dataType = 'discrete',\n",
    "               structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, faithfulnessAssumed = True, verbose = True)\n",
    "    return tetrad.getTetradGraph()\n",
    "    \n",
    "def get_model(dense, dropouts, inputs):\n",
    "    # dense is an ordered list of the number of dense neurons like [1024, 2048, 1024]\n",
    "    # dropouts is an ordered list of the dropout masks like [0.2, 0.3, 0.4]\n",
    "    inputs = keras.Input(shape = (inputs,))\n",
    "    x = keras.layers.Dense(dense[0], activation = 'relu', kernel_initializer = 'he_normal')(inputs)\n",
    "    #x = keras.layers.Dropout(dropouts[0])(x, training=True)\n",
    "    for den, drop in zip(dense[1:], dropouts[1:]):\n",
    "        x = keras.layers.Dense(den, activation = 'relu', kernel_initializer = 'he_normal')(x)\n",
    "        #x = keras.layers.Dropout(drop)(x, training=True)\n",
    "    outputs = keras.layers.Dense(1, activation = 'softmax', kernel_initializer = 'he_normal')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_bic(df, prior, penalty = 2):\n",
    "\n",
    "    tetrad.run(algoId = 'fges', dfs = df, scoreId = 'cond-gauss-bic', \n",
    "           priorKnowledge = prior, dataType = 'mixed', numCategoriesToDiscretize = 9,\n",
    "           structurePrior = 1.0, maxDegree = -1, faithfulnessAssumed = True, verbose = True,\n",
    "              penalty = 200)\n",
    "    \n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC #/ len(df)    \n",
    "\n",
    "\n",
    "temporal = [inputs, target]\n",
    "\n",
    "prior = p.knowledge( addtemporal = temporal)\n",
    "#prior = None\n",
    "\n",
    "g = examine_graph_continuous(df, prior = prior)\n",
    "dot_str = pc.tetradGraphToDot(g)\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "svg_str = graphs[0].create_svg()\n",
    "\n",
    "known_conx = set({})\n",
    "for i in tetrad.getEdges():\n",
    "    if ' --> ' in i:\n",
    "        known_conx.add((i.split(' --> ')[0], i.split(' --> ')[1]))\n",
    "known_conx\n",
    "\n",
    "prior = p.knowledge(requiredirect =  list(map(list, known_conx)),)\n",
    "models = []\n",
    "model_names = []\n",
    "randomize = False\n",
    "if randomize:\n",
    "    layers = [256, 512, 1024, 2048, 4096]\n",
    "    for i in range(num_models):\n",
    "        network = []\n",
    "        for j in range(3):\n",
    "            network.append(layers[random.randint(0,len(layers) -1)])\n",
    "        models.append(network)\n",
    "        model_names.append('temp/random' + str(i))\n",
    "    print(models, model_names)    \n",
    "else:\n",
    "    model_layers = [512,256]\n",
    "    for i in range(num_models):\n",
    "        models.append(model_layers)\n",
    "        model_names.append('temp/pima' + str(i))\n",
    "\n",
    "print(models, model_names)\n",
    "SVG(svg_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768 140\n",
      "628\n",
      "628\n"
     ]
    }
   ],
   "source": [
    "df = original_df.copy()\n",
    "print(len(df))\n",
    "holdout = 140\n",
    "    #df_test = df[df['charges'] > 0.54].copy()\n",
    "continuous = inputs\n",
    "\n",
    "small = random.randint(0,1)\n",
    "cont = random.randint(0, len(continuous) - 1)\n",
    "if small == 0:\n",
    "    df_test = df.nsmallest(holdout, continuous[cont])\n",
    "else:\n",
    "    df_test = df.nlargest(holdout, continuous[cont])\n",
    "df.head()\n",
    "print(len(df), len(df_test))\n",
    "df.drop(df_test.index, inplace = True)\n",
    "print(len(df))\n",
    "df_test.reset_index(inplace = True)\n",
    "print(len(df))\n",
    "df.sample(frac= 1).reset_index(inplace = True) # this will shuffle and reset index\n",
    "\n",
    "x_test = df_test[inputs]\n",
    "y_test = df_test[target]\n",
    "causal_split = 0.2\n",
    "val_split = 0.2\n",
    "train_split = 1 - (causal_split + val_split)\n",
    "x_causal = df[inputs][-int(causal_split * len(df)) :]\n",
    "y_causal = df[target][-int(causal_split * len(df)) :]\n",
    "x_val = df[inputs][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "y_val = df[target][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "x_train = df[inputs][:int(train_split * len(df))]\n",
    "y_train = df[target][:int(train_split * len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>BloodPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.844221</td>\n",
       "      <td>0.379433</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.527638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.538003</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.532663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384501</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427720</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.786885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Glucose   Insulin       BMI       Age  BloodPressure\n",
       "612  0.844221  0.379433  0.569300  0.316667       0.721311\n",
       "613  0.527638  0.000000  0.484352  0.083333       0.655738\n",
       "614  0.693467  0.170213  0.538003  0.483333       0.606557\n",
       "615  0.532663  0.000000  0.384501  0.100000       0.590164\n",
       "616  0.587940  0.000000  0.427720  0.150000       0.786885"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_causal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BloodPressure\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "MSE =  0.8291417591801877\n",
      "BIC =  0.8291417591801877\n",
      "COMB =  nan\n",
      "1 Age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "MSE =  0.8509302183725753\n",
      "BIC =  0.8509302183725753\n",
      "COMB =  nan\n",
      "2 BMI\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "MSE =  0.8553220690496521\n",
      "BIC =  0.8553220690496521\n",
      "COMB =  nan\n",
      "3 Glucose\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "MSE =  0.7945254361351715\n",
      "BIC =  0.7945254361351715\n",
      "COMB =  nan\n",
      "4 Insulin\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "MSE =  0.7811546907405148\n",
      "BIC =  0.7811546907405148\n",
      "COMB =  nan\n",
      "5 Glucose\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "MSE =  0.8437660119555936\n",
      "BIC =  0.8437660119555936\n",
      "COMB =  nan\n",
      "6 Glucose\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n",
      "******Found an error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2348\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2349\u001b[0;31m           \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2350\u001b[0m           \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'loss/dense_3_loss/Mean' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2352\u001b[0m         \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2353\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2354\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'loss/dense_3_loss/Mean' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a42ec4566d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'optimizer_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Build train function (to get weight updates).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0moptimizer_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             optimizer_weight_names = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \"\"\"\n\u001b[0;32m-> 2757\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 532\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 701\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    702\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    394\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 701\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    702\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0moutput_shape_kept_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduced_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtile_scaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_shape_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape_kept_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape_kept_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_safe_shape_div\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_safe_shape_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;34m\"\"\"Divides `x / y` assuming `x, y >= 0`, treating `0 / 0 = 0`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mfloordiv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m   \"\"\"\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"floordiv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mfloor_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   2868\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 2870\u001b[0;31m         \"FloorDiv\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   2871\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0;31m# Perform input type inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5282\u001b[0m           default.building_function, default.as_default)\n\u001b[1;32m   5283\u001b[0m       with super(_DefaultGraphStack, self).get_controller(\n\u001b[0;32m-> 5284\u001b[0;31m           default) as g, context.graph_mode():\n\u001b[0m\u001b[1;32m   5285\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bestMSE = []\n",
    "bestBIC = []\n",
    "bestCOMBO = []\n",
    "\n",
    "for t in range(10):\n",
    "    # let's split our df into two by race.  Let's see what happens if we \n",
    "    df = original_df.copy()\n",
    "\n",
    "    holdout = 140\n",
    "        #df_test = df[df['charges'] > 0.54].copy()\n",
    "    continuous = inputs\n",
    "    \n",
    "    small = random.randint(0,1)\n",
    "    cont = random.randint(0, len(continuous) - 1)\n",
    "    if small == 0:\n",
    "        df_test = df.nsmallest(holdout, continuous[cont])\n",
    "    else:\n",
    "        df_test = df.nlargest(holdout, continuous[cont])\n",
    "    print(t, continuous[cont])\n",
    "    df.drop(df_test.index, inplace = True)\n",
    "    df_test.reset_index(inplace = True)\n",
    "    df.sample(frac= 1).reset_index(inplace = True) # this will shuffle and reset index\n",
    "\n",
    "    x_test = df_test[inputs]\n",
    "    y_test = df_test[target]\n",
    "    causal_split = 0.2\n",
    "    val_split = 0.2\n",
    "    train_split = 1 - (causal_split + val_split)\n",
    "    x_causal = df[inputs][-int(causal_split * len(df)) :]\n",
    "    y_causal = df[target][-int(causal_split * len(df)) :]\n",
    "    x_val = df[inputs][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "    y_val = df[target][int(train_split * len(df)):-int(causal_split * len(df))]\n",
    "    x_train = df[inputs][:int(train_split * len(df))]\n",
    "    y_train = df[target][:int(train_split * len(df))]\n",
    "    #x_test_NN = make_categorical(x_test, original_df, categoricals)\n",
    "    #x_causal_NN = make_categorical(x_causal, original_df, categoricals)\n",
    "    #x_val_NN = make_categorical(x_val, original_df, categoricals)\n",
    "    #x_train_NN = make_categorical(x_train, original_df, categoricals)\n",
    "    verbosity = 0\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        #print(model_name)\n",
    "\n",
    "        if type(models[idx]) is list:\n",
    "            #clear session\n",
    "            keras.backend.clear_session() \n",
    "            #get model according to specification\n",
    "            model = get_model(models[idx], [0.2] * len(models), np.shape(x_train)[1])\n",
    "            callbacks = [ModelCheckpoint(model_name, verbose= verbosity, monitor='val_loss',save_best_only=True), \n",
    "                         EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose= verbosity, mode='auto')]\n",
    "            model.compile(optimizer = optimizers.SGD(lr = 0.0001, momentum = 0.9, ), loss='mean_squared_error', metrics = ['mse'])\n",
    "            #print(len(X), len(y))\n",
    "            model.fit(x_train, y_train, epochs = 20, validation_data = (x_val, y_val), callbacks = callbacks, batch_size = 32, verbose = verbosity)\n",
    "        else:\n",
    "            models[idx].fit(X,y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    violation = []\n",
    "    generalization = []\n",
    "    metrics = []\n",
    "    proposed = []\n",
    "    x_causal.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        #print(model_name)\n",
    "        if type(models[idx]) is list:\n",
    "            keras.backend.clear_session()\n",
    "            model = load_model(model_name)\n",
    "        else:\n",
    "            model = models[idx]\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        generalization.append(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "        #### CHECK FOR CAUSAL METRIC HERE\n",
    "        y_causal_pred = model.predict(x_causal)\n",
    "        metrics.append(mean_absolute_error(y_causal, y_causal_pred))\n",
    "        #print(\"AUC = \", roc_auc_score(y_causal, y_causal_pred))\n",
    "        y_causal_pred[y_causal_pred > 0.5] = 1\n",
    "        y_causal_pred[y_causal_pred <= 0.5] = 0\n",
    "        causal_targets = pd.DataFrame(y_causal_pred, columns = target)\n",
    "        causal_targets.reset_index(drop=True, inplace = True)\n",
    "        causal_df = x_causal.join(causal_targets)\n",
    "        #print(len(causal_df))\n",
    "\n",
    "\n",
    "\n",
    "        #print(x_causal.head)\n",
    "        bic_pred = get_bic(causal_df, prior)\n",
    "        #print(bic_pred, tetrad.getEdges())\n",
    "        #print(bic_pred)\n",
    "        found_conx = set({})\n",
    "        for i in tetrad.getEdges():\n",
    "            if ' --> ' in i:\n",
    "                found_conx.add((i.split(' --> ')[0], i.split(' --> ')[1]))\n",
    "        found_conx\n",
    "\n",
    "        if found_conx == known_conx:\n",
    "            proposed.append(bic_pred)\n",
    "            violation.append(0)\n",
    "        else:\n",
    "            print(\"******Found an error\")\n",
    "            # for now just remove bad model.  Will need to add it to distance metric.\n",
    "            proposed.append(bic_pred)\n",
    "            violation.append(1)\n",
    "            #metrics = metrics[:-1]\n",
    "            #generalization = generalization[:-1]\n",
    "    total = normalize(metrics) + normalize(proposed)\n",
    "    nbest = 10\n",
    "    final = pd.DataFrame(np.stack((metrics, proposed, total, generalization), axis = 1), columns = ['metrics', 'proposed', 'combined', 'generalization'])\n",
    "    print(\"MSE = \", np.mean(final.nsmallest(nbest, 'metrics')['generalization']))\n",
    "    print(\"BIC = \", np.mean(final.nsmallest(nbest, 'proposed')['generalization']))\n",
    "    print(\"COMB = \",np.mean(final.nsmallest(nbest, 'combined')['generalization']))\n",
    "    bestMSE.append(final.nsmallest(nbest, 'metrics')['generalization'])\n",
    "    bestBIC.append(final.nsmallest(nbest, 'proposed')['generalization'])\n",
    "    bestCOMBO.append(final.nsmallest(nbest, 'combined')['generalization'])\n",
    "    \n",
    "\n",
    "np.mean(bestMSE), np.mean(bestBIC), np.mean(bestCOMBO), np.std(bestMSE), np.std(bestCOMBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>0.461997</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.206856</td>\n",
       "      <td>0.384501</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.271868</td>\n",
       "      <td>0.682563</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.517588</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.098109</td>\n",
       "      <td>0.645306</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.515648</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.585693</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.597990</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.172577</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.628141</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.135934</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.165485</td>\n",
       "      <td>0.345753</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.728643</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>0.330849</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536513</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.793970</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.289598</td>\n",
       "      <td>0.470939</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.369598</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.613065</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411326</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.517588</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.226950</td>\n",
       "      <td>0.357675</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490313</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.552906</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.904523</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.506706</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.532663</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338301</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.859296</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.676602</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.904523</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625931</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.356784</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417288</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869347</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.313239</td>\n",
       "      <td>0.692996</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381520</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388972</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.417085</td>\n",
       "      <td>0.532787</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.548435</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488823</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.628141</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.144208</td>\n",
       "      <td>0.430700</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.402010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.552764</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387481</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.407035</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.089835</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171395</td>\n",
       "      <td>0.374069</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.228132</td>\n",
       "      <td>0.436662</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>0.375559</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.554396</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.472362</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.093381</td>\n",
       "      <td>0.496274</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.482412</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555887</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496274</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.904523</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.543964</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.653266</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.200946</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.089835</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372578</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.422111</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.329359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.457286</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.457286</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406855</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.101655</td>\n",
       "      <td>0.381520</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.819095</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>0.470939</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0       0.352941  0.743719       0.590164       0.353535  0.000000  0.500745   \n",
       "1       0.058824  0.427136       0.540984       0.292929  0.000000  0.396423   \n",
       "3       0.058824  0.447236       0.540984       0.232323  0.111111  0.418778   \n",
       "4       0.000000  0.688442       0.327869       0.353535  0.198582  0.642325   \n",
       "6       0.176471  0.391960       0.409836       0.323232  0.104019  0.461997   \n",
       "8       0.117647  0.989950       0.573770       0.454545  0.641844  0.454545   \n",
       "13      0.058824  0.949749       0.491803       0.232323  1.000000  0.448584   \n",
       "14      0.294118  0.834171       0.590164       0.191919  0.206856  0.384501   \n",
       "16      0.000000  0.592965       0.688525       0.474747  0.271868  0.682563   \n",
       "18      0.058824  0.517588       0.245902       0.383838  0.098109  0.645306   \n",
       "19      0.058824  0.577889       0.573770       0.303030  0.113475  0.515648   \n",
       "20      0.176471  0.633166       0.721311       0.414141  0.277778  0.585693   \n",
       "23      0.529412  0.597990       0.655738       0.353535  0.000000  0.432191   \n",
       "24      0.647059  0.718593       0.770492       0.333333  0.172577  0.545455   \n",
       "25      0.588235  0.628141       0.573770       0.262626  0.135934  0.463487   \n",
       "27      0.058824  0.487437       0.540984       0.151515  0.165485  0.345753   \n",
       "28      0.764706  0.728643       0.672131       0.191919  0.130024  0.330849   \n",
       "30      0.294118  0.547739       0.614754       0.262626  0.000000  0.536513   \n",
       "31      0.176471  0.793970       0.622951       0.363636  0.289598  0.470939   \n",
       "32      0.176471  0.442211       0.475410       0.111111  0.063830  0.369598   \n",
       "34      0.588235  0.613065       0.639344       0.313131  0.000000  0.411326   \n",
       "35      0.235294  0.517588       0.491803       0.333333  0.226950  0.357675   \n",
       "37      0.529412  0.512563       0.622951       0.373737  0.000000  0.490313   \n",
       "38      0.117647  0.452261       0.557377       0.424242  0.000000  0.569300   \n",
       "39      0.235294  0.557789       0.590164       0.474747  0.244681  0.552906   \n",
       "40      0.176471  0.904523       0.524590       0.252525  0.082742  0.506706   \n",
       "42      0.411765  0.532663       0.754098       0.181818  0.000000  0.338301   \n",
       "43      0.529412  0.859296       0.901639       0.242424  0.283688  0.676602   \n",
       "45      0.000000  0.904523       0.540984       0.393939  0.000000  0.625931   \n",
       "47      0.117647  0.356784       0.573770       0.272727  0.000000  0.417288   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "486     0.058824  0.698492       0.508197       0.414141  0.567376  0.606557   \n",
       "487     0.000000  0.869347       0.639344       0.323232  0.313239  0.692996   \n",
       "488     0.235294  0.497487       0.590164       0.171717  0.000000  0.381520   \n",
       "489     0.470588  0.974874       0.655738       0.000000  0.000000  0.388972   \n",
       "490     0.117647  0.417085       0.532787       0.282828  0.078014  0.548435   \n",
       "491     0.117647  0.447236       0.737705       0.303030  0.000000  0.499255   \n",
       "492     0.235294  0.497487       0.557377       0.383838  0.000000  0.488823   \n",
       "493     0.235294  0.628141       0.573770       0.181818  0.144208  0.430700   \n",
       "494     0.176471  0.402010       0.000000       0.000000  0.000000  0.000000   \n",
       "495     0.352941  0.834171       0.606557       0.000000  0.000000  0.396423   \n",
       "496     0.294118  0.552764       0.557377       0.000000  0.000000  0.387481   \n",
       "497     0.117647  0.407035       0.590164       0.151515  0.089835  0.448584   \n",
       "498     0.411765  0.979899       0.573770       0.333333  0.171395  0.374069   \n",
       "499     0.352941  0.773869       0.606557       0.323232  0.228132  0.436662   \n",
       "500     0.117647  0.587940       0.737705       0.191919  0.083924  0.375559   \n",
       "501     0.176471  0.422111       0.590164       0.323232  0.000000  0.554396   \n",
       "502     0.352941  0.000000       0.557377       0.414141  0.000000  0.581222   \n",
       "503     0.411765  0.472362       0.524590       0.252525  0.093381  0.496274   \n",
       "504     0.176471  0.482412       0.639344       0.393939  0.000000  0.555887   \n",
       "505     0.588235  0.376884       0.672131       0.000000  0.000000  0.496274   \n",
       "506     0.000000  0.904523       0.737705       0.262626  0.106383  0.543964   \n",
       "507     0.058824  0.653266       0.491803       0.232323  0.200946  0.426230   \n",
       "508     0.117647  0.422111       0.409836       0.232323  0.089835  0.453055   \n",
       "509     0.470588  0.603015       0.639344       0.000000  0.000000  0.372578   \n",
       "510     0.705882  0.422111       0.590164       0.313131  0.000000  0.442623   \n",
       "511     0.000000  0.698492       0.508197       0.171717  0.248227  0.329359   \n",
       "512     0.529412  0.457286       0.557377       0.000000  0.000000  0.360656   \n",
       "513     0.117647  0.457286       0.508197       0.000000  0.000000  0.406855   \n",
       "514     0.176471  0.497487       0.442623       0.191919  0.101655  0.381520   \n",
       "515     0.176471  0.819095       0.573770       0.181818  0.124113  0.470939   \n",
       "\n",
       "          Age  \n",
       "0    0.483333  \n",
       "1    0.166667  \n",
       "3    0.000000  \n",
       "4    0.200000  \n",
       "6    0.083333  \n",
       "8    0.533333  \n",
       "13   0.633333  \n",
       "14   0.500000  \n",
       "16   0.166667  \n",
       "18   0.200000  \n",
       "19   0.183333  \n",
       "20   0.100000  \n",
       "23   0.133333  \n",
       "24   0.500000  \n",
       "25   0.333333  \n",
       "27   0.016667  \n",
       "28   0.600000  \n",
       "30   0.650000  \n",
       "31   0.116667  \n",
       "32   0.016667  \n",
       "34   0.400000  \n",
       "35   0.200000  \n",
       "37   0.416667  \n",
       "38   0.100000  \n",
       "39   0.583333  \n",
       "40   0.083333  \n",
       "42   0.450000  \n",
       "43   0.550000  \n",
       "45   0.066667  \n",
       "47   0.016667  \n",
       "..        ...  \n",
       "486  0.000000  \n",
       "487  0.616667  \n",
       "488  0.116667  \n",
       "489  0.766667  \n",
       "490  0.050000  \n",
       "491  0.350000  \n",
       "492  0.200000  \n",
       "493  0.400000  \n",
       "494  0.016667  \n",
       "495  0.750000  \n",
       "496  0.150000  \n",
       "497  0.066667  \n",
       "498  0.566667  \n",
       "499  0.300000  \n",
       "500  0.000000  \n",
       "501  0.116667  \n",
       "502  0.333333  \n",
       "503  0.333333  \n",
       "504  0.316667  \n",
       "505  0.283333  \n",
       "506  0.233333  \n",
       "507  0.000000  \n",
       "508  0.000000  \n",
       "509  0.716667  \n",
       "510  0.416667  \n",
       "511  0.000000  \n",
       "512  0.616667  \n",
       "513  0.016667  \n",
       "514  0.050000  \n",
       "515  0.116667  \n",
       "\n",
       "[376 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0bf12da13391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_NN' is not defined"
     ]
    }
   ],
   "source": [
    "y_test_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = df.copy()\n",
    "df = original_df.copy()\n",
    "\n",
    "len(df[df['BMI'] > 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(proposed,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(proposed,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(proposed,generalization, '.')\n",
    "plt.plot(proposed, b + m * np.array(proposed), '-')\n",
    "ax.set_xlabel(\"BIC\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(metrics,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(metrics,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(metrics,generalization, '.')\n",
    "plt.plot(metrics, b + m * np.array(metrics), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "total = normalize(metrics) - (normalize(proposed) + np.array(violation))\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(total,generalization, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(total,generalization)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(total,generalization, '.')\n",
    "plt.plot(total, b + m * np.array(total), '-')\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"GEN\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest = 5\n",
    "final = pd.DataFrame(np.stack((metrics, proposed, total, generalization), axis = 1), columns = ['metrics', 'proposed', 'combined', 'generalization'])\n",
    "print(\"MSE = \", np.mean(final.nlargest(nbest, 'metrics')['generalization']))\n",
    "print(\"BIC = \", np.mean(final.nlargest(nbest, 'proposed')['generalization']))\n",
    "print(\"COMB = \",np.mean(final.nlargest(nbest, 'combined')['generalization']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('temp/pima50')\n",
    "roc_auc_score(y_val, model.predict(x_train_NN)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
