{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes \n",
    "### Required installing Oracle JAVA 8 to get javabridge installed\n",
    "### Then, I was able to install py-causal from https://bd2kccd.github.io/docs/py-causal/\n",
    "### GFCI is slower than RFCI, but more accurate (SPIRTES), GFCI and RFCI account for unobserved variables, FGES assumes no unobserved variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure Learning Performance Guarantees If the assumptions in the previous section hold, then in the large sample limit, the CBN structure output by GFCId will contain an edge of one of four kinds between Xand Y   if and only if Xand Yare not independent conditional on any subset of the other measured variables of less than or equal to a specified size. In addition, there is (1) an arc X->Y   if and only if Xdirectly or indirectly causes Y, and Y   does not directly or indirectly cause X; (2) an edge X <-->Y   if and only if X   is not a direct or indirect cause of Yand Y   is not a direct or indirect cause of X(which can only occur if there are latent confounders of Xand some other variable or Yand some other variable; (3) an edge Xo->Y   only if Yis not a direct or indirect cause of X, but Xmay or may not be an indirect cause of Y; (4) an edge X oâ€“o Y   indicates that Xand Y   are dependent no matter what subset of observed variables is conditioned on, but contains no orientation information (X   may be a direct or indirect cause of Y, and Ymay be an indirect cause of X, or there may be a latent common cause of Xand Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for continous data.\n",
    "# generate some toy data:\n",
    "SIZE = 20000\n",
    "a = np.random.normal(size=SIZE, scale = 1)\n",
    "b = np.random.normal(size=SIZE, scale = 1)\n",
    "c = np.random.normal(size=SIZE, scale = 1)\n",
    "d = np.random.normal(size=SIZE, scale = 1)\n",
    "e = np.random.normal(size=SIZE, scale = 1)\n",
    "\n",
    "f= a + b + c + d + e + np.random.normal(size=SIZE, scale = 1)\n",
    "g = f + np.random.normal(size=SIZE, scale = 1)\n",
    "\n",
    "# load the data into a dataframe:\n",
    "df = pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "import pandas as pd\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from pycausal import search as s\n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '500M')\n",
    "from pycausal import prior as p\n",
    "\n",
    "tetrad = s.tetradrunner()\n",
    "#GFCI = Greedy Fast Causal Interference (GFCI) \n",
    "# bdeu = Bayesian Dirichlet likelihood equivalence and uniform\n",
    "tetrad.run(algoId = 'gfci', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "           structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "           completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "dot_str = pc.tetradGraphToDot(tetrad.getTetradGraph())\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "svg_str = graphs[0].create_svg()\n",
    "SVG(svg_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try and predict D HERE\n",
    "\n",
    "# This is for continous data.\n",
    "# generate some toy data:\n",
    "SIZE = 100000\n",
    "a = np.random.normal(size=SIZE, scale = 1)\n",
    "b = np.random.normal(size=SIZE, scale = 1)\n",
    "c = np.random.normal(size=SIZE, scale = 1)\n",
    "d = a + b + c + np.random.normal(size=SIZE, scale = 1)\n",
    "e = d + np.random.normal(size=SIZE, scale = 1)\n",
    "f= d + np.random.normal(size=SIZE, scale = 1)\n",
    "g = d + np.random.normal(size=SIZE, scale = 1)\n",
    "\n",
    "# load the data into a dataframe:\n",
    "df = pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "import pandas as pd\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from pycausal import search as s\n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '2500M')\n",
    "from pycausal import prior as p\n",
    "\n",
    "tetrad = s.tetradrunner()\n",
    "#GFCI = Greedy Fast Causal Interference (GFCI) \n",
    "# bdeu = Bayesian Dirichlet likelihood equivalence and uniform\n",
    "tetrad.run(algoId = 'gfci', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "           structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "           completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "dot_str = pc.tetradGraphToDot(tetrad.getTetradGraph())\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "svg_str = graphs[0].create_svg()\n",
    "SVG(svg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '500M')\n",
    "from pycausal import prior as p\n",
    "\n",
    "tetrad = s.tetradrunner()\n",
    "#GFCI = Greedy Fast Causal Interference (GFCI) \n",
    "# bdeu = Bayesian Dirichlet likelihood equivalence and uniform\n",
    "tetrad.run(algoId = 'gfci', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "           structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "           completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "dot_str = pc.tetradGraphToDot(tetrad.getTetradGraph())\n",
    "graphs = pydot.graph_from_dot_data(dot_str)\n",
    "print(len(graphs))\n",
    "svg_str = graphs[0].create_svg()\n",
    "SVG(svg_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying some various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthetic data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "\n",
    "def gen_data():\n",
    "    SIZE = 10000\n",
    "    a = np.random.binomial(2, 0.5, size=SIZE)\n",
    "    b = np.random.binomial(2, 0.5, size=SIZE)\n",
    "    c = np.random.binomial(2, 0.5, size=SIZE)\n",
    "    d = np.random.binomial(2, 0.5, size=SIZE)\n",
    "    e = np.random.binomial(2, 0.5, size=SIZE)\n",
    "    f= a + b + c + d + e + np.random.binomial(2, 0.5, size=SIZE)\n",
    "    g = f + np.random.binomial(2, 0.5, size=SIZE)\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "\n",
    "\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def discrete_gauss(low, high, samples, std = 20):\n",
    "    x = np.arange(low, high)\n",
    "    xU, xL = x + 0.5, x - 0.5 \n",
    "    prob = ss.norm.cdf(xU, scale = std) - ss.norm.cdf(xL, scale = std)\n",
    "    prob = prob / prob.sum() #normalize the probabilities so their sum is 1\n",
    "    nums = np.random.choice(x, size = samples, p = prob)\n",
    "    return nums\n",
    "\n",
    "def gen_data():\n",
    "    SIZE = 40000\n",
    "    a = discrete_gauss(-3,3, SIZE)\n",
    "    b = discrete_gauss(-3,3, SIZE)\n",
    "    c = discrete_gauss(-3,3, SIZE)\n",
    "    d = discrete_gauss(-3,3, SIZE)\n",
    "    e = discrete_gauss(-3,3, SIZE)\n",
    "    f= a + b + c + d + e + np.random.binomial(2, 0.5, size=SIZE)\n",
    "    g = f + discrete_gauss(-3,3, SIZE)\n",
    "\n",
    "    #g[g < 0] = 0\n",
    "    #g[g > 0] = 1\n",
    "    #g[(g <= 3) & (g >= -3)] = 1\n",
    "    #g[g < -3] = 0\n",
    "    #g[g > 3] = 2\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "\n",
    "def gen_data():\n",
    "    #SIZE = 40000\n",
    "    SIZE = 40000\n",
    "    a = np.random.normal(0, 1, SIZE)\n",
    "    b = np.random.normal(0, 1, SIZE)\n",
    "    c = np.random.normal(0, 1, SIZE)\n",
    "    d = np.random.normal(0, 1, SIZE)\n",
    "    e = np.random.normal(0, 1, SIZE)\n",
    "    f= a + b + c + d + e + np.random.normal(0, 1, SIZE)\n",
    "    g = f + np.random.normal(0, 1, SIZE)\n",
    "    g = np.rint(g)\n",
    "    #m = np.mean(g)\n",
    "    #g[g < m] = 0\n",
    "    #g[g >= m] = 1\n",
    "\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "\n",
    "df = gen_data()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=40.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: LogisticRegression() 0.2702169625246548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.20512820512820512\n",
      "Error: DecisionTreeClassifier() 0.2583826429980276\n",
      "Error: LinearSVC() 0.2958579881656805\n",
      "Error: GaussianNB() 0.3530571992110454\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.252465483234714\n",
      "Error: LinearDiscriminantAnalysis() 0.3609467455621302\n",
      "Error: RandomForestClassifier() 0.3096646942800789\n",
      "Violation: {'f'} {'d', 'c', 'e', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: ExtraTreesClassifier() 0.2968441814595661\n",
      "Error: AdaBoostClassifier() 0.28205128205128205\n",
      "Error: BaggingClassifier() 0.3175542406311637\n",
      "Error: GradientBoostingClassifier() 0.35700197238658776\n",
      "Error: MLPClassifier() 0.35009861932938857\n",
      "Error: LogisticRegression() 0.27964426877470355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.208498023715415\n",
      "Violation: {'f'} {'a', 'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2727272727272727\n",
      "Error: LinearSVC() 0.3102766798418972\n",
      "Error: GaussianNB() 0.3685770750988142\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24703557312252963\n",
      "Error: LinearDiscriminantAnalysis() 0.3606719367588933\n",
      "Error: RandomForestClassifier() 0.3241106719367589\n",
      "Error: ExtraTreesClassifier() 0.33300395256917\n",
      "Error: AdaBoostClassifier() 0.2737154150197628\n",
      "Error: BaggingClassifier() 0.3102766798418972\n",
      "Error: GradientBoostingClassifier() 0.3695652173913043\n",
      "Error: MLPClassifier() 0.3567193675889328\n",
      "Error: LogisticRegression() 0.2943508424182359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.16551040634291378\n",
      "Error: DecisionTreeClassifier() 0.25966303270564917\n",
      "Error: LinearSVC() 0.3240832507433102\n",
      "Error: GaussianNB() 0.34985133795837464\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.22299306243805747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: LinearDiscriminantAnalysis() 0.36967294350842417\n",
      "Error: RandomForestClassifier() 0.3062438057482656\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: ExtraTreesClassifier() 0.28543111992071357\n",
      "Error: AdaBoostClassifier() 0.25173439048562934\n",
      "Error: BaggingClassifier() 0.3012884043607532\n",
      "Error: GradientBoostingClassifier() 0.3607532210109019\n",
      "Error: MLPClassifier() 0.36967294350842417\n",
      "Error: LogisticRegression() 0.2705649157581764\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.1605550049554014\n",
      "Error: DecisionTreeClassifier() 0.2705649157581764\n",
      "Error: LinearSVC() 0.31714568880079286\n",
      "Error: GaussianNB() 0.39544103072348863\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2566897918731417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: LinearDiscriminantAnalysis() 0.400396432111001\n",
      "Error: RandomForestClassifier() 0.3260654112983152\n",
      "Error: ExtraTreesClassifier() 0.31020812685827553\n",
      "Error: AdaBoostClassifier() 0.27651139742319125\n",
      "Error: BaggingClassifier() 0.3409316154608523\n",
      "Error: GradientBoostingClassifier() 0.37561942517343905\n",
      "Error: MLPClassifier() 0.3815659068384539\n",
      "Violation: {'f'} {'a', 'e', 'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2705649157581764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.19127849355797819\n",
      "Violation: {'f'} {'a', 'd', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.27750247770069375\n",
      "Error: LinearSVC() 0.3002973240832507\n",
      "Error: GaussianNB() 0.37165510406342916\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2556987115956392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: LinearDiscriminantAnalysis() 0.38453914767096137\n",
      "Error: RandomForestClassifier() 0.3012884043607532\n",
      "Error: ExtraTreesClassifier() 0.30921704658077304\n",
      "Error: AdaBoostClassifier() 0.2626362735381566\n",
      "Error: BaggingClassifier() 0.3191278493557978\n",
      "Error: GradientBoostingClassifier() 0.35678889990089196\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: MLPClassifier() 0.38057482656095143\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2644135188866799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.15705765407554673\n",
      "Error: DecisionTreeClassifier() 0.2783300198807157\n",
      "Error: LinearSVC() 0.3111332007952286\n",
      "Error: GaussianNB() 0.33399602385685884\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24254473161033796\n",
      "Error: LinearDiscriminantAnalysis() 0.34095427435387676\n",
      "Error: RandomForestClassifier() 0.2753479125248509\n",
      "Violation: {'f'} {'d', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: ExtraTreesClassifier() 0.28926441351888665\n",
      "Error: AdaBoostClassifier() 0.2485089463220676\n",
      "Error: BaggingClassifier() 0.31809145129224653\n",
      "Error: GradientBoostingClassifier() 0.34393638170974156\n",
      "Error: MLPClassifier() 0.3379721669980119\n",
      "Error: LogisticRegression() 0.26043737574552683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.21570576540755468\n",
      "Error: DecisionTreeClassifier() 0.2823061630218688\n",
      "Error: LinearSVC() 0.29721669980119286\n",
      "Error: GaussianNB() 0.37475149105367794\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24751491053677932\n",
      "Error: LinearDiscriminantAnalysis() 0.3827037773359841\n",
      "Error: RandomForestClassifier() 0.30019880715705766\n",
      "Error: ExtraTreesClassifier() 0.28429423459244535\n",
      "Error: AdaBoostClassifier() 0.2614314115308151\n",
      "Error: BaggingClassifier() 0.28926441351888665\n",
      "Error: GradientBoostingClassifier() 0.3667992047713718\n",
      "Error: MLPClassifier() 0.378727634194831\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.24378109452736318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.20398009950248755\n",
      "Error: DecisionTreeClassifier() 0.272636815920398\n",
      "Error: LinearSVC() 0.2965174129353234\n",
      "Error: GaussianNB() 0.36716417910447763\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2656716417910448\n",
      "Error: LinearDiscriminantAnalysis() 0.3701492537313433\n",
      "Error: RandomForestClassifier() 0.3253731343283582\n",
      "Error: ExtraTreesClassifier() 0.2955223880597015\n",
      "Error: AdaBoostClassifier() 0.2716417910447761\n",
      "Error: BaggingClassifier() 0.3283582089552239\n",
      "Error: GradientBoostingClassifier() 0.3661691542288557\n",
      "Error: MLPClassifier() 0.3761194029850746\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.24477611940298508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.16616915422885573\n",
      "Error: DecisionTreeClassifier() 0.27562189054726366\n",
      "Error: LinearSVC() 0.28955223880597014\n",
      "Error: GaussianNB() 0.37512437810945276\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2626865671641791\n",
      "Error: LinearDiscriminantAnalysis() 0.3800995024875622\n",
      "Error: RandomForestClassifier() 0.33134328358208953\n",
      "Error: ExtraTreesClassifier() 0.30845771144278605\n",
      "Error: AdaBoostClassifier() 0.27064676616915423\n",
      "Error: BaggingClassifier() 0.32039800995024875\n",
      "Error: GradientBoostingClassifier() 0.37910447761194027\n",
      "Error: MLPClassifier() 0.3572139303482587\n",
      "Error: LogisticRegression() 0.25970149253731345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.2099502487562189\n",
      "Violation: {'f'} {'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.26666666666666666\n",
      "Error: LinearSVC() 0.29950248756218906\n",
      "Error: GaussianNB() 0.3582089552238806\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24577114427860697\n",
      "Error: LinearDiscriminantAnalysis() 0.3701492537313433\n",
      "Error: RandomForestClassifier() 0.3034825870646766\n",
      "Error: ExtraTreesClassifier() 0.29950248756218906\n",
      "Error: AdaBoostClassifier() 0.24875621890547264\n",
      "Error: BaggingClassifier() 0.32935323383084575\n",
      "Error: GradientBoostingClassifier() 0.35522388059701493\n",
      "Error: MLPClassifier() 0.36318407960199006\n",
      "Error: LogisticRegression() 0.24975124378109453\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.23184079601990049\n",
      "Violation: {'f'} {'d', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.27064676616915423\n",
      "Error: LinearSVC() 0.27860696517412936\n",
      "Error: GaussianNB() 0.3661691542288557\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23781094527363184\n",
      "Error: LinearDiscriminantAnalysis() 0.37512437810945276\n",
      "Error: RandomForestClassifier() 0.2855721393034826\n",
      "Error: ExtraTreesClassifier() 0.2736318407960199\n",
      "Error: AdaBoostClassifier() 0.25970149253731345\n",
      "Error: BaggingClassifier() 0.29054726368159206\n",
      "Error: GradientBoostingClassifier() 0.3611940298507463\n",
      "Error: MLPClassifier() 0.3592039800995025\n",
      "Violation: {'f'} {'a', 'd', 'f', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.25870646766169153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.17114427860696518\n",
      "Error: DecisionTreeClassifier() 0.2855721393034826\n",
      "Error: LinearSVC() 0.28756218905472636\n",
      "Error: GaussianNB() 0.3482587064676617\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.21393034825870647\n",
      "Error: LinearDiscriminantAnalysis() 0.3522388059701492\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.3034825870646766\n",
      "Error: ExtraTreesClassifier() 0.2845771144278607\n",
      "Error: AdaBoostClassifier() 0.25970149253731345\n",
      "Error: BaggingClassifier() 0.29253731343283584\n",
      "Error: GradientBoostingClassifier() 0.3353233830845771\n",
      "Error: MLPClassifier() 0.35522388059701493\n",
      "Error: LogisticRegression() 0.28955223880597014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.16318407960199005\n",
      "Violation: {'f'} {'d'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2656716417910448\n",
      "Error: LinearSVC() 0.309452736318408\n",
      "Error: GaussianNB() 0.36716417910447763\n",
      "Violation: {'f'} {'a', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24477611940298508\n",
      "Error: LinearDiscriminantAnalysis() 0.36716417910447763\n",
      "Error: RandomForestClassifier() 0.28059701492537314\n",
      "Error: ExtraTreesClassifier() 0.2855721393034826\n",
      "Error: AdaBoostClassifier() 0.27064676616915423\n",
      "Error: BaggingClassifier() 0.3024875621890547\n",
      "Error: GradientBoostingClassifier() 0.34427860696517415\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: MLPClassifier() 0.36019900497512436\n",
      "Error: LogisticRegression() 0.28286852589641437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.17729083665338646\n",
      "Error: DecisionTreeClassifier() 0.2589641434262948\n",
      "Error: LinearSVC() 0.3197211155378486\n",
      "Error: GaussianNB() 0.3794820717131474\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2450199203187251\n",
      "Error: LinearDiscriminantAnalysis() 0.3934262948207171\n",
      "Error: RandomForestClassifier() 0.31274900398406374\n",
      "Error: ExtraTreesClassifier() 0.30677290836653387\n",
      "Error: AdaBoostClassifier() 0.2729083665338645\n",
      "Error: BaggingClassifier() 0.3237051792828685\n",
      "Error: GradientBoostingClassifier() 0.38147410358565736\n",
      "Error: MLPClassifier() 0.38745019920318724\n",
      "Error: LogisticRegression() 0.2868525896414343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.1553784860557769\n",
      "Error: DecisionTreeClassifier() 0.26593625498007967\n",
      "Error: LinearSVC() 0.30776892430278885\n",
      "Error: GaussianNB() 0.3854581673306773\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2340637450199203\n",
      "Error: LinearDiscriminantAnalysis() 0.399402390438247\n",
      "Error: RandomForestClassifier() 0.3256972111553785\n",
      "Error: ExtraTreesClassifier() 0.2918326693227092\n",
      "Error: AdaBoostClassifier() 0.27091633466135456\n",
      "Error: BaggingClassifier() 0.3147410358565737\n",
      "Error: GradientBoostingClassifier() 0.3834661354581673\n",
      "Error: MLPClassifier() 0.39741035856573703\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2811565304087737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.15054835493519442\n",
      "Error: DecisionTreeClassifier() 0.2711864406779661\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LinearSVC() 0.3040877367896311\n",
      "Error: GaussianNB() 0.37886340977068794\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23928215353938184\n",
      "Error: LinearDiscriminantAnalysis() 0.36390827517447655\n",
      "Error: RandomForestClassifier() 0.2951146560319043\n",
      "Error: ExtraTreesClassifier() 0.27916251246261214\n",
      "Error: AdaBoostClassifier() 0.26520438683948155\n",
      "Error: BaggingClassifier() 0.3220338983050847\n",
      "Error: GradientBoostingClassifier() 0.353938185443669\n",
      "Error: MLPClassifier() 0.36490528414755735\n",
      "Error: LogisticRegression() 0.27345309381237526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.20359281437125748\n",
      "Violation: {'f'} {'e', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2465069860279441\n",
      "Error: LinearSVC() 0.3073852295409182\n",
      "Error: GaussianNB() 0.34830339321357284\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23952095808383234\n",
      "Error: LinearDiscriminantAnalysis() 0.3463073852295409\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.27944111776447106\n",
      "Error: ExtraTreesClassifier() 0.282435129740519\n",
      "Error: AdaBoostClassifier() 0.2694610778443114\n",
      "Error: BaggingClassifier() 0.27045908183632733\n",
      "Error: GradientBoostingClassifier() 0.3373253493013972\n",
      "Error: MLPClassifier() 0.3592814371257485\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2777222777222777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.21478521478521478\n",
      "Violation: {'f'} {'e', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.26673326673326675\n",
      "Error: LinearSVC() 0.2937062937062937\n",
      "Error: GaussianNB() 0.3826173826173826\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.25774225774225773\n",
      "Error: LinearDiscriminantAnalysis() 0.3876123876123876\n",
      "Error: RandomForestClassifier() 0.3196803196803197\n",
      "Error: ExtraTreesClassifier() 0.2907092907092907\n",
      "Error: AdaBoostClassifier() 0.27672327672327673\n",
      "Error: BaggingClassifier() 0.3176823176823177\n",
      "Error: GradientBoostingClassifier() 0.38161838161838163\n",
      "Error: MLPClassifier() 0.3946053946053946\n",
      "Error: LogisticRegression() 0.27672327672327673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.18981018981018982\n",
      "Error: DecisionTreeClassifier() 0.26573426573426573\n",
      "Error: LinearSVC() 0.3146853146853147\n",
      "Error: GaussianNB() 0.36163836163836166\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24175824175824176\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LinearDiscriminantAnalysis() 0.37362637362637363\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.3166833166833167\n",
      "Error: ExtraTreesClassifier() 0.31868131868131866\n",
      "Error: AdaBoostClassifier() 0.2707292707292707\n",
      "Error: BaggingClassifier() 0.3106893106893107\n",
      "Error: GradientBoostingClassifier() 0.35864135864135865\n",
      "Error: MLPClassifier() 0.3706293706293706\n",
      "Error: LogisticRegression() 0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.158\n",
      "Violation: {'f'} {'d', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.273\n",
      "Error: LinearSVC() 0.303\n",
      "Error: GaussianNB() 0.369\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.258\n",
      "Error: LinearDiscriminantAnalysis() 0.373\n",
      "Error: RandomForestClassifier() 0.309\n",
      "Error: ExtraTreesClassifier() 0.299\n",
      "Error: AdaBoostClassifier() 0.26\n",
      "Error: BaggingClassifier() 0.3\n",
      "Error: GradientBoostingClassifier() 0.354\n",
      "Error: MLPClassifier() 0.358\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.123\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.281\n",
      "Error: LinearSVC() 0.317\n",
      "Error: GaussianNB() 0.363\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.254\n",
      "Error: LinearDiscriminantAnalysis() 0.384\n",
      "Error: RandomForestClassifier() 0.327\n",
      "Error: ExtraTreesClassifier() 0.306\n",
      "Error: AdaBoostClassifier() 0.274\n",
      "Error: BaggingClassifier() 0.324\n",
      "Error: GradientBoostingClassifier() 0.359\n",
      "Error: MLPClassifier() 0.375\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2652652652652653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.19519519519519518\n",
      "Error: DecisionTreeClassifier() 0.24124124124124124\n",
      "Error: LinearSVC() 0.3013013013013013\n",
      "Error: GaussianNB() 0.37737737737737737\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.26426426426426425\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LinearDiscriminantAnalysis() 0.3763763763763764\n",
      "Error: RandomForestClassifier() 0.32732732732732733\n",
      "Error: ExtraTreesClassifier() 0.3013013013013013\n",
      "Error: AdaBoostClassifier() 0.2732732732732733\n",
      "Error: BaggingClassifier() 0.32932932932932935\n",
      "Error: GradientBoostingClassifier() 0.3613613613613614\n",
      "Error: MLPClassifier() 0.3713713713713714\n",
      "Error: LogisticRegression() 0.2685370741482966\n",
      "Violation: {'f'} {'e', 'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: Perceptron() 0.10821643286573146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.29158316633266534\n",
      "Error: LinearSVC() 0.30561122244488975\n",
      "Error: GaussianNB() 0.3787575150300601\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.26152304609218435\n",
      "Error: LinearDiscriminantAnalysis() 0.3847695390781563\n",
      "Error: RandomForestClassifier() 0.312625250501002\n",
      "Error: ExtraTreesClassifier() 0.3186372745490982\n",
      "Error: AdaBoostClassifier() 0.27655310621242485\n",
      "Error: BaggingClassifier() 0.3336673346693387\n",
      "Error: GradientBoostingClassifier() 0.3687374749498998\n",
      "Error: MLPClassifier() 0.3837675350701403\n",
      "Error: LogisticRegression() 0.2858575727181545\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.2316950852557673\n",
      "Violation: {'e', 'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.275827482447342\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LinearSVC() 0.3139418254764293\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: GaussianNB() 0.3881644934804413\n",
      "Violation: {'e', 'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.22567703109327983\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LinearDiscriminantAnalysis() 0.39117352056168503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.3039117352056169\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: ExtraTreesClassifier() 0.29989969909729186\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: AdaBoostClassifier() 0.26479438314944836\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BaggingClassifier() 0.3239719157472417\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: GradientBoostingClassifier() 0.36609829488465395\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: MLPClassifier() 0.3630892678034102\n",
      "Violation: {'e', 'f'} {'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2948846539618857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.2136409227683049\n",
      "Error: DecisionTreeClassifier() 0.2748244734202608\n",
      "Error: LinearSVC() 0.3159478435305918\n",
      "Error: GaussianNB() 0.36609829488465395\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24473420260782347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: LinearDiscriminantAnalysis() 0.3691073219658977\n",
      "Violation: {'f'} {'a', 'd', 'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.30792377131394183\n",
      "Error: ExtraTreesClassifier() 0.316950852557673\n",
      "Error: AdaBoostClassifier() 0.2657973921765296\n",
      "Error: BaggingClassifier() 0.31093279839518556\n",
      "Error: GradientBoostingClassifier() 0.35005015045135407\n",
      "Error: MLPClassifier() 0.3650952858575727\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2748244734202608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.21865596790371114\n",
      "Violation: {'f'} {'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.26278836509528586\n",
      "Error: LinearSVC() 0.30090270812437314\n",
      "Error: GaussianNB() 0.3811434302908726\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23069207622868607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: LinearDiscriminantAnalysis() 0.3831494483450351\n",
      "Error: RandomForestClassifier() 0.3239719157472417\n",
      "Error: ExtraTreesClassifier() 0.3139418254764293\n",
      "Error: AdaBoostClassifier() 0.2848545636910732\n",
      "Error: BaggingClassifier() 0.3039117352056169\n",
      "Error: GradientBoostingClassifier() 0.3711133400200602\n",
      "Error: MLPClassifier() 0.38515546639919757\n",
      "Error: LogisticRegression() 0.2793969849246231\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.1678391959798995\n",
      "Error: DecisionTreeClassifier() 0.27738693467336684\n",
      "Error: LinearSVC() 0.30452261306532663\n",
      "Error: GaussianNB() 0.3698492462311558\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24723618090452262\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LinearDiscriminantAnalysis() 0.3708542713567839\n",
      "Error: RandomForestClassifier() 0.2964824120603015\n",
      "Error: ExtraTreesClassifier() 0.30251256281407035\n",
      "Error: AdaBoostClassifier() 0.26532663316582916\n",
      "Error: BaggingClassifier() 0.3075376884422111\n",
      "Error: GradientBoostingClassifier() 0.35577889447236183\n",
      "Error: MLPClassifier() 0.36381909547738694\n",
      "Error: LogisticRegression() 0.26532663316582916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.22914572864321608\n",
      "Error: DecisionTreeClassifier() 0.2804020100502513\n",
      "Error: LinearSVC() 0.2984924623115578\n",
      "Error: GaussianNB() 0.37386934673366834\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2371859296482412\n",
      "Error: LinearDiscriminantAnalysis() 0.36683417085427134\n",
      "Error: RandomForestClassifier() 0.3155778894472362\n",
      "Error: ExtraTreesClassifier() 0.3005025125628141\n",
      "Error: AdaBoostClassifier() 0.264321608040201\n",
      "Error: BaggingClassifier() 0.3155778894472362\n",
      "Error: GradientBoostingClassifier() 0.36180904522613067\n",
      "Error: MLPClassifier() 0.38090452261306534\n",
      "Error: LogisticRegression() 0.2595573440643863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.15995975855130784\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.27565392354124746\n",
      "Error: LinearSVC() 0.3158953722334004\n",
      "Error: GaussianNB() 0.3702213279678068\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23641851106639838\n",
      "Error: LinearDiscriminantAnalysis() 0.3611670020120724\n",
      "Error: RandomForestClassifier() 0.2917505030181087\n",
      "Error: ExtraTreesClassifier() 0.28470824949698187\n",
      "Error: AdaBoostClassifier() 0.27062374245472837\n",
      "Error: BaggingClassifier() 0.289738430583501\n",
      "Error: GradientBoostingClassifier() 0.3682092555331992\n",
      "Error: MLPClassifier() 0.3420523138832998\n",
      "Error: LogisticRegression() 0.2716297786720322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.2062374245472837\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2947686116700201\n",
      "Error: LinearSVC() 0.2947686116700201\n",
      "Error: GaussianNB() 0.3702213279678068\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23843058350100604\n",
      "Error: LinearDiscriminantAnalysis() 0.3702213279678068\n",
      "Error: RandomForestClassifier() 0.3118712273641851\n",
      "Error: ExtraTreesClassifier() 0.3299798792756539\n",
      "Error: AdaBoostClassifier() 0.2545271629778672\n",
      "Error: BaggingClassifier() 0.3209255533199195\n",
      "Error: GradientBoostingClassifier() 0.358148893360161\n",
      "Error: MLPClassifier() 0.3611670020120724\n",
      "Error: LogisticRegression() 0.2676056338028169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.2152917505030181\n",
      "Error: DecisionTreeClassifier() 0.2776659959758551\n",
      "Error: LinearSVC() 0.3008048289738431\n",
      "Error: GaussianNB() 0.36519114688128773\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24849094567404426\n",
      "Error: LinearDiscriminantAnalysis() 0.3682092555331992\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.2987927565392354\n",
      "Error: ExtraTreesClassifier() 0.2837022132796781\n",
      "Error: AdaBoostClassifier() 0.27364185110663986\n",
      "Error: BaggingClassifier() 0.31086519114688127\n",
      "Error: GradientBoostingClassifier() 0.3501006036217304\n",
      "Error: MLPClassifier() 0.3702213279678068\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2605633802816901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.18309859154929578\n",
      "Error: DecisionTreeClassifier() 0.2625754527162978\n",
      "Error: LinearSVC() 0.29577464788732394\n",
      "Error: GaussianNB() 0.38329979879275655\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24346076458752516\n",
      "Error: LinearDiscriminantAnalysis() 0.3641851106639839\n",
      "Error: RandomForestClassifier() 0.3028169014084507\n",
      "Error: ExtraTreesClassifier() 0.28772635814889336\n",
      "Error: AdaBoostClassifier() 0.2665995975855131\n",
      "Error: BaggingClassifier() 0.3148893360160966\n",
      "Error: GradientBoostingClassifier() 0.36016096579476864\n",
      "Error: MLPClassifier() 0.3682092555331992\n",
      "Error: LogisticRegression() 0.2618328298086606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.21953675730110775\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2719033232628399\n",
      "Error: LinearSVC() 0.3162134944612286\n",
      "Error: GaussianNB() 0.364551863041289\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2457200402819738\n",
      "Error: LinearDiscriminantAnalysis() 0.3716012084592145\n",
      "Error: RandomForestClassifier() 0.31017119838872104\n",
      "Error: ExtraTreesClassifier() 0.2980866062437059\n",
      "Error: AdaBoostClassifier() 0.2618328298086606\n",
      "Error: BaggingClassifier() 0.297079556898288\n",
      "Error: GradientBoostingClassifier() 0.35246727089627394\n",
      "Error: MLPClassifier() 0.3766364551863041\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.283987915407855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.19838872104733132\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.3021148036253776\n",
      "Error: LinearSVC() 0.3081570996978852\n",
      "Error: GaussianNB() 0.37462235649546827\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2588116817724068\n",
      "Error: LinearDiscriminantAnalysis() 0.3826787512588117\n",
      "Error: RandomForestClassifier() 0.30614300100704933\n",
      "Error: ExtraTreesClassifier() 0.33131923464249746\n",
      "Error: AdaBoostClassifier() 0.27492447129909364\n",
      "Error: BaggingClassifier() 0.3333333333333333\n",
      "Error: GradientBoostingClassifier() 0.3806646525679758\n",
      "Error: MLPClassifier() 0.3826787512588117\n",
      "Error: LogisticRegression() 0.2752016129032258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.1844758064516129\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.26411290322580644\n",
      "Error: LinearSVC() 0.3084677419354839\n",
      "Error: GaussianNB() 0.3467741935483871\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.2469758064516129\n",
      "Error: LinearDiscriminantAnalysis() 0.3558467741935484\n",
      "Error: RandomForestClassifier() 0.2963709677419355\n",
      "Error: ExtraTreesClassifier() 0.3084677419354839\n",
      "Error: AdaBoostClassifier() 0.26814516129032256\n",
      "Error: BaggingClassifier() 0.31350806451612906\n",
      "Error: GradientBoostingClassifier() 0.3548387096774194\n",
      "Error: MLPClassifier() 0.35786290322580644\n",
      "Error: LogisticRegression() 0.29939516129032256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.20262096774193547\n",
      "Violation: {'f'} {'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2782258064516129\n",
      "Error: LinearSVC() 0.29536290322580644\n",
      "Error: GaussianNB() 0.35685483870967744\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.25100806451612906\n",
      "Error: LinearDiscriminantAnalysis() 0.3497983870967742\n",
      "Error: RandomForestClassifier() 0.2923387096774194\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: ExtraTreesClassifier() 0.3034274193548387\n",
      "Error: AdaBoostClassifier() 0.26310483870967744\n",
      "Error: BaggingClassifier() 0.30443548387096775\n",
      "Error: GradientBoostingClassifier() 0.3598790322580645\n",
      "Error: MLPClassifier() 0.35181451612903225\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.2762096774193548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.17641129032258066\n",
      "Violation: {'f'} {'a', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2540322580645161\n",
      "Error: LinearSVC() 0.31048387096774194\n",
      "Error: GaussianNB() 0.36088709677419356\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24193548387096775\n",
      "Error: LinearDiscriminantAnalysis() 0.34475806451612906\n",
      "Violation: {'f'} {'c', 'f'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: RandomForestClassifier() 0.3185483870967742\n",
      "Error: ExtraTreesClassifier() 0.3175403225806452\n",
      "Error: AdaBoostClassifier() 0.25\n",
      "Error: BaggingClassifier() 0.29536290322580644\n",
      "Error: GradientBoostingClassifier() 0.3497983870967742\n",
      "Error: MLPClassifier() 0.3558467741935484\n",
      "Error: LogisticRegression() 0.26310483870967744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.18850806451612903\n",
      "Error: DecisionTreeClassifier() 0.2711693548387097\n",
      "Error: LinearSVC() 0.3004032258064516\n",
      "Error: GaussianNB() 0.3639112903225806\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24193548387096775\n",
      "Error: LinearDiscriminantAnalysis() 0.3639112903225806\n",
      "Error: RandomForestClassifier() 0.31350806451612906\n",
      "Error: ExtraTreesClassifier() 0.3064516129032258\n",
      "Error: AdaBoostClassifier() 0.26411290322580644\n",
      "Error: BaggingClassifier() 0.32963709677419356\n",
      "Error: GradientBoostingClassifier() 0.3588709677419355\n",
      "Error: MLPClassifier() 0.38205645161290325\n",
      "Error: LogisticRegression() 0.272452068617558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.11402623612512613\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2704339051463169\n",
      "Error: LinearSVC() 0.2976791120080727\n",
      "Error: GaussianNB() 0.3784056508577195\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.24217961654894046\n",
      "Error: LinearDiscriminantAnalysis() 0.36528758829465185\n",
      "Error: RandomForestClassifier() 0.29969727547931385\n",
      "Error: ExtraTreesClassifier() 0.29364278506559033\n",
      "Error: AdaBoostClassifier() 0.2704339051463169\n",
      "Error: BaggingClassifier() 0.32996972754793136\n",
      "Error: GradientBoostingClassifier() 0.34712411705348134\n",
      "Error: MLPClassifier() 0.36730575176589303\n",
      "Violation: {'f'} {'f', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: LogisticRegression() 0.28456104944500504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkyono/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Perceptron() 0.10898082744702321\n",
      "Violation: {'f'} set() g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: DecisionTreeClassifier() 0.2694248234106963\n",
      "Error: LinearSVC() 0.31079717457114026\n",
      "Error: GaussianNB() 0.384460141271443\n",
      "Violation: {'f'} {'a', 'd', 'f', 'c', 'e', 'b'} g <pycausal.pycausal.pycausal object at 0x7f4e18272f60>\n",
      "Error: BernoulliNB() 0.23814328960645811\n",
      "Error: LinearDiscriminantAnalysis() 0.38042381432896066\n",
      "Error: RandomForestClassifier() 0.3007063572149344\n",
      "Error: ExtraTreesClassifier() 0.3360242179616549\n",
      "Error: AdaBoostClassifier() 0.26437941473259335\n",
      "Error: BaggingClassifier() 0.30272452068617556\n",
      "Error: GradientBoostingClassifier() 0.3612512613521695\n",
      "Error: MLPClassifier() 0.36629667003027244\n",
      "Violations =  [ 5. 21.  2.  1. 40.  4.  7.  5.  1.  1.  1.  3. 15.]\n",
      "Model_name =  LogisticRegression() Violations =  5.0\n",
      "Average_violations =  0.030000000000000006 0.08426149773176358\n",
      "Accuracy =  0.2719357924703506 0.012704968989840538 MSE =  2.1591662382604198 0.07717034608946367\n",
      "Model_name =  Perceptron() Violations =  21.0\n",
      "Average_violations =  0.125 0.13181426326464069\n",
      "Accuracy =  0.18360832078065076 0.03268530254821634 MSE =  4.996569324977996 1.7784586297183103\n",
      "Model_name =  DecisionTreeClassifier() Violations =  2.0\n",
      "Average_violations =  0.01 0.04358898943540674\n",
      "Accuracy =  0.27153721594899854 0.011524320733645442 MSE =  2.1973493785324103 0.10537524874782324\n",
      "Model_name =  LinearSVC() Violations =  1.0\n",
      "Average_violations =  0.005 0.03122498999199199\n",
      "Accuracy =  0.30450218840844406 0.009583066492880094 MSE =  1.8667349956009467 0.07505845101893867\n",
      "Model_name =  GaussianNB() Violations =  40.0\n",
      "Average_violations =  0.96 0.13564659966250536\n",
      "Accuracy =  0.36881105842867423 0.01266105304132096 MSE =  1.1913456030795557 0.04159871631092531\n",
      "Model_name =  BernoulliNB() Violations =  4.0\n",
      "Average_violations =  0.02 0.060000000000000005\n",
      "Accuracy =  0.2452449827407536 0.011060013803140797 MSE =  3.0097563291354534 0.14023233478161667\n",
      "Model_name =  LinearDiscriminantAnalysis() Violations =  7.0\n",
      "Average_violations =  0.08499999999999999 0.23616731357239087\n",
      "Accuracy =  0.37141117401308205 0.013968871798877031 MSE =  1.1637576290644218 0.03486868366927182\n",
      "Model_name =  RandomForestClassifier() Violations =  5.0\n",
      "Average_violations =  0.05 0.1596871942267131\n",
      "Accuracy =  0.3072167932482279 0.013849110616028091 MSE =  1.6806429497447795 0.05664269419493484\n",
      "Model_name =  ExtraTreesClassifier() Violations =  1.0\n",
      "Average_violations =  0.005 0.03122498999199199\n",
      "Accuracy =  0.30162358139055956 0.015378173727373991 MSE =  1.7713614033359968 0.07338267002451651\n",
      "Model_name =  AdaBoostClassifier() Violations =  1.0\n",
      "Average_violations =  0.005 0.03122498999199199\n",
      "Accuracy =  0.2668718298777912 0.008427023156115819 MSE =  3.056338541130799 0.14686683798300632\n",
      "Model_name =  BaggingClassifier() Violations =  1.0\n",
      "Average_violations =  0.005 0.03122498999199199\n",
      "Accuracy =  0.3127731239827316 0.01479814948293206 MSE =  1.6602011544587394 0.058443567439624984\n",
      "Model_name =  GradientBoostingClassifier() Violations =  3.0\n",
      "Average_violations =  0.015000000000000003 0.0526782687642637\n",
      "Accuracy =  0.36044210117627384 0.011527124075892698 MSE =  1.319458510746523 0.0722703783915006\n",
      "Model_name =  MLPClassifier() Violations =  15.0\n",
      "Average_violations =  0.175 0.3072051431861127\n",
      "Accuracy =  0.3682277126323512 0.01323456264887373 MSE =  1.2023750435090899 0.04530389043357776\n",
      "[0.27193579 0.18360832 0.27153722 0.30450219 0.36881106 0.24524498\n",
      " 0.37141117 0.30721679 0.30162358 0.26687183 0.31277312 0.3604421\n",
      " 0.36822771] [0.01270497 0.0326853  0.01152432 0.00958307 0.01266105 0.01106001\n",
      " 0.01396887 0.01384911 0.01537817 0.00842702 0.01479815 0.01152712\n",
      " 0.01323456] [0.03  0.125 0.01  0.005 0.96  0.02  0.085 0.05  0.005 0.005 0.005 0.015\n",
      " 0.175] [0.0842615  0.13181426 0.04358899 0.03122499 0.1356466  0.06\n",
      " 0.23616731 0.15968719 0.03122499 0.03122499 0.03122499 0.05267827\n",
      " 0.30720514]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "\n",
    "from pycausal import search as s\n",
    "\n",
    "def get_CG(df, tetrad):\n",
    "    tetrad.run(algoId = 'gfci', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "           structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "           completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "    #tetrad.run(algoId = 'gfci', dfs = df, testId = 'bdeu', scoreId = 'bdeu', dataType = 'discrete',\n",
    "    #       structurePrior = 1.0, samplePrior = 1.0, maxDegree = 3, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "def get_MB(graph, var, pc):\n",
    "    parents = set()\n",
    "    for i in pc.extractTetradGraphEdges(graph):\n",
    "        if i[-1] == var and i[3:5] == '->':\n",
    "            parents.add(i[0])\n",
    "        if i[0] == var and i[3:5] == '->':\n",
    "            parents.add(i[-1])\n",
    "    return parents\n",
    "\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '5000M')\n",
    "tetrad = s.tetradrunner()\n",
    "def run_models(models, model_names, x, y, num_folds=40):\n",
    "    violations = np.zeros(len(models))\n",
    "    violation_mean = np.zeros((len(models), num_folds))\n",
    "    mean = np.zeros((len(models), num_folds))\n",
    "    mean2 = np.zeros((len(models), num_folds)) # used to store our secondary metric\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        for idx, model in enumerate(models):\n",
    "            model.fit(x_train, y_train)\n",
    "            original_df = pd.DataFrame(x_test, columns = ['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "\n",
    "            original_targets = pd.DataFrame(y_test, columns = ['g'])\n",
    "            original_df = original_df.join(original_targets)\n",
    "            test_df = pd.DataFrame(x_test, columns = ['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "            test_targets = pd.DataFrame(model.predict(x_test), columns = ['g'])\n",
    "            test_df = test_df.join(test_targets)\n",
    "            #print(get_MB(get_CG(test_df), 'g'))\n",
    "            print(\"Error:\", model_names[idx], accuracy_score(y_test, model.predict(x_test)))\n",
    "            \n",
    "            \n",
    "            mean[idx][fold] = accuracy_score(y_test, model.predict(x_test))\n",
    "            mean2[idx][fold] = mean_squared_error(y_test, model.predict(x_test))\n",
    "            \n",
    "            setA = get_MB(get_CG(original_df, tetrad), 'g', pc)\n",
    "            setB = get_MB(get_CG(test_df, tetrad), 'g', pc)\n",
    "            #assert(setA == {'f'})\n",
    "            violation_mean[idx][fold] = len(setA.difference(setB)) + len(setB.difference(setA))\n",
    "            if setA != setB:\n",
    "                print(\"Violation:\", setA , setB, 'g', pc)\n",
    "                violations[idx] += 1\n",
    "            \n",
    "            #pc.stop_vm()\n",
    "        fold += 1\n",
    "    \n",
    "    print(\"Violations = \", violations)\n",
    "    \n",
    "    metric = []\n",
    "    metric_err = []\n",
    "    viol = []\n",
    "    viol_err = []\n",
    "    \n",
    "    #normalize the violations for prettier graphing.\n",
    "    #also violations are always positive, so just divide by max.\n",
    "    violation_mean = violation_mean / np.max(violation_mean)\n",
    "    \n",
    "    for i in range(len(violations)):\n",
    "        print(\"Model_name = \", model_names[i], \"Violations = \", violations[i])\n",
    "        print(\"Average_violations = \", np.mean(violation_mean[i]), np.std(violation_mean[i]))\n",
    "        print(\"Accuracy = \", np.mean(mean[i]), np.std(mean[i]), \"MSE = \", np.mean(mean2[i]), np.std(mean2[i]),)\n",
    "        metric.append(np.mean(mean[i]))\n",
    "        metric_err.append(np.std(mean[i]))\n",
    "        viol.append(np.mean(violation_mean[i]))\n",
    "        \n",
    "        viol_err.append(np.std(violation_mean[i]))\n",
    "    print(np.array(metric), \n",
    "             np.array(metric_err), \n",
    "             np.array(viol), \n",
    "             np.array(viol_err))    \n",
    "    \n",
    "    bar_plot(model_names, \n",
    "             np.array(metric), \n",
    "             np.array(metric_err), \n",
    "             np.array(viol), \n",
    "             np.array(viol_err))\n",
    "    return \n",
    "\n",
    "X = df[['a', 'b', 'c', 'd', 'e', 'f']].values\n",
    "y = df['g'].values\n",
    "\n",
    "models = [LogisticRegression(), \n",
    "          Perceptron(),  \n",
    "          DecisionTreeClassifier(),\n",
    "          LinearSVC(),\n",
    "          GaussianNB(),\n",
    "          BernoulliNB(),\n",
    "          LinearDiscriminantAnalysis(),\n",
    "          RandomForestClassifier(),\n",
    "          ExtraTreesClassifier(),\n",
    "          AdaBoostClassifier(),\n",
    "          BaggingClassifier(),\n",
    "          GradientBoostingClassifier(),\n",
    "          MLPClassifier()\n",
    "         ]\n",
    "model_names = ['LogisticRegression()', \n",
    "          'Perceptron()',  \n",
    "          'DecisionTreeClassifier()',\n",
    "          'LinearSVC()',\n",
    "          'GaussianNB()',\n",
    "          'BernoulliNB()',\n",
    "          'LinearDiscriminantAnalysis()',\n",
    "          'RandomForestClassifier()',\n",
    "          'ExtraTreesClassifier()', \n",
    "          'AdaBoostClassifier()',\n",
    "          'BaggingClassifier()',\n",
    "          'GradientBoostingClassifier()',\n",
    "          'MLPClassifier()'\n",
    "         ]\n",
    "\n",
    "run_models(models,model_names, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boo', 'hoo', 'hoo2']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bar_plot(x_ax, val1, val1std, val2, val2std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ## the data\n",
    "    N = len(x_ax)\n",
    "\n",
    "    ## necessary variables\n",
    "    ind = np.arange(N)                # the x locations for the groups\n",
    "    width = 0.35                      # the width of the bars\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ## the bars\n",
    "    rects1 = ax.bar(ind, val1, width,\n",
    "                    color='gray',\n",
    "                    yerr=val1std,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "\n",
    "    rects2 = ax.bar(ind+width, val2, width,\n",
    "                        color='blue',\n",
    "                        #yerr=val2std,\n",
    "                        error_kw=dict(elinewidth=2,ecolor='gray'))\n",
    "\n",
    "    # axes and labels\n",
    "    ax.set_xlim(-width,len(ind)+width)\n",
    "    #ax.set_ylim(0,45)\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_title('')\n",
    "    plt.xticks(ind + width / 2, x_ax, rotation=75, size = )\n",
    "    ## add a legend\n",
    "    ax.legend( (rects1[0], rects2[0]), ('Accuracy', '% Violations') )\n",
    "    fig.savefig(\"violations.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "bar_plot(['boo', 'hoo', 'hoo2'], [1, 2, 3], [0, 0, 0], [1, 2, 3], [0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
