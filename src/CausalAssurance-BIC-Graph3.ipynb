{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes \n",
    "### Required installing Oracle JAVA 8 to get javabridge installed\n",
    "### Then, I was able to install py-causal from https://bd2kccd.github.io/docs/py-causal/\n",
    "### GFCI is slower than RFCI, but more accurate (SPIRTES), GFCI and RFCI account for unobserved variables, FGES assumes no unobserved variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure Learning Performance Guarantees If the assumptions in the previous section hold, then in the large sample limit, the CBN structure output by GFCId will contain an edge of one of four kinds between Xand Y   if and only if Xand Yare not independent conditional on any subset of the other measured variables of less than or equal to a specified size. In addition, there is (1) an arc X->Y   if and only if Xdirectly or indirectly causes Y, and Y   does not directly or indirectly cause X; (2) an edge X <-->Y   if and only if X   is not a direct or indirect cause of Yand Y   is not a direct or indirect cause of X(which can only occur if there are latent confounders of Xand some other variable or Yand some other variable; (3) an edge Xo->Y   only if Yis not a direct or indirect cause of X, but Xmay or may not be an indirect cause of Y; (4) an edge X oâ€“o Y   indicates that Xand Y   are dependent no matter what subset of observed variables is conditioned on, but contains no orientation information (X   may be a direct or indirect cause of Y, and Ymay be an indirect cause of X, or there may be a latent common cause of Xand Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying some various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512], [2048, 2048, 512]] ['temp/f0', 'temp/f1', 'temp/f2', 'temp/f3', 'temp/f4', 'temp/f5', 'temp/f6', 'temp/f7', 'temp/f8', 'temp/f9', 'temp/f10', 'temp/f11', 'temp/f12', 'temp/f13', 'temp/f14', 'temp/f15', 'temp/f16', 'temp/f17', 'temp/f18', 'temp/f19']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from pycausal import search as s\n",
    "import configparser\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, \\\n",
    "                        Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "import keras.optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "# select your GPU Here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #Comment this line out if you want all GPUS (2 hehe)\n",
    "\n",
    "# python full-display web browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def get_model(dense, dropouts, inputs):\n",
    "    # dense is an ordered list of the number of dense neurons like [1024, 2048, 1024]\n",
    "    # dropouts is an ordered list of the dropout masks like [0.2, 0.3, 0.4]\n",
    "    inputs = keras.Input(shape = (inputs,))\n",
    "\n",
    "    x = keras.layers.Dense(dense[0], activation = 'relu')(inputs)\n",
    "    x = keras.layers.Dropout(dropouts[0])(x, training=True)\n",
    "    for den, drop in zip(dense[1:], dropouts[1:]):\n",
    "        x = keras.layers.Dense(den, activation = 'relu')(x)\n",
    "        x = keras.layers.Dropout(drop)(x, training=True)\n",
    "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def discrete_gauss(low, high, samples, std = 20):\n",
    "    x = np.arange(low, high)\n",
    "    xU, xL = x + 0.5, x - 0.5 \n",
    "    prob = ss.norm.cdf(xU, scale = std) - ss.norm.cdf(xL, scale = std)\n",
    "    prob = prob / prob.sum() #normalize the probabilities so their sum is 1\n",
    "    nums = np.random.choice(x, size = samples, p = prob)\n",
    "    return nums\n",
    "\n",
    "\n",
    "\n",
    "def bar_plot(x_ax, val1, val1std, val2, val2std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ## the data\n",
    "    N = len(x_ax)\n",
    "\n",
    "    ## necessary variables\n",
    "    ind = np.arange(N)                # the x locations for the groups\n",
    "    width = 0.35                      # the width of the bars\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ## the bars\n",
    "    rects1 = ax.bar(ind, val1, width,\n",
    "                    color='gray',\n",
    "                    yerr=val1std,\n",
    "                    error_kw=dict(elinewidth=2,ecolor='blue'))\n",
    "\n",
    "    rects2 = ax.bar(ind+width, val2, width,\n",
    "                        color='blue',\n",
    "                        #yerr=val2std,\n",
    "                        error_kw=dict(elinewidth=2,ecolor='gray'))\n",
    "\n",
    "    # axes and labels\n",
    "    ax.set_xlim(-width,len(ind)+width)\n",
    "    #ax.set_ylim(0,45)\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_title('')\n",
    "    plt.xticks(ind + width / 2, x_ax, rotation=75, size = 14)\n",
    "    ## add a legend\n",
    "    ax.legend( (rects1[0], rects2[0]), ('Accuracy', '% Violations') )\n",
    "    fig.savefig(\"violations.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gen_data(mean = 0, var = 1, SIZE = 20000):\n",
    "    \n",
    "    \n",
    "    \n",
    "    g = np.random.normal(mean,var, SIZE)\n",
    "    a = g +np.random.normal(mean,var, SIZE)\n",
    "    b = g + np.random.normal(mean, var, SIZE)\n",
    "    c = g +np.random.normal(mean, var, SIZE)\n",
    "    d = g +np.random.normal(mean, var, SIZE)\n",
    "    \n",
    "    e = g + np.random.normal(mean, var, SIZE)\n",
    "    f = g + np.random.normal(mean, var, SIZE)\n",
    "    \n",
    "    #g = np.rint(g)\n",
    "    return pd.DataFrame({'a' : a,'b' : b, 'c' : c, 'd' : d,'e' : e,'f':f, 'g':g})\n",
    "\n",
    "def get_CG(df, tetrad):\n",
    "    tetrad.run(algoId = 'gfci', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "           structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "           completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "    #tetrad.run(algoId = 'fges-mb', targetName = 'g', dfs = df, testId = 'sem-bic', scoreId = 'sem-bic', dataType = 'continuous',\n",
    "    #       structurePrior = 1.0, samplePrior = 1.0, maxDegree = -1, maxPathLength = -1, \n",
    "    #       completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True)\n",
    "\n",
    "\n",
    "    return tetrad.getTetradGraph()\n",
    "\n",
    "\n",
    "\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from collections import defaultdict\n",
    "pc = pc()\n",
    "pc.start_vm(java_max_heap_size = '5000M')\n",
    "tetrad = s.tetradrunner()\n",
    "\n",
    "\n",
    "verbosity = 1\n",
    "\n",
    "\n",
    "\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "num_models =20\n",
    "model_layers = [2048, 2048, 512]\n",
    "for i in range(num_models):\n",
    "    models.append(model_layers)\n",
    "    model_names.append('temp/f' + str(i))\n",
    "\n",
    "print(models, model_names)\n",
    "\n",
    "from pycausal import prior as p\n",
    "def get_bic(df, prior):\n",
    "\n",
    "    tetrad.run(algoId = 'gfci', dfs = df,  scoreId = 'sem-bic-deterministic', dataType = 'continuous',\n",
    "               structurePrior = 1.0, samplePrior = 1, maxDegree = -1, maxPathLength = -1, priorKnowledge = prior,\n",
    "               completeRuleSetUsed = False, faithfulnessAssumed = True, verbose = True,\n",
    "               penaltyDiscount = 2\n",
    "               )\n",
    "    BIC = tetrad.getTetradGraph().getAllAttributes().toString()\n",
    "    BIC = float(BIC.split('=')[-1].split('}')[0])\n",
    "    return BIC #/ len(df)\n",
    "import itertools\n",
    "def get_pairs(lst):\n",
    "    a = set()\n",
    "    for i in itertools.permutations(lst,2):\n",
    "        a.add(i)\n",
    "    return a\n",
    "full_conx = get_pairs(['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "forced_conx = set({('g','a'), ('g','b'),('g','c'),('g','d'),('g','e'),('g','f'), })\n",
    "restricted_conx = full_conx.difference(forced_conx)   \n",
    "\n",
    "prior = p.knowledge(requiredirect =  list(map(list, forced_conx)),\n",
    "                       forbiddirect = list(map(list, restricted_conx))\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "inputs = ['a','b','c','d','e','f']\n",
    "target = ['g']\n",
    "\n",
    "\n",
    "df = gen_data()\n",
    "X = df[inputs].values\n",
    "y = df[target].values\n",
    "\n",
    "val_df = gen_data(SIZE = 2000)\n",
    "x_val = df[inputs].values\n",
    "y_val = df[target].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/f0\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 177us/step - loss: 0.1701 - mean_squared_error: 0.1701 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15249, saving model to temp/f0\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.1527 - mean_squared_error: 0.1527 - val_loss: 0.1519 - val_mean_squared_error: 0.1519\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15249 to 0.15192, saving model to temp/f0\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.1512 - mean_squared_error: 0.1512 - val_loss: 0.1523 - val_mean_squared_error: 0.1523\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15192\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.1512 - mean_squared_error: 0.1512 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15192 to 0.14996, saving model to temp/f0\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 158us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14996\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 161us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14996\n",
      "Epoch 00006: early stopping\n",
      "temp/f1\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 168us/step - loss: 0.1711 - mean_squared_error: 0.1711 - val_loss: 0.1533 - val_mean_squared_error: 0.1533\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15326, saving model to temp/f1\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1520 - val_mean_squared_error: 0.1520\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15326 to 0.15202, saving model to temp/f1\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 158us/step - loss: 0.1520 - mean_squared_error: 0.1520 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15202 to 0.15167, saving model to temp/f1\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15167 to 0.15067, saving model to temp/f1\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15067 to 0.15027, saving model to temp/f1\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 159us/step - loss: 0.1505 - mean_squared_error: 0.1505 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15027\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15027 to 0.15024, saving model to temp/f1\n",
      "Epoch 00007: early stopping\n",
      "temp/f2\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.1728 - mean_squared_error: 0.1728 - val_loss: 0.1530 - val_mean_squared_error: 0.1530\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15296, saving model to temp/f2\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 155us/step - loss: 0.1526 - mean_squared_error: 0.1526 - val_loss: 0.1522 - val_mean_squared_error: 0.1522\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15296 to 0.15217, saving model to temp/f2\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.1526 - mean_squared_error: 0.1526 - val_loss: 0.1521 - val_mean_squared_error: 0.1521\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15217 to 0.15211, saving model to temp/f2\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15211 to 0.15022, saving model to temp/f2\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 158us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1510 - val_mean_squared_error: 0.1510\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15022\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.1512 - mean_squared_error: 0.1512 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15022 to 0.14992, saving model to temp/f2\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1490 - val_mean_squared_error: 0.1490\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14992 to 0.14899, saving model to temp/f2\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14899\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.1496 - mean_squared_error: 0.1496 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14899\n",
      "Epoch 00009: early stopping\n",
      "temp/f3\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 180us/step - loss: 0.1727 - mean_squared_error: 0.1727 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15435, saving model to temp/f3\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15435 to 0.15272, saving model to temp/f3\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1526 - val_mean_squared_error: 0.1526\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15272 to 0.15265, saving model to temp/f3\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.1515 - mean_squared_error: 0.1515 - val_loss: 0.1515 - val_mean_squared_error: 0.1515\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15265 to 0.15152, saving model to temp/f3\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.1508 - val_mean_squared_error: 0.1508\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15152 to 0.15078, saving model to temp/f3\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 155us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15078 to 0.15009, saving model to temp/f3\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1503 - mean_squared_error: 0.1503 - val_loss: 0.1508 - val_mean_squared_error: 0.1508\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15009\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.1503 - mean_squared_error: 0.1503 - val_loss: 0.1497 - val_mean_squared_error: 0.1497\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15009 to 0.14975, saving model to temp/f3\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.1497 - mean_squared_error: 0.1497 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14975 to 0.14920, saving model to temp/f3\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.1503 - mean_squared_error: 0.1503 - val_loss: 0.1493 - val_mean_squared_error: 0.1493\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14920\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1498 - mean_squared_error: 0.1498 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.14920 to 0.14919, saving model to temp/f3\n",
      "Epoch 00011: early stopping\n",
      "temp/f4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.1711 - mean_squared_error: 0.1711 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15274, saving model to temp/f4\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1529 - mean_squared_error: 0.1529 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15274 to 0.15237, saving model to temp/f4\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15237 to 0.15161, saving model to temp/f4\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1509 - val_mean_squared_error: 0.1509\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15161 to 0.15087, saving model to temp/f4\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.1508 - mean_squared_error: 0.1508 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15087 to 0.15017, saving model to temp/f4\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.1506 - mean_squared_error: 0.1506 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15017 to 0.14918, saving model to temp/f4\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1506 - mean_squared_error: 0.1506 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14918\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1499 - mean_squared_error: 0.1499 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14918\n",
      "Epoch 00008: early stopping\n",
      "temp/f5\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.1746 - mean_squared_error: 0.1746 - val_loss: 0.1528 - val_mean_squared_error: 0.1528\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15275, saving model to temp/f5\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1535 - mean_squared_error: 0.1535 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15275 to 0.15168, saving model to temp/f5\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.1523 - mean_squared_error: 0.1523 - val_loss: 0.1511 - val_mean_squared_error: 0.1511\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15168 to 0.15108, saving model to temp/f5\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15108 to 0.15023, saving model to temp/f5\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15023 to 0.15013, saving model to temp/f5\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1505 - mean_squared_error: 0.1505 - val_loss: 0.1497 - val_mean_squared_error: 0.1497\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15013 to 0.14968, saving model to temp/f5\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14968\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14968\n",
      "Epoch 00008: early stopping\n",
      "temp/f6\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.1701 - mean_squared_error: 0.1701 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15242, saving model to temp/f6\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1532 - mean_squared_error: 0.1532 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15242\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15242 to 0.15169, saving model to temp/f6\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1509 - val_mean_squared_error: 0.1509\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15169 to 0.15086, saving model to temp/f6\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1498 - val_mean_squared_error: 0.1498\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15086 to 0.14985, saving model to temp/f6\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14985\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 142us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14985\n",
      "Epoch 00007: early stopping\n",
      "temp/f7\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1718 - mean_squared_error: 0.1718 - val_loss: 0.1531 - val_mean_squared_error: 0.1531\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15306, saving model to temp/f7\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1534 - mean_squared_error: 0.1534 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15306 to 0.15140, saving model to temp/f7\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1510 - val_mean_squared_error: 0.1510\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15140 to 0.15097, saving model to temp/f7\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 142us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15097\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15097 to 0.14991, saving model to temp/f7\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1496 - val_mean_squared_error: 0.1496\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14991 to 0.14958, saving model to temp/f7\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14958\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1498 - mean_squared_error: 0.1498 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14958 to 0.14910, saving model to temp/f7\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1497 - mean_squared_error: 0.1497 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14910\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1508 - mean_squared_error: 0.1508 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14910\n",
      "Epoch 00010: early stopping\n",
      "temp/f8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1722 - mean_squared_error: 0.1722 - val_loss: 0.1520 - val_mean_squared_error: 0.1520\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15203, saving model to temp/f8\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1524 - mean_squared_error: 0.1524 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15203 to 0.15174, saving model to temp/f8\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1513 - val_mean_squared_error: 0.1513\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15174 to 0.15131, saving model to temp/f8\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1510 - val_mean_squared_error: 0.1510\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15131 to 0.15098, saving model to temp/f8\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1510 - val_mean_squared_error: 0.1510\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15098 to 0.15096, saving model to temp/f8\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1501 - mean_squared_error: 0.1501 - val_loss: 0.1509 - val_mean_squared_error: 0.1509\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15096 to 0.15091, saving model to temp/f8\n",
      "Epoch 00006: early stopping\n",
      "temp/f9\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 167us/step - loss: 0.1713 - mean_squared_error: 0.1713 - val_loss: 0.1543 - val_mean_squared_error: 0.1543\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15429, saving model to temp/f9\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1533 - mean_squared_error: 0.1533 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15429 to 0.15252, saving model to temp/f9\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1512 - val_mean_squared_error: 0.1512\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15252 to 0.15121, saving model to temp/f9\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1519 - val_mean_squared_error: 0.1519\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15121\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15121 to 0.14989, saving model to temp/f9\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1499 - mean_squared_error: 0.1499 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14989\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1501 - mean_squared_error: 0.1501 - val_loss: 0.1498 - val_mean_squared_error: 0.1498\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14989 to 0.14978, saving model to temp/f9\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1498 - mean_squared_error: 0.1498 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14978 to 0.14939, saving model to temp/f9\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1501 - mean_squared_error: 0.1501 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14939 to 0.14917, saving model to temp/f9\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1499 - mean_squared_error: 0.1499 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14917\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1496 - mean_squared_error: 0.1496 - val_loss: 0.1490 - val_mean_squared_error: 0.1490\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.14917 to 0.14899, saving model to temp/f9\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 3s 142us/step - loss: 0.1490 - mean_squared_error: 0.1490 - val_loss: 0.1482 - val_mean_squared_error: 0.1482\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.14899 to 0.14816, saving model to temp/f9\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1492 - mean_squared_error: 0.1492 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.14816\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1486 - mean_squared_error: 0.1486 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.14816\n",
      "Epoch 00014: early stopping\n",
      "temp/f10\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1711 - mean_squared_error: 0.1711 - val_loss: 0.1539 - val_mean_squared_error: 0.1539\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15393, saving model to temp/f10\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1533 - mean_squared_error: 0.1533 - val_loss: 0.1515 - val_mean_squared_error: 0.1515\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15393 to 0.15151, saving model to temp/f10\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15151\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1508 - val_mean_squared_error: 0.1508\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15151 to 0.15082, saving model to temp/f10\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15082\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1509 - mean_squared_error: 0.1509 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15082 to 0.14949, saving model to temp/f10\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14949\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1496 - mean_squared_error: 0.1496 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14949 to 0.14940, saving model to temp/f10\n",
      "Epoch 00008: early stopping\n",
      "temp/f11\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 153us/step - loss: 0.1696 - mean_squared_error: 0.1696 - val_loss: 0.1542 - val_mean_squared_error: 0.1542\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15419, saving model to temp/f11\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.1535 - mean_squared_error: 0.1535 - val_loss: 0.1525 - val_mean_squared_error: 0.1525\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15419 to 0.15246, saving model to temp/f11\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15246 to 0.15174, saving model to temp/f11\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1530 - val_mean_squared_error: 0.1530\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15174\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15174 to 0.15000, saving model to temp/f11\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15000\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1499 - mean_squared_error: 0.1499 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15000 to 0.14937, saving model to temp/f11\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14937\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.1503 - mean_squared_error: 0.1503 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14937 to 0.14878, saving model to temp/f11\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1490 - mean_squared_error: 0.1490 - val_loss: 0.1489 - val_mean_squared_error: 0.1489\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14878\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.1492 - mean_squared_error: 0.1492 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.14878\n",
      "Epoch 00011: early stopping\n",
      "temp/f12\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.1718 - mean_squared_error: 0.1718 - val_loss: 0.1530 - val_mean_squared_error: 0.1530\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15303, saving model to temp/f12\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 142us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15303 to 0.15164, saving model to temp/f12\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1511 - val_mean_squared_error: 0.1511\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15164 to 0.15105, saving model to temp/f12\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.1509 - mean_squared_error: 0.1509 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15105 to 0.15073, saving model to temp/f12\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1492 - val_mean_squared_error: 0.1492\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15073 to 0.14925, saving model to temp/f12\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.1509 - mean_squared_error: 0.1509 - val_loss: 0.1498 - val_mean_squared_error: 0.1498\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14925\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.1505 - mean_squared_error: 0.1505 - val_loss: 0.1497 - val_mean_squared_error: 0.1497\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14925\n",
      "Epoch 00007: early stopping\n",
      "temp/f13\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.1721 - mean_squared_error: 0.1721 - val_loss: 0.1536 - val_mean_squared_error: 0.1536\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15359, saving model to temp/f13\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.1527 - mean_squared_error: 0.1527 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15359 to 0.15138, saving model to temp/f13\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1526 - mean_squared_error: 0.1526 - val_loss: 0.1512 - val_mean_squared_error: 0.1512\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15138 to 0.15116, saving model to temp/f13\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15116\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15116 to 0.15001, saving model to temp/f13\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1505 - mean_squared_error: 0.1505 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15001\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1493 - mean_squared_error: 0.1493 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15001\n",
      "Epoch 00007: early stopping\n",
      "temp/f14\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.1743 - mean_squared_error: 0.1743 - val_loss: 0.1523 - val_mean_squared_error: 0.1523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15228, saving model to temp/f14\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1530 - mean_squared_error: 0.1530 - val_loss: 0.1537 - val_mean_squared_error: 0.1537\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15228\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1524 - mean_squared_error: 0.1524 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15228\n",
      "Epoch 00003: early stopping\n",
      "temp/f15\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.1731 - mean_squared_error: 0.1731 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15273, saving model to temp/f15\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1530 - mean_squared_error: 0.1530 - val_loss: 0.1524 - val_mean_squared_error: 0.1524\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15273 to 0.15240, saving model to temp/f15\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1523 - mean_squared_error: 0.1523 - val_loss: 0.1518 - val_mean_squared_error: 0.1518\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15240 to 0.15180, saving model to temp/f15\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1538 - val_mean_squared_error: 0.1538\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15180\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15180 to 0.14995, saving model to temp/f15\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1505 - val_mean_squared_error: 0.1505\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.14995\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.1486 - val_mean_squared_error: 0.1486\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14995 to 0.14858, saving model to temp/f15\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1491 - mean_squared_error: 0.1491 - val_loss: 0.1493 - val_mean_squared_error: 0.1493\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14858\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.1497 - mean_squared_error: 0.1497 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14858\n",
      "Epoch 00009: early stopping\n",
      "temp/f16\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.1737 - mean_squared_error: 0.1737 - val_loss: 0.1523 - val_mean_squared_error: 0.1523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15233, saving model to temp/f16\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1525 - mean_squared_error: 0.1525 - val_loss: 0.1522 - val_mean_squared_error: 0.1522\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15233 to 0.15221, saving model to temp/f16\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1515 - val_mean_squared_error: 0.1515\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15221 to 0.15147, saving model to temp/f16\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1508 - val_mean_squared_error: 0.1508\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15147 to 0.15075, saving model to temp/f16\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.1508 - mean_squared_error: 0.1508 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15075 to 0.15062, saving model to temp/f16\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15062 to 0.15012, saving model to temp/f16\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15012 to 0.14988, saving model to temp/f16\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1498 - mean_squared_error: 0.1498 - val_loss: 0.1487 - val_mean_squared_error: 0.1487\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14988 to 0.14869, saving model to temp/f16\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1491 - mean_squared_error: 0.1491 - val_loss: 0.1491 - val_mean_squared_error: 0.1491\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14869\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.1496 - mean_squared_error: 0.1496 - val_loss: 0.1498 - val_mean_squared_error: 0.1498\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14869\n",
      "Epoch 00010: early stopping\n",
      "temp/f17\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 147us/step - loss: 0.1719 - mean_squared_error: 0.1719 - val_loss: 0.1529 - val_mean_squared_error: 0.1529\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15294, saving model to temp/f17\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.1530 - mean_squared_error: 0.1530 - val_loss: 0.1521 - val_mean_squared_error: 0.1521\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15294 to 0.15205, saving model to temp/f17\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1507 - val_mean_squared_error: 0.1507\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15205 to 0.15070, saving model to temp/f17\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 136us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.1510 - val_mean_squared_error: 0.1510\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15070\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15070 to 0.15008, saving model to temp/f17\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 0.1509 - mean_squared_error: 0.1509 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15008 to 0.14998, saving model to temp/f17\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 145us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1494 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14998 to 0.14940, saving model to temp/f17\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.1506 - mean_squared_error: 0.1506 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14940\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1498 - mean_squared_error: 0.1498 - val_loss: 0.1500 - val_mean_squared_error: 0.1500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14940\n",
      "Epoch 00009: early stopping\n",
      "temp/f18\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 165us/step - loss: 0.1735 - mean_squared_error: 0.1735 - val_loss: 0.1527 - val_mean_squared_error: 0.1527\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15274, saving model to temp/f18\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 142us/step - loss: 0.1525 - mean_squared_error: 0.1525 - val_loss: 0.1531 - val_mean_squared_error: 0.1531\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15274\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1509 - val_mean_squared_error: 0.1509\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15274 to 0.15093, saving model to temp/f18\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 140us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15093 to 0.15058, saving model to temp/f18\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 137us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1502 - val_mean_squared_error: 0.1502\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15058 to 0.15019, saving model to temp/f18\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1501 - val_mean_squared_error: 0.1501\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15019 to 0.15012, saving model to temp/f18\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15012\n",
      "Epoch 00007: early stopping\n",
      "temp/f19\n",
      "Train on 20000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 159us/step - loss: 0.1719 - mean_squared_error: 0.1719 - val_loss: 0.1532 - val_mean_squared_error: 0.1532\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15315, saving model to temp/f19\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 143us/step - loss: 0.1533 - mean_squared_error: 0.1533 - val_loss: 0.1520 - val_mean_squared_error: 0.1520\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15315 to 0.15196, saving model to temp/f19\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 146us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1533 - val_mean_squared_error: 0.1533\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15196\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1516 - val_mean_squared_error: 0.1516\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15196 to 0.15156, saving model to temp/f19\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1506 - val_mean_squared_error: 0.1506\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15156 to 0.15060, saving model to temp/f19\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.1509 - mean_squared_error: 0.1509 - val_loss: 0.1504 - val_mean_squared_error: 0.1504\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15060 to 0.15036, saving model to temp/f19\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 147us/step - loss: 0.1507 - mean_squared_error: 0.1507 - val_loss: 0.1495 - val_mean_squared_error: 0.1495\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15036 to 0.14948, saving model to temp/f19\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1490 - val_mean_squared_error: 0.1490\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14948 to 0.14899, saving model to temp/f19\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 3s 147us/step - loss: 0.1504 - mean_squared_error: 0.1504 - val_loss: 0.1488 - val_mean_squared_error: 0.1488\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14899 to 0.14877, saving model to temp/f19\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 148us/step - loss: 0.1496 - mean_squared_error: 0.1496 - val_loss: 0.1487 - val_mean_squared_error: 0.1487\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14877 to 0.14874, saving model to temp/f19\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 147us/step - loss: 0.1494 - mean_squared_error: 0.1494 - val_loss: 0.1489 - val_mean_squared_error: 0.1489\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.14874\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "for idx, model_name in enumerate(model_names):\n",
    "    print(model_name)\n",
    "\n",
    "    if type(models[idx]) is list:\n",
    "        #clear session\n",
    "        keras.backend.clear_session() \n",
    "        #get model according to specification\n",
    "        model = get_model(models[idx], [0.2] * len(models), len(inputs))\n",
    "        callbacks = [ModelCheckpoint(model_name, verbose= verbosity, monitor='val_loss',save_best_only=True), \n",
    "                     EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose= verbosity, mode='auto')]\n",
    "        model.compile(optimizer = optimizers.SGD(lr = 0.001, momentum = 0.9, ), loss='mean_squared_error', metrics = ['mse'])\n",
    "        #print(len(X), len(y))\n",
    "        model.fit(X, y, epochs = 20, validation_data = (x_val, y_val), callbacks = callbacks, batch_size = 32, verbose = verbosity)\n",
    "    else:\n",
    "        models[idx].fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "2 1\n",
      "2 2\n",
      "2 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n            setA = get_MB(get_CG(perturbed_df, tetrad), \\'g\\', pc)\\n            if setA != {\\'f\\'}:\\n                print(\"Error in SETA markov blanket\")\\n                #setA = {\\'f\\'}\\n            setC = get_MB(get_CG(test_df2, tetrad), \\'g\\', pc)\\n\\n            if setA != setC:\\n                causal_dicts[idx][str(m) + \\'_\\' + str(v)].append(1)\\n            else:\\n                causal_dicts[idx][str(m) + \\'_\\' + str(v)].append(0)\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_test = 2000\n",
    "metrics_dicts = []\n",
    "for m in models:\n",
    "    metrics_dicts.append(defaultdict(list))\n",
    "\n",
    "\n",
    "#means = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "#variances = [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n",
    "means = [0, 1, 2]\n",
    "variances = [1,2,3]\n",
    "\n",
    "\n",
    "# ok at this point we need to check the model on various variances and means\n",
    "for m in means:\n",
    "    for v in variances:\n",
    "        print(m,v)\n",
    "        #t0 = time.time()\n",
    "        perturbed_df = gen_data(mean =m, var = v, SIZE = nb_test)\n",
    "        y_test2 = perturbed_df[target]\n",
    "        x_test2 = perturbed_df[inputs]\n",
    "        #t1 = time.time()\n",
    "        #print(\"Time for gen_data = \", t1 - t0)\n",
    "        for idx, model_name in enumerate(model_names):\n",
    "            #t0 = time.time()\n",
    "            if type(models[idx]) is list:\n",
    "                keras.backend.clear_session()\n",
    "                model = load_model(model_name)\n",
    "            else:\n",
    "                model = models[idx]\n",
    "            #t1 = time.time()\n",
    "            #print(\"Time to load model = \", t1 - t0)\n",
    "            \n",
    "            y_pred2 = model.predict(x_test2)\n",
    "            metrics_dicts[idx][str(m) + '_' + str(v)].append(mean_squared_error(y_test2, y_pred2))\n",
    "\n",
    "            test_df2 = pd.DataFrame(x_test2, columns = inputs)\n",
    "            test_targets2 = pd.DataFrame(model.predict(x_test2), columns = target)\n",
    "            test_df2 = test_df2.join(test_targets2)\n",
    "'''\n",
    "            setA = get_MB(get_CG(perturbed_df, tetrad), 'g', pc)\n",
    "            if setA != {'f'}:\n",
    "                print(\"Error in SETA markov blanket\")\n",
    "                #setA = {'f'}\n",
    "            setC = get_MB(get_CG(test_df2, tetrad), 'g', pc)\n",
    "\n",
    "            if setA != setC:\n",
    "                causal_dicts[idx][str(m) + '_' + str(v)].append(1)\n",
    "            else:\n",
    "                causal_dicts[idx][str(m) + '_' + str(v)].append(0)\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times =  0\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8068.697388401631\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8007.619629694089\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8039.905462753027\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8104.680482807253\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7954.607235512097\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8026.416837234839\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8083.087637573258\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8018.260776361225\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7968.333852895309\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7978.7526679722405\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8099.786935197061\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8046.745943448911\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8063.031192112447\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7979.121735321379\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8007.273605827093\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8003.604161520374\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8041.491922800435\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8007.2237537431065\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8032.169793979922\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8058.057087304027\n",
      "Times =  1\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8514.418587408301\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8458.591415531344\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8447.890412906034\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8538.818307996333\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8399.347279482286\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8450.844891926647\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8493.324588382604\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8454.205119385595\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8404.233858958221\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8397.750148291836\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8523.20175527402\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8469.18707864623\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8496.724536411173\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8441.899521159974\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8463.597266038523\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8428.484363415197\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8465.919553442774\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8409.924621188751\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8444.362028132447\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8484.44603534692\n",
      "Times =  2\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8111.6624075940845\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8015.683757545325\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8031.389169608727\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8122.340178337202\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7975.975434876261\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8025.266742569509\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8073.033331453\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7997.90119083501\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7966.513335879199\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7964.044531404543\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8121.13830766455\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8031.432449065681\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8077.431665944054\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7982.197168165033\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8004.825113569495\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8005.581852233385\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8037.2812402196005\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7974.151763574224\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8028.602368915853\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8066.8218978836685\n",
      "Times =  3\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8460.087906730527\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8366.152892899356\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8395.40972863725\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8493.281137006523\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8327.864480521119\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8389.26687308513\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8444.67002070312\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8405.555876447215\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8347.322774979617\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8343.648527879799\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8480.321761755411\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8385.440378804555\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8456.437213199659\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8362.734936120307\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8380.387165723227\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8348.331655046235\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8412.014070959563\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8380.931754088975\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8395.188118464035\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8400.51068659977\n",
      "Times =  4\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8615.487533445701\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8549.564888035042\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8569.238810163457\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8660.666516801992\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8484.403497690053\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8562.073435299657\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8618.045745512642\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8545.388581779507\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8503.601242525947\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8504.48101477962\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8645.85850942519\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8569.425041331959\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8626.70627968546\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8524.42422680509\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8550.170258934895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8529.319104735989\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8583.717953555471\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8535.549561082253\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8546.660127710295\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8598.36441815911\n",
      "Times =  5\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8077.345458052634\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7999.766787123133\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8021.253063652215\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8099.440117639254\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7918.591512160429\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7995.203832958971\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8068.791942717167\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7998.817333679645\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7937.07024456724\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7936.634011372131\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8121.194161767491\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7995.900229186851\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8059.054107104233\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7981.000090847911\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8005.639496493278\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7994.35818981565\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8037.799055157776\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7956.50906556345\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8019.151402777168\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8036.516454599622\n",
      "Times =  6\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7977.829099979419\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7903.512255842831\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7918.001106776556\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7995.350105426256\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7851.167607255763\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7896.229301834569\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7968.674452043818\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7887.526775896818\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7857.825969060275\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7853.739837137249\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8002.312106748393\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7915.419583151768\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7949.956219629409\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7895.353740719652\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7884.893036563387\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7882.967779216682\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7937.849163609509\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7861.0436768507025\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7913.807612026032\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7954.019579129115\n",
      "Times =  7\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8715.592256044418\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8650.079671241487\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8692.960126749742\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8756.311112890337\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8613.511792528452\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8674.692083706472\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8747.67289064986\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8666.13747281086\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8633.783376456637\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8598.098730408181\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8762.16198773003\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8688.99843305071\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8723.010772394335\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8638.146755938791\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8681.422466642998\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8636.170923399073\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8682.56257536421\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8628.129358174705\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8654.894219715221\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8688.783830553071\n",
      "Times =  8\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8023.788092269139\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7934.272519691352\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7934.285532417729\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8032.121435322729\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7867.2442002885755\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7934.88592201923\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8010.610846224151\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7940.686752526312\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7870.8420695912755\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7884.120188265254\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-8037.050128261188\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7932.885521457\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7976.198115245996\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7912.714517752869\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7927.6670560332195\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7898.7763170579565\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7960.051523097374\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7892.567387375742\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7926.639658205605\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7974.3629738936315\n",
      "Times =  9\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7941.743831454637\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7846.839375528878\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7854.64392856722\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7946.223723559839\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7764.890157387903\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7842.786295725382\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7903.934430079131\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7842.737594134607\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7786.6784291296735\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7782.78843282471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7917.434002842431\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7854.073552528583\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7890.844376062789\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7806.875474920823\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7846.901946321816\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7826.3161164756175\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7864.230013048922\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7806.846096150699\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7833.636252958606\n",
      "['g --> a', 'g --> b', 'g --> c', 'g --> d', 'g --> e', 'g --> f']\n",
      "-7877.145379891813\n",
      "Model_name =  temp/f0 Violations =  0.0\n",
      "Average_violations =  -8250.665256138049 276.8564947803288\n",
      "MSE =  0.1501119686432111 0.005126811776896805\n",
      "Model_name =  temp/f1 Violations =  0.0\n",
      "Average_violations =  -8173.208319313283 283.96834514272905\n",
      "MSE =  0.1494491838218994 0.006122008628037503\n",
      "Model_name =  temp/f2 Violations =  0.0\n",
      "Average_violations =  -8190.497734223197 288.7018157505181\n",
      "MSE =  0.14882245270453537 0.00611262870375598\n",
      "Model_name =  temp/f3 Violations =  0.0\n",
      "Average_violations =  -8274.923311778772 287.4141049454694\n",
      "MSE =  0.14941568856131968 0.005966744887940772\n",
      "Model_name =  temp/f4 Violations =  0.0\n",
      "Average_violations =  -8115.760319770294 291.2609080016671\n",
      "MSE =  0.1489880414674386 0.005308942907199844\n",
      "Model_name =  temp/f5 Violations =  0.0\n",
      "Average_violations =  -8179.76662163604 290.4907911703629\n",
      "MSE =  0.1482893595331408 0.0061873957482559095\n",
      "Model_name =  temp/f6 Violations =  0.0\n",
      "Average_violations =  -8241.184588533875 287.6956799208891\n",
      "MSE =  0.14942399112556498 0.005460612833190294\n",
      "Model_name =  temp/f7 Violations =  0.0\n",
      "Average_violations =  -8175.72174738568 290.5896391115742\n",
      "MSE =  0.14866937959040166 0.005972446231333846\n",
      "Model_name =  temp/f8 Violations =  0.0\n",
      "Average_violations =  -8127.620515404339 294.1002069530856\n",
      "MSE =  0.15016379880009748 0.005182016949124525\n",
      "Model_name =  temp/f9 Violations =  0.0\n",
      "Average_violations =  -8124.4058090335575 286.62085545790535\n",
      "MSE =  0.14768450373204137 0.006008903645313763\n",
      "Model_name =  temp/f10 Violations =  0.0\n",
      "Average_violations =  -8271.045965666577 285.539695108872\n",
      "MSE =  0.14896930698331357 0.005983712875978129\n",
      "Model_name =  temp/f11 Violations =  0.0\n",
      "Average_violations =  -8188.950821067226 290.9953795894187\n",
      "MSE =  0.1486776463027543 0.005443225435082077\n",
      "Model_name =  temp/f12 Violations =  0.0\n",
      "Average_violations =  -8231.939447778954 293.43794912150537\n",
      "MSE =  0.14947168148128828 0.006008258674832787\n",
      "Model_name =  temp/f13 Violations =  0.0\n",
      "Average_violations =  -8152.446816775182 288.73587748922694\n",
      "MSE =  0.14927505831792698 0.006571945939438077\n",
      "Model_name =  temp/f14 Violations =  0.0\n",
      "Average_violations =  -8175.277741214792 293.50409195988937\n",
      "MSE =  0.151154073948834 0.006172190168231463\n",
      "Model_name =  temp/f15 Violations =  0.0\n",
      "Average_violations =  -8155.391046291616 283.29260853439104\n",
      "MSE =  0.14876452056400594 0.005970028668123976\n",
      "Model_name =  temp/f16 Violations =  0.0\n",
      "Average_violations =  -8202.291707125562 285.07331189545476\n",
      "MSE =  0.1481714078134597 0.005681015975766425\n",
      "Model_name =  temp/f17 Violations =  0.0\n",
      "Average_violations =  -8145.287703779261 292.265749362665\n",
      "MSE =  0.14909455132662433 0.005887554587253666\n",
      "Model_name =  temp/f18 Violations =  0.0\n",
      "Average_violations =  -8179.511158288517 283.1642574492861\n",
      "MSE =  0.14998567362790544 0.006252226834835111\n",
      "Model_name =  temp/f19 Violations =  0.0\n",
      "Average_violations =  -8213.902834336073 282.32067667754274\n",
      "MSE =  0.14846052309913896 0.006201446607119989\n",
      "[0.15011197 0.14944918 0.14882245 0.14941569 0.14898804 0.14828936\n",
      " 0.14942399 0.14866938 0.1501638  0.1476845  0.14896931 0.14867765\n",
      " 0.14947168 0.14927506 0.15115407 0.14876452 0.14817141 0.14909455\n",
      " 0.14998567 0.14846052] [0.00512681 0.00612201 0.00611263 0.00596674 0.00530894 0.0061874\n",
      " 0.00546061 0.00597245 0.00518202 0.0060089  0.00598371 0.00544323\n",
      " 0.00600826 0.00657195 0.00617219 0.00597003 0.00568102 0.00588755\n",
      " 0.00625223 0.00620145] [-8250.66525614 -8173.20831931 -8190.49773422 -8274.92331178\n",
      " -8115.76031977 -8179.76662164 -8241.18458853 -8175.72174739\n",
      " -8127.6205154  -8124.40580903 -8271.04596567 -8188.95082107\n",
      " -8231.93944778 -8152.44681678 -8175.27774121 -8155.39104629\n",
      " -8202.29170713 -8145.28770378 -8179.51115829 -8213.90283434] [276.85649478 283.96834514 288.70181575 287.41410495 291.260908\n",
      " 290.49079117 287.69567992 290.58963911 294.10020695 286.62085546\n",
      " 285.53969511 290.99537959 293.43794912 288.73587749 293.50409196\n",
      " 283.29260853 285.0733119  292.26574936 283.16425745 282.32067668]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/f0\n",
      "Area under surface (rectangular approx) =  14.800153953508506\n",
      "Violations =  0.0\n",
      "Average_violations =  -8250.665256138049\n",
      "MSE =  0.1501119686432111\n",
      "temp/f1\n",
      "Area under surface (rectangular approx) =  15.066033708142987\n",
      "Violations =  0.0\n",
      "Average_violations =  -8173.208319313283\n",
      "MSE =  0.1494491838218994\n",
      "temp/f2\n",
      "Area under surface (rectangular approx) =  14.096358398877621\n",
      "Violations =  0.0\n",
      "Average_violations =  -8190.497734223197\n",
      "MSE =  0.14882245270453537\n",
      "temp/f3\n",
      "Area under surface (rectangular approx) =  14.490292436096837\n",
      "Violations =  0.0\n",
      "Average_violations =  -8274.923311778772\n",
      "MSE =  0.14941568856131968\n",
      "temp/f4\n",
      "Area under surface (rectangular approx) =  13.521597162095938\n",
      "Violations =  0.0\n",
      "Average_violations =  -8115.760319770294\n",
      "MSE =  0.1489880414674386\n",
      "temp/f5\n",
      "Area under surface (rectangular approx) =  13.480792223527494\n",
      "Violations =  0.0\n",
      "Average_violations =  -8179.76662163604\n",
      "MSE =  0.1482893595331408\n",
      "temp/f6\n",
      "Area under surface (rectangular approx) =  15.138905931302158\n",
      "Violations =  0.0\n",
      "Average_violations =  -8241.184588533875\n",
      "MSE =  0.14942399112556498\n",
      "temp/f7\n",
      "Area under surface (rectangular approx) =  14.101932579118039\n",
      "Violations =  0.0\n",
      "Average_violations =  -8175.72174738568\n",
      "MSE =  0.14866937959040166\n",
      "temp/f8\n",
      "Area under surface (rectangular approx) =  14.47726984512723\n",
      "Violations =  0.0\n",
      "Average_violations =  -8127.620515404339\n",
      "MSE =  0.15016379880009748\n",
      "temp/f9\n",
      "Area under surface (rectangular approx) =  13.458992256731971\n",
      "Violations =  0.0\n",
      "Average_violations =  -8124.4058090335575\n",
      "MSE =  0.14768450373204137\n",
      "temp/f10\n",
      "Area under surface (rectangular approx) =  15.390848112696592\n",
      "Violations =  0.0\n",
      "Average_violations =  -8271.045965666577\n",
      "MSE =  0.14896930698331357\n",
      "temp/f11\n",
      "Area under surface (rectangular approx) =  14.039825886187742\n",
      "Violations =  0.0\n",
      "Average_violations =  -8188.950821067226\n",
      "MSE =  0.1486776463027543\n",
      "temp/f12\n",
      "Area under surface (rectangular approx) =  14.48287177315245\n",
      "Violations =  0.0\n",
      "Average_violations =  -8231.939447778954\n",
      "MSE =  0.14947168148128828\n",
      "temp/f13\n",
      "Area under surface (rectangular approx) =  13.943181828549042\n",
      "Violations =  0.0\n",
      "Average_violations =  -8152.446816775182\n",
      "MSE =  0.14927505831792698\n",
      "temp/f14\n",
      "Area under surface (rectangular approx) =  13.574210573441281\n",
      "Violations =  0.0\n",
      "Average_violations =  -8175.277741214792\n",
      "MSE =  0.151154073948834\n",
      "temp/f15\n",
      "Area under surface (rectangular approx) =  14.154867073548298\n",
      "Violations =  0.0\n",
      "Average_violations =  -8155.391046291616\n",
      "MSE =  0.14876452056400594\n",
      "temp/f16\n",
      "Area under surface (rectangular approx) =  14.224000908576814\n",
      "Violations =  0.0\n",
      "Average_violations =  -8202.291707125562\n",
      "MSE =  0.1481714078134597\n",
      "temp/f17\n",
      "Area under surface (rectangular approx) =  13.49666274574512\n",
      "Violations =  0.0\n",
      "Average_violations =  -8145.287703779261\n",
      "MSE =  0.14909455132662433\n",
      "temp/f18\n",
      "Area under surface (rectangular approx) =  14.819967796749005\n",
      "Violations =  0.0\n",
      "Average_violations =  -8179.511158288517\n",
      "MSE =  0.14998567362790544\n",
      "temp/f19\n",
      "Area under surface (rectangular approx) =  13.973010609133453\n",
      "Violations =  0.0\n",
      "Average_violations =  -8213.902834336073\n",
      "MSE =  0.14846052309913896\n"
     ]
    }
   ],
   "source": [
    "#the number of times to sample\n",
    "times = 10\n",
    "## the size of the test set\n",
    "\n",
    "\n",
    "violations = np.zeros(len(models))\n",
    "violation_mean = np.zeros((len(models), times))\n",
    "violation_mean2 = np.zeros((len(models), times))\n",
    "mean = np.zeros((len(models), times))\n",
    "\n",
    "fold = 0\n",
    "\n",
    "\n",
    "\n",
    "for t in range(times):\n",
    "    print(\"Times = \", t)\n",
    "    df_test = gen_data(SIZE = nb_test)\n",
    "    x_test = df_test[inputs].values\n",
    "    y_test = df_test[target].values\n",
    "    #bic_orig = get_bic(df_test,prior)\n",
    "\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        if type(models[idx]) is list:\n",
    "            keras.backend.clear_session()\n",
    "            model = load_model(model_name)\n",
    "        else:\n",
    "            model = models[idx]\n",
    "        test_df = pd.DataFrame(x_test, columns = inputs)\n",
    "        test_targets = pd.DataFrame(model.predict(x_test), columns = target)\n",
    "        test_df = test_df.join(test_targets)\n",
    "       \n",
    "        \n",
    "    \n",
    "        mean[idx][t] = mean_squared_error(y_test, model.predict(x_test)) \n",
    "        \n",
    "        bic_pred = get_bic(test_df,prior)\n",
    "        \n",
    "        #bic_pred = get_bic(df_test.join(pd.DataFrame(model.predict(x_test), columns = ['target'])), prior)\n",
    "        \n",
    "        print(tetrad.getEdges())\n",
    "        print(bic_pred)\n",
    "        violation_mean[idx][t] = bic_pred\n",
    "        violation_mean2[idx][t] = bic_pred\n",
    "        #print(bic_orig - bic_pred)\n",
    "metric = []\n",
    "metric_err = []\n",
    "viol = []\n",
    "viol_err = []\n",
    "\n",
    "#normalize the violations for prettier graphing.\n",
    "#also violations are always positive, so just divide by max.\n",
    "\n",
    "#TMK\n",
    "#violation_mean = violation_mean / np.max(violation_mean)\n",
    "\n",
    "for i in range(len(violations)):\n",
    "    print(\"Model_name = \", model_names[i], \"Violations = \", violations[i])\n",
    "    print(\"Average_violations = \", np.mean(violation_mean[i]), np.std(violation_mean[i]))\n",
    "    print(\"MSE = \", np.mean(mean[i]), np.std(mean[i]))\n",
    "    #print(\"mean = \", mean[i])\n",
    "    metric.append(np.mean(mean[i]))\n",
    "    metric_err.append(np.std(mean[i]))\n",
    "    viol.append(np.mean(violation_mean[i]))\n",
    "    #viol.append(violations[i]/times)\n",
    "    viol_err.append(np.std(violation_mean[i]))\n",
    "print(np.array(metric), \n",
    "         np.array(metric_err), \n",
    "         np.array(viol), \n",
    "         np.array(viol_err))    \n",
    "\n",
    "bar_plot(model_names, \n",
    "         np.array(metric), \n",
    "         np.array(metric_err), \n",
    "         np.array(viol), \n",
    "         np.array(viol_err))\n",
    "\n",
    "\n",
    "def heat_plot(x,y,z, xlab = 'Mean', ylab = 'Variance', clim_low = 0, clim_high = 1):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    cax = ax.scatter(x, y, c=z, s=450, edgecolor='')\n",
    "    cax.set_clim(clim_low, clim_high)\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(ylab)\n",
    "    plt.colorbar(cax)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "MSE = []\n",
    "VIO = []\n",
    "VIO2 = []\n",
    "AUS = []\n",
    "for i, m in enumerate(models):\n",
    "    print(model_names[i])\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    \n",
    "    rectangular_approx = 0\n",
    "    for k, v in metrics_dicts[i].items():\n",
    "        x.append(float(k.split('_')[0]))\n",
    "        y.append(float(k.split('_')[-1]))\n",
    "        z.append(np.mean(v))\n",
    "        rectangular_approx += np.mean(v)\n",
    "    print(\"Area under surface (rectangular approx) = \", rectangular_approx)\n",
    "    print(\"Violations = \", violations[i])\n",
    "    print(\"Average_violations = \", np.mean(violation_mean[i]))\n",
    "    print(\"MSE = \", np.mean(mean[i]))   \n",
    "    MSE.append(np.mean(mean[i]))\n",
    "    VIO.append(np.mean(violation_mean[i]))\n",
    "    VIO2.append(np.mean(violation_mean2[i]))\n",
    "    AUS.append(rectangular_approx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6385023179646593\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6017031908445655\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXJwSocGuFEL0gSwhaLdoYzIDxqpSldb/orVpxt0JRq/fX2qtVqxWKWlyvrXVpKVpQERfUSt0totZbY0kU2dwwEERQMKDWBUPI5/fHOaFDmKyTMzOZvJ+Pxzxyzvd8zzmfHMJ85vs93/kec3dERETaKifdAYiISMemRCIiIklRIhERkaQokYiISFKUSEREJClKJCIikhQlEhERSYoSiYiIJEWJREREkpKb7gBSoU+fPl5QUJDuMEREOpSKioqP3D2/uXqdIpEUFBRQXl6e7jBERDoUM6tqST11bYmISFKUSEREJClKJCIikhQlEhERSYoSiYiIJEWJREREkqJEIlmtomoTty5YQUXVpnSHIpK1OsX3SKRzqqjaxCkzyqipraNbbg6zJ5ZSMqhXusMSyTpqkUjWKquspqa2jjqHLbV1lFVWpzskkaykRCJZq7Qwj265OXQx6JqbQ2lhXrpDEslK6tqSrFUyqBezJ5ZSVllNaWGeurVEIqJEIlmtZFAvJRCRiKlrS0REkqJEIiIiSVEiERGRpCiRtEKXLl0oLi5m33335YQTTuCLL75Id0iRO+mkkygqKuKmm27izTffpLi4mGHDhvHuu+9uV2/lypUccMAB7Lnnnpx44onU1NTscKx//OMfFBcXU1xczH777ccjjzyybdtTTz3FXnvtxR577ME111wT+e8lIu3I3bP+VVJS4u2hZ8+e25ZPPvlkv/HGG5M+Zm1tbdLHiMq6det84MCB29anTZvmV1xxRcK6J5xwgs+ZM8fd3c8++2y/7bbbdqjz+eef+5YtW9zdfe3atZ6fn+9btmzx2tpaLyws9Hfffde/+uorLyoq8mXLlkXwG4lIawDl3oL3WLVI2uiQQw5hxYoVANxzzz2MGDGC4uJizj77bLZu3QrAueeeSywWY5999mHy5Mnb9i0oKGDq1KkcfPDBPPjgg9x8880MHTqUoqIixo8fD8DGjRs59thjKSoqorS0lMWLFwMwZcoUzjrrLEaNGkVhYSE333xzwvieeuop9t9/f/bbbz/Gjh3b5DE///xzzjrrLIYPH86wYcN49NFHATj00ENZv349xcXF/OpXv+I3v/kNM2bMYPTo0dudy9157rnnOP744wE444wz+POf/7xDTD169CA3NxgouHnzZswMCFoqe+yxB4WFhXTr1o3x48dvi0FEOoCWZJuO/mrvFsmWLVt83Lhxftttt/ny5cv96KOP9pqaGnd3P/fcc33WrFnu7l5dXe3uQavjO9/5jr/++uvu7j5o0CC/9tprtx23b9++vnnzZnd337Rpk7u7n3/++T5lyhR3d58/f77vt99+7u4+efJkP/DAA33z5s2+YcMG792797Zz11u/fr3379/fKysrt4ujsWNeeumlfvfdd287/5577umfffaZr1y50vfZZ59tx508ebJff/3129aPOOIIf//9933Dhg0+ZMiQbeWrV6/ebr94ZWVlPnToUO/Zs6c//PDD7u7+4IMP+oQJE7bVueuuu/y8885LuL+IpA7pbpGY2Z1mtt7MlsaVTTGz981sUfg6MsF+A8xsgZm9YWbLzOwnrdk/Sl9++SXFxcXEYjEGDhzIhAkTmD9/PhUVFQwfPpzi4mLmz59PZWUlAA888AD7778/w4YNY9myZSxfvnzbsU488cRty0VFRZxyyincc8892z6xv/TSS5x22mkAjBkzhurqaj755BMAjjrqKLp3706fPn3Ydddd+fDDD7eLs6ysjJEjRzJ48GAAevfu3eQxn3nmGa655hqKi4sZNWoUmzdvZvXq1c1ejyeeeIJ+/foR/L1tr7610dABBxzAsmXLWLhwIdOmTWPz5s2t2l9EMk+UX0icCdwC3NWg/CZ3v6GJ/WqB/3H3V83s60CFmT3r7stbuH9kdtppJxYtWrRdmbtzxhlnMG3atO3KV65cyQ033MDChQvp1asXZ555Jps3b962vWfPntuWH3/8cV588UXmzZvHlVdeybJly5p8c+3evfu2si5dulBbW7tDTIneiBs7prvz0EMPsddee223bdWqVTvUT6RPnz58/PHH1NbWkpuby5o1a+jXr1+T+3zrW9+iZ8+eLF26lP79+/Pee+9t29aS/UUkc0TWInH3F4GNbdhvnbu/Gi7/E3gD2L2dw2s3Y8eOZe7cuaxfvx4I7kNUVVXx6aef0rNnT77xjW/w4Ycf8uSTTybcv66ujvfee4/Ro0dz3XXX8fHHH/PZZ58xcuRIZs+eDcDzzz9Pnz592HnnnVsU04EHHsgLL7zAypUrt8UENHrMww47jN/97nfbEs1rr73WqmtgZowePZq5c+cCMGvWLI455pgd6q1cuXJb0quqquKtt96ioKCA4cOH884777By5Upqamq47777GDduXKtiEJH0SccUKeeb2elAOUHLo9EHRZhZATAMeKUt+6fC0KFDueqqqzj00EOpq6uja9eu3HrrrZSWljJs2DD22WcfCgsLOeiggxLuv3XrVk499VQ++eQT3J0LLriAXXbZhSlTpvDDH/6QoqIievTowaxZs1ocU35+PtOnT+f73/8+dXV17Lrrrjz77LONHvOXv/wlP/3pTykqKsLdKSgo4LHHHmv2PEceeSQzZsygX79+XHvttYwfP57LL7+cYcOGMWHCBADmzZtHeXk5U6dO5aWXXuKaa66ha9eu5OTkcNttt9GnTx8AbrnlFg477DC2bt3KWWedxT777NPi31dE0ssSdXe028GDRPCYu+8bru8GfAQ4cCXQ193PamTffwNeAK5294fbsP8kYBLAwIEDS6qqqtrvFxMR6QTMrMLdY83VS+nwX3f/0N23unsd8EdgRKJ6ZtYVeAiYXZ9EWrN/WHe6u8fcPZafn9++v4iIiGyT0kRiZn3jVv8LWJqgjgF3AG+4+/+2dn8REUmtyO6RmNkcYBTQx8zWAJOBUWZWTNA1tQo4O6zbD5jh7kcCBwGnAUvMrH6I1C/c/QngukT7i4hI+kR6jyRTxGIxLy8vT3cYIiIdSkbeIxERkeyjRCIiIklRIhERkaQokYiISFKUSETSqKJqE7cuWEFFVVonaBBJSjqmSBERgiRyyowyamrr6Jabw+yJpZQM6pXusERaTS0SkTQpq6ympraOOocttXWUVVanOySRNlEiEUmT0sI8uuXm0MWga24OpYV56Q5JpE3UtSWSJiWDejF7YillldWUFuapW0s6LCUSkTQqGdRLCUQ6PHVtiYhIUpRIRDKAhgFLR6auLZE00zBg6ejUIhFJMw0Dlo5OiUQkzTQMWDo6dW2JpJmGAUtHp0QikgE0DFg6ski7tszsTjNbb2ZL48qmmNn7ZrYofB3ZyL6Hm9lbZrbCzC6JKx9sZq+Y2Ttmdr+ZdYvydxARkaZFfY9kJnB4gvKb3L04fD3RcKOZdQFuBY4AhgInmdnQcPO14f57ApuACZFELiIiLRJpInH3F4GNbdh1BLDC3SvdvQa4DzjGzAwYA8wN680Cjm2XYEVEpE3SNWrrfDNbHHZ9JeoY3h14L259TViWB3zs7rUNyndgZpPMrNzMyjds2NCesYuISJx0JJLbgSFAMbAOuDFBHUtQ5k2U71joPt3dY+4ey8/Pb2usIiLSjJQnEnf/0N23unsd8EeCbqyG1gAD4tb7A2uBj4BdzCy3QbmIiKRJyhOJmfWNW/0vYGmCaguBPcMRWt2A8cA8d3dgAXB8WO8M4NEo4xURkaZFPfx3DvAysJeZrTGzCcB1ZrbEzBYDo4ELwrr9zOwJgPAeyPnA08AbwAPuviw87MXAz8xsBcE9kzui/B1ERKRpFnzIz26xWMzLy8vTHYaISIdiZhXuHmuunubaEhGRpCiRiIhIUpRIREQkKUokIiKSFCUSERFJihKJiIgkRYlERESSokQiIiJJUSIREZGkKJGIiEhSlEhERCQpSiQikpSKqk3cumAFFVWb0h2KpElu81VERBKrqNrEKTPKqKmto1tuDrMnllIyKNFDTyWbqUUiIm1WVllNTW0ddQ5bausoq6xusr5aL9lJLRIRabPSwjy65eawpbaOrrk5lBbmNVpXrZfspUQiIm1WMqgXsyeWUlZZTWlhXpOJIVHrRYkkO0TWtWVmd5rZejPb4VG6ZnahmbmZ9UmwbbSZLYp7bTazY8NtM81sZdy24qjiF5GWKRnUi/NG79FsUqhvvXQxmm29SMcSZYtkJnALcFd8oZkNAL4HrE60k7svAIrDur2BFcAzcVUucve5EcQrIhFqTetFOpbIEom7v2hmBQk23QT8HHi0BYc5HnjS3b9ox9BEJE1KBvVSAslCKR21ZWbjgPfd/fUW7jIemNOg7GozW2xmN5lZ9/aNUEREWitlicTMegCXAVe0sH5f4NvA03HFlwJ7A8OB3sDFTew/yczKzax8w4YNbY5bRESalsoWyRBgMPC6ma0C+gOvmtm/N1L/B8Aj7r6lvsDd13ngK+BPwIjGTubu09095u6x/Pz8dvslRERkeykb/uvuS4Bd69fDZBJz948a2eUkghbINmbW193XmZkBxwI7jAgTEZHUinL47xzgZWAvM1tjZhOaqBszsxlx6wXAAOCFBlVnm9kSYAnQB7iqveMWEZHWiXLU1knNbC+IWy4HJsatrwJ2T7DPmPaLUERE2oPm2hIRyUYrX4SKmbC1NvJTaYoUEZFs8OFyWHA1vPnY9uWDR0LvwkhPrUQiItIRfboWXrweyu9MvD1vDzjs15EnEVAiERHpGDZ/CmW3wfPTEm/vvjOMvQL2Px1yU/tdbSUSEZFMtHULvHY3zJ8KXzby/JaRF8GB58NOu6Q2tgaUSEREMoE7vPVEkDg2vJm4zv6nw8ifwy4DUhtbM5RIRETS5b2F8NzUYIRVIt88HEZfBn2LUhtXKymRiIikSvW7wT2OJQ8m3t5vWHCfo3A0mKU2tiQokYiIROXzj+Clm+DlWxJv33n3IHF8+wTI6ZLa2NqREomISHup+QIW/jG4z1GX4IuAOblB4hj+I+jWI/XxRUSJRESkreq2Bt1U86fCp+8nrnPg+XDwBdBzhyeLZw0lEhGRlnKHygVB4lj7WuI63z4BRl0KeUNSG1saKZGIiDTlgyXw3FXw9lOJtw8eCWN+CQMafTxS1lMiERGJ98kaeOFaePWuxNvz9w7uc+x1ZIcaWRUlJRIR6dw2fwJ//10wb1UiO/UKEkfxqZDbLbWxdRBKJCLSudTWwKuzgvscX32auM6oS6H0x/C1nVMbWwelRCIi2c0d3pgXJI7qFYnrxM4K5q3auV9qY8sSkSYSM7sTOBpY7+77Nth2IXA9kJ/oue1mtpXgkboAq919XFg+GLgP6A28Cpzm7jXR/RYi0uGsLgsSR9X/Jd6+99Ew+hew2z6pjStLRd0imQncAmx318rMBgDfA1Y3se+X7l6coPxa4CZ3v8/Mfg9MAG5vn3BFpEP6aAUsuAqWPZJ4++4l4dQjo1IZVacRaSJx9xfNrCDBppuAnwOPtuZ4ZmbAGODksGgWMAUlEumAKqo2UVZZTWlhHiWDeqU7nI7lsw3wtxvhlUb+639jQJA49j2uQ0890lGk/B6JmY0D3nf3163poXNfM7NyoBa4xt3/DOQBH7t7/dwDa4DdGznPJGASwMCBA9srfJF2UVG1iVNmlFFTW0e33BxmTyylZFAvJZfG1HwOr/wh6K7Cd9zepVs49chE6LpTysPr7BpNJGb2I+B5d38nbAncCRwHrALOdPdXW3syM+sBXAYc2oLqA919rZkVAs+Z2RIg0RCLBH9V4O7TgekAsVgsYR2RdCmrrKamto46hy21dZRVVgMkTC7ZLmHy3FoLi+8PEsdnHyTe8T/+Gw66AHrmpS5YSaipFslPCO5xAJwEFAGDgWHAb4FD2nC+IeEx6lsj/YFXzWyEu2/31+Lua8OflWb2fHjeh4BdzCw3bJX0B9a2IQ6RtCotzKNbbg5bauvomptDaWFewuSS7YnkXy2zrYzJXcLN+X+hx8ZliSsXnQijLknJM8ildZpKJLXuviVcPhq4y92rgb+a2XVtOZm7LwF2rV83s1VArOGoLTPrBXzh7l+ZWR/gIOA6d3czWwAcTzBy6wxaeZ9FJBOUDOrF7ImlO3wSb5hcstpr91Dy6Hm82QWov42xMW574SgYcwX0L0l5aNI6TSWSOjPrC2wCxgJXx21rUSekmc0BRgF9zGwNMNnd72ikbgw4x90nAt8C/mBmdUAOwT2S5WHVi4H7zOwq4DUg4fFEMl3JoF7btTgaSy5Z462nYM6JjW5+2weQ893J7HHw8Zp6pIMx98S3D8zsaOAPBJ8V/uLuPwrLvwP83N2PSlmUSYrFYl5eXp7uMEQ6lw1vwa3NTGTYb39eHXsvL6/+PDuTZwdnZhXuHmuuXqMtEnd/zMwGAV93901xm8qBxj9WiEjn9OUmuLag+Xo/WQy9Bm1b3R/Yv/PMuJ6Vmhq19f24ZQhGR30ELHL3f0YfmohktK21cGUL7uOc8RgMbsvYHOkomrpH8p8JynoDRWY2wd2fiygmEclUtx4AG95sus6RN8CIH6UmHskITXVt/TBRedjd9QBwQFRBiUiGePoyePmWpuvsMgh+ujg18UhGavU32929ysy6RhGMiKTZ8kfhgdObr3f5Bj2bQ7ZpdSIxs72BryKIRURSbcPbcOvw5uv97E3YuW/08UiH1NTN9r+w4/QjvYG+wKlRBiUiEfnqnzCtf/P1znwCCg6KPh7JCk21SG5osO4E3zvtTZBIXo4qKBFpJ+7wq12ar3fYNDjwx9HHI1mpqZvtL9Qvm1kxwdTtPwBWEsx5JSKZ6N4T4e2nmq7zzSPg5PtSE49kvaa6tr4JjCeYsLEauJ/gm/CjUxSbiLTEy7fC079ovt7kjzX1iESiqa6tN4G/Af/p7isAzOyClEQlIo1b9X8w88jm6126Brp/Pfp4pNNrKpEcR9AiWWBmTxHMtquPMyKp9uk6+N+9m6933kLI/2b08Yg00NQ9kkeAR8ysJ3AscAGwm5ndDjzi7s+kKEaRzqW2Bq7Kb77eD+6GoeOij0ekGc1+j8TdPwdmA7PNrDdwAnAJoEQi0l6mfKP5Ov/x33DoVdHHItJKrfpCortvJJha/g/RhCPSSbQkcew6FH6sUfaS+Vr9zXYRaYOHJwXPIG+Oph6RDiiyRGJmdxI8one9u+/bYNuFwPVAfoLH7BYDtwM7A1uBq939/nDbTOA7wCdh9TPdfVFUv4NImy2fBw+c1ny98/4B+XtFH49IhKJskcwEbgHuii80swHA94DVjez3BXC6u79jZv2ACjN72t0/Drdf5O5zI4pZpG3++SHc2IIRU0f9LwyfEH08IikUWSJx9xfNrCDBppuAnwOPNrLf23HLa81sPZAPfJyovkha1NXB1BY8FnZAKUx4Ovp4RNIopfdIzGwc8L67v24t+IatmY0AugHvxhVfbWZXAPOBS9xdMxFLarTkBjnAlE+aryOSRVKWSMysB3AZcGgL6/cF7gbOcPe6sPhS4AOC5DIduBiY2sj+k4BJAAMHDkwqdumk7joGKp9vvp6mHpFOLpUtkiHAYKC+NdIfeNXMRrj7B/EVzWxn4HHgcncvqy9393Xh4ldm9ifgwsZO5u7TCZINsVis4XT4WaeiahNlldWUFuZRMqgFXS6yo4Uz4PH/ab7exVWwUwtm1BXpJFKWSNx9CbBr/bqZrQJiCUZtdQMeAe5y9wcbbOvr7ussyETHAksjD7wDqKjaxCkzyqipraNbbg6zJ5YqmbTEB0vh9y145saEv8KAFjz8SaSTinL47xxgFNDHzNYAk939jkbqxoBz3H0iwVT1I4E8MzszrFI/zHe2meUTzPm1CDgnqvg7krLKampq66hz2FJbR1lltRJJIjWfw6/7NV/vu1PgYM1PKtJSUY7aOqmZ7QVxy+XAxHD5HuCeRvYZ044hZo3Swjy65eawpbaOrrk5lBbmpTukzNGSG+T/XgTn/C36WESylL7ZngVKBvVi9sRS3SMBjawSSQMlkixRMqhX50wgc06Gtx5vvt4vP4IuXaOPR6QTUiKRjmXxA/Dwj5qv99+vQt6Q6OMRESUSyUz1w5kP2a2GogcObH6HY2+H4pOjD0xEdqBEIpllay1cmUcJUNJUvT2+C6c+lKKgRKQpSiSSfi25QW5dYPLG6GMRkVZTIpHUe/5aeP7XzVYb8tVsuuZ20RcsRTKcEolE752/wuzjmq936Rro/nUguEfyMw1nFukQlEik/W1aBb/dr9lqs4fPZe99YwkTRacdzizSASmRSPK2fAlX/3vz9U59GPYY+6+5wV6qoVtZWYu7rjQxpUhmUiKR1nOHaf2h5rOm6425HEZetENxW+YG08SUIplLiURa5unL4OVbmq4z6GD4YfPfMm/L3GCamFIkcymRSGJLH4K5ZzVf74pNkJPTqkO3ZW4wTUwpkrnMPeuf+UQsFvPy8vJ0h5HZWvpsjotXwU7paQnoHolIaplZhbvHmqunFkln9cVGuG5w8/XOWwj532z307clKWgkl0hmUiLpLOrqgskOl85tut74e2HvoyINRTfORbKLEkk2e+k38NfJTdcZeVEwuiqFdONcJLtEmkjM7E7gaGC9u+/bYNuFwPVAfsPntofbzwDq3+GucvdZYXkJMBPYCXgC+Il3hhs9LfHWkzBnfNN10pA4GtKNc5HsEnWLZCZwC3BXfKGZDQC+B6xOtJOZ9QYmAzHAgQozm+fum4DbgUlAGUEiORx4MqL4M9tn6+FvN8Irv2+8zjePgBPvgS6Z0/jUEx1Fskuk7y7u/qKZFSTYdBPwc+DRRnY9DHjW3TcCmNmzwOFm9jyws7u/HJbfBRxLZ0kkNZ8HSWP+1Mbr7Nwfzn0pbSOrWko3zkWyR8o/pprZOOB9d3/dzBqrtjvwXtz6mrBs93C5YXl22loLi+8LEsdnHyauc9BP4KCfQo/eqY1NRCSU0kRiZj2Ay4BDm6uaoMybKE90rkkEXWAMHDiwFVGmkTus+CvM/xV8sCRxnf1Ogu9cDL1bMHS3nel7HCKSSKpbJEOAwUB9a6Q/8KqZjXD3D+LqrQFGxa33B54Py/s3KF+b6ETuPh2YDsEXEtsn/AisXQTPXRkkkESGjAluju/e5PMCI6chuyLSmJQmEndfAuxav25mq4BYglFbTwO/NrP6d6pDgUvdfaOZ/dPMSoFXgNOB30UfeTv6eDU8fw0smp14+277wtgrYM9DofGuv5TTkF0RaUzUw3/nELQs+pjZGmCyu9/RSN0YcI67TwwTxpXAwnDz1Pob78C5/Gv475Nk+o32LzfB338XjK5KpGd+kDj2OzmjRlY1pCG7zVPXn3RWmmurvdV+BRUzgxvkjU2zPuZyOOBc6P5vqYmpneiNsnHq+pNspLm2UqWuDt54NEgcGysT1xkxCQ75H/h6Cx7+lME0ZLdx6vqTzkyJpC2q/h4kjtUvJ94+9BgY9QvYde/UxiVpo64/6cyUSFpiw1uw4GpY3sj3JwceCGN+CQUtmIZdspK+rS+dmRJJU6pehj8dvmN578LgBvm3jmn1Q50ke6nrTzorJZKmbPki+Nm1B4ydDLEfQm739MYkIpJhlEiassdYmPJJuqMQEclo6pcREZGkKJGIiEhSlEhERCQpSiQiIpIUJRIREUmKEomIiCRFiURERJKiRCIiIklRIhERkaQokYiISFIiSyRmdqeZrTezpXFlV5rZYjNbZGbPmFm/BPuNDrfXvzab2bHhtplmtjJuW3FU8YuISMtE2SKZCTScOvd6dy9y92LgMeCKhju5+wJ3Lw7rjAG+AJ6Jq3JR/XZ3XxRR7CIi0kKRJRJ3fxHY2KDs07jVnkBzz/k9HnjS3b9o5/BERKSdpPweiZldbWbvAaeQoEXSwHhgToOyq8PusZvMTHO6i4ikWcoTibtf5u4DgNnA+Y3VM7O+wLeBp+OKLwX2BoYDvYGLm9h/kpmVm1n5hg0b2iV2ERHZUTpHbd0LHNfE9h8Aj7j7lvoCd1/nga+APwEjGtvZ3ae7e8zdY/n5+e0WtIiIbC+licTM9oxbHQe82UT1k2jQrRW2UjAzA44FlibYT0REUiiyJySa2RxgFNDHzNYAk4EjzWwvoA6oAs4J68aAc9x9YrheAAwAXmhw2Nlmlg8YsKh+fxERSR9zb27gVMcXi8W8vLw83WGIiHQoZlbh7rHm6umb7SIikhQlEhERSYoSiYiIJEWJREREkqJEIiIiSVEiERGRpCiRiIhIUpRIREQkKUokIiKSFCUSERFJihKJiIgkRYlERCRLVVRt4tYFK6io2hTpeSKb/VdERNKnomoTp8woo6a2jm65OcyeWErJoF6RnEstEhGRLFRWWU1NbR11Dltq6yirrI7sXEokIiJZqLQwj265OXQx6JqbQ2lhXmTnUteWiEgWKhnUi9kTSymrrKa0MC+ybi1QIhERyVolg3pFmkDqRdq1ZWZ3mtl6M1saV3almS02s0Vm9oyZ9Wtk361hnUVmNi+ufLCZvWJm75jZ/WbWLcrfQbJDqkaviHRGUd8jmQkc3qDsencvcvdi4DHgikb2/dLdi8PXuLjya4Gb3H1PYBMwob2DluxSP3rlxmfe4pQZZUomIu0s0kTi7i8CGxuUfRq32hNo8UPjzcyAMcDcsGgWcGySYUqWa+noFbVaRNomLfdIzOxq4HTgE2B0I9W+ZmblQC1wjbv/GcgDPnb32rDOGmD3qOOVjq1+9MqW2rpGR6+kcsy9SLZJy/Bfd7/M3QcAs4HzG6k20N1jwMnAb8xsCGCJDpdoZzObZGblZla+YcOGdok7G3TGT931o1d+duhejSaIVI65F8k26R61dS/wODC54QZ3Xxv+rDSz54FhwEPALmaWG7ZK+gNrEx3Y3acD0wFisViLu8+yWWf+1N3c6JWWtFrwEfEfAAAHQElEQVREJLGUt0jMbM+41XHAmwnq9DKz7uFyH+AgYLm7O7AAOD6segbwaFSxZtund33qblxLWi0iklikLRIzmwOMAvqY2RqClseRZrYXUAdUAeeEdWPAOe4+EfgW8AczqyNIdte4+/LwsBcD95nZVcBrwB1RxJ6Nn971qbtpqRpzL5JtIk0k7n5SguKEb/zuXg5MDJf/Dny7kXqVwIj2irExiT69d/Q3mVR+01VEOo903yPJWNn66V2fukWkvSmRNEKf3kVEWkaJpAn69C4i0jxNIy8iIklRIhERkaQokYiISFKUSEREJClKJCIikhQlEhERSYoF01dlNzPbQDAdS0fQB/go3UG0guKNTkeKFRRv1NIR7yB3z2+uUqdIJB2JmZWH0+d3CIo3Oh0pVlC8UcvkeNW1JSIiSVEiERGRpCiRZJ7p6Q6glRRvdDpSrKB4o5ax8eoeiYiIJEUtEhERSYoSSTszs8PN7C0zW2FmlyTYPtLMXjWzWjM7PsH2nc3sfTO7Ja7sJDNbYmaLzeyp8PHDmFlvM3vWzN4Jf7Z6quIUxzslrLsofB2ZIfGeGMa6zMyuiyvvbmb3h+d6xcwKMjzeM81sQ9z1nZjKeM1sa9y558WVDw6v3zvh9ewWlid1fVMca6Ze2/PD43n9/7Ow3Mzs5nDbYjPbv7Xxtoq769VOL6AL8C5QCHQDXgeGNqhTABQBdwHHJzjGb4F7gVvC9VxgPdAnXL8OmBK3fEm4fAlwbYbHOwW4MMOubx6wGsgP12cBY8PlHwO/D5fHA/dneLxn1tdLx/UFPmvkuA8A48Pl3wPnJnt90xBrpl7bYeF+qwj/z4XlRwJPAgaUAq+0NfaWvNQiaV8jgBXuXunuNcB9wDHxFdx9lbsvJnhm/XbMrATYDXgmvjh89TQzA3YG1obbjiF4IyH8eWyGx5usKOItBN529w3h+l+B48Ll+Os7Fxgb/k6ZGm+ykoo3kfB6jSG4frD932ky1zfVsSar3eMN93nN3Vcl2HQMcJcHyoBdzKxv28NvmhJJ+9odeC9ufU1Y1iwzywFuBC6KL3f3LcC5wBKCN+Sh/Ou597u5+7qw3jpg1wyPF+D8sKl9p7W+K67d4wVWAHubWYGZ5RK8cQxoeD53rwU+IWgRZGq8AMeF13eumQ2gddocb+hrZlZuZmVmVv8GnAd8HF6/hsdM5vqmOlbIvGsb5flaRYmkfSX6NNXSYXE/Bp5w9/h/fMysK8Eb8zCgH7AYuDSZIOMPn6AsynhvB4YAxcA6gjfKtMbr7pvCeO8H/kbQRVD/RpLM+ZLdvy3x/gUocPcigpbKLFon2d93oAffvD4Z+I2ZDWnmmMmcL9WxZuK1jfJ8raJH7bavNWz/6bA/Le/WORA4xMx+DPwb0M3MPgMeAnD3dwHM7AGC+yEAH5pZX3dfFzZb12dyvO7+Yf3OZvZH4LF0x+vul7j7XwjeKDCzScDWBudbE376/wawMVPjdffquP3/CFzbiliTjRd3Xxv+rDSz5wk+TDxE0K2SG37Sjz9mMtc3pbFm6LV9N6rztZZaJO1rIbBnOPKjG8ENxHnN7AOAu5/i7gPdvQC4kKB/8xLgfWComdVPnPY94I1weR5wRrh8BvBoJsfboI/2v4ClGRAvZrZr+LMXQUtgRrhb/PU9HnjOwzuZmRhvg+s7jn/9nUQer5n1MrPu4XIf4CBgeXi9FhBcP9j+7zSZ65vSWDPx2jaz2zzg9HD0VinwSX03eCSivJPfGV8EoyXeJvi0cFlYNhUYFy4PJ/i08DlQDSxLcIwziRshApxD8Ie7mOCTaF5YngfMB94Jf/bO8HjvJrh3spjgD71vhsQ7h+A/5nLCETth+deABwnuS/wDKMzweKcBywhGBC0A9k5VvMB/hP+2r4c/J8QdszC8fivC69m9Pa5vimPN1Gv7/8J9aglaHDPCcgNuDc+1BIi1Nt7WvPTNdhERSYq6tkREJClKJCIikhQlEhERSYoSiYiIJEWJREREkqJEIhKRcEbWu+PWcy2YQfaxcH03M3vMzF43s+Vm9kRYXmBmX9q/ZntdZGanp+v3EGmOvtkuEp3PgX3NbCd3/5Lgy5nvx22fCjzr7r8FMLOiuG3vuntx6kIVaTu1SESi9SRwVLh8EsGXCev1JfgyGQAezPwq0uEokYhE6z5gvJl9jeBZE6/EbbsVuMPMFpjZZWbWL27bkAZdW4ekMmiR1lDXlkiE3H2xBU/+Owl4osG2p82sEDgcOAJ4zcz2DTera0s6DLVIRKI3D7iB7bu1AHD3je5+r7ufRjCx38hUByeSLCUSkejdCUx19yXxhWY2xsx6hMtfJ3hWy+o0xCeSFHVtiUTM3dcQPHu9oRLgFjOrJfhQN8PdF4ZdYUPMbFFc3Tvd/ebIgxVpA83+KyIiSVHXloiIJEWJREREkqJEIiIiSVEiERGRpCiRiIhIUpRIREQkKUokIiKSFCUSERFJyv8H0t09bi4Rdn0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.6017031908445655"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.polynomial.polynomial import polyfit  \n",
    "from scipy.stats import pearsonr\n",
    "from pylab import text\n",
    "\n",
    "\n",
    "print(pearsonr(VIO,AUS)[0])\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(VIO,AUS, 1)\n",
    "ax.plot(VIO,AUS, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(VIO,AUS)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(VIO, b + m * np.array(VIO), '-')\n",
    "ax.set_xlabel(\"Proposed metric\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "fig.savefig('Ex4VIOVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "METRIC = -(VIO/np.max(VIO)) + np.array(MSE)\n",
    "print(pearsonr(METRIC,AUS)[0])\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(METRIC,AUS, 1)\n",
    "ax.plot(METRIC,AUS, '.')\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(METRIC,AUS)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "plt.plot(METRIC, b + m * np.array(METRIC), '-')\n",
    "    #cax = ax.scatter(VIO,AUS)\n",
    "ax.set_xlabel(\"Proposed metric\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "fig.savefig('Ex4ProposedVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b,m = polyfit(MSE,AUS, 1)\n",
    "text(0.05, 0.9,'Pearson coeff:' + str(pearsonr(MSE,AUS)[0])[0:4], ha='left', va='center', transform=ax.transAxes)\n",
    "ax.plot(MSE,AUS, '.')\n",
    "plt.plot(MSE, b + m * np.array(MSE), '-')\n",
    "    #cax = ax.scatter(VIO,AUS)\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "fig.savefig('Ex4MSEVsAUS.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "MSE = np.array(MSE)\n",
    "\n",
    "x = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "for split in range(10, len(AUS), 5):\n",
    "    #print(\"******\", split, \"*******\")\n",
    "    sorted_aus = [AUS for _,AUS in sorted(zip(VIO,AUS))]\n",
    "    sorted_mse = [MSE for _,MSE in sorted(zip(VIO,MSE))]\n",
    "\n",
    "    low = []\n",
    "    high = []\n",
    "    low = sorted_aus[:split]\n",
    "    high = sorted_aus[split:]\n",
    "\n",
    "    x.append(split)\n",
    "    \n",
    "    \n",
    "    #print(\"Low Violations = \", np.mean(low), \"for\", len(low))\n",
    "    #print(\"High Violations = \", np.mean(high), \"for\", len(high))\n",
    "    y1.append(np.mean(low)) \n",
    "    sorted_aus_by_mse = [AUS for _,AUS in sorted(zip(MSE,AUS))]\n",
    "    low = sorted_aus_by_mse[:split]\n",
    "    high = sorted_aus_by_mse[split:]\n",
    "    #print(\"Low AUS by MSE = \", np.mean(low), \"for\", len(low))\n",
    "    #print(\"High AUS by MSE = \", np.mean(high), \"for\", len(high))\n",
    "    y2.append(np.mean(low))\n",
    "    sorted_aus = [AUS for _,AUS in sorted(zip(METRIC,AUS))]\n",
    "    sorted_mse = [MSE for _,MSE in sorted(zip(METRIC,MSE))]\n",
    "\n",
    "    low = []\n",
    "    high = []\n",
    "    low = sorted_aus[:split]\n",
    "    high = sorted_aus[split:]\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Low Metric = \", np.mean(low), \"for\", len(low))\n",
    "    #print(\"High Metric = \", np.mean(high), \"for\", len(high))\n",
    "    y3.append(np.mean(low))\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x,y1, '-', label = 'BIC')\n",
    "ax.plot(x,y2, '-', label = 'MSE')\n",
    "ax.plot(x,y3, '-', label = 'METRIC')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(\"MSE\")\n",
    "ax.set_ylabel(\"AUS\")\n",
    "plt.show()  \n",
    "pearsonr(METRIC,AUS)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
